{"./":{"url":"./","title":"Introduction","keywords":"","body":"Introduction 课程介绍和·小·目标 linxu~PY，-go~>> 目录生成的方法： 打开pycharm里的windows/summary/list/directory_generate.py，运行 将运行结果去头掐尾后，复制到nodepad过滤一遍格式，然后再复制到SUMMARY.md中即可。 然后再gitbook init初始化目录结构。 github 创建项目的提示备忘： …or create a new repository on the command line echo \"# oneyearice.github.io\" >> README.md git init git add README.md git commit -m \"first commit\" git branch -M main git remote add origin https://github.com/oneyearice/oneyearice.github.io.git git push -u origin main …or push an existing repository from the command line git remote add origin https://github.com/oneyearice/oneyearice.github.io.git git branch -M main git push -u origin main …or import code from another repository You can initialize this repository with code from a Subversion, Mercurial, or TFS project. 多终端pull和push注意点： 1、首先pull下来，得到最新的版本，如果是第一次git clone即可 2、复制oneyearice.github.io并重命名为gitbook；如果是git clone的就复制文件夹里的内容到gitbook下，选择替换原文件，得到最新的版本。 注意gitbook是本地编辑目录，oneyearice.gitbhu.io是pull和push目录 3、进入gitbook下运行gitbook install安装插件 3、在gitbook里编辑md文件，也就是主要工作内容 4、运行脚本自动上传 1、进入D盘 git clone https://github.com/oneyearice/oneyearice.github.io.git 如果有Oneyearice.github.io文件夹，进去后git pull 2、将oneyearice.github.io文件夹复制，并改名为gitbook 3、进入gitbook，删除node_module文件夹，cmd在gitbook文件夹下运行gitbook install ---开始编写md文章---完了就👇--- 4、我的笔记本电脑需要注释掉book.json里的\"-anchor-navigation-ex\"👈这样注释，运行脚本自动push--如果push失败，看报错，一般就是需要先git pull一下然后再运行脚本，因为可能最近的一次push是别的终端push的。这是合理的机制。 后面再看吧，是否可以进一步弄成两个脚本，pull和push，pull就上面的1 2 3，push就是4 云服推荐：原生、靠谱干净的IP👉https://www.dmit.io/aff.php?aff=5321 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-26 09:18:39 "},"序.html":{"url":"序.html","title":"序","keywords":"","body":"一声叹息解千愁 风中再无少年游 华发霜鬓难回首 万般滋味在心头 仰天长笑忆往昔 终究哪般得自由 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-01-18 10:34:18 "},"1-基础知识介绍/1-基础知识介绍.html":{"url":"1-基础知识介绍/1-基础知识介绍.html","title":"第一章 基础知识介绍","keywords":"","body":"第一章 基础知识介绍 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:34:58 "},"1-基础知识介绍/1-计算机基础.html":{"url":"1-基础知识介绍/1-计算机基础.html","title":"第1节 计算机基础","keywords":"","body":"第1节. 计算机基础 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:34:58 "},"1-基础知识介绍/2-操作系统基础.html":{"url":"1-基础知识介绍/2-操作系统基础.html","title":"第2节 操作系统基础","keywords":"","body":"第2节. 操作系统基础 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:34:58 "},"1-基础知识介绍/3-linux介绍.html":{"url":"1-基础知识介绍/3-linux介绍.html","title":"第3节 linux介绍","keywords":"","body":"第3节. linux介绍 https://www.kernel.org/ slackware:SUSE debian:ubuntu redhat:REHEL、CentOS [11:02:17 root@pyConsole ~]#uname -r 4.18.0-193.el8.x86_64 linux只是一个内核，加上GNU工具、附加软件和软件包管理组成的操作系统才是发行版。 CentOS https://wiki.centos.org/Download http://mirrors.aliyun.com http://mirrors.sohu.com http://mirrors.163.com https://mirrors.tuna.tsinghua.edu.cn/centos/ Ubuntu http://cdimage.ubuntu.com/releases/18.04.1/release/?_ga=2.56783850.1533668672.1544323446-1412352718.1543052421 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:34:58 "},"2-linux基础和帮助/2-linux基础和帮助.html":{"url":"2-linux基础和帮助/2-linux基础和帮助.html","title":"第二章 linux基础和帮助","keywords":"","body":"第二章 linux基础和帮助 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"2-linux基础和帮助/1-linux安装前准备.html":{"url":"2-linux基础和帮助/1-linux安装前准备.html","title":"第1节 linux安装前准备","keywords":"","body":"第1节. linux安装前准备 1、 在windows是怎么安装的，类比一下， 分区、C盘、D盘，系统、数据文件。 2、 在linux同样类似思路，逻辑卷、raid， 大多数企业选择的是分区方式，而不是逻辑卷和raid。 3、 linux一切皆文件，不同类型的资源都命名为文件了 linux的目录结构 windows的C盘，D盘，里面格式有很多文件夹 C盘的顶级目录 在windows里有几个分区，就有几个顶级目录，或者叫根目录 在linux只有一个根root，而且用的是正斜线，linux不管你是几个分区，它的目录结构都是不变的。 /usr 类似于windows里的C盘下的windows目录，都是存放操作系统文件的。 /root或者/home/xx 类似windows里的C盘下的users目录，都是存放用户自己的文件的。 此外在linux还有/boot目录，存放启动文件，比如linux内核就是放在该目录下的。 日志信息在/var/log，/var本身就是变化的意思。 /tmp存放临时数据的。 /proc是个假目录，是映射成内存数据，就是看到的是内存里的数据。正常的数据是放在磁盘上的，真正的目录都是对应磁盘上的文件夹，里面的数据都是放在磁盘上。这就是一切皆文件。 /etc就是windows里的注册表，注册表并不是单一的某一个文件，是二进制的若干个文件，不是存在在磁盘的某一处的。/etc就是各种配置文件也是文本文件。 linux分区和目录结构无关 linux有个目录叫/dev，存放设备的，包括，硬盘、光盘、u盘等。都是在dev下。比如机器上多块硬盘，linxu自动会出现多个文件。命名方式为，命名硬盘的方式sda,sdb,sdc这是centos6和7的命名方式， 在硬盘上还可划分分区，涉及分区类型，在windows上的分区是用盘符来命名的。分区还有扩展分区和逻辑分区。 分区类型： 1、 分区跟你的硬盘分区策略有关，GPT只支持主分区，暂不做讨论 2、 MBR是传统的分区法，支持主分区、扩展分区、逻辑分区（逻辑驱动器） 主分区，在单块一个硬盘上只能最多四个。如果有两块硬盘，其中一块可以没有主分区。在windows里主分区通常可以安装操作系统。不仅仅存放数据，如果有多个主分区，就有且仅有一个激活的主分区，OS启动的时候会去寻找激活的主分区，一个硬盘上最多有一个。 扩展分区：仅仅是主分区的话最多是4个，所以还需要扩展分区。在一个硬盘上最多一个扩展分区。不能直接存放数据，必须先将其划分成更小的分区-逻辑分区， 逻辑分区，扩展分区里更小的单位，这个小分区才能存数据，逻辑分区的个数可以很多。 3、 一块硬盘，主分区、主分区、大的扩展分区（里面分成若干个小的逻辑分区） 4、 linux一切皆文件，硬盘是有文件的，分区同样也是。分区是有编号的，主分区是1-4，扩展分区也是1-4，主分区+扩展分区一共最多4个，因此都是用1-4来表示的。 主分区的文件名：/dev/sda1 /dev/sda2，这个就是a硬盘上的第一个分区，第2个分区。这是主分区，扩展呢，一样也是1-4，比如/dev/sda3就可能是扩展分区。 5、 逻辑分区的编号，是从5开始编号的，/dev/sda5 /dev/sda6 dev/sda7，这三个就是在/dev/sda3上面的分区的。这个逻辑的序号是自动分配的，不能像主分区和逻辑分区那样可以人为的命名。 6、 扩展分区删除，意味着里面的逻辑分区也没了。 7、 存在不同分区的同名文件。讨论分区和目录的关系。windows是C盘下的test文件，D盘下的test文件。linux呢？是从根下面开始描述的。此时就需要把分区和某一个文件夹做关联，将来这个test就是这个关联好的目录下的文件了。 8、 将第一个硬盘分区和boot关联，boot就是对应/dev/sda1，所以要访问第一个硬盘的第一个分区就访问/boot就行了。此时第一个分区里的test就在/boot/test。第二个分区要想访问，就得先把他映射成一个目录比如叫/data，把第二个主分区/dev/sda2挂载到/data下，第二个test就在/data/test 9、 这种挂载在windows里是存在的，windows的分区也可以挂载到文件夹的。windows的e盘的盘符可以删了，此时这块空间和目录结构就没有关联没有映射了，磁盘管理就看不到e盘了，但数据还在，再加回去，可以叫其他F盘之类，还可以挂载到NFS文件夹中的这就跟linux的挂载文件一样了。 10、 没有独立出来挂载分区的文件夹，都是跟在根下的，都在根所在的分区里，有些是不能独立挂载的，必须和根在一起，比如/etc /dev ， /proc是虚拟文件夹内存来着更加不能独立了。 11、 理论上一个分区也是阔以的，但是肯定不安全，一个分区挂了，就完了。 12、 一般分区这样 /dev/sda 200g硬盘的推荐分区： /dev/sda1 mount /boot 1G 这是引导目录不需要太多空间200M的实际占用，也不是给你存放数据的，你的数据也别扔这里面，1G空间足足有余了。这个目标文件夹就叫mount point挂载点。 /dev/sda2 mount / 100G 根上，根下存放的数据就比较多了，如果linux安装不是最小化安装，光是系统本身就要几个G的数据，如果是最小安装，至少1g。 /dev/sda3 mount /data 50G 测试练习用的文件夹，学习用的，工作中，用户会用来存放数据库单独占一个分区。 /dev/sda4 swap 4G，这里不能叫mount挂载，因为swap不是个文件夹，它是分区，不能叫挂载，挂载都是设备往文件里挂。 如果这样划分的话，我们知道一个硬盘上最多4个主分区，意味着200G剩下50G的空间用free，将来不能再分区了，因为4个分区满了，逻辑分区是在扩展分区里分的，扩展分区是占主分区的1-4这个编号的，现在没地儿了。所以上面的分区得改。 /dev/sda4 extend 剩下的所有空间（除了上面分的所有空间剩下的45G） /dev/sda5 逻辑分区 swap 4G sda5就是在sda4上面分的了 还可以继续分小的逻辑分区。比如/dev/sda6等。 13、 swap 交换 早期机器内存小2G 4G swap就是4g 8g的分配， 现在服务器你的内存都很大256g 512g，swap肯定不能乘以2了，swap一般就是8g 16g就足够了。 14、 linux的swap和windows里的pagefile.sys文件是一回事 15、 GPT不支持扩展分区和逻辑分区 4、 在使用vmware worksation安装镜像的时候，光盘需要最后挂载，不然系统自动安装不会让自己分区的，而且还是最小化安装。 5、 os下载，可以到阿里云上下载， 6、 vmware的lck缓存文件注意一下，突然断电关机了，lck可能需要手动删除才能保证VM正常开机。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"2-linux基础和帮助/2-centos7和rocky_linux安装详解.html":{"url":"2-linux基础和帮助/2-centos7和rocky_linux安装详解.html","title":"第2节 centos7和rocky_linux安装详解","keywords":"","body":"第2节 centos7和rocky_linux安装详解 1、安装前最好校验一下，防止iso损坏。 2、密码不符合安全要求，需要点击两次done。 3、文件格式化，linux centos6默认是ext4，也支持windows里的vfat，也支持centos7里的xfs。就用默认的就行 4、分区的sda1或sda2对应/还是/boot，这个序号对应关系不大，只要空间够就行。 5、ctrl + alt f2切到命令行界面，f6切回图形界面，cat /proc/meminfo 便于你在装机阶段查看内存大小。shift pageUp往上翻，memTotoal可见总内存大小。当然你要说 | less | more ，我也没办法。 6、在分区的时候，扩展分区是自动给你分的，你只要知道你在划分sda5的时候，会自动给你划分sda4—扩展分区就行了。 7、cat /proc/partition 可见当前只有一个sda 8、ls /dev/sda* 可见只有一个以sda开头的文件 9、等你的分区，确定格式化，werite chages to disk或done的时候，再去看ls /dev/sda*去看就看到分区开始实施了， cat /proc/partitions 也有了。 10、boot loader环节后面再说，这跳过 11、工作中一般都是minimal最小化安装，节约资源。学习选择Desktop或Server with GUI。 12、desktop，图形默认是GNOME，还有一种是KDE，一般不用KDE的（选择customize now—Desktops—KDE Desktop）。 13、centos7的安装注意： 1、内存2G，1G会导致系统安装报错-内存不够。 2、分区一样的，选择I will configure partitioning -Done-进入分区界面 单位可以输入比如1G 3、KDUMP别管，内核分析记录用的，系统崩溃查看用的，不是一般人玩的。默认是enabled，建议关掉，反正用不到。 4、关于ens33将来要改成eth1的 5、安装后，做好快照 14、ubuntu-18.04.1的安装 略，开发的，我看到的 智能小车，图像识别什么的用的就是ubuntu系统。 15、在安装过程中，可以 ctrl + alt f1 f2去切命令行界面 如果需要的话 16、centos允许你用root登陆，ubuntu不允许使用root，可以改passwd使能root的。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"2-linux基础和帮助/3-linux入门操作和基础命令.html":{"url":"2-linux基础和帮助/3-linux入门操作和基础命令.html","title":"第3节 linux入门操作和基础命令","keywords":"","body":"第3节. linux入门操作和基础命令 入门操作 1、看版本 cat [root@localhost ~]# cat /etc/os-release NAME=\"Rocky Linux\" VERSION=\"8.5 (Green Obsidian)\" ID=\"rocky\" ID_LIKE=\"rhel centos fedora\" VERSION_ID=\"8.5\" PLATFORM_ID=\"platform:el8\" PRETTY_NAME=\"Rocky Linux 8.5 (Green Obsidian)\" ANSI_COLOR=\"0;32\" CPE_NAME=\"cpe:/o:rocky:rocky:8.5:GA\" HOME_URL=\"https://rockylinux.org/\" BUG_REPORT_URL=\"https://bugs.rockylinux.org/\" ROCKY_SUPPORT_PRODUCT=\"Rocky Linux\" ROCKY_SUPPORT_PRODUCT_VERSION=\"8\" [root@localhost ~]# cat /etc/centos-release Rocky Linux release 8.5 (Green Obsidian) [root@localhost ~]# cat /etc/redhat-release Rocky Linux release 8.5 (Green Obsidian) [root@localhost ~]# cat /etc/rocky-release Rocky Linux release 8.5 (Green Obsidian) [18:27:16 root@pyConsole ~]#lsb_release -a bash: lsb_release: command not found... Install package 'redhat-lsb-core' to provide command 'lsb_release'? [N/y] y * Waiting in queue... * Loading list of packages.... Failed to install packages: Could not depsolve transaction; 1 problem detected: Problem: conflicting requests - nothing provides ncurses-compat-libs(x86-64) needed by redhat-lsb-core-4.1-47.el8.x86_64 [18:27:22 root@pyConsole ~]#cat /etc/centos-release CentOS Linux release 8.2.2004 (Core) 2、看内核 uname -r 3、关闭GUI，free可见 700M+的内存使用量，关闭前后的内存使用对比，init 3 关闭GUI，进入纯字符界面。再来看free 还剩200M+，一下500M的量省了。linux的图形界面相当于linux的一个软件可以开关。 5、runlevel 可见 5 3，说明之前是5模式切换到3的。 6、init 5如果你有图形的话，可以切回去。 7、who 不仅看当前登入的人 who -r可见这用户用的哪个运行模式，如果上一次是其他模式，也有last关键字看到 基础cli-1 1、root也不一定就是管理员，这是由UID的设置来影响的，UID=0就是超级用户 也就是管理员。 2、id 就能看到，id -u 显示当前用户的uid，id -u xx 显示xx用户的uid（从1000开始的） 3、centos6 新建用户默认从500开始，centos7和ubuntu默认冲1000开始 4、1000或500以内是特殊保留的数字 5、xx账号的uid改成0，xx就是超级用户了。 6、ll /dev/console 救援模式用的就是console终端，一般用不到 7、cat /etc/shells 可见目前支持的shell类型，在ubuntu上支持的并不相同。 8、/sbin/nologin 是一个特殊shell，禁止登入，当用户使用这种类型的shell的时候，就是不能登入的，软件运行的时候是后台运行的，但是不需要用户登入就能运行的。nologin其实就是无需登入就能运行的意思。 9、主机名：bj-yz-k8s-node1-100-10.XXX.com，北京亦庄k8snode1节点X.X.100.10.域名 10、echo $PS1 可见默认值，\\u就是用户名 \\h主机名 \\w当前目录 ，可以加上颜色 11、字体颜色 31-37 7种颜色，背景颜色 41-47 也是7种颜色 ， 1和5 就是亮色和闪烁。 PS1=\"[\\u@\\h \\W]$\" 这是默认值 PS1=\"[\\e[1;5;41;33m][\\u@\\h \\W]\\$[\\e[0m]\" PS1=\"[\\e[1;32m][[\\e[0m]\\t [\\e[1;33m]\\u[\\e[36m]@\\h[\\e[1;31m] \\W[\\e[1;32m]][\\e[0m]\\$\" 12、配置文件のPS1，ls /etc/profile.d/xx.sh 名字无所谓后缀要求是sh。 13、ubuntu切root, sudo -i 输入当前用户的口令就行了。 14、centos的PS1配置文件可以放在/etc/profile.d/xx.sh 或者和ubuntu一样放到/etc/profile文件下，unbutnu实在~/.profile，在每个账号的家目录下。 15、/etc/profile是统一的配置文件，这个文件影响范围大，配置要小心。 16、sleep 10，然后看pstree -p可以看到bash下面有一个sleep 17、还有很多程序不依赖于bash，不需要和人进行交互，后台直接运行了。 18、shell自身提供的内部命令、非shell自身提供的，磁盘上其他程序 19、bash里面集成了很多工具，就是内部命令，bash运行了，这些内部命令是加载到了内存中的。 20、cat /etc/profile.d/env.sh，这个cat就是bin下的cat cat就不是bash下内部命令了。是独立的二进制程序，这就是外部命令。 21、外部命令需要找到磁盘的存放路径，内部命令不需要会开机加载到内存中的 22、type用来查看命令是内部还是外部。 23、内部命令是集成在shell中的，而shell用户一登入就加载到内存里了；而外部命令表现为磁盘上的某个文件，所以内部命令速度更快。 24、如果有一个命令即使内部命令又是外部命令，那么内部命令优先生效，比如echo 当执行echo命令的时候，系统自动选择第一个内部命令。 25、为啥有一个内部命令了，还需要一个外部命令存在呢？因为内部命令是存在某个特定shell里的，echo在bash里，但是不一定在csh等其他shell里，所以需要外部命令来保证命令的普遍适用性。 26、切换shell 27、help可以列出所有内部命令的帮助。不多 28、外部命令就多了，表现为磁盘文件，ls /bin/ 或ls/sbin/ 29、enable会列出所有内部命令的列表 enable -n echo禁用echo后，echo就只有外部命令了，就表现为磁盘文件了，所以如上图。 禁用后，就看不到echo了 help里还可以看到一个*号 enable echo就再次启用了 30、enable -n enable enable enable不可能了，因为enable已经禁用了，退出重进就行了，或新开一个终端。 31、which专用用来查看文件的路径，自然可以查看外部命令了（外部命令就是磁盘的一个二进制bin文件） 32、bc了解一下 obase=2输出为二进制或10进制 ibase=2输入为二进制，默认都是obase=10，ibase=10. 32、whereis不仅仅显示文件（外部命令）的存放路径，还显示了相关文档帮助也显示出来了， 这是man帮助 33、外部命令，系统是怎么找到的，PATH变量了解一下 PATH变量就是存放了一个个文件夹， 1、当你输入一个命令，系统首先判断是否有别名，是执行，不是继续。 2、如果是内部命令，执行，如果不是，继续 3、如果是外部命令，就搜索PATH变量里的路径。前面的目录找到了，后面就不会找了。 4、其实也不是每次执行外部命令，都搜一遍PATH变量的路径的。为了加快访问速度，比如有一个文件我经常访问，linux就会将其缓存在内存中，因为内存中已经有了，就直接在内存中访问就行了。这也是linux的一个经常的思路。这就是所谓的缓存技术。 5、第一次执行hostname的时候，会按PATH变量里的路径来搜，一旦找到后，就会把hostname的路径缓存在内存里HASHE。下次执行hostname的时候，先从内存的HASH表里去搜索，如果查到内存中有这个路径，就不按照PATH变量搜索了，直接按HASH的记录的上次缓存的路径直接去到那个路径找到hostname文件去执行。 6、这里面还有一个细节，就是除了HASH，其实还有一个HASH对应的明文（路径的明文），这个一般不会给你讲这么细，网工会有这个思路可能。 7、这样的一个漏洞或缺点就是，如果外部命令hostname被移动了，那么HASH缓存的路径就不对了，这样命令执行就会报错。如下图 图示为hash记录的上一次hostname的路径。 再移回去就可以了， 疑点：我明明移动的是/bin/hostname而不是/user/bin/hostname，为啥一个效果！ 因为bin就是/usr/bin的快捷方式-软连接，所以一回事了。 再来一遍完整的： 8、上面的也可以不将外部命令移回去，可以清一下缓存就行了。 hash -d hostname 就行了 hash -r 全删 删掉了后，由于缓存没了，所以就会重新搜索，然后再次hash缓存到内存中了。 9、上面就意味着，自己做的程序，就要放到PATH变量里的路径或加一个新路径。 基础cli-2 1、内部命令和外部命令的本质区别，首先都会放入内存中的，本质区别是，内部命令在shell（bin/bash）二进制文件中；外部命令不在二进制文件里，是独立的文件。还一个内存方面一个是登入加载，一个是首次运行加载。 内外之分在于是否在/bin/bash文件里，在就是内部，不在就是外部。 2、问题：内部命令放在/bin/bash下，那么外部命令放在哪？首先放哪都行，关键是外部命令要运行，就得保证PATH变量里有该路径，然后规范行为是，外部命令放到PATH变量下的路径里去。所以外部命令一般来讲就在PATH下。 3、除了内部命令和外部命令，还有别名。 alias cdnet=\"cd /etc/sysconfig/network-scripts/\" 退出后失效，要想存住，就要将其放到文件里，别名的文件在家目录里的.bashrc里 重新登入后依然有效 4、alias列出所有别名，unalias cdnet可以临时删掉，但由于之前写在了配置文件里，所以重新登入后，还是没删掉 还在。所以配置文件的需要进配置文件删除 5、如果有一个字符串，既是 别名、又是内部命令、还是外部命令，那么执行的顺序是什么，这就是命令的执行优先级问题。 以echo（这个即使内部又是外部命令）为例，将其定义成别名，进行测试 说明，别名优先 总结：命令的执行顺序： ①首先判断是否是别名，如果是别名，别名是在内存中定义的，所以直接就执行了。所谓直接就是指已经在内存中了，不像外部命令那样首次执行还需要在PATH变量里进行查找。 助记词alias别名 ②其次，如果不是别名，判读是否是内部命令，如果是，直接执行内部命令（因为内部命令是内置在shell中的，用户登入就已经加载到内存中了）， 助记词 内部命令 ③最后，如果既不是别名也不是内部命令，那就按外部命令处理，就会看HASH表（表里记录了已经被执行过了外部命令的路径），如果HASH表里有该命令，就按表内记录的路径去搜索该外部命令去执行；如果HASH表里没有，就在PATH变量里查找，找到后执行。当然所谓执行也是加载到内存中执行的。对于首次运行的外部命令，也会产生的新的HASH表项。 助记词 外部命令（hash $PATH变量） ④如果找不着，就报错，此命令不存在。 PS：缓存为王，如果想提供一个慢速设备上（比如硬盘）的数据的执行效率，就把它放到内存里，下次从内存访问，速度就提升了。外部命令就是该逻辑思想。后面还有很多次这种套路。 6、加别名用~/.bashrc，这是只针对当前用户有效，家目录嘛，肯定的了。 对所有用户有效是编辑/etc/bashrc 7、别名修改后使之生效的方法，这也是很多配置文件修改后使其生效的通用方法： source /path/to/config_file #就是source 后跟你的配置文件路径 . /path/to/config_file # 就是. 后跟配置文件全路径 比如 . ~/.bashrc 比如： 8、之前的echo既是别名又是内部命令还是外部命令，如何不执行默认的别名优先呢， \\ 和 ‘ 以及 “ 或者 路径 再次command都是可以的 9、命令的格式，COMMAND [OPTIONS…] [ARGUMENTS…] 这点可以联系网络设备的cli 以及python argparse 自定义命令的格式或者规范问题。 -c 这种短选项，以及bsd风格的只有c没有-的用法，freeBSD这种好像cisco的wsa esa底层是这个。 ls -l 这个l就没有长格式 很多命令使用风格已经变了 可以理解成多层子命令的嵌套 10、ctrl+d 是正常退出 sleep 100就不能ctrl+d正常退出，得用ctrl+c强行退出。 11、ctrl+z 12、多个命令写在一行里用分号隔开 上图就是命令太长后认为换行用的。比如pycharm里面也是这么玩的。不过pycharm后来新版本直接回车也没有\\了，也能实现一套命令认为换行的效果。 13、date 系统时间：有软件操系统内核维护，通过CPU的工作频率维护的，date查看 硬件时间：主板上的CMOS，有块小电池（银币状）可供电5年。clock查看 timedatectl 看的最全 clock -s 将system time改一下，改成硬件时间 clock -w 将hardware time改一下，改成系统时间。 date -s ‘20200101 12:02:01’ 系统时间和硬件时间 或者date 010101012008.01 缺点就是看着乱七八糟，优点就是不用写引号便于python调用时的字符串拼接入库啥的。 上图GMT+8 14、时间其实内部一般用NTP去同步的 这里我先停掉ntpd服务，再去同步时间就好了 注意，ntp只会同步系统时间，不会同步硬件时间。 如果硬件时间不对，就先ntp保证系统时间准确后，再clock -w让硬件时间去同步系统时间就可以了。 15、ntp后面细讲，如果企业里时间不同步，涉及加密、集群就会出问题。 16、查看隐藏文件的方法 推荐第一种 l. -l ll -ad .* ll -a |grep -E \" \\.\" a alias b basename bc c cal 9 1752 chkconfig iptables off cd command clock(hwclock) cat /etc/rehat-release /proc/maminfo /proc/partitions d dir类似ls dirname df du date e enable enable -n exit echo f free -h g getenforce disabled h hexdump -C halt history hostname help hash i iptables -vnL init 3字符模式 5图形 0是关机 6是重启 info ifconfig id j k l lsblk logout ls lsb_release -a lshw m mount /dev/sr0 /mnt挂光盘到/mnt下 man mv mandb n ntpdate o p ps pwd poweroff ping pstree q r rpm -ivh rm rz runlevel查看当前运行模式的 s systemctl disable firewalld stat shutdown screen sleep source(.) sz sudo -i t touch tty 看在哪个终端里 type u uname -r unalias v vdir类似ll w which whereis whoami who -r whatis x xxd 等价于hexdump -C y z rz后再按esc可以产生如下图效果，并排两个提示符😶 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"2-linux基础和帮助/4-linux帮助用法.html":{"url":"2-linux基础和帮助/4-linux帮助用法.html","title":"第4节 linux帮助用法","keywords":"","body":"第4节. linux帮助用法 查看帮助相关整理 帮助有这些 whatis command –help -h man and info /usr/share/doc Red Hat documentation 其他网站和搜索 whatis是外部命令，是用来告诉你去找man手册第几页的 以及 该命令的简要说明 如果系统是刚刚装好，whatis是没有结果的，就会出现如下提示，我就不还原系统了。 whatis数据库存放的帮助的简要说明，在刚装好操作系统是没有的，是需要过一会自动生成。如果你不想等，只需要执行 centos6上 makewhatis centos7上 mandb 这样就能生成whatis数据库了。 whatis只是简单说明，详细用法还得参考其他帮助 -----------↓-----Unicode字符集和UTF-8编码--------↓----------- 1、有关文件类型 cat是查看文本文件的，二进制文件看不了，常见的二进制文件有：图片、视频、可执行文件，bash也是 2、二进制的怎么看，二进制太长了，一般就是以16进制形式查看。 hexdump /bin/bash hexdump -C /bin/bash 在linux保存处理都是二进制的，上图的A就是41这个十六进制对应的二进制进行存放在磁盘上的。 阔以的，这排版都得倒一下的~ 3、这些英文或者汉字对应的都有二进制表示的，这种就需要编码表来实现。ASCII就是早期著名的编码表。ASCII（American Standard Code for Information Interchange） 4、ASCII只能表达128个字符，只适用于欧美国家，后来就有了GB2312、GBK我国自己的编码表，以及还有韩国自己的。每个国家的编码都不一样。可能存在都是55这个十六进制，代表的字符不一样，这就产生了冲突。为了统一，就有了统一命令的Unicode， 5、Unicode只是一个规范，定义了全球所有文字或者叫字符和二进制的对应关系。它并没有明确下来这个二进制在磁盘上保存到底是什么形式（用哪种风格）并没有确定下来，比如具体这个二进制在磁盘上占几位，Unicode就没有明确下来，为了具体明确下来（磁盘上存放某个字符占多少位、在网络上传输的时候转成二进制占多少位）就推出了编码的具体实现—比如UTF-8，UTF-8就是Unicode的具体实现。 6、Unicode属于字符集（字符和二进制的对应关系）、UTF-8是编码方式（站位的明确定义）。还有UTF-16和UTF-32，UTF-8使用的最多。 UTF-16用2个或4个字节来表示某个字符。工作中，用得少 UTF-32，所有的文字全都占4个字节。工作中，用的少 UTF-8，使用1-4个字节来表示字符。比如UTF-8兼容ASCII码就是一个字节就够了。生僻字3个或4个字节，常用文字占1-2个字节。 7、Unicode（UTF-8）处理的逻辑机制是这样的，我们vim或nano处理某个文件的时候，在编辑的时候，vim是个软件，自然会在内存中运行这个vim程序。vim打开比如xx.txt这个文件，就会把xx.txt里的字符就转化成了Unicode。你在xx.txt里就可以编辑修改，此时注意这些字符都是在内存中以Unicode形式存在的，当然显示的时候是转换成人类看懂的文字的（这是计算机内部处理的）。 然后你一旦保存，就是存到磁盘上去了，保存到磁盘上就表现为具体编码形式UTF-8了。 后面你再次读xx.txt文件的时候，就是读入内存中，那么此文件在内存中又是以Unicode形式存在的。 8、在网络传输的过程中，PC----请求----Server。比如PC请求http://www.xx.com/index.html, 这个文件在server的磁盘上保存时UTF-8形式，读取到server自己的内存中就是unicode，在网络上传输就是UTF-8，读取到PC处的内存就是unicode，存到PC本地的磁盘就是UTF-8了。当然我记得还有一个BASE64，也需要了解一下。在加密数据的时候就有先使用对称加密后在使用BASE64进行网络传输的，图片在网络传输也是使用BASE64的。 ---------------------↑---------帮助的用法-------------↑------------------------ 9、命令帮助，内部命令和外部命令的help是不一样的 内部命令：help COMMAND 或 man bash 只要是内部命令，都可以通过man bash查看，（当然man也可以看外部命令） 因为/bin/bash文件里集成了所有内部命令，所有man bash就能看到所有内部命令的详细帮助。 bash的man手册有4000多行，有人对其进行了翻译，就是普通学员做了这个事。当然网上也有人汉化也可以参考。 外部命令帮助用法： ①COMMAND -help -h ②man COMMAND ③info COMMAND ④README INSTALL ChangeLog这些程序自身的帮助文档 ⑤程序官方文档 也就是官网的Documentation ⑥发行版的官方文档 ⑦Google bing baidu等搜索引擎 [OPTIONS]...就是选项可以有多个，FORMAT就是在下面列出了很多的FORMAT 10、date 1970-1-1是Unix诞生日 11、显示前天是周几 date 010210102020.300 unix的诞生日，很多时间计算都是从这个点开始的，比如 显示前天周几 12、man手册 manual的意思，利用man可以查看很多外部命令的帮助 上图whereis列出了man帮助的文档。gz压缩文档，不用解压后查看，直接用man命令查看即可。 13、man对应的文档基本都是放在/usr/share/man下的。 man1：linux命令基本都在第1章，是我们常常需要的； man2：系统调用，OS对 外部APP提供内核调用的接口，开发用的；就是应用程序需要和操作系统内核打交道，就得系统调用来完成，在第二章里。man socket 一般看到的就是man 2，属于网络方面的系统调用。不过为啥我的腾讯云上的VPS默认是man3的socket。另外就算是开发也不会直接进行这种底层调用，一般也是通过C库或者python库去调用。 man3：C库调用 man4：设备文件及特殊文件 man5：配置文件格式，也是我们关心的，linux好多配置文件，配置文件有很多格式，这些说明就在第5章里。 这个issu文件怎么配置，他的帮助就在第5章里。然而VPS上并没有 换成我自己的vm虚机就有了 应该VPS是最小化安装，当然也不是都没有，最小化安装man ls，man bash都有的。 man6：游戏 man7：杂项 man8：管理类的命令，管理员，root身份进行一些管理型的命令。 man9：和开发相关的linux内核API。 14、man使用注意点 man xx 默认看的是man1，1以外的章节 需要特别指定第几章才行。比如passwd这个文件配置说明。 /etc/passwd是个文件，/usr/bin/passwd是个命令，这两个passwd不是同一个东西。 显然whatis查看的不仅仅是命令，而type只是查看命令是内部 还是外部 亦或是alias。 man passwd看的是第1章，看的是passwd命令（/usr/bin/passwd） 如果要/etc/passwd配置文件帮助，就需要：man 5 passwd 总之，先whatis xxx看一下在那一章节，然后man n xx去看 man也是个外部命令，可以用whatis去看一下有哪些章。 1p都是和开发相关的。 man man可见 15、man搜索和vim搜索一样 或者 ”?second”，n 和 N是下一个或者上一个。方向键上下，一样调用历史记录。 man -a 查看所有，q+enter进入下一章 man -k passwd查看包含passwd的帮助类似whatis passwd，但明显要比whatis passwd多得多。 man -f passwd 等价于whatis passwd man -w date查看帮助文件在磁盘的路径，类似whereis date，区别在于man只是看man手册在哪，而whereis date还显示命令（文件）的路径。 16、man举例 \\S就是OS版本 Kernel就是Kernel \\r内部版本 \\m X86架构 这个issue就定了用户登入提示信息。 现在需要：显示用户在哪个终端登入上来的，（原本是tty查看的），还要显示时间、显示主机名，此时就需要查看帮助 说明了issue只有第5章有，是预登入和标识文件。 直接man issue就行了，因为只有1个 第5章 上图是man issue的所有信息了（就这么多行，到底了），其中并没有看到什么\\S \\r \\m的解释 不过有一个SEE ALSO可以参考 于是man motd 我们issue是登入之前，而motd是登入之后，不是此时需要的帮助，换一个 man 8 agetty 都找到了 再来对比一下 都找到出处了, welcome…是自己加的 修改为： ​ 17、linux的语言默认是英文，不建议转成中文，但是可以转，如下 有些地方就是中文了 但是man里面还是英文的， 还需要安装如下的中文的包 才能在man手册中显示为中文。 安装的话，我准备使用本地安装光盘里找一找相关软件包，所以不适用VPS了，换成本地CENTOS7 上图表示现在光盘没有挂载，可是我已经在WmwareWorkstation上勾选了connect了。此时只需要在GUI界面上使用和cli同样的账号，此时是root，登入一下就行了 进到光盘的路径下，里面就是所有的安装的软件文件，而且后缀都是.rpm。找到man开头的 发现了zh-CN的中文包了，这个就是可以修改man手册里的中文的包。 使用rpm -ivh 安装，注意ls man按tab补全后ctrl a切换到头将ls改为rpm -ivh，因为rpm 不带自动补全功能 此时在修改一下LANG，localectl set-locale LANG=zh_CN.UTF-8，退出再登入，然后就可以看到man手册里的中文了 但是man 1 passwd就是命令的帮助手册还是英文的 说明中文支持的还不是非常全。不过只是了解一下怎么切中文，一般也不会切的。 所以，切回英文 localectl set-locale LANG=en_US.UTF-8。 18、info 命令一般不用，不过info里面的都是一个个链接，更像是一个网页，是*号开头的，按回车就会跳转，挺有意思的，了解一下，比如info ls 光标停在*号行，按回车，就会跳转 19、man帮助使用较多，info基本不用，此外还有一些不怎么用的帮助，了解一下 GUI里的Applications\\help里面点开可以查看的，这是CentOS7的。CentOS6实在GUI的system/help下。 20、不怎么用帮助之/usr/share/doc 每一个安装好的软件包，都有一个对应的文件夹放在/usr/share/doc下，你可以进去查看软件的说明。 这些文档大部分都是文本，PDF\\HTML\\TXT 都能打开看基本上。 21、linxu只是一个操作系统，常规操作掌握后，更多精力是放在linux系统之上的应用程序—这些第三方软件（apache、nginx、mariadb等），这些软件就要去官方网站查看文档。 第三方应用官方文档举例 http://httpd.apache.org http://www.nginx.org https://mariadb.com/kb/en https://dev.mysql.com/doc http://tomcat.apache.org http://www.python.org 点击documentation后，可以看到 这个软件有很多moduels模块组成，其中有core模块，点击进去可以看看该模块里的各个指令directives。 点击root命令 要学会看懂这里面的说明，因为官方文档才是最权威的一手资料。 22、现在还没进入都linux上层应用的学习阶段，现在还是在学习操作系统本身，系统本身也有官方网站以及documentation的。 红帽知识库和官方在线文档 http://kbase.redhat.com http://www.redhat.com/docs http://access.redhat.com https://help.ubuntu.com/lts/serverguide/index.html 比如现在需要看centos8的安装指南 http://www.redhat.com 如图就找到了CentOS8的安装手册，有升级的、基本安装、定制化、高级安装（kickstat自动化安装），而且右边栏还可以选择查看的文档格式（pdf or web） 23、搜索引擎 http://tldp.org http://www.slideshare.net # 这网站是很多国外的人在研究技术的时候写成了PPT，可以拿下来改吧改吧。 http://www.google.com 搜索的技巧 https://segmentfault.com/a/1190000038432191 https://funletu.com/12851/.html openstack filetype:pdf rhca site:redhat.com/docs #这种站内搜索，受限于对方的安全措施，应该叫反爬机制 https://www.ibm.com/developerworks/cn/linux/index.html 要知道IBM已经收购红帽了，所以该网站也是阔以的。 24、帮助举例 ASCII 字符集 在编码的时候使用 八进制、十进制、十六进制。 然后，man ascii ASCII码总共128个字符，每个字符对应的八进制、十进制、十六进制分别是什么，分两列展示。 想用echo一下ascii，不知道怎么玩，可以man echo在搜oct就行了 所以echo -e “\\0xxx”还有echo-e “\\x21” 25、ascii查看举例 \\x0a是十六进制的，是不分大小写的 26、\\r和\\n 这是\\r的回车return的效果，没有换行，所以还在本行，就会把之前的xxx覆盖了前两位。 这是换行+回车的效果，linux的\\n就是微软的\\r\\n linux也认\\r是回车的意思，所以\\r就是回车、\\n就是换行在回车，这里两个回车了，效果还是把车停到了最左边，就是100个\\r也就是1个\\r的效果，一个\\r也被集成在\\n里了。 所以，在python使用paramiko非交互模式获取H3C的dis cu inter | I inter后，详情如下 如果上图re.split处这么写：portPer1.split(‘\\n’)，在print(i)的时候你会看到显示都是OK的，但是一旦将这些i传入list里后，就会出现xxx\\r\\r如下情况： 此处需补图，回公司才有环境，还得自己整一个网络环境出来，用eve吧明天搞。 所以H3C的display 看到的分行，其实里面是xxx\\r\\r\\n，我猜它这么做为了，为了个屁，就是强迫症，多次回车保证车必然停在最右边，然后\\n换行，所以我改成了re.plit(xxx)如上图。 27、对比一下MS和Linxu的\\r\\n 我们已经知道\\r\\n是MS的换行，\\n是linux的换行，这里说换行自然就包含了回车了。 下面看实验 传到桌面，在打开 可见linux的\\n到MS里是没问题的，结论MS兼容\\n 反过来，来一波 在windows新建f2.txt 使用rz传到linux里或直接拖进去 carriage return简写了 结论 MS的\\r\\n到linux下linux只需要\\n就能进行换行回车，所以多了一个\\r，当然cat的时候是看不到的，或者说python处理的时候可能print也是看不到的，但是\\r确实留在了文本里面，确实会为后面的数据处理带来麻烦的。 相对的，linux下的\\n到了MS里，MS处理的就很好，奇了怪了。我明明记得很多txt文本在windows里看到的都是xxxx\\nxxxx\\nxxxx\\n不换行的格式错乱啊，难道是sz工具对其进行处理了？ 尝试不使用sz工具，而是用sftp进行linxu->ms的文件传输，结果一样还是MS里显示OK。 尝试不用echo -e \"ABC\\nabc\" > f1.txt的方法创建内容，而是使用vim 依然在MS里显示OK，好了此问题不研究了。MS你优秀~ 我明明小写abc后面在linux里就没有换行，传过来结果换行了。 方法论：在文本处理的时候，文本从linux->MS，\\n前加上\\r；从ms->linux，\\r\\n去掉\\r。 以上就说明了：二进制在磁盘上保存机制不同，不可见的符号是看不到的，但是在磁盘上保存确实有的。 xxd和hexdump -C一样的效果，专门看不可见字符。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"2-linux基础和帮助/5-linux入门命令.html":{"url":"2-linux基础和帮助/5-linux入门命令.html","title":"第5节 linux入门命令","keywords":"","body":"第5节. linux入门命令 1、localectl list-locales查看所支持的语言 [11:45:53 root@localhost ~]#localectl list-locales | grep ^en_US en_US en_US.iso88591 en_US.iso885915 en_US.utf8 [11:46:02 root@localhost ~]# [11:46:02 root@localhost ~]#localectl set-locale LANG=en_US.utf8 这是界面风格是英文，不是说不支持中文，因为UTF-8全球语言都支持，之前的文章也讲过UTF-8是unicode全球文职字符集的编码格式。 2、时区文件/etc/localtime 这个时区文件Shanghai也是个二进制文件 3、timedatectl list-timezones 4、cal显示日历 -h看一下就好 [11:49:22 root@localhost ~]#cal 9 1752 September 1752 Su Mo Tu We Th Fr Sa 1 2 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 5、halt，poweroff，reboot，shutdown 关机：halt,poweroff 重启：reboot ​ -f: 强制，不调用shutdown ​ -p: 切断电源 关机或重启：shutdown shutdown [OPTION]... [TIME] [MESSAGE] -r: reboot -h: halt -c: cancel TIME: 不指定，默认就是+1（CentOS7），相对当前时间过一分钟后执行相关动作 ​ now: 立刻关机，等于+0; ​ +m: 例如+3，表示3分钟后； ​ hh:mm: 绝对时间表示，特定时间执行相关动作。 哈哈哈，shtudown -h查看帮助？想当然了，小心误操作哦。 [11:50:25 root@localhost ~]#shutdown Shutdown scheduled for Fri 2022-01-07 11:53:15 CST, use 'shutdown -c' to cancel. [11:52:15 root@localhost ~]#shutdown -c [11:52:22 root@localhost ~]# [11:52:36 root@localhost ~]#shutdown -h Shutdown scheduled for Fri 2022-01-07 11:53:38 CST, use 'shutdown -c' to cancel. [11:52:38 root@localhost ~]#shutdown -c [11:52:41 root@localhost ~]# 6、windows也有shutdown命令 1小时后关机 取消 还支持远程关机 7、who 和 who am I 以及w who，当前有哪些用户登入上来 who am I 或who x x只看当前用户 w 显示谁在登入，运行了那些程序 有点监控的意思了,并没有。 8、screen的用法 虚拟多个屏幕用 首先找到光盘进行安装，当然也用直接yum VmwareWorkstation 连接光盘后，使用非GUI界面相同账号登入(这里是root)，即可完成挂载光盘。哈哈，就这么挂，怎么滴~，当然我现在是mini没GUI。 rpm有tab自动补齐啊，上次怎么没有呢，不管了。 举例1：防止ssh断开导致ping或tftp断开 如果ping着的时候，关闭ssh窗口，ping就停了，证明方法ps aux |grep ping 问题就来了，如果我在备份数据的时候，ssh断了，那备份就失败了，所以screen有用武之地了。 screen -S ming # 创建ming命名的新的屏幕 screen -ls # 查看开启的屏幕有哪些 screen -r ming 进入ming命名的屏幕 举例2：屏幕协助 screen -S ming # A开启一个屏幕 screen -x ming # B进入这个屏幕，此时两个人就共享一个屏幕了。 screen -x ming # C同样可以可以进入该屏幕，此时就三个人共享一个屏幕了，那么问题来了上限是多少人呢？没兴趣知道。哈哈 ctrl+a+d # 注意手法，不能先按ctrl+d，因为ctrl+d是退出的快捷键（等价于exit）；临时剥离该屏幕，但是其他共享屏幕的人看不到的，此时可以干一些不想共享给别人知道的事，然后完了再screen -x ming切回去，就有成了大家共享一个屏幕的情况了。 exit # 一人退出共享屏幕，全部菜单都退出了。 9、echo，回显用 尝试使用帮助看echo，①type echo 发下是内部命令，②所以使用help echo看帮助 [root@centos7 ~]# type echo echo is a shell builtin [root@centos7 ~]# help echo echo: echo [-neE] [arg ...] Write arguments to the standard output. Display the ARGs on the standard output followed by a newline. Options: -n do not append a newline -e enable interpretation of the following backslash escapes -E explicitly suppress interpretation of backslash escapes `echo' interprets the following backslash-escaped characters: \\a alert (bell) \\b backspace \\c suppress further output \\e escape character \\f form feed \\n new line \\r carriage return \\t horizontal tab \\v vertical tab \\\\ backslash \\0nnn the character whose ASCII code is NNN (octal). NNN can be 0 to 3 octal digits \\xHH the eight-bit character whose value is HH (hexadecimal). HH can be one or two hex digits Exit Status: Returns success unless a write error occurs. 功能：显示字符 语法：echo [-neE][字符串] 说明：echo会将输入的字符串送往标准输出，输出的字符串间以空白字符隔开，并在最后加上换行符。 选项： ​ -E （默认）不支持\\解释功能，也就是\\的转义功能； ​ -e 启动\\解释功能，也就是启动转义； ​ -n 不自动换行，类似python的print(‘xxx’,end=’’) 显示变量的值 ​ echo “$VAR_NAME” # 显示变量的值 ​ echo ‘$VAR_NAME’ # 这里讲的其实不是echo的事情了，是引号的用法，单引号就是里面都是原封不动的字符串，不会给你查找变量或命令的。 单引号，最笨，里面是什么就是什么 双引号，普通，里面的变量能够解释出来，里面的命令不识别 原样输出； 反向单引号，最聪明，里面的变量、命令，统统给你识别并解释运行个结果出来。 echo只是结合echo来回显而已。 举个栗子 echo -e “\\a” # 可以发出声音，一般用在代码跑完后滴一声提示。 注意这个linux是在远端PC上，不是本地，但是声音却是本地声音 10、echo显示颜色 echo -e '\\033[43;31;5mICE\\e[0m' 前景颜色43、背景颜色31、5是闪烁‘ 注意43和31位置互换效果一样的，看的其实是4X就是背景色、3X就是字体色 注意\\e也就是\\033前后都有。颜色数字顺序不重要，然后上图是大家喜爱的红配绿。 1m的1是亮色 注意\\033等价于\\e linux里很多信息都是带颜色的，比如 我们自己也可以做出该效果 比如echo： 上图是1是加亮，下图5是闪烁 将来shell脚本，需要屏幕上显示一些东西带颜色，就这么玩。 11、一些编码转换和查询 之前一篇说过字符集和编码也就是unicode和UTF-8的事情，下面是工具网站 http://www.chi2ko.com/tool/CJK.htm https://javawind.net/tools/native2ascii.jsp?action=transform http://tool.oschina.net/encode 类似的网站 12、命令行扩展、被括起来的集合 很多时候会用到3种引号 ‘’ 单引号 “” 双引号 `` 反向单引号 等价于 $() 注意凡是在word或execl中的引号不能直接复制到linux或python里运行，不管你是否是英文的，复制过去就是不对，基本上需要重新键入引号。后面才知道word本身可以设置引号为英文的，这样就可以统一了。 花括号 echo file {1,3,5} rm -f file{1,3,5} echo {1..10} echo {a..z} echo {000..20..2} 花括号里面的就是选择或者递增的关系，花括号外面的_是必然有的。 批量创建文件、用户等。 双引号、单引号、反向单引号，针对不同的场景，作用不同， 针对echo的，针对shell编程的，不同应用地方的作用是不同的。 1、引号在echo处的作用 单引号：里面全是字符串，他大舅他二舅都是他舅。 反向单引号：能识别里面的命令和变量。 双引号：不能识别里面的命令，只能识别里面的变量。 2、一个命令调用另一个命令的结构的时候，经常使用反向单引号。 问题来了 data后面的要引起来，所改成双引号，但是问题如下 结合下图 结论date ‘+%F %T’得到的是两个值，所以touch的时候才会创建两个文件 都是空格惹的祸 所以最终的方法如下 结论：touch创建一个文件的时候不能带空格，有了就是两个文件了。上面的’+%F_T’可以不用引号了，因为本身就是一个整体了。 但文件名应该可以带空格的，虽然不太好，windows就是 3、反向单引号和$()是等价的 结论：反向单引号作为一个单元在其他引号内部出现，不影响效果。 所以上面的也可以这么写 4、每晚12点01分执行备份日志等操作，并保存为前一天的时间 5、tab补全 命令补全（命令的option也是可以补全的，按两下tab会出来一推） 路径补全 文件补全 虽然没神马用。 6、命令行历史 linux输入的每个命令默认都是有历史记录的，除非在键入命令的时候加入特别选项（也很方便做到）。 这些输入的命令记录会放在内存的缓存区里。内存里有一个历史列表，存放了输入的这些命令。 突然断电，或者直接关闭xshell，这些记录就有可能没了，可能就没写到.bash_history文件里。 一般系统会自动保存到文件里， history的ctrl r快速搜 上图的操作为：!然后按ctrl r，输入echo，就会从history里找到最近的一次包含echo的命令，我经常用来做snmpwalk -v -2c xxx 10.1.1.1 .1.3.6.1 x.x.x.x.x 这种历史的调用。 这是包含，下面的水以什么开头的最近的一次历史命令 下面是包含什么的最近的一次历史命令 10、把上一条命令的前面的换掉 11、上面的ctrl r修正一下 不需要输入history在按ctrl r直接ctrl r就行ctrl g是退出 12、非常实用的命令,把前一个命令的最后一个参数调出来 上面的!$调用比较方便，还有交互式下的快捷键可用来替代!$，比如 按esc松开不松开都可以再按. 或者按alt . 考虑到xshell的默认快捷键冲突，所以建议改一改，这么改就行 需要更加多样的调用，实际上!$是上一个命令的最后一个参数，!^是就是第一个参数，其他还有很多类似用法，但是我觉得没必要了，其他的不实用。 13、history命令选项用法继续 ①history会默认记录命令，现在考虑安全，可以清除历史 这个history -c是清楚的内存中的历史，而历史命令不仅仅是内存中有，还有磁盘文件也有。 但是这个文件放的是以前的历史命令。不是现在的几条。退出重进，发现echo passwordxxx确实不在，其实就是趁着内存中的命令还没自动放进./.bash_history里history -c直接就清掉了。 但是腾讯云上显然不是这样，应该是有了优化（内存中的命令会立刻存到.bash_history文件中的，如下图。） ①history会默认记录命令，现在考虑安全，可以清除历史 这个history -c是清楚的内存中的历史，而历史命令不仅仅是内存中有，还有磁盘文件也有。 而且腾讯云的VPS，内存里的命令清了，立即退出，重进，会发现命令还在的，说明内存和.bash_history磁盘文件是实时同步的。 为了确认一下，可以cat看一下 注意#1587828143这些是时间应该 上面写错了，不是腾讯云的优化，是这个原因： 我把历史命令前面的时间格式取消后，发现内存的命令不会自动同步进.bash_history了。 果然又再次秒同步了。 最后再验证一下 懵逼了， 终于知道什么因果关系了：将将将将~ 一般情况内存的命令不会实时同步进.bash_history文件里的。 想要实时同步，可以这么做，在history显示行首加上时间格式就能促使命令的实时存盘。 但是需要注意的事 即使注释了这行，还是会实时同步的，如下图， 但是如果你使用；去注释改行，那么 export HISTTIMEFORMAT=\"%F %T \" ①没有做时间格式的历史记录，但是命令实时同步进.bash_history ②做了时间格式，命令也是实时同步的 ③用#注释时间格式，命令还是实时同步的 ④用;号注释时间格式，命令就不再实时同步了。 什么鬼。。。睡觉 反正记着有办法让内存的命令实时同步就行了。方法之一就有上面的思路。 上面瞎折腾，靠谱的还是参考下面人家的 https://developer.aliyun.com/article/637427 14、history默认是1000条最近的记录 也可以在/etc/profile里写 退出重登，发现还是3000的历史记录，说明etc/bashrc优先 验证，去etc/bashrc下注释掉那行，退出重进，发现此时是10条记录了 history -d 36就是清第36条 怎么删除一个范围？ -a ，追加经磁盘文件 -r , 将历史文件的记录读到内存中的history记录下，默认用户登入的时候就会读取，执行该动作。 -w , 将当前的history内存记录存到指定文件中，比-a多了个路径，-a是默认的.bash_history 所以 -p 是不存在历史内存列表中，而且是将命令按空格展开成多行。 -s 是制造虚假的历史命令，实际未执行。 15、history命令历史的相关环境变量 HSITSIZE：命令历史的记录条数是内存中的记录条数 HISTFILE：指定历史文件，默认为~/.bash_history HISTFILESIZE：命令历史文件记录历史的条数，这个其实用HISTSIZE控制内存中的记录条数，就能控制文件的条数了，对了，默认HISTFILESIZE多大？也是1000条。 HISTTIMEFORMAT=”%F %T ”，显示时间，指定格式，也可以写到/etc/profile.d/env.sh下。PS1就是写在这个下面的 HISTIGNORE=”str1:str2*:...” 忽略str1命令，str2开头的历史命令。用法如下 安全敏感的不记录 HISTCONTROL：控制命令历史的记录方式，该环境变量的值如下： ​ ignoredups 默认值，忽略重复的命令，连续且相同的为“重复”.不过腾讯云主机是unset没有默认值的： 如图，不赘述 ​ ignorespace 忽略以空白开头的命令（类似HISIGNORE=”str1:str2*...”），如下图 ​ ignoreboth 相当于ignoredups,ignorespace的组合 ​ ​ erasedups 删除重复命令，不同于ignoredups(连续的相同命令只留一条随机的？)。erasedups是不连续的也删。 这些变量的赋值，上图是直接HISTCONTORL=XXX，这种不会保存在配置文件里，退出用户丢失。可以保存在/etc/profile或/etc/profile.d/env.sh或~/.bash_profile或/etc/bashrc，可以看看云主机的一些环境变量的保存路径，初步总结下来，只要大的路径对了，就行了，比如tab.vimrc不一定非要独立的文件的。感觉腾讯云这么做也无所谓规范不规范的。 16、快捷键 在xshell里没问题，但是在摸粑粑里有的不灵 ctrl + l 等价于clear清屏 ctrl + o 执行键入的命令，并重新显示出来，这玩意有延迟的，需要将命令打在屏幕上等一会，在按ctrl + o 才对，不让出来的命令是之前的 ctrl + s 锁屏，用来盲敲的 ctrl + q 解锁，恢复输入可见 crtl + c 强制退出 ctrl + d 规范退出，正常退出 ctrl + z 挂起命令 bg 恢复后就停不下来了，除非退出xshell。 fg 比较好，可以退出ctrl c ctrl z在挂起都行 17、一些有用的快捷键 ctrl+w，往前删除，一段一段的删，就是遇到空格就停下了 ctrl+k 和 ctrl+u相反，光标处删到行尾 alr+r 删除整行 和xshell冲突 ctrl + xx 光标在行首和当前位置切换 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"3-文件管理/3-文件管理.html":{"url":"3-文件管理/3-文件管理.html","title":"第三章 文件管理","keywords":"","body":"第三章 文件管理 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"3-文件管理/1-文件系统.html":{"url":"3-文件管理/1-文件系统.html","title":"第1节 文件系统","keywords":"","body":"第1节. 文件系统 1、文件系统结构元素 就是文件目录结构， /boot 启动相关文件，例如内核 /etc 配置文件，比如之前的/etc/issue /etc/profile.d/ /etc/bashrc等 /dev 硬件设备 b开头，表示块， c开头，字符文件， 都是设备文件 tty，字符设备，是一个个字符来进行输入输出的 块设备，光盘、硬盘，是以一块一块为单位，而一块代表N个字节，比如4096Byte表示一块。如果是块设备，每次输入输出就是4Kbyte。一下子读入4K或写入4K。 比如硬盘分区都是BLOCK为单位， 比如issue该文件里面存放了点数据，如图才346byte，但是由于磁盘分区上保存数据是以块为单位的，哪怕你只是修改该文件1个字节，实际上读取的也是以块为单位的，所以 假设4KB一个block，那么，读动作 就是一下子读取4kbyte到内存中，改完了写入磁盘分区也是也是 4kbyte的空间站位。 总之，实际的数据量虽然不大，可能把这个数据写入、写出的时候，实际会大很多，就是这个意思。 2、/bin 给普通用户用的 /sbin给系统管理员用的 还有/usr/tmp 都是软连接， ll的细节注意一下 ls /bin和ls /bin/效果一样，都是现实/bin下的所有文件 # 这里还是要用ll -d去看文件夹，反正有些py模块里，文件夹就要用XX/来标识。实际操作需要验证一下的。（带不带/，要不要-d，之类的） ll /bin 和 ll /bin/不一样，前者是显示文件夹本身，后缀是显示该文件夹下的文件。 # 这话也是错的，因为/bin是个软连接，本身是文件。 ll /bin -d 和 ll /bin/ -d 不一样，虽然都是显示文件夹metaDate。前者是显示软连接的元数据，后缀是显示源文件的medaDate。 这两个都是等价的 这两个显然不同。 所以总结，看文件夹的信息，就是ll /bin -d，这样最靠谱。 靠谱的原因就是-d看起来是看文件夹，其实对文件一样有效。所以看文件本身不进入子层，正确的使用方法就是ll /bin -d ll / -d这种了。 上面仔细看图就好，其实还是软连接造成的操作上的细微区别。 3、/usr 下很多文件夹和/很像， /usr 像是个二层根。 结构是有规范的无论是什么linxu版本，都基本符合这一套目录结构。 FHS：Filesystem Hierarchy Standard http://www.pathname.com/fhs 文件要存放规矩 4、两个特殊目录/proc 和 /sys 这两个目录大小为0 虽然是0，但是在/proc下是可以看到数据的。 说明proc下有很多数据的，但是proc文件夹的大小就是0。这是因为proc看到的是内存中的数据，内存数据不占磁盘空间，所以ll /proc -d显示的是磁盘空间占用大小。 /sys 是映射的硬件信息 /proc是放进程process相关信息的 5、以/sys为例，可以用里面的一些文件来管理硬件 这里换本地的VM来做实验—增加新的硬盘 当前只有一块硬盘和一个光盘 现在要实现加硬盘不重启的效果，以VmwareWorkstation为例，直接在VM里添加即可(略)。 但是添加完了，一般需要重启才行。不过可以这样： 在/sys 此时就新加的硬盘就出现了，也不需要重启系统。 一般就是host2或host0就行。 可以考虑将上面的两条命令定义成别名 现在再加一块硬盘，就可以利用别名快捷实现了 6、linux文件名最长为255个字节，验证如下 创建一个256字符（一个字符对应一个字节？），利用ALT + NUMBER 在输入字符即可 按住alt不动，紧接着输入256，然后松开后输入x，这样就完成256个x的输入。 一个x字符对应的就是一个字节，UTF-8格式规定的。不信可以这么检查 vim test，里面写一个x，然后hexdump test -C 看一下： 再man一下ascii找到小写的x 确实是16进制的78，而16进制78就是一个字节的空间。 所以，touch xxxx...xx 256个x就是256个字节的长度了，验证方法有效。 7、包含路径在内文件名最长4095个字节。 蓝色-目录 绿色-可执行文件 红色-压缩文件 其实就是看后缀，系统一看后缀是.gz的就给你打上红色了 天蓝色-链接文件 灰色-其他文件 黄色-设备文件，有的是b块设备、有的是c字符设备。 ​ b的单位是块，是随机读写，不是顺序的，是随机的放在磁盘的某些位置。而c的单位是字符，是顺序一个个字符进行输入输出的。块设备通常是有缓存的，硬盘有缓存，而字符设备是没有缓存的，就按照顺序进行访问就行了。 粉色-socke文件，套接字文件，s开头的，是为了实现网络通讯的。后面讲mysql会用到。 /run下面又很多粉红色文件 棕色-管道文件，p开头的，是实现进程间通信的，就是同一台PC上的不同APP互访，用的不多，用socket用的比较多。 文件的颜色和后缀的关系，实在/etc/DIR_COLORS下定义的 看下一个pip40,33确实是棕色 试一下上图DIR_COLORS的效果 01,31就是红色没跑了 然后在试一下exe文件，默认是注释了的， 现在打开 还是没有变，不急，执行一下DIR_COLORS文件，执行不了，退出重进就行了 搞不懂为什么.bashrc可以. ~/bashrc直接跑一遍，是修改的配置生效，无需退出重进。 而. /etc/DIR_COLORS却不能这样。 8、文件名规则 1、上面说了255个字节的文件名 2、说了4095个字节带路径的文件名 3、说了颜色 4、还有，除了斜杠和NULL，所有字符都可以用来作为文件名，但是使用特殊字符的目录名和文件名不推荐， 5、标准Linux文件系统（如ext4），文件名称大小写敏感，如果是linux挂载了fat的硬盘（ntfs，需要额外装软件，才能挂到linux下），则给硬盘下大小写不敏感。总之文件名称的大小写是跟着文件系统走的，而文件系统就是你格式化硬盘分区所选择的xfs、fat32、ntfs这些。 验证方法：linux关机，添加硬盘-使用现有的物理磁盘-选择磁盘1（假设你的fat分区在1下，这里看到的0和1就是物理硬盘的编号）-分区2（假设fat格式的是分区2），启动centos 这里的0就是硬盘0，1就是你电脑的第二块磁盘。我就一块0. 确定即可 但是我的实验不能加载物理硬盘 没什么意义，有时间可以换个机器试试，成功开机后，然后接着下面操作： lsblk -f 可见是这个硬盘是vfat格式 文件系统，需要挂载到一个目录才能使用 所以mount /dev/sdd2 /mnt df 可见sdd2已挂载 cd /mnt ls 可见各种windows下的格式， 此时该/mnt下的文件就不再区分大小写了。 这个实验就是说，标准linux文件系统(如ext4)，文件名称大小写敏感。 然而你可以挂载fat32硬盘上去，这个就不区分大小写了。 理论上可以，但直接创建是失败的。可以这么做： 删除一样， 或者 带上路径就行了 9、文件类型 - 普通文件 d 目录文件 b 块设备 c 字符设备 l 符号链接文件 p 管道文件pipe s 套接字文件socket 共7种类型，联系上文 除了-普通文件，其他的文件操作都要小心。特性不一样 p和s 主要是为了两个应用程序之间互相通信用的临时文件。比如两个软件交换数据，一个往pipe里写，另一个从对应的pipe里读。 10、CentOS 7的bin和usr/bin实际是同一个东西了 同样的，lib和/usr/lib， 这些在早期的centos6里不是这样的，都是独立。就是很相似，所以干脆合在一起了。 lib是放库文件的。 11、pwd -P 显示原文件路径 -L 显示的快捷方式就是软链接文件的路径 pwd默认带-L 同样需要注意的是，ll -d 看到的情况也要验证一下，是否是软链接的还是原文件的。 12、有些场合下，相对路径不是相对当前的cwd（current work direction）当前工作目录 比如前文提到的软连接，以及练习-2里也有提到， 就是相对于你要存放软连接的路径的 相对路径 13、basename和dirname， 创建和之前文件相同目录下的另一个文件，可以将下图中的/data/dir1/通过其他方式取出来，比如py里的os.gold、os.walk还是os.list都有方法的。或者你直接将/data/dir1作为变量。 14、cd备忘 cd ~ 等于 cd 进入当前用户的home目录 cd ~user1就回到了user1的家目录 cd – 上一次的路径，效果就是当前和上一次路径返回切换，原理就是OLDPWD这个变量里保存了上一次目录 之所以回得去，就是因为有一个变量保存了上一次的pwd信息。 15、ls备忘 ls -a 包含隐藏 ls -l 显示metadata ls -R 递归，应该有用，os.walk估计还没这个ls -R原生的优秀呢 ls -d 虽然是directory，但是ll -d通常用来看单个文件或文件夹都可以的 ls -1 文件分行显示？啥意思 ls -S 按从大到小排序，这个好 ls -t 按mtime排序 ls -u 配合-t选项，显示并按atime从新到旧排序 ls -U 按目录存放顺序显示 ls -X 按文件后缀排序 ls其实现在也是alias别名了，想用原始的ls只需要\\ls就行了 关于atime 所以正如练习-2里提到过的，atime并不是实时更新的 Access：最近访问时间acces time (atime)，这个不是实时更新的，为了防止大量的写accesstime这个操作，节省资源 但是当你当前读取的时间比上次atime超过1天了都，所以肯定给你立马更新了。最小差值多少，这个可以测一下。 由此可见，还正就是日期从25号变成了26号， 且时间跨度有一个值大概在12小时， 总结一下，hours在12小时，day + 1，基本就会cat后立刻更新时间了。当然可能12小时都嫑。我只是无聊，至于到底几个小时，who care。 clock -s 记得还原 16、ctime 文件的属性发生改变的时间 属性就是：一行里的各种数据，包括 文件的权限、inode数量（硬链接个数，注意软连接不算在meta data里）、所有者、所属组、大小。 这些通通都是元数据 上图cli写错了，直接stat /etc/motd就行了，不要time stat meta data发生改变，ctime就变了 注意atime 各种time不属于元数据。文件名是属于元数据的 17、selinux和防火墙 先不管，关闭即可 上图是selinux 防火墙也是启用的 关闭selinux 原来是enforceing，改成disabled 改完后，需要重启才能生效，不过可以结合cli方式临时关闭selinux就不用重启了。 不过可惜，disabled没有对应的值，0-permissive，1-enforcing。所以我还是老老实实重启吧。 systemctl disabled firewalld.service # 开启不启动 systemctl stop firewalld # 关闭防火墙 最后这样： Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"3-文件管理/2-文件管理.html":{"url":"3-文件管理/2-文件管理.html","title":"第2节 文件管理","keywords":"","body":"第2节. 文件管理 1、centos6以前的版本禁用selinux vi /etc/selinux/config SELINUX=disabled chkconfig iptables off service firewalld stop # 应该是这个吧，如果不是，上面一条重启不自启动就行了 2、文件通配符 ★文件通配符，顾名思义，就是匹配文件名称的，别想多了。 * 匹配零个或多个字符 ? 匹配任何单个字符 ~ 当前用户家目录 ~haiwang 用户haiwang家目录 ~+ 当前工作目录 ~- 前一个工作目录 # 等同于cd -，但是ls 不能ls -这么用，要ls ~-这样 [0-9] 匹配任意一个数字 [a-z] 任意小写字母一个 [A-Z] 任意一个大写字母 [haiwang] 匹配列表中的任何的一个字符 yingxiong 匹配列表中的所有字符以外的字符 y开头的 包含x的 .txt结尾的，但是不包括.txt，因为*不会包含隐藏文件。 *在文件名通配符领域里，表示该位置有一个或多个，或者没有，都可以 要在非隐藏文件里找需要的文件名，就可以用ls *来做 而要在隐藏文件里找，就用正则就行了 而查看隐藏的我现在想到的就可以用正则来做，后来又发现还有l.（列出当前所有的隐藏文件和文件夹）。 查看隐藏文件 l.只能看当前文件夹下的隐藏文件/文件夹，如果是看其他路径，就需要参考l.这个alias里的原来语法： ls -d /data/.* 只看文件夹 ll |grep \"^d\" ll -d */ ls ??? 表示就看3个字符的文件 汉字unicode，一个汉字也是一个字符。只是一个汉字这一个字符 在磁盘上保存不是占一个字节。 unicode 汉字，可能占2-4个字节。 在通配符里面没有^[xxx]这种写法，和正则regex相似又不一样 文件里面过滤字符串，这是不是通配符的活，通配符是匹配文件名称，文件内容交给regex 注意事项 ls /data/f[a-c].html表示啥 [a-c]代表aAbBc，这个regex又不同了 [A-C]等价于AbBcC 见下图 如果就是想要小写或大写，可以这么写 [:digit:] 任意数字，相当于0-9 [:lower:] 任意小写字母 [:upppere:] 任意大写字母 [:alpha:] 任意 大 小 写字母 [:alnum:] 任意数字或字母 [:blank:] 水平空白字符 [:space:] 水平或垂直空白字符，垂直空白字符是啥？回车？还是↓ [:punct:] 标点符号 [:print:] 可打印字符 [:cntrl:] 控制（非打印）字符 [:graph:] 图形字符 [:xdigit:] 十六进制字符 注意两个[[:lower:]] 方括号的意思，里面的[:lower:]是一个整体表示一个小写字符，外面的表示任意一个字母。 等价于正则里的[a-z]写法。 只看隐藏文件的方法，和上面的对比一下 l.的缺陷，只能看当前文件夹，下图就是，明明cli里写的ls -d /data/ .*但是看得还是当前目录的 上图有一个思路对了，手残敲错了，应该如下 只看文件夹的方法 一个是看非隐藏，一个是看隐藏的文件夹 通配符，在py的os.xx模块里，好像就不是regex而是通配符 按理说练习应该放在外面，但是这是课堂视频里的练习，不是作业，就不放在外面单独文章了 1、显示/var目录下所有以l开头，以一个小写字母结尾，且中间出现至少一位数字的文件或目录 ls /var l*[0-9]*[[:lower:]] 2、显示/etc目录下任意一位数字开头，且以非数字结尾的文件或目录 ll -d /etc/[0-9]*[^0-9] 这里可以考虑吧-d去掉，为的就是遍历一下/etc下文件夹下的文件或更深层次 3、显示/etc目录下以非字母开头，后面跟了一个字母及其他任意长度任意字符的文件或目录 ll -d /etc/[^[:alpha:]][[:alpha:]]* 注意些通配符的时候，有根弦--通配符不是正则。然后一个字母要有大小写[a-zA-Z] 4、显示/etc/目录下所有以rc开头，并后面是0-6之间的数字，其他为任意字符的文件或目录 ls -d /etc/rc[0-6]* 5、显示/etc目录下，所有以.d结尾的文件或目录 ls -d /etc/*.d # 注意.d文件也算是.d结尾的，这样就看不到了 ls -d /etc/*.d;ls -d /etc/.d 6、显示/etc目下，所有.conf结尾的，且以m.n,r,p开头的文件或目录 ls -d /etc/[mnrp]*.conf 7、只显示/root下的隐藏文件和目录 ls -d /root/.* 8、只显示/etc下的非隐藏目录 ls -d /etc/*/ 3、touch 1、创建文件 2、如果文件存在，只是修改时间（atime、ctime、mtime）都给你改当前时间了 补充： 默认ll的时间是mtime 3、总结，touch是安全的创建文件的方法 还有个创建文件的方法 > echo >> f5.txt 追加内容也是一个道理 以上的> 或 >> 是依赖于shell的， 上图换成csh就不行了 > 、>>不是命令，其实是重定向。 > 常用来快速给文件清空，无论文件有多大，都给你快速清空。据说灰常好的小功能。 touch [OPTION]... FILE... -a 仅改变atime和ctime -m 仅改变mtime和ctime -t [[CC]YY]MMDDhhmm[ss] 指定atime和mtime的时间戳 -c 如果文件不存在，则不予创建，这个一看就不错 4、保持日志为前一天 生成昨天日期作为文件名，上图是错误的写法，会自己坑自己 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"3-文件管理/3-cp和mv.html":{"url":"3-文件管理/3-cp和mv.html","title":"第3节 cp和mv","keywords":"","body":"第3节. cp和mv 1、cp命令 cp的三种语法 前两种用的多， cp [OPTION]... [-T] SOURCE DEST # 复制并改名 cp [OPTION]... SOURCE... DIRECTORY # 复制多个源文件到一个文件夹中 cp [OPTION]... -t DIRECTORY SOURCE # 同上，多了个-t 其实第三种用的也很多，因为通常会将rm，alisa成mv，此时就需要将目的文件夹放到前面，如下图： cp 复制文件的meta data会改变的 cp复制文件的时候，可能有一些信息会丢失（时间） cp复制文件的时候，可能有一些信息会丢失（时间，所属用户 用户组） 文件拷过来了，但是所属者、所属组，也包括时间都变了。 这就是信息丢失了，很可能导致文件复制过来不可用了。 cp赋值普通文件是可以的，除了上面的说的问题。但是cp不能复制特殊文件 之前讲过7种类型的文件 ll看最前面的符号就是类型了 zero也是一个常用的字符文件 cp复制文件的时候，cp复制问题-文件内容变了，拷的就不是你要的文件 下图注意复制的其实不是软连接，而是真是的文件被复制的。 cp复制文件的时候，cp了一个/dev/zero设备文件，如下图，什么都不一样了（文件类型、权限、大小）都变了 其实zero好像通常用来产生固定大小的文件的，一般你测试网速，就可以用zero产生一个大文件提供下载。 所以 cp主要针对普通文件的。要复制特殊文件，需要加一些选项，就算普通文件，如果需要保留原来的时间也需要cp加选项。 2、复制文件夹的注意事项 复制到文件夹，不改名字 复制多个文件，复制到文件夹下 如果是复制文件夹 需要递归选项 如果文件夹不存在，自动给你创建 如果文件夹存在，会覆盖？！不是，看清楚下图，①sysconfigbak文件存在，②所以会把sysconfig文件夹的内容全都复制到sysconfigbak文件夹下。③而再次cp -r的时候由于sysconfigbak下已经有sysconfig整个文件夹的内容了，所以会问你是否覆盖。 这就是传说中的：幂等性 多次重复执行一个命令，效果一样，这就叫做幂等性。 所以cp命令不具有幂等性的特点。 源 目标 不存在 存在且为文件 存在且为目录 一个文件 新建DEST，并将SRC中内容填充至DEST中 将SRC中的内容覆盖至DEST中 注意数据丢失风险！ 建议用-i 选项 在DEST下新建与原文件同名的文件，并将SRC中内容填充至新文件中 多个文件 提示错误 提示错误 在DEST下新建与原文件同名的文件，并将原文件内容复制进新文件中 目录 须使用-r选项 创建指定DEST同名目录，复制SRC目录中所有文件至DEST下 提示错误 在DEST下新建与原目录同名的目录，并将SRC中的内容复制到目录中 3、CP常用选项 -i 覆盖前提示，默认就有 需要注意 这是因为root账号有自己的alias别名定义，user1没有定义，别名的定义在家目录的.bashrc里写的。在root账号的家目录里有定义的别名，这里 -n 不覆盖，注意两者顺序 -r, -R 递归复制目录及内容 -a 归档，相当于-dR –perserv=all -d --no-dereference –preserv=links 不复制原文件，只复制链接名 --preserv[=ATTR_LIST] ​ mode:权限 ​ ownership:属主属组 ​ timestamp: ​ links ​ xattr ​ connext ​ all 4、cp的技巧 cp通常是需要加上-i ，cp – i 作为alias别名存在，但是存在下图情况，一个个问就很烦了。也不能取消别名的安全措施 所以可以利用\\前缀来还原成原始的命令，不用别名 不要想当然以为是cp -f，并不是这样的 -n 不覆盖 -d 不复制原文件，只复制链接名 默认是复制原始文件，而不是软链接本身。 --preserv[=ATTR_LIST] ​ mode:权限 ​ ownership:属主属组 ​ timestamp: ​ links ​ xattr ​ connext ​ all !*等价于上一次命令的后面所有参数，不仅仅是下图表示的两个，上图就出现了三个 如果我们希望保留时间属性，就可以 cp xx xx –preserv=timestamp 这会时间就保留住了 如果所有的都保留住 -p 等同于 –preserv=mode,ownership,timestamp #mode是权限、owership所有者所属组、timestamp就是时间了。 -a 前文有，能保留的属性都保留了，最全了。相当于-dR --preserv=all # 这个其实是help里这么写的，但是你不觉得很奇怪吗，r = R, -d只是--preserv=links，所以-a应该是-r 和 --preverv=all这样表示才对。很明显帮助里多了个-d。作为-dr --preserv=all，写法应该就是cli的是偶带了多个参数。所以自然也是and的关系。 -v --verbose # 复制的时候看到过程，如果文件很大，就需要这个直观显示，防止有人以为卡主不动了。 所以工作中推荐av经典组合 -f --force 演示过程中的错误注意事项： ​ root用户将某文件复制到user1用户的家目录下 正确写法是~user1，经常写错的原因是因为cd ~/切到自身的家目录这里是可以有/的。 现在user1家目录下的fstab的所属用和用户组是root的 于是如图所示，不能覆盖了，但是我自己的家目录，我还不能改吗？！-f就是强制措施 -f的思路，就是如果覆盖不了，实际上先删掉后 重新创建新的文件。当然如果删不了就肯定不行了！ 谁复制的，就变成谁的↑，但这话又不全对↓ -f 此时是删了再创建的，所以用户和用户组都是user1。 切到root用户下，cp /etc/fstab ~user1，覆盖掉，发现用户和组还是user1。 -u --update 只复制源比目标更新文件或目标不存在的文件 复制的时候存在一个覆盖的问题，一般都是更新的数据整个文件夹，cp -u 到服务器上的数据，这样就只做 增量更新。 -b 目标存在，覆盖前先备份，形式为filename~ --backup=numbered目标存在，覆盖前先备份加数字后缀 ★工作中，可以做个alias bak=’cp -a --backup=numbered’ 这样就小整合了一下。 所以-a 经常用来做备份的效果，①保留了所有能保留住的属性，②本身-a就集成了-d和递归的功能。 PS：之所以说保留了能保留的，原因见上图，至少有一个ctime是实时的。 简化写法示例 ll grub2.cfg{,.bak} # {}里面被,逗号分隔成两个部分，,号前面是空，后面是.bak，所以就是 ll grub2.cfg grub2.cfg.bak 这个了。用echo可以直观的看 据说这还是常用的备份方法，搞不懂，秀技术吗？ 练习： 1、每天将/etc/目录下的所有文件，备份到/data独立的子目录下，并要求子目录格式为backupYYYY-mm-dd，备份过程可见 cp -av /etc /data/bakcup`data +%F` 2、创建/data/rootdir目录，并复制/root下所有文件到该目录内，要求保留原有权限。 mkdir /data/rootdir;cp -a /root /data/rootdir cp -r --perserv=mode /root /data/rootdir cp -rp /root /data/rootdir cp -a /root /data/rootdir 5、mv 移动和改名 ★可以用mv替代rm，方法就是alias rm=mv ... mv [OPTION]... [-T] SOURCE DEST mv [OPTION]... SOURCE... DIRECTORY mv [OPTION]... -t DIRECTROY SOURCE 常用选项： -i 交互式 -f 强制 -b 目标存在，覆盖前先备份 6、rm删除 rm [OPTION]... FILE... 常用选项： ​ -i 交互式 ​ -f 强制删除 ​ -r 递归 带文件夹一般都带r ​ -no-preserve-root 删除/ 示例： ​ rm -rf /* 有的rm会被alias成rm -i，所以如果需要关闭提示，就用\\rm f1 f2 f3 当然也可以使用-f选项 ★rm -rf / data #这就完蛋了，你带了空格，就是把/下面全删了 rm -rf --no-preserve-root / 在windows里正在使用的文件是不能删除的，但是在linux里没有这个概念。 有些是删不了的，比如media光盘、proc、sys内存、/home /misc /net有些是特殊情况，确实不能删，其他都能。 /删掉后，pwd，cd都能用，原因就是这些都是内部命令，内部命令都已经加载到了内存里。 你删掉的是磁盘文件，内存里的东西都还在。 但是 内部命令依赖的/bin/bash文件已经没了，下次重启后，这些命令就没了。 外部命令那些本次开机后还没有使用过的就不行了，因为外部命令第一次使用后才会加载到内存中，那些本次开机后没有用过的，还都是磁盘文件呢。所以文件没了，就不能使用这些命令了。 rm -rf /* 这个命令误操作的可能性不太大，但是下一个命令就不行了 ★上图就把/data和 /*下的文件全删了。 工作中rm就别用了，别名成mv，其中涉及mv覆盖同名的文件的解决思路 思路就是，rm改成mv mv的时候考虑同名文件，就事前创建一个以当前时间（精确到秒单位,这样只要你的rm命令频率在1s以外，都没有问题）为文件夹名称。然后将要删除的文件移动到该文件夹里。 所以最终的mv替代rm的方法就是： 待填空 7、tree 显示目录树 ​ -d：只显示目录 ​ -L level：指定显示多少层 ​ -P pattern：只显示由指定pattern匹配到的路径，pattern涉及一些正则表达式 mkdir d1/d2/d3/d4 -pv 竟然不是-r,-v 就是建立的过程 -m MODE：创建目时，直接指定权限 rmdir a1/a2/a3/a4 这是删了a4，且a4是空文件夹，rmdir用的不多。 -p：递归删除父空目录 -v：显示详细信息 rm也不是都能删的，报错资源忙，忙的原因是因为/data是个设备挂载点 rm -rf /data确实会把里面的文件都删了，但是当删/data这个文件夹的时候（注意rm -rf /data是删了整个/data文件夹的）由于data是个分区挂载点，所以报错忙。 8、关于磁盘利用率的释放 cp /dev/zero /boot/bigfile # 时间越久，产生的文件越大 ll /boot/bigfile -h >该实验第1遍 现在删除bigfile，该磁盘利用率是否会立刻降下来呢？不一定。这个实验是立即降下来的。 rm -f /boot/bigfile >该实验第2遍 同样上面的实验，现在再rm删除bigfile该文件之前，先用另一个ssh登入打开它。然后在尝试删除观察磁盘利用率是否下降。 然后删除该文件 工作中，很多企业会遇到类似的场景，有些分区要满了，硬盘如果要满了，数据写不进去，就会造成很严重的结果，系统会崩溃，对外服务就挂了。 可能一些log日志文件，就删了不能立刻释放，存在这种情况。 现在关闭之前vim打开的bigfile的窗口 此时空间就释放了 下面 >该实验第3遍 恢复bigfile被占用的情形，就是rm -rf bigfile后磁盘空间不会得到释放的。 推荐的方法为：> fileName ，就是将文件清空 然后再删除该文件就可以了，整个过程完整截图如下 面试题：发现文件删了，空间没释放，正确应该怎么做，面试常见的答案就是上图。 rmdir 删除空目录 ​ -p：递归删除父空目录，就是从内层外外层删，当删除一个子目录后发现父目录也空了，就把父目录也删了。一直删到根。 # 和mkdir -p相反，mkdir -p是先创建父目录，再创建子目录，删除就自然反着删了。 9、rename：改文件名，mv如何改多个文件 rename --help 这样就改了，改文件名称，不仅仅只知道mv，还要知道rename。 再改回去（将.bak删掉） rename .bak \"\" * 练习 第一题的思路，存在一个组合，会想到是大括号的组合用法 ②第二题 ③第三题 这样也可以 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"3-文件管理/4-文件节点表.html":{"url":"3-文件管理/4-文件节点表.html","title":"第4节 文件节点表","keywords":"","body":"第4节. 文件节点表 文件的存放有inode表格和data表格 上图可见，创建一个文件夹后，inode就占掉一个。 touch命令本身不支持这么多个参数，所以换种方式 echo f{1..524288} |xargs touch 节点编号 上图可见分区的空间大小，以及节点数最大值。sda1的inodes最大值为65536。 超出节点编号就不行了 echo f{1..65539} |xargs touch 所以看到没有设备空间不一定是真的，可能是节点编号满了。 删除rm *是不行的，可以删除所在文件夹rm -rf /boot/testdir 或者这么删就行了啊： echo f{1..524288} |xargs rm -rf 节点编号和软连接和硬链接密切相关 ext文件系统的架构 直接指针是12个 ①数据量低于48K，直接指针就可以搞定。 ②超出48K--4M，使用间接指针表示。 ③4M-4GB的采用二级指针 现在centos7是XFT文件系统和ext的文件系统不一样。 不管什么系统都是类似的机制。 对于文件夹来讲他的内容放的是什么 文件名是属于文件夹的内容DATA。是放在数据块空间的。 明白这一点，rm f1本质上是删除他的节点表，指正指向的数据块就没人用了，该空间标记为空闲free状态，但是不会删除数据。如果你新建一个文件可能会覆盖掉的。 此外dir1/下的F1的数据就清了。 所以删除f1是需要有f1所在文件夹的权限就行了。 硬连接，本身就是同一个文件 跨分区了，不同分区肯定不是一个文件了，所以肯定不支持 硬链接不能针对文件夹创建。据说是防止循环现象。 删a1的操作等价上图的示例 备注： 👉以下是vim一个文件，然后echo 然后vim vim 发现indoe在两个数字跳来跳去的(估计和vim打开的时候会自动创建一个.xxx.swp有关，可能是这个原因，也不是swp文件的inode不在那两个反复替换的inode里面，反正vim该文件inode是变的，而且是2个inode数字来回变)。然后echo不会。 [10:54:28 root@localhost data]#echo inode_echo >> test [10:54:43 root@localhost data]#stat test File: test Size: 19 Blocks: 8 IO Block: 4096 regular file Device: fd00h/64768d Inode: 33577448 Links: 1 Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root) Context: unconfined_u:object_r:default_t:s0 Access: 2022-01-29 10:54:20.066021237 +0800 Modify: 2022-01-29 10:54:43.345023132 +0800 Change: 2022-01-29 10:54:43.345023132 +0800 Birth: 2022-01-29 10:54:20.066021237 +0800 [10:54:44 root@localhost data]#ll -i total 8 51325766 drwxr-xr-x. 2 root root 6 Jan 19 19:57 dir 373349 drwxr-xr-x. 2 user1 g12 6 Jan 19 19:58 dir2 33577410 -rw-rw-r--+ 1 root root 7 Jan 29 10:53 f1 33577446 -rw-r--r--. 1 user1 g12 0 Jan 19 19:58 f2 33577448 -rw-r--r--. 1 root root 19 Jan 29 10:54 test [10:54:47 root@localhost data]# [10:54:50 root@localhost data]#vim test [10:55:00 root@localhost data]# [10:55:00 root@localhost data]#vim test [10:55:03 root@localhost data]#ll -i total 8 51325766 drwxr-xr-x. 2 root root 6 Jan 19 19:57 dir 373349 drwxr-xr-x. 2 user1 g12 6 Jan 19 19:58 dir2 33577410 -rw-rw-r--+ 1 root root 7 Jan 29 10:53 f1 33577446 -rw-r--r--. 1 user1 g12 0 Jan 19 19:58 f2 33577450 -rw-r--r--. 1 root root 28 Jan 29 10:54 test [10:55:04 root@localhost data]#stat test File: test Size: 28 Blocks: 8 IO Block: 4096 regular file Device: fd00h/64768d Inode: 33577450 Links: 1 Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root) Context: unconfined_u:object_r:default_t:s0 Access: 2022-01-29 10:55:01.373024600 +0800 Modify: 2022-01-29 10:54:59.985024487 +0800 Change: 2022-01-29 10:54:59.987024487 +0800 Birth: 2022-01-29 10:54:59.985024487 +0800 [10:55:09 root@localhost data]#vim test [10:55:25 root@localhost data]# [10:55:25 root@localhost data]# [10:55:25 root@localhost data]#stat test File: test Size: 39 Blocks: 8 IO Block: 4096 regular file Device: fd00h/64768d Inode: 33577448 Links: 1 Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root) Context: unconfined_u:object_r:default_t:s0 Access: 2022-01-29 10:55:25.695026580 +0800 Modify: 2022-01-29 10:55:25.695026580 +0800 Change: 2022-01-29 10:55:25.697026580 +0800 Birth: 2022-01-29 10:55:25.695026580 +0800 [10:55:27 root@localhost data]# [10:55:35 root@localhost data]# [10:55:35 root@localhost data]#vim test [10:55:44 root@localhost data]# [10:55:44 root@localhost data]#stat test File: test Size: 50 Blocks: 8 IO Block: 4096 regular file Device: fd00h/64768d Inode: 33577450 Links: 1 Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root) Context: unconfined_u:object_r:default_t:s0 Access: 2022-01-29 10:55:44.687028126 +0800 Modify: 2022-01-29 10:55:44.687028126 +0800 Change: 2022-01-29 10:55:44.688028126 +0800 Birth: 2022-01-29 10:55:44.687028126 +0800 [10:55:45 root@localhost data]# [10:57:23 root@localhost data]#stat test File: test Size: 55 Blocks: 8 IO Block: 4096 regular file Device: fd00h/64768d Inode: 33577448 Links: 1 Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root) Context: unconfined_u:object_r:default_t:s0 Access: 2022-01-29 10:57:23.128036141 +0800 Modify: 2022-01-29 10:57:23.128036141 +0800 Change: 2022-01-29 10:57:23.129036141 +0800 Birth: 2022-01-29 10:57:23.128036141 +0800 [10:57:23 root@localhost data]#echo 12 >> test [10:57:29 root@localhost data]#stat test File: test Size: 58 Blocks: 8 IO Block: 4096 regular file Device: fd00h/64768d Inode: 33577448 Links: 1 Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root) Context: unconfined_u:object_r:default_t:s0 Access: 2022-01-29 10:57:23.128036141 +0800 Modify: 2022-01-29 10:57:29.437036654 +0800 Change: 2022-01-29 10:57:29.437036654 +0800 Birth: 2022-01-29 10:57:23.128036141 +0800 [10:57:30 root@localhost data]#echo 333 >> test [10:57:35 root@localhost data]#stat test File: test Size: 62 Blocks: 8 IO Block: 4096 regular file Device: fd00h/64768d Inode: 33577448 Links: 1 Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root) Context: unconfined_u:object_r:default_t:s0 Access: 2022-01-29 10:57:23.128036141 +0800 Modify: 2022-01-29 10:57:35.603037157 +0800 Change: 2022-01-29 10:57:35.603037157 +0800 Birth: 2022-01-29 10:57:23.128036141 +0800 [10:57:36 root@localhost data]# total 20 33577460 drwxrwxrwx. 4 root root 78 Jan 29 10:58 . 128 dr-xr-xr-x. 18 root root 236 Jan 10 18:13 .. 51325766 drwxr-xr-x. 2 root root 6 Jan 19 19:57 dir 373349 drwxr-xr-x. 2 user1 g12 6 Jan 19 19:58 dir2 33577410 -rw-rw-r--+ 1 root root 7 Jan 29 10:53 f1 33577446 -rw-r--r--. 1 user1 g12 0 Jan 19 19:58 f2 33577448 -rw-r--r--. 1 root root 62 Jan 29 10:57 test 33577447 -rw-r--r--. 1 root root 12288 Jan 29 10:58 .test.swp Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"3-文件管理/5-文件链接.html":{"url":"3-文件管理/5-文件链接.html","title":"第5节 文件链接","keywords":"","body":"第5节. 文件链接 硬链接，在同一个分区的不同目录下 不能针对文件夹 不能跨分区 data有3个inode ID的原因，是多一个子文件夹就多一个硬连接。 ll -i查看的连接数是硬连接数，与软连接无关。 硬连接如果使用相对路径是，相对的当前操作的路径。 软连接文件的大小是指向路径的长度决定的 软连接的原始文件要写相对于你要创建的连接文件的路径。 写相对路径，你直接复制/data复制重命名其他的，你的软连接一样使用OK。 软连接可以针对文件夹创建 删除软连接是个危险活~ 因为rm -rf d1.你一个tab键补全就是rm -rf d1.link/ ， 然后你删除的就是d1.link链接的那个源文件夹里的所有东西，而d1.link这个软链接本身并没有删除。 软连接、硬链接区别 1、本质上：硬链接-本质上是同一个文件多个名字；软连接-本质上是不同文件； 2、跨分区：硬链接不支持，软连接支持 3、目录创建：硬链接不支持；软连接支持 4、相互关系：硬链接是相互平等；软连接原始文件删除软连接失效 5、inode编号：硬链接是相同的；软连接不同 6、连接数：硬链接的创建删除会影响连接数；软连接删了这个文件就没了不存在连接数多个的问题。 7、路径问题：原始文件路径：硬链接创建是相对当前工作目录，软连接是相对于要创建的软连接的相对路径。 8、文件类型：软连接时l表示软连接；硬链接就是文件本身是啥类型就是啥。 9、颜色：软连接是蓝色、硬链接看原文件 10、命令实现不同：ln -s和ln linux的文件格式，不存在后缀一说，可以通过file xxx去判断该文件类型。 file -b # 只显示文件名本身 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"4-文本编辑工具vim/4-文本编辑工具vim.html":{"url":"4-文本编辑工具vim/4-文本编辑工具vim.html","title":"第四章 文本编辑工具vim","keywords":"","body":"第四章 文本编辑工具vim Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"4-文本编辑工具vim/1-vim.html":{"url":"4-文本编辑工具vim/1-vim.html","title":"第1节 vim","keywords":"","body":"第1节. vim 大篇幅编辑使用软件如vscode的plugin弄就行了。 会用到的备忘： :set nu 删除100dd,dGG,dgg ^$切换行尾行首w光标移动一个空格 vim +10 xxx # 打开就进入了第10行 vim 颜色也不是都加的，/etc/passwd，复制到/data下再vim就会发现颜色没了。/etc/下的属于系统配置文件，所以给你加颜色了。 vim -m 只读打开 /XXX搜索，nN u撤销 U 改行的修改全部撤销 s/要查找的内容/替换的内容/修饰符 这是正则，后面到了正则再说 整个文件的内容vim里替换用%s :%s/XXX/YYY/g /可以替换的 :%s#/dev#/tmp#g 0的ASCI码 cat也看不到 可以这么看二进制文件 00000000这是位置，后面00 00 00是内容 批量注释会有用 复制到vim里，空行格式错位，可以试试 :set paste 这个比较好用， 跳行同学的福音 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"5-标准I&O和管道/5-标准I&O和管道.html":{"url":"5-标准I&O和管道/5-标准I&O和管道.html","title":"第五章 标准I&O和管道","keywords":"","body":"第五章 标准I&O和管道 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"5-标准I&O和管道/1-标准输入输出和重定向.html":{"url":"5-标准I&O和管道/1-标准输入输出和重定向.html","title":"第1节 标准输入输出和重定向","keywords":"","body":"第1节. 标准输入输出和重定向 三种I/O设备 把I/O重定向到文件 使用管道 标准输入 每打开一个文件，系统都会分配一个数字编号对应该文件， 可见一个文件会有4个描述符与之对应，退出tail后，这里的对应关系就没了。 可以看到tail -f .bashrc，系统分配了一个3的文件描述符-软连接指向。 而0 1 2是输入输出信息对应的设备文件描述符，什么意思，就是你对.bashrc文件进行操作，会存在各种交互信息，正常的，错误的，等等从键盘输入的，打印到屏幕的。 关于输出重定向的小例子 > # 这是标准输出的重定向 以下命令特别的一个：C ls /data /xxx 2> all.log 1>&2 ls /data /xxx &> all.log ls /data /xxx 2>&1 all.log # 打印到屏幕上去了 ls /data /xxx > all.log 2>&1 以上是标准输出 标准输入 tr的一些用法 tr abcde 123 tr -t abcde 123 tr [:lower:] [:upper:] tr -d '135' tr -s 'ace' tr就可以和标准输入结合 所以转换的话，也可以用tr来做 tr可以转换、压缩、删除，也方便了。 上图是CTRL+D结束才会看到结果。是除了a、b、c以外的都删了。 单行重定向举例 此时多开一个窗口可见aaa已近写进去了 多行重定向 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"5-标准I&O和管道/2-管道实现重定向.html":{"url":"5-标准I&O和管道/2-管道实现重定向.html","title":"第2节 管道实现重定向","keywords":"","body":"第2节. 管道实现重定向 如何对错误信息进行管道符传递 上图：管道符|只能处理标准输出，而标准错误无法传递，不过可以下图做法： 上图有两种写法，最后的|&是相对2>&1晚一些时间出来的写法。 换种邮件正文的写法 bc的灵活用法 tee的意义 tee会覆盖 tee的追加效果 tee的意义 计算1+2+3+ ... +100 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"6-用户、用户组和权限/6-用户、用户组和权限.html":{"url":"6-用户、用户组和权限/6-用户、用户组和权限.html","title":"第六章 用户、用户组和权限","keywords":"","body":"第六章 用户、用户组和权限 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"6-用户、用户组和权限/1-用户和组的增删改查.html":{"url":"6-用户、用户组和权限/1-用户和组的增删改查.html","title":"第1节 用户和组的增删改查","keywords":"","body":"第1节. 用户和组的增删改查 AAA authentication、authorization、accouting|audition UID windows看用户和组 windows里user和group 不能同名，但是在linux里是正常情况。 早期密码是放在/etc/passwd里的，后买放到shaow里，可以回归早期的情况 pwunconv # 密码放到/etc/passwd里 pwconv # 密码放到/etc/shadow里 UID才是关键，将root的UID改成1000，它就不是管理员了。 如果没有一个user的UID=0，重启就起不来了。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"6-用户、用户组和权限/2-用户和组的权限管理.html":{"url":"6-用户、用户组和权限/2-用户和组的权限管理.html","title":"第2节 用户和组的权限管理","keywords":"","body":"第2节. 用户和组的权限管理 /etc/shaow字段说明 useradd -r ming [09:19:15 root@localhost ~]#echo cisco | passwd --stdin ming Changing password for user ming. passwd: all authentication tokens updated successfully. ming:$6$AUsIFTgTuY/hWn8Y$0PgiuhWLxBGeGRtbd/Niz5R1EsMRvV3gdSRT45jnXMyZisgBzcCybETswhJzuuUQeIPkO/gMzo3rKyXvRAE6h.:19008:::::: ---上面是rocke-linux复制过来的---下面是centos----- ming:$6$nfkcZ5x7$Le5WQnLSUiJbw2tdXiilhvVZFGy69iuzKQq2XoA84jrHtrOp8fwQgMyunGIt1wQimPf37xdUL7B6rCOvpSaDE0:19008:0:99999:7::: [root@centos7 ~]# 这些字段的帮助信息可通过man 5 shadow获得 $6 ：表示sha512 $1 ：表示md5 👇注意第一个时间字段=0的特殊功效，就是首次登入修改密码 你改口令的时间距离1970-1-1号的时间 date of last password change The date of the last password change, expressed as the number of days since Jan 1, 1970. The value 0 has a special meaning, which is that the user should change her pasword the next time she will log in the system. An empty field means that password aging features are disabled. # 这句其实不对，该字段为空，后面设置了超时，实际还是超的 [09:25:26 root@localhost ~]#echo `date +%s`/86400 |bc 19008 这就是上图ming用户的19008的由来 minimum password age 用户必须等多久才能修改口令，0就是可以立即修改密码，以天为单位，centos8里默认是0，rocke-linux默认为空 maximum password age 用户不改密码，密码多久到期，以天为单位，centos8默认99999，rocke-linux/centos7默认为空 password warning period 上面的最大密码时间意味着过期，而过期前提前7天会提醒你修改密码，但是实际情况是提前6天，因为那个提前的第7天是也可继续用的，而且时间是当天8点0分0秒作为天数24小时去算的，可能是GTM+8估计。估计这2个小点就可以问住一拨人 [root@centos7 ~]# date -s \"+5 day\" # 这个必须root才能修改成功 Fri Jan 21 09:40:55 CST 2022 [root@centos7 ~]# date 然后再将本地时间延后10天，此时在用ming登入看看 [root@centos7 ~]# date -s \"+5 day\" Wed Jan 26 09:44:25 CST 2022 [root@centos7 ~]# date -s \"+5 day\" Mon Jan 31 09:45:03 CST 2022 [root@centos7 ~]# password inactivity period 围绕着密码过期时间--maximum password age，如果超过这个时间X天就禁用该账号，这个X就是password inactivity period的意思。 ming:$6$nfkcZ5x7$Le5WQnLSUiJbw2tdXiilhvVZFGy69iuzKQq2XoA84jrHtrOp8fwQgMyunGIt1wQimPf37xdUL7B6rCOvpSaDE0:19008:0:10:7:5:: account expiration date 账户有效期，前面都是针对密码过期的，这个参数是针对账号的 注意这里和前一张图的区别，已经不再说authentication的事了，直接说的事账号挂了。 /etc/group和/etc/gshadow dbus:x:81: polkitd:x:998: ssh_keys:x:997: sshd:x:74: postdrop:x:90: postfix:x:89: user1:x:1000: ming:x:1001: [root@centos7 ~]# cat /etc/group systemd-journal:!:: systemd-network:!:: dbus:!:: polkitd:!:: ssh_keys:!:: sshd:!:: postdrop:!:: postfix:!:: user1:!:: ming:!:: [root@centos7 ~]# cat /etc/gshadow 组设置口令是给普通用户加组的权限， 附加组显示在/etc/group里的行最后一个字段 ming:x:1001:user1 user1用户就加入进了ming这个组，ming就是user1的附加组 /etc/gshadow 存放组口令的文件 ming:!!::user1,user2,user3 !!组密码禁用的，不能通过组口令来往里加成员，只能是root管理了 ::里放的是管理员账号，每个组可以设置管理员,用来添加删除组成员，默认为空就只有root管理 user1,user2,user3就是和/etc/group一样，加入该组的成员就罗列在这里 随机口令的产生 [root@centos7 ~]# openssl rand -base64 9 rvgumQ+4U67t [root@centos7 ~]# openssl rand -base64 9 328culZ3wpV1 [root@centos7 ~]# yum -y install expect 查看man手册： FLAGS The -l flag defines the length of the password. The default is 9. The following example creates a 20 character password. mkpasswd -l 20 The -d flag defines the minimum number of digits that must be in the password. The default is 2. The following example creates a password with at least 3 digits. mkpasswd -d 3 The -c flag defines the minimum number of lowercase alphabetic characters that must be in the password. The default is 2. The -C flag defines the minimum number of uppercase alphabetic characters that must be in the password. The default is 2. EXAMPLE The following example creates a 15-character password that contains at least 3 digits and 5 uppercase characters. mkpasswd -l 15 -d 3 -C 5 [root@centos7 ~]# mkpasswd -l 15 -d 3 -C 5 \\Dpbel2VZa8Dv9W [root@centos7 ~]# mkpasswd -l 15 -d 3 -C 5 m0hsZaXZ*O1Dap9 [root@centos7 ~]# mkpasswd -l 15 -d 3 -C 5 zBfuS0evQP6x1H/ C:\\Users\\MingYi>net accounts 强制用户在时间到期之后多久必须注销?: 从不 密码最短使用期限(天): 0 密码最长使用期限(天): 42 密码长度最小值: 0 保持的密码历史记录长度: None 锁定阈值: 从不 锁定持续时间(分): 30 锁定观测窗口(分): 30 计算机角色: WORKSTATION 命令成功完成。 真要改这个时间，不推荐上文的直接修改/etc/shadow，而是用命令去改 [12:33:30 root@localhost ~]#chage ming Changing the aging information for ming Enter the new value, or press ENTER for the default Minimum Password Age [-1]: 2 Maximum Password Age [-1]: 33 Last Password Change (YYYY-MM-DD) [2022-01-16]: Password Expiration Warning [-1]: 7 Password Inactive [-1]: Account Expiration Date (YYYY-MM-DD) [-1]: 2023-01-16 [12:34:26 root@localhost ~]# ----改时间---- 这里rockety-linux还弄出个-1出来，呵呵，反正估计也是不限制的意思 [12:36:06 root@localhost ~]#getent shadow ming ming:$6$AUsIFTgTuY/hWn8Y$0PgiuhWLxBGeGRtbd/Niz5R1EsMRvV3gdSRT45jnXMyZisgBzcCybETswhJzuuUQeIPkO/gMzo3rKyXvRAE6h.:19008:2:33:7::19373: [12:36:13 root@localhost ~]# [12:36:26 root@localhost ~]#getent passwd ming ming:x:992:988::/home/ming:/bin/bash [12:36:34 root@localhost ~]# [12:36:36 root@localhost ~]#getent group ming ming:x:988: [12:36:48 root@localhost ~]#getent gshadow ming ming:!:: [12:36:53 root@localhost ~]# [12:36:54 root@localhost ~]#getent passwd ming root ming:x:992:988::/home/ming:/bin/bash root:x:0:0:root:/root:/bin/bash [12:37:02 root@localhost ~]# vipw和vigr 编辑passwd和group的推荐命令 pwck和grpck 检查passwd和group的命令 [12:38:19 root@localhost ~]#pwck [user 'cockpit-ws': directory '/nonexisting' does not exist user 'cockpit-wsinstance': directory '/nonexisting' does not exist user 'ming': directory '/home/ming' does not exist pwck: no changes [12:39:02 root@localhost ~]#grpck [12:39:11 root@localhost ~]#ll /home/ total 0 groupadd 创建组 创建组 [13:39:41 root@localhost ~]#groupadd admins [13:39:50 root@localhost ~]#getent group admins admins:x:1000: [13:40:00 root@localhost ~]# 创建系统组 [13:40:46 root@localhost ~]#groupadd -r mysql [13:40:50 root@localhost ~]# [13:40:52 root@localhost ~]#getent group mysql mysql:x:987: [13:40:55 root@localhost ~]# 修改组名 [13:42:45 root@localhost ~]#getent group admins admins:x:1000: [13:42:50 root@localhost ~]#groupmod -n mgmt admins [13:42:56 root@localhost ~]#getent group mgmt mgmt:x:1000: 删除组 [13:44:06 root@localhost ~]#getent group mgmt mgmt:x:1000: [13:44:08 root@localhost ~]#getent group mysql mysql:x:987: [13:44:10 root@localhost ~]#groupdel mgmt [13:44:18 root@localhost ~]#groupdel mysql [13:44:20 root@localhost ~]#getent group mysql [13:44:23 root@localhost ~]#getent group mgmt 删不掉组的原因 [13:49:33 root@localhost ~]#groupdel ming groupdel: cannot remove the primary group of user 'ming' 是因为有用户将ming作为主组，这个用户就是ming自己。是useradd创建ming的时候自动生成的主组。 [13:49:43 root@localhost ~]#useradd ming2 [13:51:05 root@localhost ~]#getent group ming2 ming2:x:1000: [13:51:23 root@localhost ~]#groupdel ming2 groupdel: cannot remove the primary group of user 'ming2' [13:51:32 root@localhost ~]#userdel ming2 [13:51:39 root@localhost ~]#getent group ming2 [13:51:45 root@localhost ~]#ll /home/ total 0 drwx------. 2 1000 1000 62 Jan 16 13:51 ming2 userdel 删除用户连带组，但不会连带家目录，所以关于创建用户和删除用户的时候要注意家目录是否连带生成和删除 man useradd -r, --system Create a system account. System users will be created with no aging information in /etc/shadow, and their numeric identifiers are chosen in the SYS_UID_MIN-SYS_UID_MAX range, defined in /etc/login.defs, instead of UID_MIN-UID_MAX (and their GID counterparts for the creation of groups). Note that useradd will not create a home directory for such a user, regardless of the default setting in /etc/login.defs (CREATE_HOME). You have to specify the -m options if you want a home directory for a system account to be created. man userdel -f, --force This option forces the removal of the user account, even if the user is still logged in. It also forces userdel to remove the user's home directory and mail spool, even if another user uses the same home directory or if the mail spool is not owned by the specified user. If USERGROUPS_ENAB is defined to yes in /etc/login.defs and if a group exists with the same name as the deleted user, then this group will be removed, even if it is still the primary group of another user. Note: This option is dangerous and may leave your system in an inconsistent state. -h, --help Display help message and exit. -r, --remove Files in the user's home directory will be removed along with the home directory itself and the user's mail spool. Files located in other file systems will have to be searched for and deleted manually. The mail spool is defined by the MAIL_DIR variable in the login.defs file. [14:01:12 root@localhost ~]#useradd ming2 useradd: warning: the home directory already exists. Not copying any file from skel directory into it. Creating mailbox file: File exists [14:01:18 root@localhost ~]# [14:01:18 root@localhost ~]# [14:01:18 root@localhost ~]#getent passwd ming2 ming2:x:1000:1000::/home/ming2:/bin/bash [14:01:22 root@localhost ~]# [14:01:23 root@localhost ~]#ll /home/ total 0 drwx------. 2 ming2 ming2 62 Jan 16 13:51 ming2 [14:01:25 root@localhost ~]# [14:01:26 root@localhost ~]#userdel -r ming2 [14:01:30 root@localhost ~]#ll /home/ total 0 [14:01:32 root@localhost ~]#getent passwd ming2 [14:01:39 root@localhost ~]#getent group ming2 [14:01:43 root@localhost ~]# 用户创建管理 [14:03:53 root@localhost ~]#rpm -q --scripts postfix preinstall scriptlet (using /bin/sh): # Add user and groups if necessary /usr/sbin/groupadd -g 90 -r postdrop 2>/dev/null /usr/sbin/groupadd -g 89 -r postfix 2>/dev/null /usr/sbin/groupadd -g 12 -r mail 2>/dev/null /usr/sbin/useradd -d /var/spool/postfix -s /sbin/nologin -g postfix -G mail -M -r -u 89 postfix 2>/dev/null ------------------------- -g 90 gid -r 指定为系统组 useradd的选项学习 /usr/sbin/useradd -d /var/spool/postfix -s /sbin/nologin -g postfix -G mail -M -r -u 89 postfix 2>/dev/null -u 89 ： 指定用户UID为89 -s : 指定shell类型 -o ： 忽略uid唯一性的检查 [14:12:58 root@localhost ~]#getent passwd root root:x:0:0:root:/root:/bin/bash [14:13:09 root@localhost ~]#useradd -u 0 ming3 useradd: UID 0 is not unique [14:13:20 root@localhost ~]#getent passwd ming3 [14:13:36 root@localhost ~]#useradd -u 0 -o ming3 [14:13:42 root@localhost ~]#getent passwd ming3 ming3:x:0:1000::/home/ming3:/bin/bash [14:13:43 root@localhost ~]#getent passwd root root:x:0:0:root:/root:/bin/bash [14:14:47 root@localhost ~]#id root uid=0(root) gid=0(root) groups=0(root) [14:14:49 root@localhost ~]#id ming3 uid=0(root) gid=0(root) groups=0(root) [14:14:51 root@localhost ~]# 创建系统服务， [14:18:18 root@localhost ~]#useradd -r -s /sbin/nologin mysql [14:18:26 root@localhost ~]#getent passwd mysql mysql:x:991:987::/home/mysql:/sbin/nologin 默认行为是useradd不指定主组，就会自动创建和用户名同名的主组 [14:21:35 root@localhost ~]#useradd alice [14:21:48 root@localhost ~]#id alice uid=1000(alice) gid=1000(alice) groups=1000(alice) 通过-g指定主组，就不会自动创建主组了，指定的组要事先存在 [14:22:33 root@localhost ~]#useradd tom -g alice [14:22:58 root@localhost ~]#id tom uid=1001(tom) gid=1000(alice) groups=1000(alice) -G 是附加组 [14:24:10 root@localhost ~]#groupadd g1 [14:24:13 root@localhost ~]#groupadd g2 [14:24:21 root@localhost ~]#groupadd g3 [14:24:23 root@localhost ~]# [14:24:24 root@localhost ~]#useradd jack -g alice -G g1,g2 [14:24:44 root@localhost ~]#id jack uid=1002(jack) gid=1000(alice) groups=1000(alice),1001(g1),1002(g2) [14:26:44 root@localhost ~]#getent group | grep jack g1:x:1001:jack g2:x:1002:jack [14:26:49 root@localhost ~]#getent gshadow | grep jack g1:!::jack g2:!::jack [14:26:55 root@localhost ~]# -N 不创建同名的主组，也不指定，就默认创建一个users [14:28:06 root@localhost ~]#useradd rose -N [14:28:15 root@localhost ~]#id rose uid=1003(rose) gid=100(users) groups=100(users) [14:28:18 root@localhost ~]# 看下windows的创建用户的默认行为，默认就是和linux的useradd -N一样的，都是将新建用户放到users组下面。 C:\\WINDOWS\\system32>net user test001 passwd001 /add 命令成功完成。 C:\\WINDOWS\\system32>net user \\\\DESKTOP-5T7A4A1 的用户帐户 ------------------------------------------------------------------------------- ___VMware_Conv_SA___ admin Administrator ciscoacvpnuser DefaultAccount Guest MingYi named test001 WDAGUtilityAccount 命令成功完成。 C:\\WINDOWS\\system32>net localgroup users 别名 users 注释 防止用户进行有意或无意的系统范围的更改，但是可以运行大部分应用程序 成员 ------------------------------------------------------------------------------- NT AUTHORITY\\Authenticated Users NT AUTHORITY\\INTERACTIVE test001 命令成功完成。 C:\\WINDOWS\\system32>net user \\\\DESKTOP-5T7A4A1 的用户帐户 ------------------------------------------------------------------------------- ___VMware_Conv_SA___ admin Administrator ciscoacvpnuser DefaultAccount Guest MingYi named test001 WDAGUtilityAccount 命令成功完成。 C:\\WINDOWS\\system32>net user test001 /del 命令成功完成。 C:\\WINDOWS\\system32>net user \\\\DESKTOP-5T7A4A1 的用户帐户 ------------------------------------------------------------------------------- ___VMware_Conv_SA___ admin Administrator ciscoacvpnuser DefaultAccount Guest MingYi named WDAGUtilityAccount 命令成功完成。 关于家目录 不带家目录的方式，useradd -r -s /sbin/nologin mysql [14:35:33 root@localhost ~]#getent passwd | tail -5 mysql:x:991:987::/home/mysql:/sbin/nologin alice:x:1000:1000::/home/alice:/bin/bash tom:x:1001:1000::/home/tom:/bin/bash jack:x:1002:1000::/home/jack:/bin/bash rose:x:1003:100::/home/rose:/bin/bash [14:35:38 root@localhost ~]#ll /home/ total 0 drwx------. 2 alice alice 62 Jan 16 14:21 alice drwx------. 2 jack alice 62 Jan 16 14:24 jack drwx------. 2 rose users 62 Jan 16 14:28 rose drwx------. 2 tom alice 62 Jan 16 14:22 tom [14:35:43 root@localhost ~]# 指定创建家目录 [14:43:13 root@localhost ~]#useradd -d /data/jerryhome jerry [14:43:18 root@localhost ~]#ll /data/jerryhome/ -d drwx------. 2 jerry jerry 62 Jan 16 14:43 /data/jerryhome/ [14:43:29 root@localhost ~]#id jerry uid=1004(jerry) gid=1004(jerry) groups=1004(jerry) [14:43:32 root@localhost ~]# 有个奇怪的行为，就是创建用户的时候指定家目录，但是并不创建 [14:46:22 root@localhost ~]#useradd -d /data/xiaohong -M xiaohong [14:46:36 root@localhost ~]#id xiaohong uid=1005(xiaohong) gid=1005(xiaohong) groups=1005(xiaohong) [14:46:38 root@localhost ~]#ll /data/xiao* ls: cannot access '/data/xiao*': No such file or directory 还有与之相反的思路，useradd -r是系统用户不会创建家目录，-m就是会创建了 [14:47:50 root@localhost ~]#useradd -r zhangsan [14:48:09 root@localhost ~]#id zhangsan uid=990(zhangsan) gid=986(zhangsan) groups=986(zhangsan) [14:48:10 root@localhost ~]#ll /home/ total 0 drwx------. 2 alice alice 62 Jan 16 14:21 alice drwx------. 2 jack alice 62 Jan 16 14:24 jack drwx------. 2 rose users 62 Jan 16 14:28 rose drwx------. 2 tom alice 62 Jan 16 14:22 tom [14:48:14 root@localhost ~]# [14:48:14 root@localhost ~]#useradd -r lisi -m [14:48:33 root@localhost ~]#ll /home/lisi/ -d drwx------. 2 lisi lisi 62 Jan 16 14:48 /home/lisi/ [14:48:38 root@localhost ~]# [14:49:16 root@localhost ~]#useradd -r -m -d /data/ada ada [14:49:20 root@localhost ~]#ll /data/ada -d drwx------. 2 ada ada 62 Jan 16 14:49 /data/ada [14:49:24 root@localhost ~]#id ada uid=988(ada) gid=988(ada) groups=988(ada) [14:49:26 root@localhost ~]# -c : 描述信息，有点用的，讲究人士的专用 [14:51:48 root@localhost ~]#useradd -c \"sbZhuanYong\" sb001 [14:52:21 root@localhost ~]#getent passwd sb001 sb001:x:1006:1006:sbZhuanYong:/home/sb001:/bin/bash [14:52:26 root@localhost ~]# 如果是centos可以yum -y install finger然后查看用户描述信息，rokey-linux好像yum不了finger，yum源rocky的里面貌似没有finger 的rpm包。 [root@centos7 ~]# useradd -c 'dalaozhuanyong' dalao001 [root@centos7 ~]# getent passwd dalao001 dalao001:x:1002:1002:dalaozhuanyong:/home/dalao001:/bin/bash [root@centos7 ~]# [root@centos7 ~]# finger dalao001 Login: dalao001 Name: dalaozhuanyong Directory: /home/dalao001 Shell: /bin/bash Never logged in. No mail. No Plan. [root@centos7 ~]# -----改描述------desc--------- [root@centos7 ~]# chfn dalao001 Changing finger information for dalao001. Name [dalaozhuanyong]: Office []: !wgame Office Phone []: 110 Home Phone []: 110 Finger information changed. [root@centos7 ~]# finger dalao001 Login: dalao001 Name: dalaozhuanyong Directory: /home/dalao001 Shell: /bin/bash Office: !wgame, 110 Home Phone: 110 Never logged in. No mail. No Plan. [root@centos7 ~]# getent passwd dalao001 dalao001:x:1002:1002:dalaozhuanyong,!wgame,110,110:/home/dalao001:/bin/bash [root@centos7 ~]# 所以人家postfix的安装后或者前，跑的脚本里的useradd就能理解了 [root@centos7 ~]# rpm -q --scripts postfix preinstall scriptlet (using /bin/sh): # Add user and groups if necessary /usr/sbin/groupadd -g 90 -r postdrop 2>/dev/null /usr/sbin/groupadd -g 89 -r postfix 2>/dev/null /usr/sbin/groupadd -g 12 -r mail 2>/dev/null /usr/sbin/useradd -d /var/spool/postfix -s /sbin/nologin -g postfix -G mail -M -r -u 89 postfix 2>/dev/null [15:08:55 root@localhost yum.repos.d]#yum -y remove postfix [15:10:09 root@localhost yum.repos.d]#groupadd -r postfix [15:11:58 root@localhost yum.repos.d]#groupadd postfix-1 [15:12:02 root@localhost yum.repos.d]# [15:12:03 root@localhost yum.repos.d]#getent group postfix postfix:x:984: [15:12:09 root@localhost yum.repos.d]#getent group postfix-1 postfix-1:x:1007: [15:12:12 root@localhost yum.repos.d]# [15:12:16 root@localhost yum.repos.d]#id postfix id: ‘postfix’: no such user [15:12:19 root@localhost yum.repos.d]#/usr/sbin/useradd -d /var/spool/postfix -s /sbin/nologin -g postfix -G mail -M -r -u 89 postfix [15:12:23 root@localhost yum.repos.d]#id postfix uid=89(postfix) gid=984(postfix) groups=984(postfix),12(mail) [15:12:28 root@localhost yum.repos.d]#ll /home/pos* ls: cannot access '/home/pos*': No such file or directory [15:12:33 root@localhost yum.repos.d]#ll /var/spool/pos* ls: cannot access '/var/spool/pos*': No such file or directory [15:12:43 root@localhost yum.repos.d]# 其实-M没有意义，就是保险，-r本身就不会创建家目录。 注意下，不管是不是需要userdel -r 加不加r都要去确认下家目录是否真的删除，因为我操作时候发现有时候不加-r，好像也是把家目录删了。这个是在rockey-linux上操作的。 默认useradd的行为有文件定义的 [15:25:22 root@localhost ~]#cat /etc/default/useradd # useradd defaults file GROUP=100 HOME=/home INACTIVE=-1 EXPIRE= SHELL=/bin/bash SKEL=/etc/skel CREATE_MAIL_SPOOL=yes [15:25:27 root@localhost ~]#getent group users users:x:100: [15:26:08 root@localhost ~]# GROUP = 100 默认useradd -N 不创建主组的时候，自动加到users主组里，这个行为就是GROUP=100设置的。 INACTIVE=-1 默认用密码过期后 是否给宽限期，默认是永远宽限。 HOME=/home 默认家目录在哪 CREATE_MAIL_SPOOL=yes 默认用户创建的时候创建它的邮箱， [15:26:08 root@localhost ~]#ll /var/spool/mail/ total 0 -rw-rw----. 1 alice mail 0 Jan 16 14:21 alice -rw-rw----. 1 jack mail 0 Jan 16 14:24 jack -rw-rw----. 1 jerry mail 0 Jan 16 14:43 jerry -rw-rw----. 1 rose mail 0 Jan 16 14:28 rose -rw-rw----. 1 sb001 mail 0 Jan 16 14:52 sb001 -rw-rw----. 1 tom mail 0 Jan 16 14:22 tom -rw-rw----. 1 xiaohong mail 0 Jan 16 14:46 xiaohong SKEL=/etc/skel 默认创建家目录里的隐藏文件的由来 [15:33:50 root@localhost ~]#ls -a /etc/skel/ . .. .bash_logout .bash_profile .bashrc [15:33:53 root@localhost ~]# 所以如果需要创建用户，生成的家目录里自动带上什么文件，就有办法了 [15:36:42 root@localhost ~]#ls -a /etc/skel . .. .bash_logout .bash_profile .bashrc [15:36:51 root@localhost ~]# [15:37:01 root@localhost ~]#ls -a /home/ alice/ jack/ lisi/ rose/ sb001/ tom/ [15:37:01 root@localhost ~]#ls -a /home/alice/ . .. .bash_logout .bash_profile .bashrc [15:37:13 root@localhost ~]#touch /etc/skel/.vimrc [15:37:22 root@localhost ~]#ls -a /etc/skel/ . .. .bash_logout .bash_profile .bashrc .vimrc [15:37:32 root@localhost ~]#useradd test-1 [15:37:43 root@localhost ~]#ls -a /home/test-1/ . .. .bash_logout .bash_profile .bashrc .vimrc [15:37:49 root@localhost ~]# 还有个默认行为文件 [15:43:09 root@localhost ~]#cat /etc/login.defs | grep -Ev \"^#|^$\" MAIL_DIR /var/spool/mail UMASK 022 HOME_MODE 0700 PASS_MAX_DAYS 99999 # 口令最大有效期 PASS_MIN_DAYS 0 # 口令修改无需等待直接改 PASS_MIN_LEN 5 # 口令最短5个 PASS_WARN_AGE 7 UID_MIN 1000 # 默认普通用户UID从1000开始，就是这里设置的 UID_MAX 60000 # 这里的1000和60000都是自动的范围，手动除外 SYS_UID_MIN 201 # 系统UID自动范围 SYS_UID_MAX 999 # 系统UID自动范围 GID_MIN 1000 GID_MAX 60000 SYS_GID_MIN 201 SYS_GID_MAX 999 CREATE_HOME yes USERGROUPS_ENAB yes ENCRYPT_METHOD SHA512 # 默认的哈希算法，/etc/passwd里的$6 [15:43:16 root@localhost ~]# root 不受上述配置的限制 所以默认新建用户的相关文件如下 [15:51:36 root@localhost ~]#ll /etc/default/useradd -d -rw-r--r--. 1 root root 119 Aug 19 03:04 /etc/default/useradd [15:51:40 root@localhost ~]#ll /etc/skel -d drwxr-xr-x. 2 root root 76 Jan 16 15:37 /etc/skel [15:51:44 root@localhost ~]#ll /etc/login.defs -d -rw-r--r--. 1 root root 2512 Aug 19 03:04 /etc/login.defs /etc/default/useradd也可以用useradd -D查看 [15:53:09 root@localhost ~]#useradd -D GROUP=100 HOME=/home INACTIVE=-1 EXPIRE= SHELL=/bin/bash SKEL=/etc/skel CREATE_MAIL_SPOOL=yes [15:54:10 root@localhost ~]#cat /etc/default/useradd # useradd defaults file GROUP=100 HOME=/home INACTIVE=-1 EXPIRE= SHELL=/bin/bash SKEL=/etc/skel CREATE_MAIL_SPOOL=yes 1、直接修改文件 2、通过useradd修改 useradd -D -s SHELL类型 useradd -D -b BASE_DIR/home useradd -D -g GROUP默认useradd -N所带的组 [15:54:10 root@localhost ~]#cat /etc/default/useradd # useradd defaults file GROUP=100 HOME=/home INACTIVE=-1 EXPIRE= SHELL=/bin/bash SKEL=/etc/skel CREATE_MAIL_SPOOL=yes [15:54:22 root@localhost ~]#useradd -D -g 1000 [16:01:36 root@localhost ~]#cat /etc/default/useradd # useradd defaults file GROUP=1000 HOME=/home INACTIVE=-1 EXPIRE= SHELL=/bin/bash SKEL=/etc/skel CREATE_MAIL_SPOOL=yes [16:01:37 root@localhost ~]# 批量操作 newusers # passwd格式文件 批量创建用户 chpasswd # 批量修改用户口令 将/etc/passwd文件里的格式复制出来，放入单个文件，然后到别的机器上newusers xxx即可创建 user1:x:1008:1009::/home/user1:/bin/bash user2:x:1009:1010::/home/user2:/bin/bash user3:x:1010:1011::/home/user3:/bin/bash user4:x:1011:1012::/home/user4:/sbin/nologin [13:58:02 root@localhost ~]#getent passwd -----看下👇创建的具体过程---------- [root@centos7 ~]# cat addusers user1:x:1008:1009::/home/user1:/bin/bash user2:x:1009:1010::/home/user2:/bin/bash user3:x:1010:1011::/home/user3:/bin/bash user4:x:1011:1012::/home/user4:/sbin/nologin [root@centos7 ~]# newusers addusers newusers: line 5: invalid line newusers: line 6: invalid line newusers: error detected, changes ignored [root@centos7 ~]# cat addusers -n 1 user1:x:1008:1009::/home/user1:/bin/bash 2 user2:x:1009:1010::/home/user2:/bin/bash 3 user3:x:1010:1011::/home/user3:/bin/bash 4 user4:x:1011:1012::/home/user4:/sbin/nologin 5 6 [root@centos7 ~]# ---------👆可惜报错鸟------------ 删掉多余的空行后，尝试👇----------- [root@centos7 ~]# cat addusers user1:x:1008:1009::/home/user1:/bin/bash user2:x:1009:1010::/home/user2:/bin/bash user3:x:1010:1011::/home/user3:/bin/bash user4:x:1011:1012::/home/user4:/sbin/nologin [root@centos7 ~]# [root@centos7 ~]# newusers addusers [root@centos7 ~]# getent passwd |grep user* user1:x:1000:1000::/home/user1:/bin/bash user2:x:1009:1010::/home/user2:/bin/bash user3:x:1010:1011::/home/user3:/bin/bash user4:x:1011:1012::/home/user4:/sbin/nologin [root@centos7 ~]# -------------然后再批量改口令方法1👇-------------- [root@centos7 ~]# chpasswd user1:cisco # ctrl d安全退出才能生效 [root@centos7 ~]# getent shadow user1 user1:$6$dR6ZP/lQ5aA$V6xJwgibZELgZh2NKOVDSez8CTzw6h05NX.n/Ft4ZpGtlVNfNEpkpTFRdZqkSQWKKgeZ/BxKgfSm2BRcFaMgo0:19029:0:99999:7::: [root@centos7 ~]# chpasswd user1:huawei ^C # 不能ctrl c强制退出 [root@centos7 ~]# getent shadow user1 user1:$6$dR6ZP/lQ5aA$V6xJwgibZELgZh2NKOVDSez8CTzw6h05NX.n/Ft4ZpGtlVNfNEpkpTFRdZqkSQWKKgeZ/BxKgfSm2BRcFaMgo0:19029:0:99999:7::: [root@centos7 ~]# ------👆注意没截图就是方便后面搜索，但是要小心失真丢东西，这里是ctrl C强制退出，所以没改成功，很多这种交互式的配置都需要ctrl +d 退出。--------- ----非交互式配置方式👇------ [root@centos7 ~]# echo user1:lianxiang |chpasswd [root@centos7 ~]# getent shadow user1 user1:$6$A55IfCFmc$aJPxuWvGRvpTzNocXonzz/gEZTEjV7y3qcHSWEPvxZg1IfA0EUrXMMBpOsw9DXodx4KQ1yCa8SZCTiQtvDYu50:19029:0:99999:7::: [root@centos7 ~]# ---------批量改的方法👇---改口令1---------- [root@centos7 ~]# vi p.set [root@centos7 ~]# cat p.set user1:centos user2:cisco user3:huawei [root@centos7 ~]# cat p.set |chpasswd [root@centos7 ~]# getent shadow user1 user1:$6$PFoqG/41wd3x$PDCFFjFD84xNc2t4je5119lP.ifsTyspYRGnbP4Bx0QpP/9XRd4s9vUFICbEdoDv3pOd7y/7PBLuBsE6EXhwu/:19029:0:99999:7::: [root@centos7 ~]# getent shadow user2 user2:$6$0ilWD/oW7CN$IdC6Gz0.eJKdPBWuGx4KJR00GBrjoxE8KWtCp9lurmP1TaCQGcUra5.VscBTQZ5Um0lKYZO.qb6/fNyYiey0s1:19029:0:99999:7::: [root@centos7 ~]# getent shadow user3 user3:$6$Uv41MY/y9$Q1251b9f9CPX5/sQ1aDhITVsl9pbKEXJspkV4uib/ugaCAlMfg9/Xy4WJBdyq56SJF4k5YuIc0muouxLpi61T0:19029:0:99999:7::: [root@centos7 ~]# 查看id [root@centos7 ~]# id user1 uid=1000(user1) gid=1000(user1) groups=1000(user1) [root@centos7 ~]# id -u user1 1000 [root@centos7 ~]# id -g user1 1000 [root@centos7 ~]# id -G user1 1000 [root@centos7 ~]# id -n user1 id: cannot print only names or real IDs in default format [root@centos7 ~]# id -ng user1 user1 [root@centos7 ~]# id -ngG user1 id: cannot print \"only\" of more than one choice [root@centos7 ~]# id -nG user1 user1 usermod修改用户 [16:04:46 root@localhost ~]#id jack uid=1002(jack) gid=1000(alice) groups=1000(alice),1001(g1),1002(g2) [16:04:48 root@localhost ~]#usermod -g sb001 jack # 修改主组 [16:04:56 root@localhost ~]#id jack uid=1002(jack) gid=1006(sb001) groups=1006(sb001),1001(g1),1002(g2) [16:04:58 root@localhost ~]#usermod -G root jack # -G附加组要注意是覆盖性操作 [16:05:11 root@localhost ~]#id jack uid=1002(jack) gid=1006(sb001) groups=1006(sb001),0(root) [16:05:13 root@localhost ~]# 需要用到-aG,-a只能配合G用，因为其他属性不存在多个值。 [16:05:11 root@localhost ~]#id jack uid=1002(jack) gid=1006(sb001) groups=1006(sb001),0(root) [16:06:01 root@localhost ~]#usermod -aG g1,g2,g3 jack [16:06:12 root@localhost ~]#id jack uid=1002(jack) gid=1006(sb001) groups=1006(sb001),1001(g1),1002(g2),1003(g3),0(root) 空口令登入方法 关联用户锁定，就是不需要输入密码进行登入 修改/etc/shadow里的两个!!，没设置密码，就是两个!! [11:38:54 root@localhost ~]#cat /etc/shadow |grep lisi lisi:!!:19008:::::: [11:38:59 root@localhost ~]#vi /etc/shadow ][11:39:14 root@localhost ~]#cat /etc/shadow |grep lisi lisi::19008:::::: 修改/etc/passwd里的x拿掉，效果一样，无需密码，x就是占位，表示密码放在了/etc/shadow里。 [11:47:43 root@localhost ~]#cat /etc/passwd |grep sb001 sb001:x:1006:1006:sbZhuanYong:/home/sb001:/bin/bash [11:47:44 root@localhost ~]#vi /etc/passwd [11:48:00 root@localhost ~]#cat /etc/passwd |grep sb001 sb001::1006:1006:sbZhuanYong:/home/sb001:/bin/bash 注意这个好像没用了 锁定用户 [root@centos7 ~]# useradd test [root@centos7 ~]# getent passwd test test:x:1003:1003::/home/test:/bin/bash [root@centos7 ~]# getent shadow test test:!!:19029:0:99999:7::: # 新创建的用户是被锁定的 [root@centos7 ~]# getent group test test:x:1003: [root@centos7 ~]# getent gshadow test test:!:: -------↓--------设置密码后的变化------↓--------- [root@centos7 ~]# echo cisco |passwd --stdin test Changing password for user test. passwd: all authentication tokens updated successfully. [root@centos7 ~]# getent passwd test test:x:1003:1003::/home/test:/bin/bash [root@centos7 ~]# getent shadow test test:$6$QexkrOWQ$3e85TAtRmiYEMioZOU8QJ7qaD0xCP2lW4Dposctg7evJMRZy3kseNQXD.C21lKtXtqFnzGEhCnbiFq7yI4c5H.:19029:0:99999:7::: [root@centos7 ~]# getent group test test:x:1003: [root@centos7 ~]# getent gshadow test test:!:: -------👇------加锁后的变化---------- [root@centos7 ~]# usermod -L test [root@centos7 ~]# getent passwd test test:x:1003:1003::/home/test:/bin/bash [root@centos7 ~]# getent shadow test test:!$6$QexkrOWQ$3e85TAtRmiYEMioZOU8QJ7qaD0xCP2lW4Dposctg7evJMRZy3kseNQXD.C21lKtXtqFnzGEhCnbiFq7yI4c5H.:19029:0:99999:7::: # 锁是加在shadow里 [root@centos7 ~]# getent group test test:x:1003: [root@centos7 ~]# getent gshadow test test:!:: #gshadow这里一直都是这样的 [root@centos7 ~]# ------👇----解锁------ [root@centos7 ~]# usermod -U test [root@centos7 ~]# getent shadow test test:$6$QexkrOWQ$3e85TAtRmiYEMioZOU8QJ7qaD0xCP2lW4Dposctg7evJMRZy3kseNQXD.C21lKtXtqFnzGEhCnbiFq7yI4c5H.:19029:0:99999:7::: [root@centos7 ~]# -------👇如果是空口令是不给你解锁的---- [root@centos7 ~]# useradd ceshi [root@centos7 ~]# getent passwd ceshi ceshi:x:1004:1004::/home/ceshi:/bin/bash [root@centos7 ~]# getent shadow ceshi ceshi:!!:19029:0:99999:7::: [root@centos7 ~]# usermod -U ceshi usermod: unlocking the user's password would result in a passwordless account. You should set a password with usermod -p to unlock this user's password. 至于两个！！和一个！没啥区别，一来都是锁定。二来只要没有设置密码都不能-U解锁 不过可以vi进去解锁。 当然这个!可以加在passwd里的--通过vi手动加，usermod -L -U都是针对shadow操作，而且要比加在shadow里优先。 其实针对这个 echo \"cisco\" | passwd --sdtin test 这个非交互是的修改密码，其实我可以这样做 亲测有效稳定。 修改账号有效期 chage比它好 就是shadow文件里单行，倒数第二个字段--账号有效期，倒数第一字段保留字段。 [root@centos7 ~]# getent shadow test test:!$6$QexkrOWQ$3e85TAtRmiYEMioZOU8QJ7qaD0xCP2lW4Dposctg7evJMRZy3kseNQXD.C21lKtXtqFnzGEhCnbiFq7yI4c5H.:19029:0:99999:7::: [root@centos7 ~]# usermod -U test [root@centos7 ~]# usermod -e 2023-12-12 test [root@centos7 ~]# getent shadow test test:$6$QexkrOWQ$3e85TAtRmiYEMioZOU8QJ7qaD0xCP2lW4Dposctg7evJMRZy3kseNQXD.C21lKtXtqFnzGEhCnbiFq7yI4c5H.:19029:0:99999:7::19703: 设置密码宽限期 chage比它好 在最大超时时间到期后，你还能用几天 [root@centos7 ~]# getent shadow test test:$6$QexkrOWQ$3e85TAtRmiYEMioZOU8QJ7qaD0xCP2lW4Dposctg7evJMRZy3kseNQXD.C21lKtXtqFnzGEhCnbiFq7yI4c5H.:19029:0:99999:7::19703: [root@centos7 ~]# usermod -f 3 test [root@centos7 ~]# getent shadow test test:$6$QexkrOWQ$3e85TAtRmiYEMioZOU8QJ7qaD0xCP2lW4Dposctg7evJMRZy3kseNQXD.C21lKtXtqFnzGEhCnbiFq7yI4c5H.:19029:0:99999:7:3:19703: [root@centos7 ~]# 改时间还是用chage 交互式和非交互是都有 [root@centos7 ~]# chage test Changing the aging information for test Enter the new value, or press ENTER for the default Minimum Password Age [0]: Maximum Password Age [99999]: Last Password Change (YYYY-MM-DD) [2022-02-06]: Password Expiration Warning [7]: Password Inactive [3]: Account Expiration Date (YYYY-MM-DD) [2023-12-12]: [root@centos7 ~]# [root@centos7 ~]# chage -h Usage: chage [options] LOGIN Options: -d, --lastday LAST_DAY set date of last password change to LAST_DAY -E, --expiredate EXPIRE_DATE set account expiration date to EXPIRE_DATE -h, --help display this help message and exit -I, --inactive INACTIVE set password inactive after expiration to INACTIVE -l, --list show account aging information -m, --mindays MIN_DAYS set minimum number of days before password change to MIN_DAYS -M, --maxdays MAX_DAYS set maximum number of days before password change to MAX_DAYS -R, --root CHROOT_DIR directory to chroot into -W, --warndays WARN_DAYS set expiration warning days to WARN_DAYS [root@centos7 ~]# ------注意-E选项时间格式有点坑---------👇--人工写成YYYY-MM-DD----- [root@centos7 ~]# chage -E 10 test [root@centos7 ~]# getent shadow test test:$6$QexkrOWQ$3e85TAtRmiYEMioZOU8QJ7qaD0xCP2lW4Dposctg7evJMRZy3kseNQXD.C21lKtXtqFnzGEhCnbiFq7yI4c5H.:19029:0:99999:7:3:10: [root@centos7 ~]# chage -E 2022-12-12 test [root@centos7 ~]# getent shadow test test:$6$QexkrOWQ$3e85TAtRmiYEMioZOU8QJ7qaD0xCP2lW4Dposctg7evJMRZy3kseNQXD.C21lKtXtqFnzGEhCnbiFq7yI4c5H.:19029:0:99999:7:3:19338: [root@centos7 ~]# chage -I 2 test [root@centos7 ~]# getent shadow test test:$6$QexkrOWQ$3e85TAtRmiYEMioZOU8QJ7qaD0xCP2lW4Dposctg7evJMRZy3kseNQXD.C21lKtXtqFnzGEhCnbiFq7yI4c5H.:19029:0:99999:7:2:19338: [root@centos7 ~]# userdel删除用户 [root@centos7 ~]# ll /home/ total 0 drwx------. 2 ceshi ceshi 83 Feb 6 12:08 ceshi drwx------. 2 dalao001 dalao001 62 Feb 5 14:54 dalao001 drwx------. 2 ming ming 83 Jan 26 09:44 ming drwx------. 2 test test 83 Feb 6 12:08 test drwx------. 2 998 996 62 Feb 5 15:20 test001 drwx------. 2 user1 user1 96 Jan 10 14:16 user1 [root@centos7 ~]# [root@centos7 ~]# [root@centos7 ~]# ll /var/spool/mail/ total 0 -rw-rw----. 1 ceshi mail 0 Feb 6 12:06 ceshi -rw-rw----. 1 dalao001 mail 0 Feb 5 14:54 dalao001 -rw-rw----. 1 ming mail 0 Jan 16 09:28 ming -rw-rw----. 1 test mail 0 Feb 6 11:57 test -rw-rw----. 1 user1 mail 0 Jan 10 11:12 user1 [root@centos7 ~]# [root@centos7 ~]# userdel test [root@centos7 ~]# ll /home/test -d drwx------. 2 1003 1003 83 Feb 6 12:08 /home/test [root@centos7 ~]# ll /var/spool/mail/test -d -rw-rw----. 1 1003 mail 0 Feb 6 11:57 /var/spool/mail/test # 除了家目录，邮箱也要注意是否删除 [root@centos7 ~]# ------不要以为重新创建test用户能继续关联之前没有删除的家目录和邮箱---那是不可能的👇--因为此用户非彼用户，正所谓去年今日此门中，人面桃花相映红，人面不知何处去，桃花依旧笑春风一句话就是uid变了，要是uid没变还是可以对接回去的，或者你人工修改新建用户名的uid为之前的id就可以对接上了-- [root@centos7 ~]# useradd test useradd: warning: the home directory already exists. Not copying any file from skel directory into it. Creating mailbox file: File exists [root@centos7 ~]# [root@centos7 ~]# [root@centos7 ~]# ll /var/spool/mail/test -d -rw-rw----. 1 1003 mail 0 Feb 6 11:57 /var/spool/mail/test [root@centos7 ~]# ll /home/test -d drwx------. 2 1003 1003 83 Feb 6 12:08 /home/test [root@centos7 ~]# userdel -r test userdel: /var/spool/mail/test not owned by test, not removing userdel: /home/test not owned by test, not removing [root@centos7 ~]# ll /var/spool/mail/test -d -rw-rw----. 1 1003 mail 0 Feb 6 11:57 /var/spool/mail/test [root@centos7 ~]# ll /home/test test/ test001/ [root@centos7 ~]# ll /home/test -d drwx------. 2 1003 1003 83 Feb 6 12:08 /home/test [root@centos7 ~]# userdel -r test userdel: user 'test' does not exist -----选项 -r ----👇能够删除用户家目录和邮箱------- [root@centos7 ~]# useradd test2 [root@centos7 ~]# ll /home/test2 -d drwx------. 2 test2 test2 62 Feb 6 13:36 /home/test2 [root@centos7 ~]# ll /var/spool/mail/test2 -d -rw-rw----. 1 test2 mail 0 Feb 6 13:36 /var/spool/mail/test2 [root@centos7 ~]# userdel -r test2 [root@centos7 ~]# ll /home/test2 -d ls: cannot access /home/test2: No such file or directory [root@centos7 ~]# ll /var/spool/mail/test2 -d ls: cannot access /var/spool/mail/test2: No such file or directory [root@centos7 ~]# 附加，group如果是组里没有其他人，userdel 也会删除组的。 所以这里userdel，要注意 组、家目录、邮箱 信息是否有变化。user没了，group、家目录、邮箱如果在，那么这些文件的属性里的user id都会变成该用户的uid--数字，而不再是原来的用户名。而且1005也只是个空数字，并没有任何用户与其对应。 PATH内容随用户而变 变量变量，它是变的，root和user1的PATH变量的内容是不一样 [root@centos7 ~]# echo $PATH /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin [user1@centos7 ~]$ echo $PATH /usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/user1/.local/bin:/home/user1/bin [user1@centos7 ~]$ su 切换 su - user1 # 这种切换用户环境一并切换 su # 原地切换，pwd的所在路径都不变 ------------完全切换👇---------------- [root@centos7 data]# pwd /data [root@centos7 data]# su - user1 Last login: Sun Feb 6 16:10:51 CST 2022 on pts/0 [user1@centos7 ~]$ pwd /home/user1 [user1@centos7 ~]$ echo $PATH /usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/user1/.local/bin:/home/user1/bin [user1@centos7 ~]$ --------------原地切换👇-pwd和$path都不变的-------------- [root@centos7 data]# su user1 [user1@centos7 data]$ pwd /data [user1@centos7 data]$ echo $PATH /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin [user1@centos7 data]$ --------换个用户执行命令，本身不切换过去----👇-------------- [user1@centos7 data]$ su root -c \"getent shadow root\" Password: root:$6$Kih8C.5/adh8TNjx$wNC09CUb7KsECwLH1LFfAagv8N47OAEqSMHLlOuU.vB24ZzU/H5p6DLpNV31zLKlJioqNmXkIkQEaAUf0H74Z0::0:99999:7::: [user1@centos7 data]$ su活su - 直接回车就是切root，root参数默认就有 root 切换 普通用户 无需密码 普通用户 切换 root 需要密码 ubuntu默认不让root登入的情况 ubuntu默认root等不了，su 切换要密码，但是没设置过root密码默认就 root的口令情况，你非root用户也看不全 这个时候就的使用sudo命令咯 sudo -i 提示出入的是当前普通用户的口令---👇-- 不是每个账号都能sudo 切换到root的，之所以可以是因为系统安装的时候授予了wang账号可以切换。 所以ubuntu这里的！去掉，root就直接无口令登入了 ----而且上面知识运行了root本地登入👆-----远程root还是无法登入ubuntu-------- -----👇一般只有系统安装时设置的默认第一个账户才能sudo -i 切成root用户------ passwd的有用选项 [root@centos7 data]# type passwd # 外部命令，就是用--help去查看帮助，当然也可以man passwd is hashed (/usr/bin/passwd) [root@centos7 data]# passwd --help Usage: passwd [OPTION...] -k, --keep-tokens keep non-expired authentication tokens -d, --delete delete the password for the named account (root only) -l, --lock lock the password for the named account (root only) -u, --unlock unlock the password for the named account (root only) -e, --expire expire the password for the named account (root only) -f, --force force operation -x, --maximum=DAYS maximum password lifetime (root only) -n, --minimum=DAYS minimum password lifetime (root only) -w, --warning=DAYS number of days warning users receives before password expiration (root only) -i, --inactive=DAYS number of days after password expiration when an account becomes disabled (root only) -S, --status report password status on the named account (root only) --stdin read new tokens from stdin (root only) Help options: -?, --help Show this help message --usage Display brief usage message -d ： 删除密码 -l : 这个和usermode -L一样 -u: 这个和usermode -U一样 -e: 👈这个好，典型应用按理，强制用户首次登入修改密码的。 -n -x -w 这些和chage以及usermod差不多，都可以改，推荐chage或者passwd。 改口令的方法2 echo cisco | passwd --stdin user1 &> /dev/null 这个passwd怎么批量啊？密码和用户都是变量，密码可以放到文件里，cat file |重定向给passwd，问题时用户怎么弄呢？好像没有chpasswd方面呢~注意此处划重点敲黑板👉呢字带尾音~。其他技术问题忽略即可~ [root@centos7 data]# vi change_passwd.sh [root@centos7 data]# [root@centos7 data]# . change_passwd.sh # 这里也是个点，放到后面，就是脚本执行的N种方法 Changing password for user user1. passwd: all authentication tokens updated successfully. Changing password for user user2. passwd: all authentication tokens updated successfully. Changing password for user user3. passwd: all authentication tokens updated successfully. [root@centos7 data]# [root@centos7 data]# cat change_passwd.sh #!/bin/bash echo cisco |passwd --stdin user1 echo huawei |passwd --stdin user2 echo juniper |passwd --stdin user3 [root@centos7 data]# --------👇优化输出----------- [root@centos7 data]# . change_passwd.sh [root@centos7 data]# [root@centos7 data]# cat change_passwd.sh #!/bin/bash echo cisco |passwd --stdin user1 > /dev/null echo huawei |passwd --stdin user2 > /dev/null echo juniper |passwd --stdin user3 > /dev/null [root@centos7 data]# 修改shell类型 [root@centos7 data]# getent passwd user1 user1:x:1000:1000::/home/user1:/bin/bash [root@centos7 data]# chsh -s /sbin/nologin user1 Changing shell for user1. chsh: Warning: \"/sbin/nologin\" is not listed in /etc/shells. Shell changed. [root@centos7 data]# getent passwd user1 user1:x:1000:1000::/home/user1:/sbin/nologin [root@centos7 data]# cat /etc/shells /bin/sh /bin/bash /usr/bin/sh /usr/bin/bash [root@centos7 data]# -------- 等价于usermod -s --------- [root@centos7 data]# getent passwd user2 user2:x:1009:1010::/home/user2:/bin/bash [root@centos7 data]# usermod -s /sbin/nolgin user2 [root@centos7 data]# getent passwd user2 user2:x:1009:1010::/home/user2:/sbin/nolgin [root@centos7 data]# 组操作补充 附加组的操作 [root@centos7 data]# id user1 uid=1000(user1) gid=1000(user1) groups=1000(user1) [root@centos7 data]# usermod -G g11,g12 user1 usermod: group 'g11' does not exist usermod: group 'g12' does not exist [root@centos7 data]# groupadd g11 [root@centos7 data]# groupadd g12 [root@centos7 data]# usermod -G g11,g12 user1 [root@centos7 data]# id user1 uid=1000(user1) gid=1000(user1) groups=1000(user1),1013(g11),1014(g12) [root@centos7 data]# -------------删除附加组👇----------- [root@centos7 data]# usermod -G \"\" user1 [root@centos7 data]# id user1 uid=1000(user1) gid=1000(user1) groups=1000(user1) [root@centos7 data]# 查看组信息的其他方法 [root@centos7 data]# usermod -G g11,g12 user1 [root@centos7 data]# groups user1 user1 : user1 g11 g12 [root@centos7 data]# [root@centos7 data]# gpasswd --help Usage: gpasswd [option] GROUP Options: -a, --add USER add USER to GROUP -d, --delete USER remove USER from GROUP -h, --help display this help message and exit -Q, --root CHROOT_DIR directory to chroot into -r, --delete-password remove the GROUP's password -R, --restrict restrict access to GROUP to its members -M, --members USER,... set the list of members of GROUP -A, --administrators ADMIN,... set the list of administrators for GROUP Except for the -A and -M options, the options cannot be combined. [root@centos7 data]# gpasswd -a user1 root Adding user user1 to group root [root@centos7 data]# id user1 uid=1000(user1) gid=1000(user1) groups=1000(user1),0(root),1013(g11),1014(g12) [root@centos7 data]# 有时候发现直接图片更好看一些，要不还是放弃cli复制了，直接图片吧，补充关键字就好。 给组设置口令 某个普通用户要加入某个组，就用到了组密码 id user1 su - user1 touch file1 ll file1 希望创建的文件主组时g12，可修改user1的主组为g12， newgrp g12 user1 -------👆 上图的newgrp时临时有效的，exit后就退出来临时的主组了，👇见下图------ root一样可以 永久的修改就用usermod -g 一些操作排查踩坑记录 因为user3创建之前就有同名的家目录，所以带来一些问题：这也是su user3为什么显示-bash-4.2$ 的原因 查看附加组 [root@centos7 ~]# id ming uid=1001(ming) gid=1001(ming) groups=1001(ming) [root@centos7 ~]# [root@centos7 ~]# [root@centos7 ~]# groupmems --help Usage: groupmems [options] [action] Options: -g, --group groupname change groupname instead of the user's group (root only) -R, --root CHROOT_DIR directory to chroot into Actions: -a, --add username add username to the members of the group -d, --delete username remove username from the members of the group -h, --help display this help message and exit -p, --purge purge all members from the group -l, --list list the members of the group [root@centos7 ~]# groupmems -l -g ming [root@centos7 ~]# groupadd g1 [root@centos7 ~]# groupadd g2 [root@centos7 ~]# groupadd g3 [root@centos7 ~]# usermod -G ming g1,g2,g3 usermod: user 'g1,g2,g3' does not exist [root@centos7 ~]# usermod -G ming g1 g2 g3 [root@centos7 ~]# usermod -G g1,g2,g3 ming # 注意次序 [root@centos7 ~]# id ming uid=1001(ming) gid=1001(ming) groups=1001(ming),1015(g1),1016(g2),1017(g3) [root@centos7 ~]# groupmes -l -g ming -bash: groupmes: command not found [root@centos7 ~]# groupmems -l -g ming [root@centos7 ~]# groupmems -l -g g1 # 这是以某个组为线索看谁把它作为附加组了 ming [root@centos7 ~]# groupmems -l -g g2 ming [root@centos7 ~]# groupmems -l -g g3 ming [root@centos7 ~]# -----如果本身就是group的附加组，newgrp直接切成主组 无需密码-----👇---- [11:41:27 root@localhost ~]#usermod -G g12 user1 [11:41:43 root@localhost ~]#id user1 uid=1008(user1) gid=1009(user1) groups=1009(user1),1013(g12) [11:41:47 root@localhost ~]#id uid=0(root) gid=0(root) groups=0(root) context=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 [11:41:48 root@localhost ~]#su - user1 Last login: Mon Jan 17 20:48:42 CST 2022 on pts/0 [11:41:55 user1@localhost ~]$id uid=1008(user1) gid=1009(user1) groups=1009(user1),1013(g12) context=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 [11:42:01 user1@localhost ~]$id user1 uid=1008(user1) gid=1009(user1) groups=1009(user1),1013(g12) [11:42:03 user1@localhost ~]$newgrp g12 [11:42:09 user1@localhost ~]$id uid=1008(user1) gid=1013(g12) groups=1013(g12),1009(user1) context=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 [11:42:10 user1@localhost ~]$exit exit [11:42:25 user1@localhost ~]$exit logout [11:42:29 root@localhost ~]#groupmems -l -g g12 user1 [11:42:35 root@localhost ~]# 删除附加组成员 [11:42:29 root@localhost ~]#groupmems -l -g g12 user1 [11:45:06 root@localhost ~]#groupmems -l -g g12 user1 [11:45:08 root@localhost ~]#id user1 uid=1008(user1) gid=1009(user1) groups=1009(user1),1013(g12) [11:45:24 root@localhost ~]#groupmems -d user1 -g g12 [11:45:30 root@localhost ~]#id user1 uid=1008(user1) gid=1009(user1) groups=1009(user1) [11:45:32 root@localhost ~]# 这个只是附加组里的成员 [11:47:07 root@localhost ~]#groupmems -d user1 -g user1 groupmems: user 'user1' is not a member of 'user1' [11:47:12 root@localhost ~]#id user1 uid=1008(user1) gid=1009(user1) groups=1009(user1) 其实usermod就挺好，方法有点多，哈哈 [11:49:06 root@localhost ~]#id user1 uid=1008(user1) gid=1009(user1) groups=1009(user1),1014(g13) [11:49:08 root@localhost ~]#usermod -G g12,g13 user1 [11:49:19 root@localhost ~]#id user1 uid=1008(user1) gid=1009(user1) groups=1009(user1),1013(g12),1014(g13) [11:49:21 root@localhost ~]#usermod -G g12 user1 [11:49:46 root@localhost ~]#id user1 uid=1008(user1) gid=1009(user1) groups=1009(user1),1013(g12) [11:49:48 root@localhost ~]# 清空组中所有成员 工具各有所长 [11:51:22 root@localhost ~]#id user1 uid=1008(user1) gid=1009(user1) groups=1009(user1),1013(g12) [11:51:24 root@localhost ~]#usermod -G g12 user2 [11:51:44 root@localhost ~]#usermod -G g12 user3 [11:51:46 root@localhost ~]#id user1 uid=1008(user1) gid=1009(user1) groups=1009(user1),1013(g12) [11:51:48 root@localhost ~]#id user2 uid=1009(user2) gid=1010(user2) groups=1010(user2),1013(g12) [11:51:48 root@localhost ~]#id user3 uid=1010(user3) gid=1011(user3) groups=1011(user3),1013(g12) [11:51:49 root@localhost ~]# [11:51:49 root@localhost ~]#groupmems -l -g g12 user1 user2 user3 [11:51:57 root@localhost ~]# 情况附加组成员就用groupmems [11:51:49 root@localhost ~]#groupmems -l -g g12 user1 user2 user3 [11:51:57 root@localhost ~]# [11:52:28 root@localhost ~]#groupmems -p -g g12 [11:52:53 root@localhost ~]#groupmems -l -g g12 [11:52:56 root@localhost ~]#id user1 uid=1008(user1) gid=1009(user1) groups=1009(user1) [11:52:59 root@localhost ~]#id user2 uid=1009(user2) gid=1010(user2) groups=1010(user2) [11:53:02 root@localhost ~]#id user3 uid=1010(user3) gid=1011(user3) groups=1011(user3) [11:53:02 root@localhost ~]# 不知道主组成员能不能清 [11:53:55 root@localhost ~]#usermod -g g12 user1 [11:54:03 root@localhost ~]#id user1 uid=1008(user1) gid=1013(g12) groups=1013(g12) [11:54:05 root@localhost ~]#groupmems -l -g g12 [11:54:18 root@localhost ~]#groupmems -p -g g12 [11:54:35 root@localhost ~]#groupmems -l -g g12 [11:54:35 root@localhost ~]# --------👆肯定不能了，主组是不归groupmems管的----------- useradd\\usermod\\userdel基本上这些事都能做， groupmems这个命令有问题啊 [root@centos7 ~]# id user1 uid=1000(user1) gid=1000(user1) groups=1000(user1),1014(g12) [root@centos7 ~]# whatis groupmems groupmems (8) - administer members of a user's primary group [root@centos7 ~]# groupmems -l -g user1 [root@centos7 ~]# groupmems -l -g g12 user1 [root@centos7 ~]# ---------毛的primary group，它就是个附加组管理工具------------👆------------ 练习 创建用户cacti，附加组为bin和root，默认shell为/bin/csh，注释信息为\"i am a cacti\" useradd -s /bin/csh -G bin,root -c \"i am a cacti\" cacti [root@centos7 ~]# useradd -s /bin/csh -G bin,root -c \"i am a cacti\" cacti [root@centos7 ~]# id cacti uid=1007(cacti) gid=1007(cacti) groups=1007(cacti),0(root),1(bin) [root@centos7 ~]# getent passwd cacti cacti:x:1007:1007:i am a cacti:/home/cacti:/bin/csh [root@centos7 ~]# finger cacti Login: cacti Name: i am a cacti Directory: /home/cacti Shell: /bin/csh Never logged in. No mail. No Plan. [root@centos7 ~]# 创建下面的用户、组和组成员关系， 名字为webs的组， 用户nginx，使用webs作为附加组 用户varnish，使用webs作为附加组 用户mysql，不可交互登入西路，且不是webs的成员 nginx,varnish,mysql密码都是cisco groupadd webs useradd -G webs nginx useradd -G webs varnish useradd -s /sbin/nologin mysql cat p.set nginx:cisco varnish:cisco mysql:cisco EOF cat p.set |chpasswd ---------------------------👇检查下，效果杠杠的----------------------- --------👆上面讲了用户和组，👇下面开始整理文件针对这些用户和组的权限------- QoS， diff serv （打标\\分类+后面的管制、限速、队列）也是这个道理，区别对待，上面的用户和组就是区别，下面针对这些人设置对应文件的访问就是对待。 文件权限 chown修改文件所属 [root@centos7 ~]# touch /data/f1 [root@centos7 ~]# su - user1 Last login: Mon Feb 7 12:33:30 CST 2022 on pts/0 [user1@centos7 ~]$ ll /data/f1 -rw-r--r--. 1 root root 0 Feb 7 12:33 /data/f1 [user1@centos7 ~]$ cat /data/f1 [user1@centos7 ~]$ echo 111 > /data/f1 -bash: /data/f1: Permission denied -------👆user1作为other没有f1的写权限----------- -------👇chown就可以修改文件的所有者和所属组，好像也用不到chgrp------- [user1@centos7 ~]$ [user1@centos7 ~]$ exit logout [root@centos7 ~]# chown user1 /data/f1 [root@centos7 ~]# ll /data/f1 -rw-r--r--. 1 user1 root 0 Feb 7 12:33 /data/f1 [root@centos7 ~]# chown :g12 /data/f1 [root@centos7 ~]# ll /data/f1 -rw-r--r--. 1 user1 g12 0 Feb 7 12:33 /data/f1 [root@centos7 ~]# ll /data/f1 -rw-r--r--. 1 user1 g12 0 Feb 7 12:33 /data/f1 [root@centos7 ~]# chown root:g13 /data/f1 chown: invalid group: ‘root:g13’ [root@centos7 ~]# chown root:g1 /data/f1 [root@centos7 ~]# ll /data/f1 -rw-r--r--. 1 root g1 0 Feb 7 12:33 /data/f1 [root@centos7 ~]# chown user1.g12 /data/f1 [root@centos7 ~]# ll /data/f1 -rw-r--r--. 1 user1 g12 0 Feb 7 12:33 /data/f1 --------👇chgrp就是文件属组---------- [root@centos7 ~]# chgrp g2 /data/f1 [root@centos7 ~]# ll /data/f1 -rw-r--r--. 1 user1 g2 0 Feb 7 12:33 /data/f1 [root@centos7 ~]# chmod修改文件权限 模式法： chmod who opt per file who: u,g,o,a opt: +,-,= per: r,w,x 去掉文件的所有者r权限：chmod u-r file [user1@centos7 ~]$ ll total 4 -rw-rw-r--. 1 user1 user1 0 Feb 6 20:23 file1 [user1@centos7 ~]$ chmod u-r file1 [user1@centos7 ~]$ ll total 4 --w-rw-r--. 1 user1 user1 0 Feb 6 20:23 file1 [user1@centos7 ~]$ ---------此时再看👇user1用户对file1的权限的情况----------- [user1@centos7 ~]$ cat file1 cat: file1: Permission denied [user1@centos7 ~]$ echo xx >> file1 [user1@centos7 ~]$ ll total 8 --w-rw-r--. 1 user1 user1 3 Feb 7 13:43 file1 -rwxrwxrwx. 1 root root 839 Jan 10 14:20 fstab [user1@centos7 ~]$ -----------可见👆权限是所属者适用就只看所属者了--------------- ---------------user>group>other-----3个权限只一个有效--------- [root@centos7 ~]# chmod u=-,g=r,o=rwx /data/f1 [root@centos7 ~]# ll /data/f1 ----r--rwx. 1 user1 g2 3 Feb 7 13:48 /data/f1 [root@centos7 ~]# su user1 [user1@centos7 root]$ cat /data/f1 cat: /data/f1: Permission denied [user1@centos7 root]$ echo xx > /data/f1 bash: /data/f1: Permission denied [user1@centos7 root]$ exit exit [root@centos7 ~]# su user2 [user2@centos7 root]$ cat /data/f1 11 [user2@centos7 root]$ echo xx > /data/f1 [user2@centos7 root]$ cat /data/f1 xx [user2@centos7 root]$ --------------user1的文件权限user1自然可以加回去-------👇--- [user1@centos7 root]$ ll /data/f1 ----r--rwx. 1 user1 g2 3 Feb 7 13:52 /data/f1 [user1@centos7 root]$ chmod u=rwx /data/f1 [user1@centos7 root]$ ll /data/f1 -rwxr--rwx. 1 user1 g2 3 Feb 7 13:52 /data/f1 [user1@centos7 root]$ cat /data/f1 xx [user1@centos7 root]$ echo yy >> /data/f1 [user1@centos7 root]$ cat /data/f1 xx yy [user1@centos7 root]$ ----------非文件拥有者自然不能修改该文件的属性👇------------- [root@centos7 ~]# su user2 [user2@centos7 root]$ ll /data/f1 -rwxr--rwx. 1 user1 g2 6 Feb 7 13:53 /data/f1 [user2@centos7 root]$ chmod u=rx /data/f1 chmod: changing permissions of ‘/data/f1’: Operation not permitted [user2@centos7 root]$ chmod g=- /data/f1 chmod: changing permissions of ‘/data/f1’: Operation not permitted [user2@centos7 root]$ [root@centos7 ~]# chmod a=rwx /data/f1 [root@centos7 ~]# ll /data/f1 -rwxrwxrwx. 1 user1 g2 6 Feb 7 13:53 /data/f1 [root@centos7 ~]# chmod a=- /data/f1 [root@centos7 ~]# ll /data/f1 ----------. 1 user1 g2 6 Feb 7 13:53 /data/f1 [root@centos7 ~]# chmod a=r /data/f1 [root@centos7 ~]# ll /data/f1 -r--r--r--. 1 user1 g2 6 Feb 7 13:53 /data/f1 [root@centos7 ~]# chmod a= /data/f1 [root@centos7 ~]# ll /data/f1 ----------. 1 user1 g2 6 Feb 7 13:53 /data/f1 [root@centos7 ~]# ------------谁都不行，root还行👇------root超脱🐟权限除了x执行权限----- [root@centos7 ~]# chown root.root /data/f1 [root@centos7 ~]# ll /data/f1 ----------. 1 root root 9 Feb 7 13:59 /data/f1 [root@centos7 ~]# cat /data/f1 xx yy zz [root@centos7 ~]# echo ee >> /data/f1 [root@centos7 ~]# cat /data/f1 xx yy zz ee [root@centos7 ~]# ---------👇--执行权限root要是没有的，也不行，root也就rw读写不受权限影响----- [root@centos7 ~]# ll /bin/cat -rwxr-xr-x. 1 root root 54080 Aug 20 2019 /bin/cat [root@centos7 ~]# [root@centos7 ~]# chow a-x /bin/cat -bash: chow: command not found [root@centos7 ~]# chmod a-x /bin/cat [root@centos7 ~]# ll /bin/cat -rw-r--r--. 1 root root 54080 Aug 20 2019 /bin/cat [root@centos7 ~]# cat /data/f1 -bash: /usr/bin/cat: Permission denied [root@centos7 ~]# /bin/cat /data/f1 -bash: /bin/cat: Permission denied [root@centos7 ~]# chmod +x /bin/cat # 这里等价于a+x [root@centos7 ~]# cat /data/f1 xx yy zz ee -------👇----root比较牛逼，只要u、g、o里一个角色有执行权限，那他就有权限了--------- [root@centos7 ~]# ll /bin/cat -rwxr-xr-x. 1 root root 54080 Aug 20 2019 /bin/cat [root@centos7 ~]# chmod u-x,g-x /bin/cat [root@centos7 ~]# ll /bin/cat -rw-r--r-x. 1 root root 54080 Aug 20 2019 /bin/cat [root@centos7 ~]# cat /data/f1 xx yy zz ee [root@centos7 ~]# 修改目录下所有文件和子目录的权限，这个R特别的坑和rm也差不多了 [root@centos7 ~]# ll /data/ total 8 -rw-r--r--. 1 root root 151 Feb 6 19:31 change_passwd.sh ----------. 1 root root 12 Feb 7 14:19 f1 -rw-r--r--. 1 root root 0 Feb 7 14:19 f10 -rw-r--r--. 1 root root 0 Feb 7 14:19 f11 -rw-r--r--. 1 root root 0 Feb 7 14:19 f12 -rw-r--r--. 1 root root 0 Feb 7 14:19 f13 -rw-r--r--. 1 root root 0 Feb 7 14:19 f14 -rw-r--r--. 1 root root 0 Feb 7 14:19 f15 -rw-r--r--. 1 root root 0 Feb 7 14:19 f16 -rw-r--r--. 1 root root 0 Feb 7 14:19 f17 -rw-r--r--. 1 root root 0 Feb 7 14:19 f18 -rw-r--r--. 1 root root 0 Feb 7 14:19 f19 -rw-r--r--. 1 root root 0 Feb 7 14:19 f2 -rw-r--r--. 1 root root 0 Feb 7 14:19 f20 -rw-r--r--. 1 root root 0 Feb 7 14:19 f3 -rw-r--r--. 1 root root 0 Feb 7 14:19 f4 -rw-r--r--. 1 root root 0 Feb 7 14:19 f5 -rw-r--r--. 1 root root 0 Feb 7 14:19 f6 -rw-r--r--. 1 root root 0 Feb 7 14:19 f7 -rw-r--r--. 1 root root 0 Feb 7 14:19 f8 -rw-r--r--. 1 root root 0 Feb 7 14:19 f9 [root@centos7 ~]# chmod a+x -R /data/ [root@centos7 ~]# ll /data/ -d drwxr-xr-x. 2 root root 241 Feb 7 14:19 /data/ [root@centos7 ~]# ll /data/ total 8 -rwxr-xr-x. 1 root root 151 Feb 6 19:31 change_passwd.sh ---x--x--x. 1 root root 12 Feb 7 14:19 f1 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f10 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f11 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f12 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f13 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f14 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f15 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f16 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f17 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f18 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f19 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f2 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f20 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f3 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f4 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f5 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f6 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f7 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f8 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f9 [root@centos7 ~]# [root@centos7 ~]# ll /data/ total 8 -rw-r--r--. 1 root root 151 Feb 6 19:31 change_passwd.sh ----------. 1 root root 12 Feb 7 14:19 f1 -rw-r--r--. 1 root root 0 Feb 7 14:19 f10 -rw-r--r--. 1 root root 0 Feb 7 14:19 f11 -rw-r--r--. 1 root root 0 Feb 7 14:19 f12 -rw-r--r--. 1 root root 0 Feb 7 14:19 f13 -rw-r--r--. 1 root root 0 Feb 7 14:19 f14 -rw-r--r--. 1 root root 0 Feb 7 14:19 f15 -rw-r--r--. 1 root root 0 Feb 7 14:19 f16 -rw-r--r--. 1 root root 0 Feb 7 14:19 f17 -rw-r--r--. 1 root root 0 Feb 7 14:19 f18 -rw-r--r--. 1 root root 0 Feb 7 14:19 f19 -rw-r--r--. 1 root root 0 Feb 7 14:19 f2 -rw-r--r--. 1 root root 0 Feb 7 14:19 f20 -rw-r--r--. 1 root root 0 Feb 7 14:19 f3 -rw-r--r--. 1 root root 0 Feb 7 14:19 f4 -rw-r--r--. 1 root root 0 Feb 7 14:19 f5 -rw-r--r--. 1 root root 0 Feb 7 14:19 f6 -rw-r--r--. 1 root root 0 Feb 7 14:19 f7 -rw-r--r--. 1 root root 0 Feb 7 14:19 f8 -rw-r--r--. 1 root root 0 Feb 7 14:19 f9 [root@centos7 ~]# chown -R user1 /data/ [root@centos7 ~]# ll /data/ total 8 -rw-r--r--. 1 user1 root 151 Feb 6 19:31 change_passwd.sh ----------. 1 user1 root 12 Feb 7 14:19 f1 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f10 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f11 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f12 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f13 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f14 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f15 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f16 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f17 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f18 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f19 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f2 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f20 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f3 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f4 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f5 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f6 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f7 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f8 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f9 [root@centos7 ~]# [root@centos7 ~]# ll /data/ -d drw-r--r--. 2 user1 root 241 Feb 7 14:19 /data/ -------坑在这里👇----- rm -rf / data #小手一抖，空格全没有 chmod -R a=rwx / data #小手再都，大妈食堂有 ------👆你把/根下所有的文件夹和子文件权限都弄了，更狠的来了👇---- chown -R user1 / data #/根下所有文件夹和文件所有者都变成了user1了 参考别的文件设置同样的用户和组，以及权限 [root@centos7 ~]# ll /etc/fstab -rw-r--r--. 1 root root 595 Jan 5 17:41 /etc/fstab [root@centos7 ~]# ll /data/f1 ----------. 1 user1 root 12 Feb 7 14:19 /data/f1 [root@centos7 ~]# chown --reference /etc/fstab /data/f1 [root@centos7 ~]# ll /data/f1 ----------. 1 root root 12 Feb 7 14:19 /data/f1 [root@centos7 ~]# chmod --reference /etc/fstab /data/f1 [root@centos7 ~]# ll /data/f1 -rw-r--r--. 1 root root 12 Feb 7 14:19 /data/f1 [root@centos7 ~]# Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"6-用户、用户组和权限/3-文件和特殊权限.html":{"url":"6-用户、用户组和权限/3-文件和特殊权限.html","title":"第3节 文件和特殊权限","keywords":"","body":"第3节. 文件和特殊权限 接上文，模式法 chmod who opt per file who: u,g,o,a opt: +,-,= per: r,w,x 数字法 rwxrw-r-- f1 111110100 👉 111 110 100 = 7 6 4 r 4 w 2 x 1 文件夹的权限 w：针对文件夹，就是创建、删除其中的文件。而修改文件涉及的是文件本身的写权限。 ----------👇--------------------------------- [user1@centos7 dir]$ ll ./ -d drwxr-xr-x. 2 root root 16 Feb 8 09:23 ./ # 文件夹dir的权限 [root@centos7 dir]# su user1 [user1@centos7 dir]$ ll total 0 -rw-r--rw-. 1 root root 0 Feb 8 09:23 f1 [user1@centos7 dir]$ touch 11 touch: cannot touch ‘11’: Permission denied [user1@centos7 dir]$ vi f1 [user1@centos7 dir]$ cat f1 111 [user1@centos7 dir]$ rm f1 rm: cannot remove ‘f1’: Permission denied [user1@centos7 dir]$ echo xxx > f1 [user1@centos7 dir]$ cat f1 xxx [user1@centos7 dir]$ r: 读权限针对文件夹就是看不到文件夹下面的内容，但是如果你知道某个文件的名称，是可以直接看该文件内容的。 [root@centos7 data]# chmod o-r dir/ [root@centos7 data]# ll total 0 drwxr-x--x. 2 root root 16 Feb 8 09:46 dir [root@centos7 data]# su user1 [user1@centos7 data]$ cat dir/f1 xx [user1@centos7 data]$ cd dir [user1@centos7 dir]$ ls ls: cannot open directory .: Permission denied [user1@centos7 dir]$ cat f1 xx [user1@centos7 dir]$ ll -d f1 -rw-r--r--. 1 root root 3 Feb 8 09:48 f1 [user1@centos7 dir]$ ll ls: cannot open directory .: Permission denied [user1@centos7 dir]$ x：执行权限针对文件夹就是进入咯，这个执行一旦取消，关系就大了，你连文件夹都进不去，那么文件夹下的文件就看不到 dir/f1 bash: dir/f1: Permission denied [user1@centos7 data]$ ll dir/ ls: cannot open directory dir/: Permission denied [user1@centos7 data]$ 👇-----给上面的dir补一个r读权限---- [root@centos7 data]# chmod o=r dir [root@centos7 data]# ll total 0 drwxr-xr--. 2 root root 16 Feb 8 09:46 dir [root@centos7 data]# ll dir/f1 -rw-r--rw-. 1 root root 3 Feb 8 09:48 dir/f1 [root@centos7 data]# [root@centos7 data]# su user1 [user1@centos7 data]$ ll dir ls: cannot access dir/f1: Permission denied total 0 -????????? ? ? ? ? ? f1 # 👈元数据看不到，文件名字倒是可以的 [user1@centos7 data]$ cd dir bash: cd: dir: Permission denied [user1@centos7 data]$ ll dir/f1 ls: cannot access dir/f1: Permission denied [user1@centos7 data]$ 文件夹来讲： 目录存放的数据块里的内容是各个文件名和其对应的节点信息 文件存放的数据块里的内容是文件的内容 读：可以列出该文件夹下的文件名，拿掉后，如果知道文件夹下的文件名，也能通过/dir/file去直接cat（这取决于文件本身的r权限）。 执行：可以进入目录，可以访问目录里的文件内容(依赖于文件本身的r权限)。 写：决定是否可以在目录里面创建和删除文件。文件本身的权限还得看文件自己的。 注意，w需要x加持~如果文件夹的执行权限取消，及时有写权限，由于进不到该目录下，所以也就没法去写文件的。 说下大X，后面再将st [root@centos7 data]# ll total 0 drwxr-xr--. 2 root root 16 Feb 8 09:46 dir -rw-r--r--. 1 root root 0 Feb 8 11:31 f1 -rw-r--r--. 1 root root 0 Feb 8 11:31 f2 [root@centos7 data]# chmod -R a+x /data [root@centos7 data]# ll /data total 0 drwxr-xr-x. 2 root root 16 Feb 8 09:46 dir -rwxr-xr-x. 1 root root 0 Feb 8 11:31 f1 -rwxr-xr-x. 1 root root 0 Feb 8 11:31 f2 [root@centos7 data]# ll /data -d drwxr-xr-x. 3 root root 37 Feb 8 11:31 /data ------👆通过-R可以使文件夹和其下所有文件的权限都递归改掉----- 但是如果遇到文件你给它一个x执行权限，往往存在安全风险---所以-R 配合大X就可以过滤文件的权限修改 👇 [root@centos7 data]# chmod -R a-x /data/ [root@centos7 data]# ll /data/ total 0 drw-r--r--. 2 root root 16 Feb 8 09:46 dir -rw-r--r--. 1 root root 0 Feb 8 11:31 f1 -rw-r--r--. 1 root root 0 Feb 8 11:31 f2 [root@centos7 data]# chmod -R a+X /data/ [root@centos7 data]# ll /data/ total 0 drwxr-xr-x. 2 root root 16 Feb 8 09:46 dir -rw-r--r--. 1 root root 0 Feb 8 11:31 f1 -rw-r--r--. 1 root root 0 Feb 8 11:31 f2 [root@centos7 data]# 练习： 误删了用户ming的家目录，进行恢复 三条命令 cp -r /etc/skel /home/ming chown -R ming.ming /home/ming chmod 700 /home/ming # 里面的几个隐藏文件都是从/etc/skel下复制过来的，属性不变就好。 ---误删除了用户ming家目录下的文件，但是目录还在，进行恢复👇 [root@centos7 ~]# rm -rf /home/ming/.* rm: refusing to remove ‘.’ or ‘..’ directory: skipping ‘/home/ming/.’ rm: refusing to remove ‘.’ or ‘..’ directory: skipping ‘/home/ming/..’ [root@centos7 ~]# ll -a /home/ming total 0 drwx------. 2 ming ming 6 Feb 8 13:43 . drwxr-xr-x. 16 root root 192 Feb 8 12:01 .. --👇注意，此时通过.*复制/etc/skel/下的所有文件--包含隐藏和非隐藏，会有大问题🐕-- [root@centos7 home]# cp -r /etc/skel/.* /home/ming cp: will not create hard link ‘/home/ming/skel’ to directory ‘/home/ming/.’ cp: overwrite ‘/home/ming/.bash_logout’? ^C [root@centos7 home]# ll /home/ming total 1036 -rw-r--r--. 1 root root 16 Feb 8 13:44 adjtime -rw-r--r--. 1 root root 1529 Feb 8 13:44 aliases -rw-r--r--. 1 root root 12288 Feb 8 13:44 aliases.db drwxr-xr-x. 2 root root 236 Feb 8 13:44 alternatives -rw-------. 1 root root 541 Feb 8 13:44 anacrontab -rw-r--r--. 1 root root 55 Feb 8 13:44 asound.conf drwxr-x---. 3 root root 43 Feb 8 13:44 audisp drwxr-x---. 3 root root 83 Feb 8 13:44 audit drwxr-xr-x. 2 root root 22 Feb 8 13:44 bash_completion.d -rw-r--r--. 1 root root 2853 Feb 8 13:44 bashrc drwxr-xr-x. 2 root root 6 Feb 8 13:44 binfmt.d -rw-r--r--. 1 root root 37 Feb 8 13:44 centos-release -rw-r--r--. 1 root root 51 Feb 8 13:44 centos-release-upstream drwxr-xr-x. 2 root root 6 Feb 8 13:44 chkconfig.d drwxr-xr-x. 2 root root 21 Feb 8 13:44 cron.d drwxr-xr-x. 2 root root 42 Feb 8 13:44 cron.daily -rw-------. 1 root root 0 Feb 8 13:44 cron.deny drwxr-xr-x. 2 root root 22 Feb 8 13:44 cron.hourly drwxr-xr-x. 2 root root 6 Feb 8 13:44 cron.monthly -rw-r--r--. 1 root root 451 Feb 8 13:44 crontab drwxr-xr-x. 2 root root 6 Feb 8 13:44 cron.weekly -rw-------. 1 root root 0 Feb 8 13:44 crypttab -rw-r--r--. 1 root root 1620 Feb 8 13:44 csh.cshrc -rw-r--r--. 1 root root 1103 Feb 8 13:44 csh.login 👆发现复制很N多文件过来了，原因是因为.*通配符它代表.xxx还有..xxx所以复制.*意味着你不仅仅复制了当前目录下的所有文件，也复制了上级目录下的所有文件。 推荐👇👉使用cp -r /etc/skel/. /home/ming这种方式复制所有文件含隐藏文件 drwx------. 2 root root 6 Feb 8 13:52 ming [root@centos7 home]# cp -r /etc/skel/. /home/ming [root@centos7 home]# ll -a ming total 12 drwx------. 2 root root 72 Feb 8 13:53 . drwxr-xr-x. 16 root root 192 Feb 8 13:52 .. -rw-r--r--. 1 root root 18 Feb 8 13:53 .bash_logout -rw-r--r--. 1 root root 193 Feb 8 13:53 .bash_profile -rw-r--r--. 1 root root 231 Feb 8 13:53 .bashrc -rw-r--r--. 1 root root 0 Feb 8 13:53 f1 [root@centos7 home]# ------👇这样也行，就是通过.[^.]*来表示所有隐藏文件，和*来表示所有非隐藏文件---- [root@centos7 home]# cp -r /etc/skel/.[^.]* /home/ming [root@centos7 home]# ll /home/ming -a total 12 drwx------. 2 root root 62 Feb 8 13:55 . drwxr-xr-x. 16 root root 192 Feb 8 13:52 .. -rw-r--r--. 1 root root 18 Feb 8 13:55 .bash_logout -rw-r--r--. 1 root root 193 Feb 8 13:55 .bash_profile -rw-r--r--. 1 root root 231 Feb 8 13:55 .bashrc [root@centos7 home]# cp -r /etc/skel/* /home/ming [root@centos7 home]# ll /home/ming -a total 12 drwx------. 2 root root 72 Feb 8 13:55 . drwxr-xr-x. 16 root root 192 Feb 8 13:52 .. -rw-r--r--. 1 root root 18 Feb 8 13:55 .bash_logout -rw-r--r--. 1 root root 193 Feb 8 13:55 .bash_profile -rw-r--r--. 1 root root 231 Feb 8 13:55 .bashrc -rw-r--r--. 1 root root 0 Feb 8 13:55 f1 [root@centos7 home]# mkdir创建文件夹的时候可以设置权限 [root@centos7 home]# mkdir --help Usage: mkdir [OPTION]... DIRECTORY... Create the DIRECTORY(ies), if they do not already exist. Mandatory arguments to long options are mandatory for short options too. -m, --mode=MODE set file mode (as in chmod), not a=rwx - umask -p, --parents no error if existing, make parent directories as needed -v, --verbose print a message for each created directory -Z set SELinux security context of each created directory to the default type --context[=CTX] like -Z, or if CTX is specified then set the SELinux or SMACK security context to CTX --help display this help and exit --version output version information and exit GNU coreutils online help: For complete documentation, run: info coreutils 'mkdir invocation' [root@centos7 home]# [root@centos7 ~]# mkdir -m 000 /home/sb001 [root@centos7 ~]# ll /home/sb001 -d d---------. 2 root root 6 Feb 8 14:00 /home/sb001 [root@centos7 ~]# 文件的特殊权限 /etc/shaow这个文件普通用户没有权限对其修改，但是可以通过passwd命令对其进行修改的，因为改自身密码本质上就是修改了shadow文件。 [root@centos7 ~]# ll /etc/shadow ----------. 1 root root 1366 Feb 8 14:06 /etc/shadow [root@centos7 ~]# su user1 [user1@centos7 root]$ cat /etc/shadow cat: /etc/shadow: Permission denied [user1@centos7 root]$ echo xx /etc/shadow xx /etc/shadow [user1@centos7 root]$ echo xx >> /etc/shadow bash: /etc/shadow: Permission denied [user1@centos7 root]$ passwd Changing password for user user1. Changing password for user1. (current) UNIX password: passwd: Authentication token manipulation error [user1@centos7 root]$ passwd Changing password for user user1. Changing password for user1. (current) UNIX password: New password: Retype new password: passwd: all authentication tokens updated successfully. [user1@centos7 root] 这是因为passwd命令-也就是这/bin/passwd这个执行文件用户属性位上有s位。 [user1@centos7 root]$ ll /bin/passwd suid当用户使用该程序/命令访问某个文件的时候，原则上是使用这个用户的权限去访问文件。 一旦有了suid，不管谁运行这个程序，通过这个程序访问文件，就是获得这个程序所有者的权限。上图只要你运行passwd，你的身份就转换为root了。suid全称就是set owner user id up to execution在执行时设置所有者用户ID。 第二点，suid一定是作用在二进制的可执行的文件上(对shell脚本无效)，否则没有意义了就。所以大S没有意义-去掉x后就是大S [root@centos7 ~]# ll /usr/bin/vi -rwsr-xr-x. 1 root root 928056 Oct 14 2020 /usr/bin/vi [root@centos7 ~]# su user su: user user does not exist [root@centos7 ~]# su user1 [user1@centos7 root]$ vi /etc/shadow # 此时就可以vi进去修改并保持了 [user1@centos7 root]$ echo xxx >> /etc/shadow # echo不行肯定的啊你suid的是vim啊 bash: /etc/shadow: Permission denied ----------这个，，，尝试将echo变成suid权限，发现还是不行，可能要该重定向文件咯呵呵---- [root@centos7 ~]# which echo /usr/bin/echo [root@centos7 ~]# ll /usr/bin/echo -rwxr-xr-x. 1 root root 33088 Aug 20 2019 /usr/bin/echo [root@centos7 ~]# chmod u+s /usr/bin/echo [root@centos7 ~]# ll /usr/bin/echo -rwsr-xr-x. 1 root root 33088 Aug 20 2019 /usr/bin/echo [root@centos7 ~]# su user1 [user1@centos7 root]$ echo xx >> /etc/shadow bash: /etc/shadow: Permission denied [user1@centos7 root]$ exit exit [root@centos7 ~]# which >> -bash: syntax error near unexpected token `newline' [root@centos7 ~]# 数字法修改suid： 4是单独算的 [root@centos7 ~]# ll /usr/bin/echo -rwsr-xr-x. 1 root root 33088 Aug 20 2019 /usr/bin/echo [root@centos7 ~]# chmod 755 /usr/bin/echo [root@centos7 ~]# ll /usr/bin/echo -rwxr-xr-x. 1 root root 33088 Aug 20 2019 /usr/bin/echo [root@centos7 ~]# chmod 4755 /usr/bin/echo [root@centos7 ~]# ll /usr/bin/echo -rwsr-xr-x. 1 root root 33088 Aug 20 2019 /usr/bin/echo [root@centos7 ~]# sgid 1、如果某个用户运行cat程序也即是使用cat去访问文件，就会继承所属组的权限。或者说就会将用户原本的所属组提升至该程序的所属组。 同样数字法 755前面补一个2，sgid 755前面补一个4，sguid 755前面补一个6，suid+sgid 粘滞位 针对文件夹的属性 非用户本人，无法删除文件夹下的文件 粘滞位对文件不生效 [root@centos7 dir]# su user1 [user1@centos7 dir]$ ll total 0 -rw-r--r--. 1 root root 0 Feb 8 16:19 f1 -rw-rw-r-T. 1 user1 user1 0 Feb 8 16:22 f2 [user1@centos7 dir]$ rm -rf f2 [user1@centos7 dir]$ ll total 0 -rw-r--r--. 1 root root 0 Feb 8 16:19 f1 [user1@centos7 dir]$ 总结 suid： ​ 作用于可执行的二进制的程序，权限4，功能：用户执行此程序时，将继承此程序所有者的权限。 sguid： ​ 作用于可执行的二进制的程序，权限2，功能：用户执行此程序时，将集成此程序所属组的权限。 ​ 作用于目录，权限2，功能，新建的文件，将自动集成该目录的所属组。 sticky： ​ 作用于目录，权限1，功能：只能删除自己的文件，root不受限。 创建一个目录可以让有限的几个用户使用 [16:49:55 root@localhost data]#mkdir -m 770 testdir [16:50:10 root@localhost data]#ll total 1 drwxrwx---. 2 root root 6 Jan 19 16:50 testdir [16:52:38 root@localhost data]#chown .grp001 testdir [16:52:50 root@localhost data]#ll total 1 drwxrwx---. 2 root grp001 6 Jan 19 16:50 testdir [16:53:01 root@localhost data]#usermod -G grp001 user1 [16:54:31 root@localhost data]#usermod -G grp001 user2 [16:55:01 root@localhost data]#groupmems -l -g grp001 user1 user2 [16:55:14 root@localhost data]#su user1 [16:55:19 user1@localhost data]$cd testdir/ [16:55:28 user1@localhost testdir]$touch f1 [16:55:30 user1@localhost testdir]$echo 11 >> f1 [16:55:34 user1@localhost testdir]$exit exit [16:55:36 root@localhost data]#su user2 [16:55:43 user2@localhost data]$cd testdir/ [16:55:54 user2@localhost testdir]$echo xx >> f2 [16:56:06 user2@localhost testdir]$cat f2 xx 貌似centos7.9和7.6这里有个不一样的点👇 就是user1可以修改user2创建的文件，如果时之前的观点，就会再设置文件夹的sguid来使目录下的文件创建的时候自动集成父目录的所属组。 当然最好还是设置一下文件夹的sgid [root@centos7 data]# chmod g+s renyue/ [root@centos7 data]# ll total 0 drwxrws---. 2 root renyue-group 26 Feb 8 17:12 renyue [root@centos7 data]# [root@centos7 data]# su client1 [client1@centos7 data]$ ll total 0 drwxrws---. 2 root renyue-group 26 Feb 8 17:12 renyue [client1@centos7 data]$ cd renyue/ [client1@centos7 renyue]$ touch f3 [client1@centos7 renyue]$ ll total 4 -rw-rw-r--. 1 client1 client1 2 Feb 8 17:12 f1 -rw-rw-r--. 1 client2 client2 0 Feb 8 17:12 f2 -rw-rw-r--. 1 client1 renyue-group 0 Feb 8 17:35 f3 [client1@centos7 renyue]$ cp /etc/fstab /data/dir/ 普通需要什么权限？ cp 命令的执行权限 /etc文件夹的执行 fstab文件的读 /data文件夹的执行 /dir文件夹得执行和写 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"6-用户、用户组和权限/4-umask权限.html":{"url":"6-用户、用户组和权限/4-umask权限.html","title":"第4节 umask权限","keywords":"","body":"第4节. umask权限 chattr i :文件不会被修改、删除、包含所在目录也不能被删除。 [19:40:28 root@localhost data]#chattr +i f1 [19:40:37 root@localhost data]#ll total 0 -rw-r--r--. 1 root root 0 Jan 19 19:40 f1 [19:40:38 root@localhost data]#lsattr f1 ----i--------------- f1 [19:41:22 root@localhost data]#rm -rf f1 rm: cannot remove 'f1': Operation not permitted [19:41:29 root@localhost data]#echo xx > f1 -bash: f1: Operation not permitted [19:41:32 root@localhost data]#mv f1 f2 mv: cannot move 'f1' to 'f2': Operation not permitted [19:41:36 root@localhost data]#cd .. [19:41:38 root@localhost /]#rm -rf /data/ rm: cannot remove '/data/f1': Operation not permitted [19:41:44 root@localhost /]# a:文件仅可以添加，同样所在目录不能被删除 [19:45:29 root@localhost data]#chattr +a f1 [19:45:36 root@localhost data]#lsattr f1 ----ia-------------- f1 [19:45:39 root@localhost data]#echo xx > f1 -bash: f1: Operation not permitted [19:45:45 root@localhost data]#echo xx >> f1 -bash: f1: Operation not permitted [19:45:48 root@localhost data]#chattr -i f1 [19:46:05 root@localhost data]#lsattr f1 -----a-------------- f1 [19:46:09 root@localhost data]#echo xx > f1 -bash: f1: Operation not permitted [19:46:13 root@localhost data]#echo xx >> f1 [19:46:16 root@localhost data]#cat f1 xx [19:46:19 root@localhost data]#rm -rf f1 rm: cannot remove 'f1': Operation not permitted [19:46:22 root@localhost data]#exit logout [19:46:54 root@localhost /]#rm -rf /data/ rm: cannot remove '/data/f1': Operation not permitted ---但是👇vi进去后在最后一行添加这种操作，系统判定不出来你是不是追加所以这种追加时不行的。 umask 1、root用户新建文件和文件夹可发现默认的权限分别时644和755 [19:57:42 root@localhost data]#ll total 0 drwxr-xr-x. 2 root root 6 Jan 19 19:57 dir -rw-r--r--. 1 root root 0 Jan 19 19:57 f1 [19:57:42 root@localhost data]# 2、换普通用户创建文件和文件夹权限就不一样 [putong@centos7 data]$ ll |grep putong drwxrwxr-x. 2 putong putong 6 Feb 8 20:02 dir2 -rw-rw-r--. 1 putong putong 0 Feb 8 20:02 f2 [putong@centos7 data]$ [putong@centos7 data]$ type umask umask is a shell builtin [putong@centos7 data]$ umask 0002 [putong@centos7 data]$ exit exit [root@centos7 data]# umask 0022 [root@centos7 data]# umask+default_value=777目录|666文件 000+default=777，假设文件也用777总和，会导致文件可能就带上了x执行权限，带来一定的风险。 022+default=777|666，文件夹default=755，文件default=644 👆上面的公式不正确 umask，mask时掩码，user的mask就是用户的掩码的意思。 umask ugo 也分user group other umask的功能，将777或者666中对应的权限去掉，得出默认权限。 777 022 ↓转成二进制,0锁死，1放开，就是通配符或者反掩码的算法. 111 111 111 000 010 010 ------------ 111 101 101 = 755 这就是文件夹创建默认权限 666 022 110 110 110 000 010 010 ------------ 110 100 100 = 644 这就是文件创建默认权限 ----👇修改umask值再来看，发现777|666-umask就不准确了---- [root@centos7 data]# umask 123 [root@centos7 data]# touch f1 [root@centos7 data]# mkdir dir [root@centos7 data]# ll total 0 drw-r-xr--. 2 root root 6 Feb 8 20:18 dir -rw-r--r--. 1 root root 0 Feb 8 20:18 f1 [root@centos7 data]# ------- 分析： 777 123 111 111 111 001 010 011 -------------- 110 101 100 => 掩出来的文件夹默认值为：654，这个确实就是777-123=654 如果是文件 666 123 110 110 110 001 010 011 -------------- 110 100 100 => 得到：644，这个就不是666-123=543，使用奇数+1的规律=644，所以速算法就是 543里面带上了执行权限了，肯定不可能的。 👇 如果是文件夹777-umask=default 如果是文件666-umask=default(3个数，如果是奇数就+1，偶数不变) umask退出后丢失，可以写到.bashrc或者/etc/bashrc里，这里也有个点就是几个文件里配置环境变量等，谁优先的原则，涉及文件有/etc/profile bashrc等，这个后面讲。 [root@centos7 ~]# cat /etc/bashrc | tail -3 fi # vim:ts=4:sw=4 umask 123 [root@centos7 ~]# [root@centos7 ~]# umask 0022 [root@centos7 ~]# umask -p umask 0022 [root@centos7 ~]# umask -p >> .bashrc # 将当前umaks值写入配置文件里 [root@centos7 ~]# tail -1 .bashrc umask 0022 [root@centos7 ~]# FACL 解决一些特殊需求，普通权限解决不了，比如 user1不能访问f1，user2能对f1完全控制，user3只能读f1，user4只能写f1 此时ugo三个角色，user、group、other，用户权限超过3个，就需要ACL了。 setfacl -m u:user1:0 f1 setfacl -m u:user1:- f1 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"6-用户、用户组和权限/5-FACL实现权限的灵活控制.html":{"url":"6-用户、用户组和权限/5-FACL实现权限的灵活控制.html","title":"第5节 FACL实现权限的灵活控制","keywords":"","body":"第5节. FACL实现权限的灵活控制 解决一些特殊需求，普通权限解决不了，比如 user1不能访问f1，user2能对f1完全控制，user3只能写f1，user4只能读f1 此时ugo三个角色，user、group、other，用户权限超过3个，就需要ACL了。 setfacl -m u:user1:0 f1 👈表示啥权限都没有 setfacl -m u:user1:- f1 👈表示啥权限都没有，等价于0 👉user1不能访问f1 [10:03:19 root@localhost data]#ll f1 -rw-r--r--+ 1 root root 4 Jan 29 10:03 f1 [10:04:59 root@localhost data]#su user2 -c \"cat f1\"👈切换用户输入cli后直接退出来 123 [10:05:00 root@localhost data]#su user1 -c \"cat f1\" cat: f1: Permission denied 👉user2完全控制f1 [10:20:21 root@localhost data]#su user2 -c 'cat f1' 123 [10:20:39 root@localhost data]#su user2 -c 'echo 123 > f1' bash: f1: Permission denied [10:20:43 root@localhost data]#setfacl -m u:user2:rw f1 [10:20:59 root@localhost data]#su user2 -c 'echo 321 > f1' [10:21:05 root@localhost data]#su user2 -c 'cat f1' 321 [10:21:11 root@localhost data]# 👉user3只能写f1 [10:24:33 root@localhost data]#setfacl -m u:user3:w f1 [10:25:44 root@localhost data]#su user3 -c 'cat f1' cat: f1: Permission denied [10:25:52 root@localhost data]#su user3 -c 'echo aaa >> f1' [10:26:01 root@localhost data]#su user3 -c 'cat f1' cat: f1: Permission denied [10:26:03 root@localhost data]#cat f1 321 aaa [10:26:15 root@localhost data]# 👉user4只能读f1,就归到other整体权限去，无需修改 👉查看facl [10:26:15 root@localhost data]#getfacl f1 # file: f1 # owner: root # group: root user::rw- user:user1:--- user:user2:rw- user:user3:-w- group::r-- mask::rw- other::r-- 针对group设置facl [10:28:34 root@localhost data]#setfacl -m g:g1:rw f1 [10:36:27 root@localhost data]#getfacl f1 # file: f1 # owner: root # group: root user::rw- user:user1:--- user:user2:rw- user:user3:-w- group::r-- group:g1:rw- 👈g1有了rw mask::rw- other::r-- [10:38:33 root@localhost data]#su user5 -c \"echo 123 > f1\" bash: f1: Permission denied [10:38:37 root@localhost data]#usermod -G g1 user5 👈user5加入g1扩展组 [10:39:09 root@localhost data]#id user5 uid=1012(user5) gid=1016(user5) groups=1016(user5),1001(g1) [10:39:11 root@localhost data]# [10:39:15 root@localhost data]#su user5 -c \"echo aaa > f1\" [10:39:28 root@localhost data]#cat f1 aaa 针对user1 同时设置facl的user和group权限，user优先。 [11:03:16 root@localhost data]#setfacl -m u:user1:- f1 [11:03:37 root@localhost data]#su user1 -c 'cat f1' cat: f1: Permission denied [11:03:46 root@localhost data]#su user1 -c 'echo 123 > f1' bash: f1: Permission denied [11:03:49 root@localhost data]#getfacl f1 # file: f1 # owner: root # group: root user::rw- user:user1:--- user:user2:rw- user:user3:-w- group::r-- group:g1:rw- mask::rw- other::r-- [11:03:55 root@localhost data]#id user1 uid=1008(user1) gid=1013(g12) groups=1013(g12),1015(grp001) [11:03:59 root@localhost data]#usermod -G g1 user1 [11:04:08 root@localhost data]#id user1 uid=1008(user1) gid=1013(g12) groups=1013(g12),1001(g1) [11:04:46 root@localhost data]#su user1 -c 'echo 123 > f1' bash: f1: Permission denied [11:05:06 root@localhost data]#su user1 -c 'cat f1' cat: f1: Permission denied 所有文件的权限判定规则：从上往下优先，先中先得 1、先看所有者 2、看针对user的FACL 3、看所属组 4、看针对group的FACL 5、看other 交换机的acl 、linux 路由表 ip roue show (metric小的自动放到上面) ，都是从上到下匹配的， ssg 的policy 也是从上到下匹配，linux的shell脚本、python的主程序都是从上到下，所以此乃天地法则🤮 👇判断所有者优于facl的user [11:12:11 root@localhost data]#getfacl f1 # file: f1 # owner: root # group: root user::rw- user:user1:--- user:user2:rw- user:user3:-w- group::r-- group:g1:rw- mask::rw- other::r-- [11:12:18 root@localhost data]#ll f1 -rw-rw-r--+ 1 root root 7 Jan 29 10:53 f1 [11:12:21 root@localhost data]#chown user1 f1 [11:12:35 root@localhost data]#ll f1 -rw-rw-r--+ 1 user1 root 7 Jan 29 10:53 f1 [11:12:36 root@localhost data]#su user1 -c 'cat f1' aaa bb [11:15:58 root@localhost data]#getfacl f1 # file: f1 # owner: root # group: root user::rw- user:user2:rw- user:user3:-w- group::r-- group:g1:rw- mask::rw- other::r-- 👇判断facl的group 优先于本来的group，这里错啦，group没命令中，自然不起作用啦 [11:16:01 root@localhost data]#su user1 -c 'catf1' bash: catf1: command not found [11:16:10 root@localhost data]#su user1 -c 'echo aa > f1' [11:16:16 root@localhost data]#su user1 -c 'cat f1' aa [11:16:21 root@localhost data]#setfacl -x g:g1 f1 [11:16:48 root@localhost data]#su user1 -c 'cat f1' aa [11:16:54 root@localhost data]#su user1 -c 'echo 11 >> f1' bash: f1: Permission denied [11:16:59 root@localhost data]#getfacl f1 # file: f1 # owner: root # group: root user::rw- user:user2:rw- user:user3:-w- group::r-- mask::rw- other::r-- [11:17:04 root@localhost data]# 删除facl两种方法 -x删一个 -b全删 -R -b dir 递归删除文件夹下所有的acl，据说相当有用 [11:19:58 root@localhost data]#getfacl f1 # file: f1 # owner: root # group: root user::rw- user:user1:--- user:user2:rw- user:user3:-w- group::r-- group:g1:rw- mask::rw- other::r-- [11:28:31 root@localhost data]#setfacl -x u:user1 f1 [11:28:41 root@localhost data]#setfacl -x g:g1 f1 [11:28:46 root@localhost data]#getfacl f1 # file: f1 # owner: root # group: root user::rw- user:user2:rw- user:user3:-w- group::r-- mask::rw- other::r-- [11:28:48 root@localhost data]#setfacl -b f1 [11:28:54 root@localhost data]#getfacl f1 # file: f1 # owner: root # group: root user::rw- group::r-- other::r-- [11:28:57 root@localhost data]# 经典案例 我们复制文件夹的时候总担心权限、所有者、所属组这些信息的丢失，cp -a 可以提供思路 我们修改文件夹的权限比如chmod -R 777 dir/ , 带来的问题是，以后想要回收权限，没有办法了，这个时候facl就提供了很好的思路。 [11:40:55 root@localhost ~]#setfacl -R -m u:user1:r data/ [11:41:02 root@localhost ~]#ll total 12 -rw-r--r--. 1 root root 3 Jan 12 16:53 1 -rw-------. 1 root root 1031 Jan 5 16:52 anaconda-ks.cfg drwxrwxrwx+ 4 root root 61 Jan 29 10:59 data -rw-r--r--. 1 root root 0 Jan 12 16:53 f1 -rw-r--r--. 1 root root 0 Jan 12 16:53 f2 -rw-r--r--. 1 root root 4 Jan 12 17:51 hello.txt [11:41:03 root@localhost ~]#cd data/ [11:41:04 root@localhost data]#ll total 8 drwxr-xr-x+ 2 root root 6 Jan 19 19:57 dir drwxr-xr-x+ 2 user1 g12 6 Jan 19 19:58 dir2 -rw-r--r--+ 1 root root 3 Jan 29 11:16 f1 -rw-r--r--+ 1 user1 g12 0 Jan 19 19:58 f2 -rw-r--r--+ 1 root root 65 Jan 29 10:59 test [11:41:05 root@localhost data]#getfacl f2 # file: f2 # owner: user1 # group: g12 user::rw- user:user1:r-- group::r-- mask::r-- other::r-- [11:41:31 root@localhost ~]#getfacl data # file: data # owner: root # group: root user::rwx user:user1:r-- group::rwx mask::rwx other::rwx [11:41:56 root@localhost ~]#setfacl -R -b data/ [11:42:08 root@localhost ~]# [11:42:09 root@localhost ~]#ll total 12 -rw-r--r--. 1 root root 3 Jan 12 16:53 1 -rw-------. 1 root root 1031 Jan 5 16:52 anaconda-ks.cfg drwxrwxrwx. 4 root root 61 Jan 29 10:59 data -rw-r--r--. 1 root root 0 Jan 12 16:53 f1 -rw-r--r--. 1 root root 0 Jan 12 16:53 f2 -rw-r--r--. 1 root root 4 Jan 12 17:51 hello.txt [11:42:11 root@localhost ~]#ll data/ total 8 drwxr-xr-x. 2 root root 6 Jan 19 19:57 dir drwxr-xr-x. 2 user1 g12 6 Jan 19 19:58 dir2 -rw-r--r--. 1 root root 3 Jan 29 11:16 f1 -rw-r--r--. 1 user1 g12 0 Jan 19 19:58 f2 -rw-r--r--. 1 root root 65 Jan 29 10:59 test [11:42:19 root@localhost ~]# 其他用法参考setfacl -h 比如 setfacl -m d:u:ming:rx dir👈意思是dir文件夹下创建的文件默认就带针对ming的rx权限，d设置的默认权限，删除用setfac -k dir来删 setfacl -X file.acl dir👈意思是file.acl里写好g:sales:rw这些facl的明细，这个比较好的。 setfacl -m u:user1:rwX dir👈X是只是针对文件夹设置，不过我用x一i杨的效果。要么是rocky-linux自带的，要吗是版本高的好处，不管。 getfacl file1 | setfacl --set-file=- file2👈参考chmod里的--reference一个效果，就是将f2的权限设置成f1一样的。 FACL里的mask mask就是设置一个最高权限，谁都不能超过 ll可见group的rwx3位现在用来填充mask的值了。 mask默认设置了facl后位rwx，手动修改后getfacl 可见#effective:rw-这种 mask只影响单个人，所有者和other不受影响 [11:59:54 root@localhost data]#getfacl f1 # file: f1 # owner: root # group: root user::rw- group::r-- other::r-- [11:59:57 root@localhost data]#ll total 8 drwxr-xr-x. 2 root root 6 Jan 19 19:57 dir drwxr-xr-x. 2 user1 g12 6 Jan 19 19:58 dir2 -rw-r--r--. 1 root root 3 Jan 29 11:16 f1 -rw-r--r--. 1 user1 g12 0 Jan 19 19:58 f2 -rw-r--r--. 1 root root 65 Jan 29 10:59 test [12:00:03 root@localhost data]#setfacl -m u:user1:rw f1 [12:00:25 root@localhost data]#ll f1 -rw-rw-r--+ 1 root root 3 Jan 29 11:16 f1 [12:00:27 root@localhost data]#setfacl -m u:user2:rwx f1 [12:00:42 root@localhost data]#ll total 8 drwxr-xr-x. 2 root root 6 Jan 19 19:57 dir drwxr-xr-x. 2 user1 g12 6 Jan 19 19:58 dir2 -rw-rwxr--+ 1 root root 3 Jan 29 11:16 f1 -rw-r--r--. 1 user1 g12 0 Jan 19 19:58 f2 -rw-r--r--. 1 root root 65 Jan 29 10:59 test [12:00:44 root@localhost data]#getfacl f1 # file: f1 # owner: root # group: root user::rw- user:user1:rw- user:user2:rwx group::r-- mask::rwx 👈mask默认值 other::r-- [12:00:57 root@localhost data]#setfacl -m mask::r f1 [12:01:14 root@localhost data]#ll total 8 drwxr-xr-x. 2 root root 6 Jan 19 19:57 dir drwxr-xr-x. 2 user1 g12 6 Jan 19 19:58 dir2 -rw-r--r--+ 1 root root 3 Jan 29 11:16 f1 👈修改mask后group位的3位用来表示mask的3位 -rw-r--r--. 1 user1 g12 0 Jan 19 19:58 f2 -rw-r--r--. 1 root root 65 Jan 29 10:59 test [12:01:15 root@localhost data]#getfacl f1 # file: f1 # owner: root # group: root user::rw- user:user1:rw- #effective:r-- 👈注意mask影响了单个用户的权限上限 user:user2:rwx #effective:r-- group::r-- mask::r-- other::r-- [12:01:20 root@localhost data]# facl的备份 怎么备份和还原 getfacl -R /tmp/dir1 > acl.txt 👈备份到acl.txt setfacl -R -b /tmp/dir1 👈清空下，Centos8 -b一旦用了，组权限清空为---，8的BUG,centos7亲测没问题，放心用，读我这篇的你自己测你的版本啊。 setfacl -R --set-file=acl.txt /tmp/dir1 👈恢复方法1 setfacl --restore acl.txt 👈恢复方法2 getfacl -R /tmp/dir1 👈递归，也就是包含dir1及其下所有文件的facl cp -p 或-a就能备份facl，还有所有者权限等 mv 也支持facl这些的保留 tar不行，tar备份的时候facl就丢了 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-11-30 19:45:46 "},"7-文本三剑客1_grep和正则表达式/7-文本三剑客1_grep和正则表达式.html":{"url":"7-文本三剑客1_grep和正则表达式/7-文本三剑客1_grep和正则表达式.html","title":"第七章 文本三剑客1_grep和正则表达式","keywords":"","body":"第七章 文本三剑客1_grep和正则表达式 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:01 "},"7-文本三剑客1_grep和正则表达式/1-常见文本处理工具.html":{"url":"7-文本三剑客1_grep和正则表达式/1-常见文本处理工具.html","title":"第1节 常见文本处理工具","keywords":"","body":"第1节. 常见文本处理工具 cat查看行结束符/行尾 cat -A查看回车、换行、TAB建 👆cat 空行不算行号 cat 压缩连续空行 倒着看tac和rev nl等价于cat -b 文本截取前后 head默认前10行 tail默认后10行 head一行内取前3个字节，密码生成方法2 前面有openssl还有一种，这里就是3中随机数的生成方法了。好像就一个靠谱，其他缺胳膊少腿的。 tail -f和-F跟踪是不同的，删除文件的效果 文件描述符时连接着inode的，删除文件后重新创建同名，其实inode变了。 文件名就是简单的只看名称了 当然文件描述符本身和inode也不是等价的 只要文件名恢复了，tail -F又继续跟踪了 只是理解一下各个用法，不一定这么用 这就是一个取某个网卡IP地址的固定语法咯，可以做成别名来用。 cut列截取 多个空格的压缩成1个边缘cut基于空格 进一步 [16:14:14 root@localhost ~]#df Filesystem 1K-blocks Used Available Use% Mounted on devtmpfs 897812 0 897812 0% /dev tmpfs 916616 0 916616 0% /dev/shm tmpfs 916616 8868 907748 1% /run tmpfs 916616 0 916616 0% /sys/fs/cgroup /dev/mapper/rl-root 17811456 2153364 15658092 13% / /dev/sda1 1038336 198012 840324 20% /boot tmpfs 183320 0 183320 0% /run/user/0 [16:14:16 root@localhost ~]# [16:14:17 root@localhost ~]#df |cut -c48-51 Use 0 0 1 0 13 20 0 [16:14:18 root@localhost ~]#df |cut -c48-51|tr -dc '[0-9\\n] ' 0 0 1 0 13 20 0 [16:14:50 root@localhost ~]#df |cut -c48-51|tr -dc '[0-9\\n]' 0 0 1 0 13 20 0 [16:14:55 root@localhost ~]# 👆这可以作为观察服务器的登入信息 👇看网站访问信息 linux的词汇量？ 起密码的时候，说明你这是一个单词不让你起，凭的就是这个words里的单词了吧 文件内容纵向合并 文件内容横向合并 两个文件的内容合并到一行 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:01 "},"7-文本三剑客1_grep和正则表达式/2-文本三剑客1_grep和正则.html":{"url":"7-文本三剑客1_grep和正则表达式/2-文本三剑客1_grep和正则.html","title":"第2节 文本三剑客1_grep和正则","keywords":"","body":"第2节. 文本三剑客1_grep和正则 wc统计 显示最长一行的长度（单位字符？5个字符） sort排序 排名部分先后，可以用R 对第3列当作数字进行排序 对IP地址排序， 这个还是要用lambda去排的，比如接口和IP这种g1/0/1,192.16.10.1分段去比较的，这里仅仅是整体比一下，看下效果就好。 sort -u 去掉重复行 uniq删除上下连续的重复行 last -f wtmp就是last一个意思 [17:33:36 root@localhost data]#ll /var/log/*tmp -rw-rw----. 1 root utmp 2688 Jan 17 12:00 /var/log/btmp 👈lastb看的是这个文件，是密码输错了的记录 -rw-rw-r--. 1 root utmp 36480 Jan 29 11:15 /var/log/wtmp 👈last看的就是这个文件，是登入成功的记录 [17:33:41 root@localhost data]# 👆以什么样的用户猜密码的，安全加固的方式 uniqd -d 只显示重复的 uniq 的话如果不前置一个sort排序的话，就只是抓取连续的情况。 找出两个文件的相同行 👆上面的题目有BUG啊，如果a.txt里有两行z，那么就会误判咯。 [17:50:07 root@localhost data]#cat f1 z z a b c [17:50:10 root@localhost data]#cat f2 b c [17:50:11 root@localhost data]#cat f1 f2 | sort |uniq -d b c z [17:50:23 root@localhost data]# 可以这样优化👇，先各自去重后再cat结合再找出重复的就行了。 [17:51:20 root@localhost data]#cat f1 z z a b c [17:51:29 root@localhost data]#cat f2 b c [17:51:49 root@localhost data]#uniq f1 |cat - f2 z a b c b c [17:52:22 root@localhost data]#uniq f1 |cat - f2 | sort | uniq -d 👈这才是正解-d就是重复的 b c [17:52:29 root@localhost data]#uniq f1 |cat - f2 | sort | uniq -u 👈u就是取uniqu不一样的 a z 比较文件 -号代表第一个文件，+代表第二个文件,-号去掉+号加上 👆注意patch -b 选项是为了恢复之前先备份a.txt，因为patch的还原文件时直接将a.txt原文件覆盖掉的。 grep三剑客之一 grep不一定都带颜色，因为root的grep系统默认是别名 grep选项 grep -m匹配N次后停止 grep -i忽略大小写 grep -n命中第几行 grep -c匹配的行数 grep -o 命中多少个单行内多次也算 统计文本出现字符的次数-o出现一次单行列出来，再wc -l计算行数 grep -q 静默输出0找到1没找到0是true保持一惯的linux的真假标准 grep -A或-B或-C还是经常用的，但是cisco的show run | section router ospf显然更优化 此外还有-B -C nmap扫描、关于IP探测要总结一下好几种呢ping呢也是有灰常快速的方法的很赞的，当然ping肯定不可靠的。 👉最好是探测该IP上的几个常用端口，然后才能说这个IP是不是UP。他这个sP就是scan ping，聊胜于无，要用-Pn去扫 这招可以用来梳理IDC或者内网的HOST网段使用情况，选项不靠谱，仅作参考咯。 --- grep -E \"XX|YY|ZZ\"或的关系等价于grep -e xx -e yy -e zz 一样 grep 并且过滤 grep -w单词等价于grep的定界符grep \"\\\" grep -w 或grep \"\\\"的这个单词整体 判断的能力： 👆数字 字母 下划线 是一个单词，- 默认会当作分隔符的 ；同样也算作分隔符了 -w就是查找root单词，而root-er是当做root和er两个单词的。-不会被当做一个整体的。 不支持regex，这是什么需求？👇就是比如. *这玩意不做正则的时候，省的转义了 -F 或者fgrep就挺好，挺好~lizheng~tt tx sf sx grep -f 文件内容去匹配，这个玩意支持regex吗？支持的 用文件过滤文件，文件里也是可以写正则的 说明：以前学习的通配符是匹配文件名的，而grep里的正则是匹配文本内容的。 而且通配符的*和regex的\\，以及通配符的.和regex的.都不太一样。regex的.\\表示所有差点比如换行符？，而且regex的*不能独立存在，然是通配符的*就是自称一体表示所有。 1、regex的 .表示 除了 \\n以外任何一个字符，*表示前面的字符不出现或者出现N次。 2、通配符的.就表示. 而通配符的*表示除了.开头的文件名，其他都可以匹配(大概吧哈哈，有的文章说明什么路径中带/的，我就纳闷了通配符是抓文件名的，你文件名中能带/这玩意？呵呵所以这块理解的差不多得了，够了)，包括文件名中带.的(只要不是.开头的就好) 3、还有regex和通配符的其他区别，比如[a-z]在通配符中表示小写的a-z和大写的A-Y不到Z；regex显然没这么奇葩。 好，下面是工作中遇到的补充👇 -l, --files-with-matches Suppress normal output; instead print the name of each input file from which output would normally have been printed. The scanning will stop on the first match. 就是去重的效果咯，我只要知道在哪个文件里，不需要知道一个文件里出现了几次，所以加上-l。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:01 "},"7-文本三剑客1_grep和正则表达式/3-基本和扩展正则.html":{"url":"7-文本三剑客1_grep和正则表达式/3-基本和扩展正则.html","title":"第3节 基本和扩展正则","keywords":"","body":"第3节 基本和扩展正则 举个例子 [^ming] 不是m、i、n、g的字符 [0-9] [[:lower:]] 任意一个小写字母 . 任意一个非\\n的字符 * 前一个字符出现0次或N次 a\\? a出现了0次或1次，可有可无的表达方式 a\\+ a出现1次及以上 a\\{10\\} a出现了10次 a\\{10,20\\} 10到20次 a\\{,20\\} 20次以下 a\\{10,\\} 10次以上 .* 所有但是不能匹配\\n，所以你用.*抓全文只能抓到换行符就结束了， .*等价于通配符里的* 位置锚定 [16:47:46 root@host1 ~]#grep -v \"^#\" /etc/fstab /dev/mapper/centos_host1-root / xfs defaults 0 0 UUID=e36eac36-1940-4883-8c19-a05f6b4bb4a6 /boot xfs defaults 0 0 /dev/mapper/centos_host1-swap swap swap defaults 0 0 [16:47:55 root@host1 ~]# [16:47:56 root@host1 ~]# [16:47:56 root@host1 ~]#grep ^[^#] /etc/fstab /dev/mapper/centos_host1-root / xfs defaults 0 0 UUID=e36eac36-1940-4883-8c19-a05f6b4bb4a6 /boot xfs defaults 0 0 /dev/mapper/centos_host1-swap swap swap defaults 0 0 [16:48:07 root@host1 ~]# 上图注意下，grep -v \"^#\" 和 grep \"^[^#]\"的区别，明显第二种也过滤空行。因为[^#]里面至少的又一个字符的。 这种[^#]写法是有问题的，不推荐这么写。 搜索shutdown行尾👆 [[:space:]]他不仅仅抓空格，还抓TAB。当然上图其实都是空格，因为做了4空格等1tab的设置，取消后再验证下 还是[[:space:]]能够抓到空格和TAB的。没问题。注意一个细节，cat -A 是能够区分TAB和空格的，但是如果你优化了tab=4空格，那么就自然都是空格了。-A看到的都是空格了就。 搜索空行👆 单词：在系统中，数字字母下划线都算单词的范畴。此外都不算单词。 空行是^$,空白行^[[:space:]]*$ 注意，写的思路： :%s///g :%s/(abc)(123)/1eradmin2/g :%s/(abc)(123)/\\1eradmin\\2/g 👆这个叫后向引用，在后面的sed搜索替代有关 nginx里也有后向引用的 [17:30:32 root@host1 ~]#echo rootrootxxroot |grep -E \"(root){2}\" rootrootxxroot 👆抓两连续的root 练习 4题 cat /etc/passwd |grep -E \"[0-9]{2,3}\" -o | grep -Ev ^0 👈这是错误的，因为4位数也会搜出来的比如65534这个数字也会当作655和34两个匹配结果的，需要词尾锚定 cat /etc/passwd |grep -E \"/\" -o | grep -Ev ^0 注意该方法由于是:xx:所以对于后面的数字是不匹配的。 方法一肯定只能是抓出第一个段数字， 方法二可以匹配所有数字 --- 词尾铆钉的必要性👇 扩展正则 grep -E还是有一些还是需要加\\的。 nginx的后向引用举例 这是nginx里的rewrite替换的正则写法 windows里也有正则 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:01 "},"8-shell脚本编程基础/8-shell脚本编程基础.html":{"url":"8-shell脚本编程基础/8-shell脚本编程基础.html","title":"第八章 shell脚本编程基础","keywords":"","body":"第八章 shell脚本编程基础 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:01 "},"8-shell脚本编程基础/1-shell编程脚本基础.html":{"url":"8-shell脚本编程基础/1-shell编程脚本基础.html","title":"第1节 shell编程脚本基础","keywords":"","body":"第1节. shell编程脚本基础 编程基础 shell和py都是边解释边执行 gcc是个编译软件，可以把高级语言转换成机器代码 gcc就是编译器 在执行的时候有python解释器，会读到内存里翻译成机器码了。但是这个机器码是在内存里的，不是个放在硬盘里的文件。它是边执行边翻译。 编程基本概念 shell脚本基础 创建shell脚本 脚本规范 脚本的基本结构 vim的初始化 脚本执行的方法1:bash xxx 方法2，source xxx和. xxxx 方法3：添加执行权限 👆直接运行脚本，就是外部命令了，是要到PATH变量里找路径的，而当前目录是/root并不在PATH变量里，所以找不到。 添加到PATH变量 👆其实也可以用ln -s 软连接来实现path变量的 但是如果你以后很多脚本都统一放到/data/scipts下的话，还是加/data/scripts为PATH变量好一点 脚本运行方法4：传递给bash命令 evn.sh，只要是sh后缀就行了。 例子，写个脚本创建用户 让其口令立即过期 chage -d 0 test等价于passwd -e tezt都是修改date of last password chage这个值为0，意思就是登入后强制修改密码 语法错误检查方法 两种语法检查方法 删除if那行后 再次执行就OK了 举个例子 之前接触过%s/xx/yy/g，现在又看到了.,$s/XX/yy/g .点表示当前行号,逗号是一直到整个文件最后一行 u撤销后，改成 引号替换一下 变量 变量代表着内存空间 内存中的一个地址块放了magedu，而name就表示地址值。于是就是name中存放了magedu。 变量，值可变化，当然也有不可变 python和shell都不需要事先申明变量 变量起名规范 特殊变量 👆变量的正儿八经的写法，很重要 如果此时Y的值变成了30，问X的值是多少，这个在PYTHON里面叫变量赋值，如果是列表、字典是需要.copy()的 变量取消 上图替换语法存在错误 不用加g，%s/xx/yy/g，的g如果是每行只有一个不需要加g全局 一般脚本结束了变量也就没了。不过还是建议删掉。 把命令放到变量里 第一题答案就有了 cp -a 的a等价于-dR 文件夹不存在cp会直接创建的 第二题答案 nl 和 cat -b一个意思，不过不能列出空行行号 环境变量的查看 env和printenv是等价的 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:01 "},"8-shell脚本编程基础/2-shell编程特殊位置变量.html":{"url":"8-shell脚本编程基础/2-shell编程特殊位置变量.html","title":"第2节 shell编程特殊位置变量","keywords":"","body":"第2节. shell编程特殊位置变量 初识变量生效范围 1、tty再开一个终端就没了 2、退出后就没了 3、再次运行/bin/bash后就没了👇 [23:15:39 root@host1 ~]#NAME=ming [23:15:43 root@host1 ~]#echo $NAME ming [23:16:21 root@host1 ~]#pstree |grep -A 2 bash |-sshd---sshd---bash-+-grep | `-pstree |-systemd-journal [23:16:34 root@host1 ~]#pstree -p |grep -A 2 bash |-sshd(1191)---sshd(2132)---bash(2140)-+-grep(2207) | `-pstree(2206) |-systemd-journal(502) [23:17:10 root@host1 ~]#/bin/bash [23:17:17 root@host1 ~]#pstree -p |grep -A 2 bash |-sshd(1191)---sshd(2132)---bash(2140)---bash(2208)-+-grep(2239) | `-pstree(2238) |-systemd-journal(502) [23:17:29 root@host1 ~]#echo $NAME [23:17:36 root@host1 ~]#echo $BASHPID 2208 [23:17:49 root@host1 ~]#exit exit [23:17:52 root@host1 ~]#echo $BASHPID 2140 [23:17:56 root@host1 ~]#echo $NAME ming [23:17:58 root@host1 ~]# 父进程的NAME变量并没有传给子进程。 每个账号都有个shell类型，比如👇，表示root账号一登入就会自动去运行/bin/bash [23:23:25 root@host1 ~]#getent passwd root root:x:0:0:root:/root:/bin/bash 父进程的NAME变量并没有传给子进程，如果需要传进去，就要使用环境变量。 其上👆这句话也不完全对，换个方式就能将局部变量传进去了，比如小括号 环境变量 查看上级父进程编号 查看环境变量 举例EDITOR=vim 默认编辑器是 vipw是调用的EDITOR编辑器这个变量，而EDITOR默认复制应该就是vi，如下： 现在将EDITOR改成vim，再看，发现还是黑底白字，只有将EDITOR提升为环境变量，才会出彩，也就是vipw调用的是环境变量EDITOR里的值，普通变量没有关系。 unset name普通变量和环境变量都适用 环境变量可以由父进程传给子进程，但是不能从子进程传给父进程，也就是说子进程里修改的环境变量只在子进程里有效，退出子进程后，在父进程中还是原来的值；但是子进程再次赋值可以影响身后的子进程 [23:49:22 root@host1 ~]#export name=ming [23:49:42 root@host1 ~]#echo $name ming [23:49:46 root@host1 ~]#bash [23:49:51 root@host1 ~]#echo $name ming [23:49:55 root@host1 ~]#name=yi [23:50:11 root@host1 ~]#echo $name yi [23:50:13 root@host1 ~]#export name=yi 👈多余动作，name早就是环境变量了，所以无需再次申明 [23:50:24 root@host1 ~]#echo $name yi [23:50:28 root@host1 ~]#exit exit [23:50:29 root@host1 ~]#echo $name ming [23:50:31 root@host1 ~]# shell的嵌套深度 上一次执行的命令 常量就是只读变量 可能父进程和子进程配合使用是有用的， 小括号就是开启子shell，一运行完，子shell就退出了 注意只针对内部命令和变量赋值 证明小括号就是开启了子shell 上图👆此时可以再开一个窗口pstree -p看到确实8542就是7703的子进程 大括号和小括号是不同的 上图说明，小括号开启子进程，大括号不开启子进程。 位置变量 这样的话，就可以将输入的固定位置的参数变量传到脚本里面。 对比下$*和$@ 引号引起来才是一个整体，不能去掉。 练习，rm=rm.sh，rm.sh里写mv f1.txt /tmp/当前日期精确到秒，开局设置里可以用 用mv替代rm 如果要使用原来的rm，则\\rm就行了，不过要自带-i了 其他注意事项 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-12-05 14:02:03 "},"8-shell脚本编程基础/3-算术逻辑运算和条件测试.html":{"url":"8-shell脚本编程基础/3-算术逻辑运算和条件测试.html","title":"第3节 算术逻辑运算和条件测试","keywords":"","body":"第3节. 算术逻辑运算和条件测试 退出状态 [00:16:02 root@host1 ~]#grep aaa /etc/passwd #找到找不到结果自然不同 [03:44:30 root@host1 ~]#echo $? 1 [03:44:35 root@host1 ~]#grep -q root /etc/passwd [03:44:59 root@host1 ~]#echo $? 0 [03:45:02 root@host1 ~]# 错误对照表：https://www.cnblogs.com/x_wukong/p/5148237.html 一个脚本里2条命令，最后一条执行成功了，返回的$0就是0 算术运算 图中的echo $[$RANDOM%50]里面的$可以去掉的，因为$[]里面会认为RANDOM就是变量 方法一：let 方法二：中括号 方法三：2个小括号 方法四：expr 方法五：declare申明强制运算 65取模是0-64 如果是0-65的随机数呢？哈哈，不好弄了吧。 /66啊，不就行了哦，笨哦。 颜色的取值范围是31-37，可以用RANDOM随机数产生，用7取模范围就是0-6，+31就可以了。 ++i和i++ let id+=5 就是 id=id+5 逻辑运算与或非 python里也学过与或非，来了解一下，哈哈哈 and是与，&也是与，两者截然不同，貌似相同又。举例 再来 再看 懂了吧~ 1、and和or是基于运算符两边的整体值来算的；而&又叫做位与是将运算符两边化作0101后再进行位与的哈哈，我在用名称解释名称咯，额。 2、然后and和or里的99 or 100 和99 and 100也挺有意思的。一句话做人呐or就行了，做研究呐可能需要and。 or就是已经是true的情况下就不会再继续比了。反正或的话，结果都是true。 and就是当前如果是真，就一定要看到最后一个元素，万一他是假，就全盘就是假了，所以要那最后一个元素。A(true) and B(true)也就取B了。 3、一句话，or和and是真假运算--基于表达式两边的整体，而&和|是二进制的与或运算--基于表达式两边的数值的二进制单个位来算的。 这里的短路与的真假，不要简单按上图0和1，去理解，0啊他这个图是假的意思。但是linux，true你去echo $?会发现是0，所以0代表的是真。所以这种运算是真假运算，不要用0和1区理解，除非你定死了01和真假的一一对应。 当然也可以不要理解短路与，而直接理解第一个cmd1执行ok了再执行cmd2：cmd1 && cmd2 true和false就是命令，专门产生真假的 还有yes就是专门产生y，不停的 其实不是y，而是yes后面的参数 两个变量值互换 方法二就是上图的A^B=C，C^A=B，C^B=A x=$[x^y]就是得出了中间值C赋值给了x，x此时就是中间值。然后拿中间值x去和y异或得到的就是原来的x，将x赋值给y。此时y里的值就变成了x。再拿中间值x去和现在的y--其实是原来的x异或就得到原来的y将此值赋给x，这样x里的值就变成了原来的y。 短路与 短路或 true是真，echo true本身也是真，同时打印出true，此时两个都是真，结果就是真，后面的就不执行了。 false是假，只要是假都是假，所以就不会执行后面的 echo true。 然后不会执行&&后面的内容，但是&&的结果还是假，所以就会执行||后面的内容，于是打印出false了就。 test比较表达式 这个和if else还不是一样的，因为A && B || C，不是if A成立就执行B，A不成立就执行C这么简单，还多一个A成立执行B，B执行失败，那么||前面的整体就是假，于是还是会执行C的。 除了字符串的比较，还有数字比较 printf是是格式化字符串的。类似python里的format 中括号代替test test $x -gt $y Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:01 "},"8-shell脚本编程基础/4-条件判断.html":{"url":"8-shell脚本编程基础/4-条件判断.html","title":"第4节 条件判断","keywords":"","body":"第4节. 条件判断 判断是否为空 不是的，空格当然不为空，但是[ ]综括号的写法 里面空格再多就是不算的。你引号来表示空格试试 上图是help test出来的，内部命令的帮助用法help xx 0自然也不是空 文件夹存在就不创建的方法 存在就不会创建了。 本身touch就是这样的效果了，不过touch一个存在的文件，虽然内容不会清掉，但是3个时间统统刷新。如下 [03:22:10 root@host1 ~]#stat f1 File: ‘f1’ Size: 9 Blocks: 8 IO Block: 4096 regular file Device: fd00h/64768d Inode: 71287069 Links: 1 Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root) Context: unconfined_u:object_r:admin_home_t:s0 Access: 2022-02-02 18:49:12.966012106 +0800 Modify: 2022-02-02 18:49:11.773012078 +0800 Change: 2022-02-02 18:49:11.777012078 +0800 Birth: - [03:22:14 root@host1 ~]#cat f1 dd [03:22:17 root@host1 ~]#touch f1 [03:22:21 root@host1 ~]#ll f1 -rw-r--r--. 1 root root 9 Feb 6 03:22 f1 [03:22:24 root@host1 ~]#stat f1 File: ‘f1’ Size: 9 Blocks: 8 IO Block: 4096 regular file Device: fd00h/64768d Inode: 71287069 Links: 1 Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root) Context: unconfined_u:object_r:admin_home_t:s0 Access: 2022-02-06 03:22:21.871014487 +0800 Modify: 2022-02-06 03:22:21.871014487 +0800 Change: 2022-02-06 03:22:21.871014487 +0800 Birth: - [03:22:26 root@host1 ~]#cat f1 dd -e -a后面不跟文件，单单一个-e或者-a就不认为是选项了，而是当作字符了，有字符就是非空了👆👇所以使用-e这种一定要后面用双引号引起来。 所以加上 双引号 可以避免严重逻辑错误， 判断是否位数字，可以用正则表达式👇 [03:41:04 root@host1 ~]#[ \"11\" -gt 10 ] && echo true true [03:41:09 root@host1 ~]#[ '11' -gt 10 ] && echo true true [03:41:16 root@host1 ~]#[ 'xx' -gt 10 ] && echo true -bash: [: xx: integer expression expected [03:41:22 root@host1 ~]# 说明linux里的引号，并不会改变里面值的类型，这里11引起来还是数字，不会变成字符串。这话不对， 其实是shell是动态编译语言--就是类型是随时改变的。 双综括号里面支持正则，需要这么写： 纯数字的判断👆 还是需要补上双引号👆，虽然不影响结果，一般在[]里变量都是推荐加上双引号。 判断是否位.sh后缀 判断合法IP 判断是否是一个合法IP的办法：其实还可以进一步到A B C 类地址以及私网地址。 下图第三行才是正解，没有^和$就是包含了。 注意上图命令是转行了 reg嵌入到字符串表达式里shell的写法。 并且的关系-方法1 [ xxx -a yyy] 并且的写法，不过它这里不支持正则了，正则得用短路与，不过不是普遍适用的，可能还需要第二种方式： 并且的关系-方法2 判断的是实际上的权限，不是表面上的文件权限。上图是root执行的命令，所以就是可读可写的。 但是执行权限不同，root也是需要文件的执行权限的。 补充个点，f1.sh要执行，用户要有f1.sh的r读权限，然后再/bin/bash f1.sh就能执行了，如果连f1.sh的读权限都没有，必然无法执行的。 [04:52:19 root@host1 ~]#su user1 [04:52:23 user1@host1 root]$bash /data/f1 bash: /data/f1: Permission denied [04:52:27 user1@host1 root]$ll /data/f1 ----------. 1 root root 23 Feb 6 04:49 /data/f1 [04:52:30 user1@host1 root]$exit exit [04:52:58 root@host1 ~]#chmod 444 /data/f1 [04:53:09 root@host1 ~]#ll /data/f1 -r--r--r--. 1 root root 23 Feb 6 04:49 /data/f1 [04:53:11 root@host1 ~]#su user1 [04:53:15 user1@host1 root]$bash /data/f1 xxx 需求： 写个脚本user10.sh创建用户，考虑用户存在以及user10.sh后没有跟参数的问题。 上图是第一版有问题啊不少 这版是OK了 这是对应的结果 可能$1为空要改一下，改成S# 好理解一下，一个参数都没有不就是$1为空嘛。对不对，所以上面无需修改。 但是还是有问题 添加花括号： 现在应该OK了 可以个屁，（ ）小括号是子shell，exit10是退出的子shell。 优化一下将Changing passowd for user tom和passwd：xxx隐藏。 如果你干了这事：将chmod的执行权限弄没了 利用facl修复权限 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-12-08 14:31:17 "},"8-shell脚本编程基础/5-算术运算和read.html":{"url":"8-shell脚本编程基础/5-算术运算和read.html","title":"第5节 算术运算和read","keywords":"","body":"第5节. 算术运算和read && || 和 || &&先后效果不一样 = 是比字符串 -eq是比整数的，小数不行。 上图的两个等号，一般一个就行了，双综括号里可以用两个等号，然后双综括号里一般用=~正则表达式。 read read varXX unset varXX 这两个后面跟的都是变量名，不需要加$xxx这样。就是变量了。 优化不换行 echo 不换行 再次优化，read的本身就自带提示语句 写个脚本实现鸡兔同笼算法 read一下赋值多个 失败案例 man bash可见 管道符后面是一个子进程，所以要括起来，你用小括号就是子进程后面再接一个子进程了。 花括号就是管道符-子进程后面直接一个整体。 总之作为一个整体就行了。 证明管道符确实开启了子进程 先来一个还阔以但是有点不太推荐的解法，因为短路与或用的太多了 if条件判断 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:01 "},"8-shell脚本编程基础/6-脚本条件分支和安全.html":{"url":"8-shell脚本编程基础/6-脚本条件分支和安全.html","title":"第6节 脚本条件分支和安全","keywords":"","body":"第6节. 脚本条件分支和安全 type xxx一般可见就是build in 这种内部命令或者外部命令或者alias，现在忽然发现type if不一样的显示 [17:19:51 root@host1 ~]#type echo echo is a shell builtin [17:19:59 root@host1 ~]#type help help is a shell builtin [17:20:07 root@host1 ~]#type ls ls is aliased to `ls --color=auto' [17:20:09 root@host1 ~]#type cp cp is aliased to `cp -i' [17:20:10 root@host1 ~]#type date date is /usr/bin/date [17:20:13 root@host1 ~]#type if if is a shell keyword 👈不能独立作为命令，是shell的关键字 [17:20:15 root@host1 ~]# 老王说得好，世界上最远的距离就是，一个在if下，另一个在else里。 if的shell格式 有个问题啊，上面的exit没有意义。下面的都是一样效果，# 怎么没有意义，那会的脑子是没带嘛我！ 有啥意义 你告诉我呢。我告诉你个二五仔，fi下面要是还有东西，你不加exit试试。要做靓仔啊，不要做二五仔啊~ 例子：ping一个主机通就算了，不通看下是否处于维护状态(维护的机器一般规范的话是放到一个文件里记着的)，如果不在维护 则认为机器是down的。 if不适合的情况 此时就需要case 👆上图注意关键字：变量引用。变量引用和变量是两码事，变量引用是要加$的，就是说case 和read 不同，read后面是直接写NAME就表示变量了，而case得写$NAME，引用一下。 注意：PAT1)是通配符，不是正则！ 变量引用和变量是两码事 if开头，fi结尾，case开头esac结尾。 下面是一些补充 上图的小括号是什么鬼？！，上图还差一个小括号没讲，小括号的优先级最高。 各种符号的优先级见👆上图： 小括号的分组优先级最高 1、命令行里先拆成单词， 2、然后看单词里有没有别名，别名要展开 3、然后看花括号，也要展开，{1..10}这种 4、如果有~表示家目录 5、然后再看$()和``表示里面放的命令 6、因为5所以再次将命令行拆成单词 7、展开通配符命令的文件名 8、接着再重定向 9、最后再运行命令 转义 [11:18:16 root@localhost ~]#echo \"ls\" 👈双引号防止扩展，就是转义的意思 ls 上图就是说双引号也可以转义，但是以下几个情况转不了。 [11:23:13 root@localhost ~]#echo \"$PATH\" /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin [11:23:20 root@localhost ~]# [11:23:24 root@localhost ~]#echo \"`ls`\" 1 anaconda-ks.cfg data f1 f2 hello.txt [11:23:50 root@localhost ~]#\"!1020\" \"ls\" 1 anaconda-ks.cfg data f1 f2 hello.txt [11:29:23 root@localhost ~]#echo \"\\\\n\" \\n [11:29:25 root@localhost ~]#echo '\\\\n' \\\\n [11:29:28 root@localhost ~]# 环境配置文件等到底放哪里 “个人配置”只影响家目录的这个用户，“全局” 所有用户生效。 交互登入就是：xshell或者直接终端登入，su - 完全切换是交互式登入。 非交互登入：su 这种不完全切换就是非交互式登入；图新界面里右键打开终端也是非交互登入；脚本登入； 👉非交互方式，看的配置文件就少了两个，所以推荐放到/etc/profile.d/*.sh这样，你脚本上来也是OK的。不过一般脚本上来也不太需要这些环境配置吧，比如vim 空格 退出不清屏 PS1颜色等脚本上来也不需要的啊。 演示1： [11:45:23 root@localhost ~]#vim /etc/profile 👈最后一行添加echo xxxxyyyy [11:46:01 root@localhost ~]# [11:46:02 root@localhost ~]# [11:46:02 root@localhost ~]#su - user1 👈完全切换的交互登入 Last login: Mon Feb 7 11:45:20 CST 2022 on pts/0 xxxxyyyy [11:46:09 user1@localhost ~]$exit logout [11:46:12 root@localhost ~]#su user1 👈不完全切换的非交互登入 [11:46:14 user1@localhost root]$exit exit [11:46:15 root@localhost ~]# 演示2： 👆仔细看上图，分析一下到底是~/.bash_profile优先还是~/.bashrc优先，对吧，脑经多走两步就出来了。.bash_profile是加载了.bashrc的，如果在fi xxx后面重新设置相同的变量，则就是.bash_profiile优先，如果是在if xxx之前设置，肯定是.bashrc优先嘛，所以上面的PPT也不一定的哦，同理FACL的优先级，owner肯定也没有FACL针对owner的优先。这些不要学的太细，树干+枝叶+框架比较合理。 下图👇是su - 完全切换 这是属于交互方式的真正原因，而不是什么终端，他这个终端明显是GUI里右键调出来--属于非交互式，但是又用了su - 所以最终还是交互式的。 profile是配置文件的意思 bashrc是bash和rc，bash是shell类型，rc是run config，run bash运行的时候的对应的配置文件。run command profile和bashrc分工不是很明确 一般认为profile用来定义环境变量和运行命令或脚本 bashrc用来定义别名和函数还有本地变量 profile和bashrc修改后生效的方法 其实就是把profie当作脚本执行一下 1、加执行权限 2、bash xxx 3、cat xxx | bash 这种有点问题 4、source xxx或. xxx sleep观察source和bash的区别 在文件里跑个slepp 100看看当前的bash，source和bash不同👇 而bash bash会开启子进程，一般运行脚本都会开启子进程。否则可能会影响当前变量的值。 source(.)运行脚本不推荐哈，否则👇；配置文件恰恰建议用source(.) 所以一般脚本不用source。而一般配置config文件就是要用source，因为配置文件就是希望改变当前环境的。 退出的时候执行点东西 set命令相关 $_是上条命令最后一个参数 $-又是啥 插入题外话 关闭**VIM后，屏幕唉显示之前的VIM里的内容：** 在.vimrc文件里加上配置语句： 在.vimrc中设置set t_ti= t_te= 方法二 回到原题 [13:56:43 root@localhost ~]#echo ${-#*i} 👈好神奇的表达式，意思就是$-的值 从左到右 看到i，就连i一起截除掉。其实搜索也没搜到，然后一想换个变量用$-试试，一下子就知道答案了。 mBHs [13:56:46 root@localhost ~]# 然后himBHs的s是这个意思 https://unix.stackexchange.com/questions/329682/what-is-an-s-inside 其他补充 解释下unmask为什么root时022，普通账户时002 uid大于199，并且 gid=uid，则umask=002，否则umask=022 同理 脚本安全 当使用一个没有定义的变量的时候，直接报错。 问题来了，如果上面的脚本写成如下错误 变量写错，$DIR为空，直接就灾难性的把根删了。 将上图略微修改一下（rm -rf $DIR/*.txt），然后👇测试结果如下： 如何避免 上图👆问题大了-如果没有set -u的话就是$DIR不存在直接把/根下面都删了，删库的100种方法你又学废了一种，恭喜恭喜。 还有一个 说明脚本也是在子进程里跑的。 脚本错误就不执行了的方法，因为不是语法错误时会继续执行的。 虽然出错了，但是还是继续执行了 处理方法如下 整一个这个还是不错的。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-12-09 19:26:40 "},"9-文本查找和压缩/9-文本查找和压缩.html":{"url":"9-文本查找和压缩/9-文本查找和压缩.html","title":"第九章 文本查找和压缩","keywords":"","body":"第九章 文本查找和压缩 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:01 "},"9-文本查找和压缩/1-文件查找.html":{"url":"9-文本查找和压缩/1-文件查找.html","title":"第1节 文件查找","keywords":"","body":"第1节. 文件查找 章节目录 grep是过滤文本的行 cut是过滤文本的列 这里是磁盘上搜索文件 locate找文件非常快，依赖于mlocate.db 用updatedb创建/var/lib/mlocate/mlocate.db文件。如果工作中磁盘文件很多，就会占用磁盘IO，瞬间飙高，导致业务被波及。所以需要操作窗口。 默认模糊搜索 👇要updatedb(不能随便用，生产小心)更新一下数据库，就能利用locate查找了 locate支持基本正则 👆基本正则写起来还是比较麻烦，上图。 [15:27:53 root@localhost ~]#find / -name passwd |grep -Ei \"^/[a-z]+/passwd$\" /etc/passwd /Etc/passwd /a/passwd /A/passwd /Z/passwd /z/passwd [15:28:17 root@localhost ~]#find / -name passwd |grep -Ei \"^/[A-Z]+/passwd$\" /etc/passwd /Etc/passwd /a/passwd /A/passwd /Z/passwd /z/passwd [15:28:51 root@localhost ~]#find / -name passwd |grep -E \"^/[A-Z]+/passwd$\" /A/passwd /Z/passwd [15:28:57 root@localhost ~]#find / -name passwd |grep -E \"^/[a-z]+/passwd$\" /etc/passwd /a/passwd /z/passwd [15:29:03 root@localhost ~]#find / -name passwd |grep -E \"^/[a-Z]+/passwd$\" /etc/passwd /Etc/passwd /a/passwd /A/passwd /Z/passwd /z/passwd [15:29:09 root@localhost ~]#find / -name passwd |grep -E \"^/[A-z]+/passwd$\" grep: Invalid range end [15:29:17 root@localhost ~]#find / -name passwd |grep -E \"^/[A-z]+/passwd$\" grep: Invalid range end [15:29:22 root@localhost ~]# 👆通过上面的实验发现find后面的[A-Z][a-z][a-Z]这样写都有其特定的意义，但是没有[A-z]的写法。这点和通配符不同 [15:37:01 root@localhost ~]#locate -r \"^/[a-z]+/passwd$\" [15:37:06 root@localhost ~]#locate -r \"^/[A-Z]+/passwd$\" [15:37:10 root@localhost ~]#find / -name passwd |grep -E \"^/[a-z]+/passwd$\" /etc/passwd /a/passwd /z/passwd 👆可见locate -r只支持正则，所以+这种扩展正则表达式 是不支持的。 [15:38:24 root@localhost ~]#locate -r \"^/[A-Z]*/passwd$\" /A/passwd /Z/passwd [15:39:57 root@localhost ~]#locate -r \"^/[a-Z]*/passwd$\" /A/passwd /Etc/passwd /Z/passwd /a/passwd /etc/passwd /z/passwd [15:40:01 root@localhost ~]#locate -r \"^/[[:alnum:]]*/passwd$\" /A/passwd /Etc/passwd /Z/passwd /a/passwd /etc/passwd /z/passwd [15:40:45 root@localhost ~]#find / -name passwd |grep -E \"^/[[:alnum:]]+/passwd$\" /etc/passwd /Etc/passwd /a/passwd /A/passwd /Z/passwd /z/passwd find 实时查找，其实也可以利用xargs变得快些，同样占CPU，locate就是在机器上APP服务维护阶段执行updatedb会占CPU [15:36:15 root@pyConsole /]#time `ls --hide=proc | xargs -i -P 0 find /{} -name \"*i*\"` -bash: /bin: Is a directory real 0m1.101s user 0m1.206s sys 0m0.336s [15:36:17 root@pyConsole /]#time `ls --hide=proc | xargs -i -P 0 find /{} -name \"*i*\"` -bash: /bin: Is a directory real 0m1.391s user 0m1.496s sys 0m0.356s [15:36:22 root@pyConsole /]#time `ls --hide=proc | xargs -i -P 0 find /{} -name \"*i*\"` -bash: /bin: Is a directory real 0m1.123s user 0m1.186s sys 0m0.363s [15:36:24 root@pyConsole /]#time `find / -name \"*i*\"` find: ‘/proc/4065730’: No such file or directory find: ‘/proc/4065733’: No such file or directory -bash: /boot/efi: Is a directory real 0m1.677s user 0m1.380s sys 0m0.396s [15:36:28 root@pyConsole /]#time `find / -name \"*i*\"` -bash: /boot/efi: Is a directory real 0m1.721s user 0m1.400s sys 0m0.399s [15:36:31 root@pyConsole /]#time `find / -name \"*i*\"` -bash: /boot/efi: Is a directory real 0m1.739s user 0m1.407s sys 0m0.404s [15:36:34 root@pyConsole /]# locate和find一样存在一些普通用户没有某些文件夹权限，也会搜不到。 find默认就是递归查找，也就是会进到子目录里继续查找。 [处理动作]比较实用，搜出来删除之类。 find 指定搜索深度 [16:08:08 root@pyConsole /]#find / -name \"*i*\" -maxdepth 1 find: warning: you have specified the -maxdepth option after a non-option argument -name, but options are not positional (-maxdepth affects tests specified before it as well as those specified after it). Please specify options before other arguments. /bin /sbin /lib /lib64 /media /.bash_history /switch 更精准一些的搜索方法 [16:10:06 root@pyConsole /]#find / -name \"passwd\" /etc/pam.d/passwd /etc/passwd /var/lib/sss/mc/passwd /usr/bin/passwd /usr/share/licenses/passwd /usr/share/doc/passwd /usr/share/bash-completion/completions/passwd [16:10:11 root@pyConsole /]# [16:10:13 root@pyConsole /]# [16:10:13 root@pyConsole /]#find / -name \"passwd\" -maxdepth 2 find: warning: you have specified the -maxdepth option after a non-option argument -name, but options are not positional (-maxdepth affects tests specified before it as well as those specified after it). Please specify options before other arguments. /etc/passwd [16:10:18 root@pyConsole /]#find -maxdepth 2 / -name passwd find: paths must precede expression: / Usage: find [-H] [-L] [-P] [-Olevel] [-D help|tree|search|stat|rates|opt|exec] [path...] [expression] [16:10:59 root@pyConsole /]#find / -maxdepth 2 -name passwd /etc/passwd [16:11:11 root@pyConsole /]#find / -maxdepth 2 -mindepth 2 -name passwd /etc/passwd [16:11:22 root@pyConsole /]#find / -name passwd /etc/pam.d/passwd /etc/passwd /var/lib/sss/mc/passwd /usr/bin/passwd /usr/share/licenses/passwd /usr/share/doc/passwd /usr/share/bash-completion/completions/passwd [16:11:29 root@pyConsole /]# [16:11:32 root@pyConsole /]#find / -maxdepth 3 -mindepth 3 -name passwd /etc/pam.d/passwd /usr/bin/passwd [16:11:36 root@pyConsole /]# find -depth选项,这个有什么应用场景？想不出来 默认是先搜索目录本身，再进到每个目录再去搜索。 现在就是先处理文件，再处理文件夹。应用场景呢？ find自带的是通配符不是正则 find -iname 不分大小写 [16:32:18 root@localhost ~]#find / -name etc /run/initramfs/state/etc /etc /usr/share/factory/etc /usr/local/etc [16:32:25 root@localhost ~]#find / -iname etc 👈忽略大小写的方法，这也是个总结点，以后用▲来表示总结线索吧，▲忽略大小写2 /run/initramfs/state/etc /etc /root/ETc /usr/share/zoneinfo/Etc /usr/share/zoneinfo/posix/Etc /usr/share/zoneinfo/right/Etc /usr/share/factory/etc /usr/local/etc /Etc [16:32:32 root@localhost ~]# find -inum 根据inode编号来搜 [16:54:36 root@localhost ~]#find / -inum 70 /sys/kernel/tracing/events/raw_syscalls/sys_exit/filter /sys/kernel/debug/tracing/events/raw_syscalls/sys_exit/filter /sys/fs/cgroup/devices/system.slice/sys-kernel-tracing.mount/tasks /sys/fs/cgroup/memory/system.slice/system-systemd\\x2dhibernate\\x2dresume.slice/tasks /sys/fs/cgroup/pids/system.slice/systemd-journald-dev-log.socket/pids.current /sys/bus/memory/drivers_autoprobe [16:54:39 root@localhost ~]# [16:54:41 root@localhost ~]# [16:54:41 root@localhost ~]#find / -inum 70 -exec ls -il {} + 👈提前用一下exec看下效果呵呵 70 -rw-r--r--. 1 root root 4096 Feb 7 16:54 /sys/bus/memory/drivers_autoprobe 70 -rw-r--r--. 1 root root 0 Feb 7 16:54 /sys/fs/cgroup/devices/system.slice/sys-kernel-tracing.mount/tasks 70 -rw-r--r--. 1 root root 0 Feb 7 16:54 '/sys/fs/cgroup/memory/system.slice/system-systemd\\x2dhibernate\\x2dresume.slice/tasks' 70 -r--r--r--. 1 root root 0 Feb 7 16:54 /sys/fs/cgroup/pids/system.slice/systemd-journald-dev-log.socket/pids.current 70 -rw-r--r--. 1 root root 0 Jan 29 09:57 /sys/kernel/debug/tracing/events/raw_syscalls/sys_exit/filter 70 -rw-r--r--. 1 root root 0 Jan 29 09:57 /sys/kernel/tracing/events/raw_syscalls/sys_exit/filter [16:54:43 root@localhost ~]# 👆节点编号相同也不是同一个文件哈哈。 插入一个find -exec的用法细节 搜索inode节点编号，以及搜索inode相同的文件(硬的) find 的regex要匹配的是全路径，locate不需要 对比实验 17:07:14 root@localhost ~]#ll /usr/share/pixmaps/ total 92 -rw-r--r--. 1 root root 5459 Sep 9 13:25 cockpit.png -rw-r--r--. 1 root root 13071 Jun 28 2021 fedora-gdm-logo.png -rw-r--r--. 1 root root 21820 Jun 28 2021 fedora-logo.png -rw-r--r--. 1 root root 12760 Jun 28 2021 fedora-logo-small.png -rw-r--r--. 1 root root 6620 Jun 28 2021 fedora-logo-sprite.png -rw-r--r--. 1 root root 1442 Jun 28 2021 fedora-logo-sprite.svg -rw-r--r--. 1 root root 14493 Jun 28 2021 system-logo-white.png 👇这是 -name后跟通配符 [17:07:37 root@localhost ~]#find /usr/share/pixmaps -name *png /usr/share/pixmaps/fedora-gdm-logo.png /usr/share/pixmaps/fedora-logo-small.png /usr/share/pixmaps/fedora-logo-sprite.png /usr/share/pixmaps/fedora-logo.png /usr/share/pixmaps/system-logo-white.png /usr/share/pixmaps/cockpit.png 👇这是 -regex后跟正则(扩展正则，因为不用\\[xx\\]这样写，也支持+)，注意这里的正则匹配的是全路径 [17:08:21 root@localhost ~]#find /usr/share/pixmaps -regex \".*\\.png$\" /usr/share/pixmaps/fedora-gdm-logo.png /usr/share/pixmaps/fedora-logo-small.png /usr/share/pixmaps/fedora-logo-sprite.png /usr/share/pixmaps/fedora-logo.png /usr/share/pixmaps/system-logo-white.png /usr/share/pixmaps/cockpit.png [17:08:30 root@localhost ~]#find /usr/share/pixmaps -regex \"\\.png$\" [17:08:33 root@localhost ~]# [17:08:34 root@localhost ~]# 👇这是locate -r 后跟 正则 [17:09:12 root@localhost ~]#locate -r \"/usr/share/pixmaps/.*\\.png$\" /usr/share/pixmaps/cockpit.png /usr/share/pixmaps/fedora-gdm-logo.png /usr/share/pixmaps/fedora-logo-small.png /usr/share/pixmaps/fedora-logo-sprite.png /usr/share/pixmaps/fedora-logo.png /usr/share/pixmaps/system-logo-white.png 👇当然locate无需全路径 find 选项的PPT总结图 还有一个补充，要注意-name 后面要带上双引号的 [18:32:04 root@localhost ~]#find -name \"f*\" ./f2 ./data/f2 ./data/f1 ./f1~ ./fz~ ./f3 ./f1 ./f1.link [18:32:05 root@localhost ~]#find -name f* find: paths must precede expression: f1~ Usage: find [-H] [-L] [-P] [-Olevel] [-D help|tree|search|stat|rates|opt|exec] [path...] [expression] [18:32:11 root@localhost ~]# [18:32:12 root@localhost ~]# [18:32:12 root@localhost ~]# 按属主和属组查找 默认是print，这里换了个动作-ls 所以其实不用上面的-exec \"ls\" {} + 这么麻烦，简单的ls直接加就行了。 这样-nouser就体现出来了👆 根据文件类型查找 搜索所有文件夹 搜索所有块 搜索空文件或空文件夹 组合条件与或非 非空文件和文件夹 并且关系 或者关系 -a与的运算优先级要比-o或运算高，所以-type f -a -ls先进行运算了。 关键点来了，为什么-name \"f*\" -o -type f -a -ls 后面先算，结果就是t.txt了呢 [17:28:06 root@localhost data]#ll total 16 -rw-r--r--+ 1 root root 10 Jan 29 17:49 f1 -rw-r--r--+ 2 root root 4 Jan 29 17:49 f2 -rw-r--r--+ 2 root root 4 Jan 29 17:49 f2.link drwxr-xr-x. 2 root root 6 Feb 8 10:39 fdir -rw-r--r--. 1 root root 65 Jan 29 10:59 t.txt [17:28:08 root@localhost data]# [17:28:10 root@localhost data]#find ./ -name \"f*\" -o -type f -ls 👈不太好解释为什么变成了1行 33577450 4 -rw-r--r-- 1 root root 65 Jan 29 10:59 ./t.txt 👆上面的命令等价于下面两个的结果做了-o，但是-o显然不能用man里的用法来解释这个结果。 [17:28:12 root@localhost data]#find ./ -name \"f*\" ./f1 ./f2 ./fdir ./f2.link [17:28:16 root@localhost data]#find ./ -type f -ls 33577448 4 -rw-r--r-- 1 root root 10 Jan 29 17:49 ./f1 33577447 4 -rw-r--r-- 2 root root 4 Jan 29 17:49 ./f2 33577450 4 -rw-r--r-- 1 root root 65 Jan 29 10:59 ./t.txt 33577447 4 -rw-r--r-- 2 root root 4 Jan 29 17:49 ./f2.link [17:28:21 root@localhost data]# 👇倒是如果大家都是一个格式都是ls -l长格式就可以-o了 [17:32:00 root@localhost data]#find ./ -name \"f*\" -ls 33577448 4 -rw-r--r-- 1 root root 10 Jan 29 17:49 ./f1 33577447 4 -rw-r--r-- 2 root root 4 Jan 29 17:49 ./f2 51325760 0 drwxr-xr-x 2 root root 6 Feb 8 10:39 ./fdir 👈 33577447 4 -rw-r--r-- 2 root root 4 Jan 29 17:49 ./f2.link [17:32:02 root@localhost data]#find ./ -type f -ls 33577448 4 -rw-r--r-- 1 root root 10 Jan 29 17:49 ./f1 33577447 4 -rw-r--r-- 2 root root 4 Jan 29 17:49 ./f2 33577450 4 -rw-r--r-- 1 root root 65 Jan 29 10:59 ./t.txt 👈 33577447 4 -rw-r--r-- 2 root root 4 Jan 29 17:49 ./f2.link [17:32:08 root@localhost data]#find ./ -name \"f*\" -ls -o -type f -ls 33577448 4 -rw-r--r-- 1 root root 10 Jan 29 17:49 ./f1 33577447 4 -rw-r--r-- 2 root root 4 Jan 29 17:49 ./f2 33577450 4 -rw-r--r-- 1 root root 65 Jan 29 10:59 ./t.txt 👈 51325760 0 drwxr-xr-x 2 root root 6 Feb 8 10:39 ./fdir 👈 33577447 4 -rw-r--r-- 2 root root 4 Jan 29 17:49 ./f2.link ------------👇这段是符合-o的本来逻辑的，就是前面true就不算后面了---------- [17:33:24 root@localhost data]#find ./ -name \"f*\" -ls -o -type f 33577448 4 -rw-r--r-- 1 root root 10 Jan 29 17:49 ./f1 33577447 4 -rw-r--r-- 2 root root 4 Jan 29 17:49 ./f2 51325760 0 drwxr-xr-x 2 root root 6 Feb 8 10:39 ./fdir 33577447 4 -rw-r--r-- 2 root root 4 Jan 29 17:49 ./f2.link [17:33:28 root@localhost data]# [17:33:44 root@localhost data]#find ./ -name \"f*\" -ls 33577448 4 -rw-r--r-- 1 root root 10 Jan 29 17:49 ./f1 33577447 4 -rw-r--r-- 2 root root 4 Jan 29 17:49 ./f2 51325760 0 drwxr-xr-x 2 root root 6 Feb 8 10:39 ./fdir 33577447 4 -rw-r--r-- 2 root root 4 Jan 29 17:49 ./f2.link [17:33:59 root@localhost data]# [17:34:01 root@localhost data]#find ./ -type f ./f1 ./f2 ./t.txt ./f2.link ------------👇这段是不符合-o的本来\"表面\"逻辑的，看起来像是短格式在前(左)，长格式在(右),会变成左边的文件名去掩码右边的文件名，掩出来就剩下一个t.txt在用find里的ls(其实就是ls -dils)显示出来----------可能这里的-o就是异或运算了，相同出0就消掉了，不同也就是t.txt不同就出1也就保留了-----但显然上面的例子是逻辑或--▲linux逻辑混乱案例1-- [17:34:22 root@localhost data]#find ./ -name \"f*\" ./f1 ./f2 ./fdir ./f2.link [17:34:34 root@localhost data]#find ./ -type f -ls 33577448 4 -rw-r--r-- 1 root root 10 Jan 29 17:49 ./f1 33577447 4 -rw-r--r-- 2 root root 4 Jan 29 17:49 ./f2 33577450 4 -rw-r--r-- 1 root root 65 Jan 29 10:59 ./t.txt 33577447 4 -rw-r--r-- 2 root root 4 Jan 29 17:49 ./f2.link [17:34:48 root@localhost data]# [17:34:56 root@localhost data]#find ./ -name \"f*\" -o -type f -ls 33577450 4 -rw-r--r-- 1 root root 65 Jan 29 10:59 ./t.txt [17:35:04 root@localhost data]# 总之，这东西要规范了用就是-a是默认存在的 优于 -o，然后要规范使用小阔话来实现正确的逻辑，否则结果很难解释。 德·摩根定律 locate -r xx是正则，find -name xx是通配，locate xx是包含就算，find -regex 是扩展正则，本章上文有总结过了。 如果find 后接 regex就需要是全路径匹配。 [18:04:14 root@localhost ~]#find /etc -name *.conf | head -10 /etc/dnf/dnf.conf /etc/dnf/plugins/kpatch.conf /etc/dnf/plugins/copr.conf /etc/dnf/plugins/debuginfo-install.conf /etc/dnf/protected.d/dnf.conf /etc/dnf/protected.d/setup.conf /etc/dnf/protected.d/systemd.conf /etc/dnf/protected.d/sudo.conf /etc/dnf/protected.d/yum.conf /etc/libreport/events.d/collect_dnf.conf [18:04:18 root@localhost ~]#touch x.conf [18:04:33 root@localhost ~]#find /etc -name *.conf | head -10 [18:04:36 root@localhost ~]#find /etc -name *.conf [18:04:39 root@localhost ~]#👇-name后面一定要加上引号，否则你看家目录里的文件竟然会影响/etc/下面的文件匹配，这个似乎很不合理，但是让我联想到了pycharm的init文件也是，你只要跑一个普通的xx.py文件，就会先跑一个init文件，但是也不至于像linux这种奇奇怪怪的问题。 都说linux稳定，今儿给大家看看逻辑不通的两个案例~▲linux逻辑混乱案例2 [18:04:39 root@localhost ~]#find /etc -name \"*.conf\" | head -10 /etc/dnf/dnf.conf /etc/dnf/plugins/kpatch.conf /etc/dnf/plugins/copr.conf /etc/dnf/plugins/debuginfo-install.conf /etc/dnf/protected.d/dnf.conf /etc/dnf/protected.d/setup.conf /etc/dnf/protected.d/systemd.conf /etc/dnf/protected.d/sudo.conf /etc/dnf/protected.d/yum.conf /etc/libreport/events.d/collect_dnf.conf ▲linux逻辑混乱案例2 [18:13:15 root@localhost ~]#cd /data/ ---进到/data下find -name 不带*看看，果然是当前目录会干掉实际搜索的目录文件，具体往下看👇--- [18:13:25 root@localhost data]# [18:13:25 root@localhost data]# [18:13:25 root@localhost data]# [18:13:25 root@localhost data]#find /etc -name *.conf | head -10 👈现在不带引号可以搜到 /etc/dnf/dnf.conf /etc/dnf/plugins/kpatch.conf /etc/dnf/plugins/copr.conf /etc/dnf/plugins/debuginfo-install.conf /etc/dnf/protected.d/dnf.conf /etc/dnf/protected.d/setup.conf /etc/dnf/protected.d/systemd.conf /etc/dnf/protected.d/sudo.conf /etc/dnf/protected.d/yum.conf /etc/libreport/events.d/collect_dnf.conf [18:13:28 root@localhost data]#ll total 16 -rw-r--r--+ 1 root root 10 Jan 29 17:49 f1 -rw-r--r--+ 2 root root 4 Jan 29 17:49 f2 -rw-r--r--+ 2 root root 4 Jan 29 17:49 f2.link drwxr-xr-x. 2 root root 6 Feb 8 10:39 fdir -rw-r--r--. 1 root root 65 Jan 29 10:59 t.txt [18:13:31 root@localhost data]#touch a.conf 👈只要在find的命令键入的当前目录下创建a.conf [18:13:48 root@localhost data]#find /etc -name *.conf | head -10 👈就搜不到了 [18:13:51 root@localhost data]# [18:13:53 root@localhost data]#touch /etc/b.conf [18:14:02 root@localhost data]#touch /etc/a.conf 👈然后在/etc/下面创建a.conf就搜索到了 [18:14:05 root@localhost data]# [18:14:05 root@localhost data]#find /etc -name *.conf | head -10 /etc/a.conf [18:14:07 root@localhost data]# [18:14:07 root@localhost data]#touch b.conf 👈再在/data下创建b.conf，就报错了哈哈。 [18:16:14 root@localhost data]#find /etc -name *.conf | head -10 find: paths must precede expression: b.conf Usage: find [-H] [-L] [-P] [-Olevel] [-D help|tree|search|stat|rates|opt|exec] [path...] [expression] [18:16:40 root@localhost data]#rm -rf b.conf [18:17:32 root@localhost data]#find /etc -name *.conf | head -10 /etc/a.conf [18:17:34 root@localhost data]# find的裁剪，让我想到了vtp的裁剪 用裁剪prune，它的裁剪语法是组合逻辑的，不是很简洁 题外话 搜arp协议文件 搜文件大小区间(] -size 写10K，实际上是(9k-10k] 👆既然是(9k-10k]之间，那么8192就不在里面了，自然就搜不到了。 搜文件时间区间[) -size 👆这个线索可以拎出来，▲判断某个动作或者事件 带来了哪些影响，①比如yum history是可以回滚yum的动作(包括依赖，这是remove做不到的)；②就是这里的时间，我这一分钟内完成了用户的创建，于是我查看1分钟来产生的新文件-mmin -1就这些，所以八九不离十的 就是useradd 产生的。 权限搜索-perm xxx -perm /222的意思是三个人(所有者、所属组、other)只要有一个角色有写权限就匹配出来，本质是222 和 / 的组合，010 或 010 或 010 ，0是不关心，1是固定住，/是或的关系。 -perm 222的意思是只找出 权限为222的文件或文件夹 -perm -222的意思是010 且 010 且 010，三者都必须有写权限就行。 助记： -少就是且 /多就是或 要知道/以前等价于+ ，就是说+222等价于/222，只不过+不推荐了。 下面👇的理解过程是不是有问题，是的~！ 总结下 当/XXX都不为0的时候好理解：就是xx or xx or xx或者的关系，比如/222就是只要三者一个有写 当/XXX为101 001 010 反正只要有0出现，就意味着0不看，比如/202就是u和o两个中的有一人有写 注意/333表示u,g,o三者一人有写和执行？请看下例👇 ★是拆成二进制然后bit位之间或的关系 ★是整体111111111 9个bit位之间是或的关系，而不是u,g,o之间的关系。 [18:06:26 root@pyConsole test]#find -perm /333 👈表示111111111都是或 . ./f1 ./f2 ./f3 ./f4 ./f5 [18:06:32 root@pyConsole test]#find -perm /303 👈表示011nulnulnul011都是或，不看g，只看u和o . ./f1 ./f2 ./f3 ./f5 [18:06:34 root@pyConsole test]#ll total 0 ---x--x-w- 1 root root 0 Feb 9 17:45 f1 -rw-rw--w- 1 root root 0 Feb 9 17:45 f2 -r--r---wx 1 root root 0 Feb 9 17:48 f3 ------x--- 1 root root 0 Feb 9 17:56 f4 ---x------ 1 root root 0 Feb 9 17:59 f5 [18:06:35 root@pyConsole test]# ----------------------上面这段其实是后写的，下面的是梳理过程中的截图，保留供参考---上面的结论OK的---------- [18:00:21 root@pyConsole test]#ll total 0 ---x--x-w- 1 root root 0 Feb 9 17:45 f1 -rw-rw--w- 1 root root 0 Feb 9 17:45 f2 -r--r---wx 1 root root 0 Feb 9 17:48 f3 ------x--- 1 root root 0 Feb 9 17:56 f4 ---x------ 1 root root 0 Feb 9 17:59 f5 [18:00:22 root@pyConsole test]#find -perm /100 . ./f1 ./f5 [18:00:25 root@pyConsole test]#find -perm -100 . ./f1 ./f5 [18:00:27 root@pyConsole test]#find -perm /101 . ./f1 ./f3 ./f5 [18:00:29 root@pyConsole test]#find -perm /111 . ./f1 ./f3 ./f4 ./f5 [18:00:31 root@pyConsole test]# 分析 find -perm /622 的意思👇 上图错了，/622，不是必须6，而是110里面有一个就行了 哈哈，上图是最最开始的笔记，那会我就发现啦，哈哈，给自己点个赞👍。不过没有这一次梳理的完整。 所以回到一开始的PPT ① xxx就是精确匹配，000就是u,g,r三者权限都是---的文件，精确匹配不存在什么或，不存在0表示不关注的说法；倒是存在bit位的并且哦，哈哈~ ② 然后接下来： 2.1 /表示或，人家说了一位就是bit位，看到没，哈哈 2.2 0表示不关注，这个0说的是/303，里的这个0是十位数的0，哈哈(不对，这个0依然是二进制的0)，好家伙，PPT果然言简意赅，结果大佬就讲错了。 2.3 同样-xxx 人家也说了0表示不关注，然后是bit位之间的且。 2.5 一句话总结：/ 和 - 都是展开bit二进制后，0不关注，然后/就是或，-就是与。 ③ 我牛逼的地方来了哦，以上总结OK了到位了，问题来了，如果我要find 权限是rw?---rw?也就是707,606,607,706的文件捏，哦你要输入 find -perm -606 没办法了吧，哈哈，还不如这样 find 后的处理 👆上面的用法很危险。 重定向的>等于-fls -ok 的交互 但是是交互式的。 -exec的非交互 案例，日志处理 找到大于10M的，移动到tmp/下。 还是不行，因为还有子文件夹，//没关系的，不影响效果。 👆上图存在同名冲突的问题的。那样怎么做呢？遗留问题用⚪这个吧哈哈。 文章标识有▲、⚪、了★预留。⚪是微软输入法yuan第5个。 找到符合文件\\文件夹，然后整体(带路径)搬到某个文件里去将上面查找出来的符合条件：1天内修改过的 并且 名字不是 . 的--这就去除了当前目录。找出来后，带路径复制到目标文件夹处。.png) 但是上图要注意cp -a --path 才行，-a就是保证属性不变。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-12-12 19:53:07 "},"9-文本查找和压缩/2-文件压缩和解压缩.html":{"url":"9-文本查找和压缩/2-文件压缩和解压缩.html","title":"第2节 文件压缩和解压缩","keywords":"","body":"第2节. 文件压缩和解压缩 参数太多，一个个传进去 touch rm 等命令后面的参数都有上限的。 touch f{1..100000000}应该就会报错， xargs可以解决该问题 没有标准输入，怎么传给他比如rm 上图 ls是没有标准输入的，管道符是传不过去的，所以说它是错误的，不是说：+号过时了用/替代。 参数太长怎么办 利用xargs获取stdin来传给rm -f作为参数 ▲xargs是用来传参数的。 注意默认行为，达到一定长度就换行了 上图不是一个个传给touch的，而是一堆堆，大概是2000+一次传给touch，一个个传如下图 就是说 touch f1 f2 f3 这种一下创建多个文件，xargs 一行传过去也没问题，但是useradd xx yy 的yy生效的，所以需要换行。 创建10个用户 /7000，0不关心，7就是111，针对3个特殊权限有一个有就行 上图因为没有xargs传过去，所以就仅执行了ls -SL，验证下👇 find 后删除 上面是表面上合理，但可能有问题的。 特殊情况案例：单个文件名称位\"fa b.txt\"中间带空格。 观察上面报错，find 传给xargs后xargs默认是空格作为分隔符，所以\"fa b.txt\"就被判定位fa和b.txt两个文件了。 print0 是啥呢？是ASCII码为0，可不是十进制的0哦。 验证下-print0的分隔符为null的效果👇 这是txt的t后买那就是00(print0) -print0就是为了避免文件名带特殊符号。 第一个示例，是原地目录备份提好的，好在如果备份到其他地方存在子，子子文件夹不存在的情况从而报错的。要么复制其他目录就别带文件夹了，统统放在一个层级下就是不带{}的意思，这样又会存在文件同名的问题。详情见上一章节的文末内容。 练习 打包压缩 gz bz2 xz 3个主流 压缩要消耗CPU的，看你需求，你的磁盘空间大，你需要节省CPU消耗，就不压。空间换性能(时间) compress默认压缩后原文件就没了。 👆上图就是compress比较聪明，不给你压缩.jgp文件。同样👇issue根本不给你压缩。 compress是标准输入的信息进行压缩，完了屏幕上打印ctrl+d退出可见，可能存在乱码。 zcat直接预览 gz后缀用的多 也是压完，原文件没了。 gzip -d 一样的也是gunzip解压 压缩比 gzip也是标准输入形式，不过要带上-f 其实有没有标准输入都可以传的，有就用|，没有就用xargs。 当一个命令的标准输出非常大，比如数据库特别大就(压缩一下放硬盘里)，就可以使用gzip配合生成文件。 bz2 压缩比跟高 bz还是比gz的9级，压缩度还要高。 所以 看下两个压缩算法： 上图的-r是不是写错了，应该是-R啊？⚪表示疑问。 👇解是能解，但是不能tab补全 👇这次都不能解了 后缀很关键啊 gzip、bz2 、xz 三种压缩，网上比较多。 zcat看.gz和.Z；bzcat看.bz2；xzcat看xz xz 压缩工具 所以linux内核就是用xz xz 压缩和解压缩速度慢，耗时长。 理论上xz要强，但是数据量不大的时候，还不如bz2。 观察 这里都是有tar 结论：都需要先用tar打个包，再用gz，bz2，xz去压缩（这些工具只能针对一个文件去压缩，不能针对文件夹）。 打完包就是一个文件了，再压就行了。 zip打包和压缩 这个勾选，你感觉不到什么变化，该怎么用还是怎么用。就是读取的时候会自动压缩解压缩。NTFS有这个压缩功能。 zip在windows和linux都是一样的软件 adding：下面的明细etc前头是没有/的，就是担心将来你解压缩导致覆盖了/etc。目的就是让你解压到当前文件夹下。👈压缩的时候把/etc/变成了etc/，把/根拿掉了，防止你加压缩把根下面的etc覆盖掉了，所以给你变成了相对路径。 👆上面的压完后再看：白压了，越压越大了，哈哈，找原因： 因为把内存里的文件带上了吧？搞不清⚪存在问题。 前面sysconfig是压缩后产生的文件，会自动打赏后缀.zip的。 管道符的使用▲ 线索总结 这是解压后重定向到文件中。 原来是436K压缩后为93K 解压的风险，存在撑爆磁盘的可能 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:01 "},"9-文本查找和压缩/3-文件打包和解包.html":{"url":"9-文本查找和压缩/3-文件打包和解包.html","title":"第3节 文件打包和解包","keywords":"","body":"第3节. 文件打包和解包 传统公司还有用磁带保存数据的tap -cpvf 这个只是打包，没有压缩 c就是创建 v详情显示 f指定创建的文件名 p是保留权限，但是保留不住acl (联想到cp -p，不过tar的-p保留不住facl) 之前讲过备份acl的方法，，，恩，cp也能备份facl的--“第5节. FACL实现权限的灵活控制--文末”。 tar -cvf 的-可有可无，bsd unix风格 打包不会压缩什么的 t是预览 x是解包 也可以解压到指定文件夹 r是追加 打包且压缩 传统打包压缩 也可以合并起来 解压和解包 压缩格式是自动识别，J不用加 102M ---解开后大小--->930M 查看C代码一共多少行 到底花了多久呢 如此大的差距啊 sys不是系统空间是内核空间。 一些常见后缀比如tgz .**tar.gz 就等于 .tgz** 排除以及filelist 要打包的文件名统一放到一个文件里，↑ split切割文件 合并的方法 cpio不常用，老文件可能采用该格式 cpio也是个打包的，类似tar 预览可见，这其实就是一个小linux系统-虚拟的小文件系统。 i就是解包，d就是自动创建文件夹，解开后就是一个完整的操作系统 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:01 "},"10-文本三剑客2_sed/10-文本三剑客2_sed.html":{"url":"10-文本三剑客2_sed/10-文本三剑客2_sed.html","title":"第十章 文本三剑客2_sed","keywords":"","body":"第十章 文本三剑客2_sed Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:34:59 "},"10-文本三剑客2_sed/1-文本处理三剑客2_sed.html":{"url":"10-文本三剑客2_sed/1-文本处理三剑客2_sed.html","title":"第1节 文本处理三剑客2_sed","keywords":"","body":"第1节. 文本处理三剑客2_sed sed内置行为 Stream EDitor, 行编辑器 sed是一种流编辑器，它一次处理一行内容。处理时，把当前处理的行存储在临时缓冲区中，称为“模式空间”（ pattern space），接着用sed命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕。然后读入下行，执行下一个循环。如果没有使诸如‘D’ 的特殊命令，那会在两个循环之间清空模式空间，但不会清空保留空间。这样不断重复，直到文件末尾。文件内容并没有改变，除非你使用重定向存储输出。 功能：主要用来自动编辑一个或多个文件,简化对文件的反复操作,编写转换程序等 参考： http://www.gnu.org/software/sed/manual/sed.html sed就是用来解决我多地方dns文件的最佳实践，好好学。 sed命令内置特性，内置循环，内置一行行，和grep也是一样一行一行处理 内存空间在这里就叫模式空间 一行处理完 print，删除，第二行读进来，处理，print，删除，第三行继续 sed 语法 地址+命令， 地址就是哪行， sed '' passwd 👈这个就是内置行为的证明了，就是每行打印一遍 下面是脱裤子放屁的命令，是不是很吊~👇 2P- 只打印第2行 sed是读取标准输入处理的👇，有这玩意--标准输入，就可以利用管道；没有就利用xargs一样传！ 最后一行 tail -n1就行，sed 10 | tail -1或seq 10 | sed -n '$p' 正则匹配 基本上还是grep的等价命令。还没有体现sed的自己的活。 行的范围 显示3-5行 👆上图可以用来过滤出你想要的日志--几点几分到几点几分。 步进行-实现打印奇偶行 sed编辑命令-这个只是print的时候修改下，不修改原文件 d 删除模式空间匹配的行，并立即启用下一轮循环 两个sed👆其实可以合成一个sed来做👇，两次操作合并▲ 但是要注意下这个是不是真的就是两个sed合在一起，看下图👇就知道明显不是。 我觉得正确解释就是，针对处理内容，进行分号前后的两个命令的执行。这也是还原了最基本的逻辑。①👆针对/etc/fstab执行去注释;和去空行的动作②👇针对/etc/passwd执行了打印10行和打印20行的动作。你看有的就是两个sed合并，有的就不是，哈哈。神奇嘛，其实不神奇，就是一个常规操作在不同场景(一个描述在不同语境)里的不同解释。 一个是d删除操作，一个是p选择操作；删除自然两个动作可以用|管道符两个sed作为前后传参，说~哦，我一个文件删除这个再删除那个；而挑选的动作就是我针对这个文件挑选这个，再挑选那个。一个圆圈挖掉两个洞和一个圆圈取出两个洞，都是针对圈圈这个实体，但是挖掉两个洞和先挖一个后的结果作为后挖动作的输入是一致的；而一个圆圈取出两个洞，就不能说我取出的那个洞作为后取得输入参数，这就是逻辑上好玩地方，我希望我自己能把这些看似不好理解，但是实际是一会事得东西啊，有时间又机会琢磨透，世人常说转牛角尖，我很小的时候就想过很小很小10岁，小学吧好像，就说钻出来不就行了，哈哈，其实底层知识逻辑就是哲学了，换了个名字，世人就认了，世人是愚昧的。但是这样的人当前社会很难成功，因为给他的时间不够，他也要玩啊，哈哈哈哈哈~ 同样对原文件未做修改 如果想要改 sed修改原文件-i，为了安全推荐-i.bak 👆/^Listen/i listen 8080，这里你几个空格都没用，如果你要插入的字符前面带空额，就需要上图的 ​ /^Listen/i\\ listen 8080，转义下 注意c是找到行后，整行替换 sed另存为，之前是修改原文件或是备份，这个直接是另存为 👆注意d;w用;分开来，两次操作合并▲ a是追加文本，r是追加整个文件的内容，注意sed -r和上图的r不是一个东西哦。 其实就是位置+动作，位置就是/正则或者行号之类/ ，都工作就是这里的a也好c也好。 包含root行的行号 查找替换 这里和vim里面很像 sed -e 的用法-等价于上面的两次操作合并▲ 例子，找出IP地址 sed -r 是表示后面使用扩展正则，而sed /基本正则/ ▲正则 这里用到了分组()的概念 这个和py里的format字符串格式化一样。再合并一下整成一个sed命令👇 这个其实就等价于py里的rematch，而不是refind，而refind不用写全。rematch还需要写全。确实要用正则匹配全了，证明： 优化下 牛逼的是👆(())这种写法它能识别好。 例子，取消注释 先定位位置 上图是系统判定为/的用法，至少查找的//是占用了的。不行你猫猫看。 批量取消注释▲，这个vim里也有操作比如ctrl+v ,I, # 两下esc注意是vim不是vi。 例子，sed实现dirname和basename 例子，修改网卡名称为eth0，可能不对 思考这么对不对 sed -rn '/ .*linux/s/$/net.ifnames=0$/' /boot/grub2/grub.cfg 上面的显然不对，而且还多了一个$ 上图infname写错了改成ifname &就表示前面搜索出来的内容。注意下面的p参数拿掉，不然会将目标行复制2遍。 成功案例 [root@centos7 ~]# sed -rn 's/^[[:space:]]+linux16.*/& net.ifnames=0/p' /boot/grub2/grub.cfg linux16 /vmlinuz-3.10.0-1160.el7.x86_64 root=UUID=db575dcc-512a-4240-ab49-f3d41bc3e372 ro crashkernel=auto rhgb quiet LANG=en_US.UTF-8 net.ifnames=0 linux16 /vmlinuz-0-rescue-8173b565dc324c7180303567796b941c root=UUID=db575dcc-512a-4240-ab49-f3d41bc3e372 ro crashkernel=auto rhgb quiet net.ifnames=0 [root@centos7 ~]# [root@centos7 ~]# sed -ri.org 's/^[[:space:]]+linux16.*/& net.ifnames=0/' /boot/grub2/grub.cfg [root@centos7 ~]# ll /boot/grub2/grub* -rw-r--r--. 1 root root 4267 Feb 11 14:47 /boot/grub2/grub.cfg -rw-r--r--. 1 root root 4239 Jan 5 17:45 /boot/grub2/grub.cfg.bak -rw-r--r--. 1 root root 4239 Jan 5 17:45 /boot/grub2/grub.cfg.org -rw-r--r--. 1 root root 1024 Jan 5 17:45 /boot/grub2/grubenv [root@centos7 ~]# cat /boot/grub2/grub.cfg |grep ifname linux16 /vmlinuz-3.10.0-1160.el7.x86_64 root=UUID=db575dcc-512a-4240-ab49-f3d41bc3e372 ro crashkernel=auto rhgb quiet LANG=en_US.UTF-8 net.ifnames=0 linux16 /vmlinuz-0-rescue-8173b565dc324c7180303567796b941c root=UUID=db575dcc-512a-4240-ab49-f3d41bc3e372 ro crashkernel=auto rhgb quiet net.ifnames=0 重启后 [root@centos7 ~]# ip a 1: lo: mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: eth0: mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:b9:89:eb brd ff:ff:ff:ff:ff:ff inet 192.168.25.44/24 brd 192.168.25.255 scope global noprefixroute dynamic eth0 valid_lft 64705sec preferred_lft 64705sec inet6 fe80::4efd:3be2:da5a:12cb/64 scope link noprefixroute valid_lft forever preferred_lft forever [root@centos7 ~]# [root@centos7 ~]# [root@centos7 ~]# 然后再补一个这个：也不知道是不是上面需求擦头必须的： 或者 [root@centos7 ~]# cat /etc/default/grub GRUB_TIMEOUT=5 GRUB_DISTRIBUTOR=\"$(sed 's, release .*$,,g' /etc/system-release)\" GRUB_DEFAULT=saved GRUB_DISABLE_SUBMENU=true GRUB_TERMINAL_OUTPUT=\"console\" GRUB_CMDLINE_LINUX=\"crashkernel=auto rhgb quiet\" GRUB_DISABLE_RECOVERY=\"true\" [root@centos7 ~]# [root@centos7 ~]# [root@centos7 ~]# sed -rn 's/(.*CMD.*)\"$/\\1 net.ifnames=0\"/p' /etc/default/grub GRUB_CMDLINE_LINUX=\"crashkernel=auto rhgb quiet net.ifnames=0\" 这样👇更好，我找到不直接s///，而是先//再s///也就是/zz/s#xx#yy#m，因为/CMD/是找出这一行然后再查找部分字符进行替换，而s///可能就匹配的过多，理由不充分哈哈~还没没找到 [root@centos7 ~]# sed -rn '/CMD/s/\"$/net.ifnames=0\"/p' /etc/default/grub GRUB_CMDLINE_LINUX=\"crashkernel=auto rhgb quietnet.ifnames=0\" [root@centos7 ~]# 👇如果是直接s@@@，会全部行都直接换了 “部分” 字符比如s@CMD@zzz@， [root@centos7 ~]# sed -rn 's/\"$/net.ifnames=0\"/p' /etc/default/grub GRUB_DISTRIBUTOR=\"$(sed 's, release .*$,,g' /etc/system-release)net.ifnames=0\" GRUB_TERMINAL_OUTPUT=\"consolenet.ifnames=0\" GRUB_CMDLINE_LINUX=\"crashkernel=auto rhgb quietnet.ifnames=0\" GRUB_DISABLE_RECOVERY=\"truenet.ifnames=0\" [root@centos7 ~]# sed -rn 's/CMD/net.ifnames=0\"/p' /etc/default/grub GRUB_net.ifnames=0\"LINE_LINUX=\"crashkernel=auto rhgb quiet\" [root@centos7 ~]# [root@centos7 ~]# sed -rn 's/CMD//p' /etc/default/grub GRUB_LINE_LINUX=\"crashkernel=auto rhgb quiet\" [root@centos7 ~]# sed -rn 's/CMD/&/p' /etc/default/grub GRUB_CMDLINE_LINUX=\"crashkernel=auto rhgb quiet\" [root@centos7 ~]# s///是基于行去进行字符替换，//是找到这一行。 不加g，就是只处理每行第一个命中的，g加上就是行内所有都替换。 --------------- sed 中的变量要注意双引号的基本常识 sed自己可以👇这样，在单引号里使用变量 这是sed的自己的用法，比较少见。 存在这种情况 'xx'''$var'''xx\"xxx'，这样可以使用变量了，然后可不可以这样 \"xx$varxx\\\"xx\" 使用转义可以不，可以的吧，可以的 所以要啥自行车~，注意哦，下图三引号不是在sed里用的，是我在echo玩的，别搞混了，本段讨论的是sed里如何使用变量以及转义的双引号，哈哈。 然后上图的另一个点就是和sed一样，也支持单引号里表达变量 sed高级命令-多了一个空间 体现在sed内置的行为就是一个模式空间，高级就高级在多了一个保持空间 hold空间就是临时存一下 sed的强大之处还体现在高级命令及其保持空间。 hold住保持一会，待会取回来用。 模式空间里是可以放好几行的，D是删除一行，后续行就不删了。 sed高级用法的的例子 分析sed -n 'n;p' FILE ​ ①初始 ​ ②打印第2行 ​ ③读入第3行 ​ ④同理 ​ ⑤试试： 看sed '1!G;h;$!d' FILE 不是第一行就G，不是最后一样就删除，中间有G和h追加和覆盖操作，涉及两个模式空间 真要倒着写，tac就行了， 例子sed 'N;D' FILE 补充 linux每行结尾只有换行“\\n”， Windows每行结尾是换行+回车“\\r\\n” Mac OS 为 “\\r”。 用dos2unix file 活unix2dos file命令直接转换，有时候是最小化安装，所以vim里的方法也是要会的。 利用Linux下的vim，去除^M，去之前file看一下 vi xxx 然后 :set ff 用于查看当前文件是dos格式还是unix格式，显示如下： 切换为unix格式，然后保存即可： :set ff=unix #👈转换为unix格式 :wq 如果上图的格式不对，直接./xxx.py是找不到文件的，只能用python xxx变通运行，这里改成unix换行符后，就可以直接./xxx.py运行了。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-12-26 11:06:48 "},"11-软件包管理/11-软件包管理.html":{"url":"11-软件包管理/11-软件包管理.html","title":"第十一章 软件包管理","keywords":"","body":"第十一章 软件包管理 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:34:59 "},"11-软件包管理/1-软件管理基础.html":{"url":"11-软件包管理/1-软件管理基础.html","title":"第1节 软件管理基础","keywords":"","body":"第1节. 软件管理基础 ABI 应用程序二进制接口，API是开发接口 WINE，让linux上跑windows的软件 Cygwin，windows上跑linux的软件 预处理：去掉注释、打上行号、引用的文件(include代码)等放进来，等 编译：语法分析，错误，转成汇编代码 汇编：汇编代码还是文本，汇编之后就是机器码了，还要把库连接起来。这些库有静态和动态之分 静态：把库和二进制结合在一起，合成一个文件； 动态：程序运行的时候再寻找依赖库；不合并。 .so是shareobject 共享对象，好多程序会共用这个库 ldd可以看用的哪些库，不仅仅cat依赖这个库，ls也依赖。共同依赖的库 共用的库 .c源代码C语言写的---用gcc预处理成.i后缀---compilation编译成汇编语言assembly----汇编成二进制.o对象文件----link链接.a静态库----生成最终的一个文件。 动静优缺点 应用案例：注意通常我们都是动态链接的库，所以把一个二进制程序复制过去别的电脑上需要考虑把依赖的库文件也一并找出来复制过去。 JAVA号称一次编译，到处运行的底层思路： 1、存在本质上的两次编译 2、第1次编译，是编译成标准字节码文件 3、然后再各个系统上面预装了JVM java虚拟机，当字节码在这些JVM上运行的时候 就会再次编译一次。 需求产生了，降低使用开源软件的难度，直接给C，编译困难，就出来了debian版本 三大主流linux分支debian、redhat、slackware。 debian就率先考虑的需求，就帮你编译好，打好包，让你使用的时候自动的解包，dpkg debian package管理器，Ubuntu就是debian咯。 RPM GNU自己定义自己~八错八错~ linux-5.1.4 5是大版本号，1是次版本号，4是小版本号；大5-就是版本大变动，次1-就是小变化，小4-就是打个补丁。大概这么个意思。 rpm就是什么，就是开源软件，红帽拿过来打包整合的rpm包。所以包名的意思是 bash-4.3.46-19.el7.x86_64.rpm 包名和人家包自己的版本 19是红帽拿过来编译的次数 el7是红帽企业版7 x86_64CPU架构 神奇的文件夹/misc， 明明里面没东西，强行进入/misc/cd下就生成了cd文件夹，并自动挂载了光盘 后面补一个这个神奇的文件夹是什么来的，6上面可能自带的。7上面要想这么用，就执行systemctl start autofs systemctl enable autofs ;-安装方法要对--应该是server的套餐吧，反正最小化安装是没有这东西的。 在centos6和7上进到这Packages文件夹下，注意5和8都不叫这么名字好像，不管了8也不用了 用sed来弄 问题来了，什么用-n什么时候用p，怎么这里不用-n 和p呢，结果是对的。它这个上图的命令是已经对print的结果进行编辑过了修改过了，所以无需-n p，当然你加上-n 和p应该也是OK的 1、-n就是不打印了呗，全都不打印 2、xxxp就是你处理后的结果也要打印出来，如果此时前头没有-n就是说默认打印+处理后的打印 3、-n xxxp就是只打印处理后的结果 4、-n和xxxp 两个都不带，就是处理后的全文显示。 5、上图为啥-n xxxp和 都不带 效果一样呢，因为匹配了所有都能匹配到的，所以就一样咯。 ================================================================================ rpm包el6\\el7\\x86_64\\noarch\\i686 大软件 一般会拆包，挑着安装就可以比较方便。 这就是拆包分类 rpm安装的依赖只是直接的依赖包，间接依赖包不会显示，所以一眼看不见 --------------------------- lib64库文件 思考是不是cat命令就是用的/bin/cat文件，还是后面调用了C语言的库呢？ 再者so就是share object 很多二进制文件都是依赖一些共同的so库 例子-移动一个库及修复 可惜mv也是依赖这个库 然后图形界面也死掉了 修复要么快照，或者借助光盘 上面的关闭客户机这些本质上还是调系统的命令，下面的重置才是按电源重启。 重启也起不来了 重试救援光盘来解决 1、插入光盘，连着的 2、进度条出来后果断esc 3、选择3 CD-ROM启动 4、选择troubleshooting 5、救援系统 就是类似windows的pe，交换机路由器的RMON，类似这种最小操作系统。 6、进入后界面 因为是从光盘启动，所根不再是/了，而是/mnt/sysimage/ 你的系统被挂载到了/mnt/sysimage。你看到的文件系统是/mnt/sysimage这套 上图system写错了改成sysimage。 而我们要找的文件就在： 思考此时mv能用吗？ 因为用的是光盘里的mv，不是硬盘里的mv。所以是可以用的。 然后exit退出，自动重启就修复好了。 以上就是mv修复，下面是rm修复： 应该就在上面救援模式的/lib64下面有的。 lib64，库现在都是64位的了 学习包管理 一个RPM包里可能包含的东西比较多： 脚本的意义在于，你安装程序前先给你创建好用户，这样你才有所有者，所有组啊。诸如此类的信息。 前两行都有： 第三行的脚本不一定每个RPM包里都有。 RPM包不是安装好了就行了，还需要处理文件的属性信息存放便于后续查找。 数据库简单说就是文件夹，里面存放了安装rpm包的很多信息。如果没有/var/lib/rpm，你都不知道你安装了那些程序。也不知道哪些文件来自哪个包。 /var/lib/rpm的意义 比如安装软件，如果已经安装过了，就不会安装了，这就是到这里查找的。 有些官网提供了编译好的，有些就是提供源码给你自己编译。 操作路径 ppc是powerpc的，不用管 EPEL Fedora是红帽的上游测试版，dnf在Fedora 18版就有了。 然后现在centos-stream要取代centos8变成rehat的上游了。 ------- 配置 > /dev/null就可以实现静默安装。 一般warning看下，问题不大，是光盘里的，但是这里的告警是说验证来源是没有验证的。 signature是来源，其实就是公钥的验证。就是windows里的受信任的证书。 --- 选项放前面，这里习惯不好。 软件脚本安装的思路 之前装过了，这里查询的话只要写名称就行了 没装是这个样子的 我们-e卸载后再试试 ====== 或者查询某个包里包含哪些文件 是不是重新安装一些tree就行了 因为那个var/lib/rpm里有安装过的信息了，所以不会给你安装了，你说rpm -e卸载呢，不推荐，因为说不定之前都做过一些配置优化了。 办法也许可以，但通常不行，因为会全部覆盖的。方法还在下面往下看 replacepkgs和replacesfiles，就是只覆盖有的，没有的就安装。 replacefiles是只覆盖有冲突的文件。一般用在两个包一样但是版本不同，第二个包安装覆盖掉冲突的就是相同的文件就能正常安装第二个包了，同时第一个包的不同版本的软件可以自然可以使用同名的文件。 bash这个包基本就是随着操作系统安装而安装的，所以通过rpm -qi bash也能看到何时安装的系统 查看软件包的信息 上图中的官方站点可以去获取最新的版本 tgz就是tar.gz 如何只修复其中一个文件呢 利用cpio来解开rpm 利用cpio -tv查看文件列表 不过这样cpio解开的rpm再mv过去，有个问题，文件属性可能还需要注意一下。 据说类似于菜市场猪肉上面的蓝章。不过我想起来好像有红的。 默认就不具备完整性校验 先看下包里有没有脚本 -q --scripts 查看已安装的包 -qp --scripts 查未安装的包 将来如果是源码安装，就需要参考这些rpm安装的脚本来自己创建这些用户和组。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-12-28 10:41:06 "},"11-软件包管理/2-rpm管理软件.html":{"url":"11-软件包管理/2-rpm管理软件.html","title":"第2节 rpm管理软件","keywords":"","body":"第2节. rpm管理软件 rpm包升级 感觉，不会单单升某一个包吧，除非比较清楚依赖版本的限制情况。 -U也就是--upgrade，包没有就给你安装的，有就给你升级。 -F也就是--freshen，包没有就不安装，仅仅升级。 类似--replacekgs还有一个force，一个效果。 思考能不能安装两个版本的软件 windows的比如foxmail可以安装在不同的文件夹里，同时使用，无需关注注册表。 rpm包的话，除非名称都改一改，不然是不能共存的，很多都不能共存。 内核倒是可以的 可见kernel安装的文件绝大多数是带版本号的，所以可以并存的。 个别文件是冲突的，替代掉： 包查询 上图PPT有问题啊，cpio 的-i是解包，你都解包了，还和t预览个屁啊。 名字记不住，可以这样： -qa 加过滤的方法grep的regex和直接的通配符 两个不同版本的内核就有了 下面开始安装 强制安装 机器上存在两套内核， 计算机启动后可选择其中一套 如果要卸载就要注意 卸载哪个都可以，即使是当前使用的内核也可以的，因为linux加载到内存里了已经，而内核作为文件存在是可以删的。 重启后就剩一个内核了 查询文件来自哪个包 删除文件依然可以查，因为/var/lib/rpm下面有安装tree的文件信息的 如果卸载了就自然这些信息就没了 记一次VmwareWorkstation的光盘挂载问题和重启解决的经过 重新挂载光盘依然还是8.8G，还是不行。重启VM主机后，变为11G此时光盘挂载正常。后续rpm和cp正常。 查询包里面的文件。 ----------------------- 包里依赖文件叫做能力 上图查询的前提是已经安装完毕 上图是某个能力是由某个包提供的，而下图是哪些包需要这个能力 不安装包仅查询依赖的办法 yum可以查到这些依赖的能力来自于哪些包-不安装也能查询，rpm还做不到这一点。 不对，还有更直接全面的办法。 和依赖相关的能力的四个选项 包查询还有一些选项 ql就是全列出来 qc是列出配置文件 qd是看文档 bash提供了哪些能力，也就是哪些文件。 如果你安装了两个软件，卸载的时候想一起都卸了，可以考虑--allmatches。 rpm命令修复例子 查找rpm命令来自哪个包 所以进入救援模式 这样安装路径是不对的，如下 安装都是在/根下的 所以要以/mnt/sysimage为根安装 至此就修复好了 包校验-就是rpm觉察到包变化了， 对就是觉察到，用词就是这样的恶心。 恢复下上面的tree，怎么把上面的echo 弄进去的一个换行给去掉呢。 ----------------------------------------------- tree刚才被echo了一个换行，所以找到最后一行 删掉就可以恢复rpm -V tree检查 xxd🐖助记词，怎么改二进制 哈哈， 时间没办法，肯定改了，数据内容大小MD5都恢复了 查询所有包有无变化 包校验-来源性 导入这个验证工具--import，其实就是公钥。 导入这个验钞机实际上是放在了这个地方 检查某个rpm包的合法性-也是依赖于公钥的 公钥本地有，光盘也有的 缺少验钞机（公钥），只要安装完系统后，本地光盘上就有 修改一下验证 进rpm包里删除最后一行的回车 如果不转回去，则文件大小会差很多，且都不再是rpm包了 rpm数据库 上图初始化没有啥意义，因为你删掉/var/lib/rpm后系统也会自动给你初始化，但是安装的信息都没了。 yum就是python写的，依赖于rpm的，你把rpm的数据库删了，yum也就挂了。 rpm是单机命令，yum是c/s架构。 yum在client和server都要配置好。c和s通过网络互通，单机就是c、s在一台机器上。 光盘就是一个仓库 EPEL也是一个仓库 仓库的元数据metadata：rpm文件列表和依赖关系就是放到元数据里。还会分组-分门别类。repodata文件夹就是专门放元数据的。 仓库可能会叫做packages文件夹，也可以是别的名称 客户端要配置config文件 yum install httpd就是： 1、查询本地repo文件，看你配置的仓库 2、按照仓库配置的服务器以及对应的路径就是文件夹， 下载元数据到本地，将这些元数据下载到本地的缓冲区中（所谓缓冲区就是磁盘上的某个文件夹）。 去看元数据。是有httpd包的。而且依赖的包也找到。 3、针对httpd和依赖的包，去服务器上下载rpm包。也要放到一个缓冲区里。 4、安装。。。 5、下载完了的rpm包默认自动删除，而元数据不删。下载的东西有两个：元数据和rpm包。元数据下次就不用再下载了。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 16:08:58 "},"11-软件包管理/3-yum工作原理.html":{"url":"11-软件包管理/3-yum工作原理.html","title":"第3节 yum工作原理","keywords":"","body":"第3节. yum工作原理 在已经安装了autofs后，rpm -ql autofs，看下该包里的关键文件 以后看到 表示/usr/lib/systemd/system下面的都是服务。 基于光盘的yum源 autofs开启后就可以实现自动挂载光盘路径了，号称神奇目录：直接访问/misc下面不存在的文件夹就可以自动挂载。 为什么一定要这个目录呢，因为要当yum源必须有一个repodata文件夹。 当yum源的前提：路径下有repodata 只要看到repodata文件夹，那么其所在的文件夹就是yum源的目录。不要看packages那些。 yum repolist的本质 下载到哪里呢？通过yum.conf可见该目录 [root@centos7 ~]# cat /etc/yum.conf [main] cachedir=/var/cache/yum/$basearch/$releasever keepcache=0 ... 省略... [root@centos7 ~]# cd /var/cache/yum/ [root@centos7 yum]# ll total 0 [root@centos7 yum]# l. . .. [root@centos7 yum]# yum repolist 👈本质上就是把元数据的down到本地 Loaded plugins: fastestmirror Determining fastest mirrors * base: mirrors.cn99.com * extras: ftp.sjtu.edu.cn * updates: ftp.sjtu.edu.cn base | 3.6 kB 00:00:00 extras | 2.9 kB 00:00:00 updates | 2.9 kB 00:00:00 (1/4): base/7/x86_64/group_gz | 153 kB 00:00:00 (2/4): extras/7/x86_64/primary_db | 243 kB 00:00:00 (3/4): updates/7/x86_64/primary_db | 13 MB 00:00:00 (4/4): base/7/x86_64/primary_db | 6.1 MB 00:00:00 repo id repo name status base/7/x86_64 CentOS-7 - Base 10,072 extras/7/x86_64 CentOS-7 - Extras 500 updates/7/x86_64 CentOS-7 - Updates 3,411 repolist: 13,983 [root@centos7 yum]# ll total 0 drwxr-xr-x. 3 root root 15 Feb 14 12:06 x86_64 [root@centos7 yum]# [root@centos7 yum]# ll -R x86_64/ x86_64/: total 0 drwxr-xr-x. 5 root root 87 Feb 14 12:06 7 x86_64/7: total 8 drwxr-xr-x. 4 root root 278 Feb 14 12:06 base drwxr-xr-x. 4 root root 183 Feb 14 12:06 extras -rw-r--r--. 1 root root 84 Feb 14 12:06 timedhosts -rw-r--r--. 1 root root 473 Feb 14 12:06 timedhosts.txt drwxr-xr-x. 4 root root 183 Feb 14 12:06 updates x86_64/7/base: total 6376 -rw-r--r--. 1 root root 6351994 Oct 30 2020 6d0c3a488c282fe537794b5946b01e28c7f44db79097bb06826e1c0c88bad5ef-primary.sqlite.bz2 -rw-r--r--. 1 root root 156763 Oct 30 2020 a4e2b46586aa556c3b6f814dad5b16db5a669984d66b68e873586cd7c7253301-c7-x86_64-comps.xml.gz -rw-r--r--. 1 root root 0 Feb 14 12:06 cachecookie drwxr-xr-x. 2 root root 31 Feb 14 12:06 gen -rw-r--r--. 1 root root 546 Feb 14 12:06 mirrorlist.txt drwxr-xr-x. 2 root root 6 Feb 14 12:06 packages -rw-r--r--. 1 root root 3736 Oct 30 2020 repomd.xml x86_64/7/base/gen: total 30876 -rw-r--r--. 1 root root 31614976 Oct 30 2020 primary_db.sqlite x86_64/7/base/packages: total 0 x86_64/7/extras: total 256 -rw-r--r--. 1 root root 0 Feb 14 12:06 cachecookie -rw-r--r--. 1 root root 248733 Sep 3 23:22 db1c88508275ffebdc6cd8686da08745d2552e5b219b2e6f4cbde7b8afd3b1a3-primary.sqlite.bz2 drwxr-xr-x. 2 root root 31 Feb 14 12:06 gen -rw-r--r--. 1 root root 589 Feb 14 12:06 mirrorlist.txt drwxr-xr-x. 2 root root 6 Feb 14 12:06 packages -rw-r--r--. 1 root root 2998 Sep 3 23:22 repomd.xml x86_64/7/extras/gen: total 1296 -rw-r--r--. 1 root root 1326080 Sep 3 23:22 primary_db.sqlite x86_64/7/extras/packages: total 0 x86_64/7/updates: total 13736 -rw-r--r--. 1 root root 14049533 Feb 9 04:02 c96f20635c7f289398519818a077b294f1855722181378b5105f5ef49f0cf57a-primary.sqlite.bz2 -rw-r--r--. 1 root root 0 Feb 14 12:06 cachecookie drwxr-xr-x. 2 root root 31 Feb 14 12:06 gen -rw-r--r--. 1 root root 589 Feb 14 12:06 mirrorlist.txt drwxr-xr-x. 2 root root 6 Feb 14 12:06 packages -rw-r--r--. 1 root root 3011 Feb 9 04:02 repomd.xml x86_64/7/updates/gen: total 75048 -rw-r--r--. 1 root root 76846080 Feb 9 04:02 primary_db.sqlite x86_64/7/updates/packages: total 0 [root@centos7 yum]# yum clean all 👈这下理解到位了，清的哪里，就是这里 Loaded plugins: fastestmirror Cleaning repos: base extras updates Cleaning up list of fastest mirrors [root@centos7 yum]# ls -R x86_64/ x86_64/: 7 x86_64/7: base extras timedhosts updates x86_64/7/base: gen packages x86_64/7/base/gen: x86_64/7/base/packages: x86_64/7/extras: gen packages x86_64/7/extras/gen: x86_64/7/extras/packages: x86_64/7/updates: gen packages x86_64/7/updates/gen: x86_64/7/updates/packages: 也可以用du -sh /var/cache/yum验证可见大小为0 yum clean all，如果你修改yun源后不清理，就是照着就得yum源那会的yum repolist下载下来的元数据缓存去找rpm包的。所以要清一下的。 yum的问题主要就2个，①路径写错了②缓存没清。你别跟我讲rpm数据库删了。③/etc/yum.repos.d/下面只要有一个repo文件不能用就会影响所有的repo源。 下面是将base源和epel源合在一起讲的： 上图👆是epel的alias 快速启用和禁用。主要是考虑安装rpm包的时候，不让他再去找epel，因为base是再本地的，而epel在网上，所以即使你安装base也会去epel找一遍，浪费时间的。不过yum 本地仓库其实是将base和epel都拉下来的，所以实际工作中base和epel都是内网本地的仓库。也无需禁用epel。 👆上图是将base源和epel合在一个.repo文件里的，也可以分开来，将epel单独做一个epel.repo文件。 这两个应该是从上往下，能走哪里走哪个。 下图是key的写法 key启用后的第一次安装rpm包，会问你是否导入key，👇下图， 然后后面再安装其他rpm包就不会问你了。 YUM出问题就两个：①配置文件以及路径问题，②缓存清一下 比如要安装sl这个小火车，就要删除yum仓库，清除缓存，安装yum源，epel源，比如centos8 https://developer.aliyun.com/mirror/centos?spm=a2c6h.13651102.0.0.23961b11BCsMUT yum cleall all yum makcache yum updata https://developer.aliyun.com/mirror/epel 安装会自动给你安装依赖，那么卸载是否会自动卸载依赖包呢 默认不会自动卸载依赖包的，因为可能别的包也会依赖这些依赖包。 yum list可以看到安装历史 实际上yum安装的时候也有自己的log，👇 Centos8就是dnf.log yum history info 11可见当时做的事情，比如command line install mariadb-server。 把这个事件撤销 undo就是卸载掉 这样就卸掉了，然后看下yum事件，卸掉了10个包Altered 如果你又不想卸了，还可以yum事件回去 redo就是重装一遍。 baseurl还有一个mirroslist(这个后面讲) baseurl可以写多个，如下👇图： 写多个baseurl，都生效， 上图是光盘禁用后，走的网络yum安装的。但是这多个baseurl，优先用谁呢？答案还是在上面的PPT里：failovermethod={roundrobin|priority},cost的值越大优先级越低。 然后是yum的baseurl的4种路径： yum仓库的内置变量 自己写脚本，里面的yum源可以使用多行重定向来写，👇▲脚本惯用手法-cat多行重定向写文件内容。 别忘了别名、vim、history格式、PS1、yum源。 yum list就列出了这1w多个包，一共就是1w多行： yum 看到已安装的包是@打头 anaconda是操作系统安装向导的时候安装的程序，所以yum list不仅看到哪些已安装，还知道从哪装的，①比如anaconda②还有base仓库③epel等其他仓库。 这两个包是base仓库创建后，利用yum安装上去的。 比如，下图👇其实查看已经安装的可以yum list installed更快，必进grep要CPU计算的。 也可以用yum search http 上图，说的是搜索的包名，前提你的知道包名， 包名不知道咋办？以httpd为例，先卸载掉👇 整体卸掉包含之前yum install的所有东西，就需要查案yum history info NUMBER，见到httpd就行。 然后undo就行 上图提示的是依赖的文件名，而不是包名 找到依赖的文件来自哪个包 -qf必须已经安装了的文件名；-pqf后面必须跟包名，package；不对，换方法： 这里注意 yum search 和 yum provides 的差异，provides更胜一筹啊看来~ 查找文件由哪个包提供。这种方法一般也就是用在没有yum源的情况下，自己把依赖准备好，放一起，走哪都yum -y install *rpm就行了。 list查所有的、已经装好的，可用的available-就是未安装的。 yum list 默认就是yum list all yum repolist是将仓库的元数据down下来，同时给你list列出来，不过是针对启用的仓库，加上all就是关掉的也会列出来： yum provides 后面可以是某个文件的，也可以是依赖包。相当于既有了-qf的跟文件能力，也有了-qpi的跟包能力。 👆上图就是展示了怎么rpm查询/bin/tree来自于哪个包。 yum的reinstall和rpm --replaces和--force一样咯。显然不一样，yum的reinstall还带依赖的。 红色框框里的常用，其他不怎么用了，使用yum yum info 类似于rpm -qi rpm包也是yum安装的。需要依赖也会自动给你安装的。 尽量还是不要升级包。 还有centos6不会升级到7，而是重装成7 注意update和upgrade的区别就是没区别 https://cloud.tencent.com/developer/article/1375013?from=article.detail.1604418 update If run without any packages, update will update every currently installed package. If one or more packages or package globs are specified, Yum will only update the listed packages. While updating packages, yum will ensure that all dependencies are satisfied. (See Specifying package names for more information) If the packages or globs specified match to pack‐ ages which are not currently installed then update will not install them. update operates on groups, files, provides and filelists just like the \"install\" command. makecahe一般不需要用 因为，第一次使用过yum，就自动makecahe了 这样一下yum的缓存也就有了。 总结： 这是查这个包依赖哪些文件，然后这些文件又是由哪些包提供的--这就需要再次yum deplist xxx了，比如上面的bash Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-12-29 17:12:16 "},"11-软件包管理/4-实现yum源仓库和使用yum管理软件以及dnf.html":{"url":"11-软件包管理/4-实现yum源仓库和使用yum管理软件以及dnf.html","title":"第4节 实现yum源仓库和使用yum管理软件以及dnf","keywords":"","body":"第4节. 实现yum源仓库和使用yum管理软件以及dnf 定下来学某个东西的时候，就要摸清楚来龙去脉，这样比较对得起人这种动物它这个脑部、神经、心跳节奏的规律。否则不舒服的，我在试图理解底层心理学？显然这是不对的，感觉对了就好。 配置内网的YUM源 yum -y install httpd 安装httpd服务，通过光盘镜像安装就行（各种rpm包，和yum仓库-repodata元数据） 通过rpm -ql 查看安装的文件 systemctl start httpd 目录结构 所以就是/var/www/html/centos/7/os/x86_64 把centos7的安装光盘整个目录复制过去，也可以挂在光盘的。 再接一个CENTOS6的 把对应的光盘挂过去-工作中复制过去 临时挂用命令mount就行 centos6的也有了 yum源就OK了。 服务端就配置好了，下面开始配置CLIENT 只要不是repo后缀的就不会干扰repo源。 验证可以不写，写的话也很简单 这就是校验文件，赋值一下路径 搞定，当然上面的6也可以用$releasever替代他 测试下 这里注意下，6713个包的解释：我们就挂了一张盘，但是6K个包是两张盘的总量，可能就是第一张盘里有两张盘的包总量信息。然后一些偏门的包在第二张盘里，你是安装不了的。 以上就是基于HTTP协议的yum源 如果没有光驱-显然基本都没有，就用iso文件去挂 光盘可以挂，ISO文件也可以挂 然后web看到就成功了 但是前置条件别忘了：selinux和防火墙 还有客户端 其他补充 mirrorlist是把多个路径写到一个文件里 现在这个机器可以指两个源，准备添加一个网上的阿里源： 复制远端路径 把上面的txt路径一复制，贴到下面去就行了。 搞定了 不信可以看看centos默认的yum源写法，他也是用的mirrorlist的。 包组的管理用group group分为环境组和普通组，环境组就是安装系统的时候让你选择的包--老王使用的事GNOME Destop，老刘使用的是Server with GUI，俺使用的是Minimal Install。 你选择某一种比如Serer with GUI就会对应地安装很多包。 开发包组里的包 \"Development Tools\"注意引号，否则当作两个包组了。 强制组、可选组 不是随着group包组安装的，是随系统安装的。 不同符号不同状态 groupinstall可以连起来写 工作中一般不用包组group，都是需要什么安装什么，group里的东西可能太多了。 yum 的脚本安装可以加上-q --disablerepo和--enablerepo没有试验成功，不知道咋弄的，不过我倒是可以用sed 来开关。恩，也不常用。这么用的，临时的，所以是要配和install xx一起用的 创建自定义的仓库createrepo-其实就是为一堆rpm包生成元数据。 仓库虽然说要rpm包和元数据以及公钥，但实际上站在机器角度，仓库其实就只要一个repodata文件夹和里面的元数据。 自己研发的rpm包，或者网上找的单个rpm包，没有现成的仓库，或是就算你down的是常规的rpm包，但是仓库没down，也可以自己生成。这个题外话参考别人的博客https://www.jianshu.com/p/3b669bcebfb6 👆这样仓库的元数据就有了。 但是有个问题 httpd要开启443 仓库路径得找repodata的路径。 如图是在server下的，而其他的分别是集群、集群存储、server、虚拟化的repodata 多个repodata就是多个yum源。如果你不需要就配一个yum源就行了。 上图👆两个点①cat 重定向写法ctrl + d安全退出才行②baseurl的路径是repodate的pwd路径。 DNF dnf比yum的优势据说就是速度快 推荐yum install *.rpm因为包可能不全，还需要依赖。 这样就可以用dnf了， dnf的使用和yum一样 仓库配置也是一样yum的配置文件。 比较下dnf的性能 = = 效果不行啊，哈哈 time dnf reinstall httpd -y time yum reinstall httpd -y 这个可以看到dnf快些，可能。 yum其实是python写的程序 yum底层就是依赖于rpm的 小软件编译举例 上图gcc hello.c 回车，会自动生成一个a.out。注意上图不是一个命令哦。 指定一个名称-o 将来要编译的软件必然不是一个c文件咯： 看看这个httpd的源码有多少个c 解开的文件里有284个c文件 gcc 能搞定吗？还有编译先后顺序的。所以就不是gcc这种方式了。 那是项目了，项目管理工具了，不同的语言编译工具不一样。JAVA用maven。C语言里make Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-12-30 16:18:45 "},"11-软件包管理/5-编辑安装httpd2.html":{"url":"11-软件包管理/5-编辑安装httpd2.html","title":"第5节 编辑安装httpd2","keywords":"","body":"第5节. 编辑安装httpd2 理解源码安装 很多较新的版本，光盘里是没有的，这就需要自行到官网下载源码进行安装（官网提供的软件通常就是源码的）。 源码理论上是通过gcc从源代码-->预处理-->编译-->汇编-->链接--最终生成二进制然后执行起来。 但中间过程源码多、不仅仅源代码 还有各种文档 配置文件 说明等，这些文件你放在哪 手动拷贝工作量巨大，所以针对发布的源码 都会有一个官方的 源码编译的项目管理工具 + 配合脚本。 C一般是make这个项目管理器，把软件作为项目统筹管理。利用make里的项目管理功能便捷的部署源码。大概步骤有3： ①创建makefile文件 ​ 这个makefile就定义一些必要信息：各种文件的安装路径（二进制文件放在哪里、配置文件放在哪里、man帮助等分门别类 也可以不分同一个一个总目录放进去 各有各的子目录，这点和yum截然不同了，yum安装时自动给你安排好了，而源码得自己指定安装路径） ​ 为什么要源码编译呢，其中一个原因就是，功能定制，比如源码内置100个功能，如果你是yum或rpm安装，yum的底层也是rpm，官方给你编译完了，官方觉得50个功能是常用的，就给你把这个50个功能编译在了rpm包里，剩下50功能就用不了了。或者生产环境场景单一无需已启用的50个功能这么多，所以就需要定制化。 ----所以就需要把哪些特性功能 放到Makefile里。 ​ 所以makefile尤其2点：安装路径、启用特性。所以configure 后面启用功能的参数就可能很长，cli就会很长了。 ​ Makefile手动写不现实，也是使用工具configure脚本 借助Makefile.in(Makefile模板文件)来生成。 ②利用C语言的项目管理工具make 自动读取Makefile的内容，进行后续工作（编译） ③利用make install 将编译后的文件复制到指定的路径，就是安装动作。 然后configure脚本也是通过autocnf生成的，Makefile.in这个模板也是通过automake生成的。这里不用管，源码下载下来configure脚本和makefile.in模板都是自带的，开发人员做好的。 ./configure要进到当前目录运行的，不然可能人家的代码里写的都是相对路径，会存在问题的。 还有一点./configure的时候会检查依赖，所以会报各种错误，然后工程师就更正错误，补上对应的包，然后再回过来继续./configure。 上述的./configure , make , make install 三大步是通用的，但是每个软件各有特点，所以还需要参考install 和readme里的说明。通常源码解压缩后也会有这两个文件。有时候把install里的东西拿出来复制粘贴就直接执行就行了。 所以源码安装就是上面那回事，easy~，源码安装说的是安装，又不是让你写源码，哈哈，难不成让你跨行理解还是执行吗，no way~。不要有畏难情绪，不要有什么都敢尝试的莽撞。 源码安装tree 上图👆可见tree这个工具-ql就是安装的所有文件了，除了/usr/bin/tree其他都是文档了，不重要。 很多软件都是这个cli格式xx -V yyy --version这种查看自身版本的方式。 右键得到下载链接后使用wget下载 REAME里没啥东西，看看INSTALLL 上图👆说了它这个源码的Makefile是适合各种OS的，但是需要你改一改设置。 CC=gcc，编译器是gcc tree编译后的二进制文件放在/usr/bin下 MAN帮助放在了/usr/man/man1下 默认是linux的。需要什么OS，就取消哪个模块的注释。 源码安装的不要了，只能手工删除 看看install说明，就是常用的make 这和CPU核数有关。多线程 大量的文件才需要-j并行编译。 其实这个时候已经就能用了 当前的tree 1.6和安装后的tree 1.8共存了， 修改PATH变量 你希望tree 1.8执行而不是1.6，所以就要把1.8的path路径放到/usr/bin的前面 这是自己在这些特殊文件下创建的env.sh 上图👆有个sb的操作，就是PATH='/apps/tree/bin:$PATH'，不信你试试，回头vi都用不了，只能/bin/vi编辑。 退出一下shell使之生效 大软件和小软件 大软件是长期站着内存在系统中运行，小软件就是简单的各个选项用的时候就加载一下内存run一下就好了。 而大软件长期运行，就需要把一些设置存到一个配置文件中，下次再用的时候自动就加载配置文件里的一堆配置。 编译安装一个大点的软件httpd 这是光盘自带的2.4.6👆 这是官网下的2.4.25（用这个简单点来感受下编译安装）。2.4.39难度较大。 1、tar 解包 这次发现和tree不一样了，有绿色的configure脚本了 有这个configure脚本，就没有Makefile文件了，因为这玩意就是configure生成的。自然也就有Makefile.in文件了，in就是模板。 参考Makefile.in模板利用configure脚本来生成Makefile文件。 看看readme，也没啥用 看看install ./configure --prefix=PREFIX就是跟了个路径，安装到什么地方。 然后./config需要些指定一些配置：①安装路径指定好，②哪些特性启用哪些不启用。 如上图不写就是默认安装在/usr/local/apache2 然后再看下特性的启用： enable 或 disable 特性 然后开始执行./configure生成Makefile文件 这就制定了安装的总文件夹，和配置文件的存放地点。而且这些文件夹是 不需要事先有的。 需要enable说明默认是未启用的，需要disabled说明默认是启用的。这话对不对哦？⚪疑问 后缀很长建议这么放 我们编译工具之前已经安装了gcc，但是这些特性启用可能还需要依赖 好，下面开始一步步检查和拍错 记住咯，一般提示XXX not found，就是需要XXX.devel这个包，所以需要的就是apr.devel。缺什么就加devel，通常对的。 继续./configure go on 。。。 继续./configure --prefx --xxx 这次依据惯例，使用mode_ssl-devel是没有的 仔细观察上图，提示OpenSSL version is too old 继续 MD，上图我还以为是打了个叉叉，几个月前写的了，现在梳理突然第一眼没看明白，哈哈。是成功两字哦呵呵~。 所以httpd的依赖包列表如下 上面就可以写脚本了~，部署就很快乐~ 字词configure编译完了，就会生成Makefile文件 这个图的步骤在cat install里一样看得到 然后make -j 4 可能是和CPU核数对应的。 我们来复习编译的安装路径 最后一步makeinstall复制文件 主目录/apps/httpd24，配置文件/etc/httpd 这就安装好了，那么就要使用了 每次写路径比较麻烦，所以还是写到PATH变量里去 启动： 这种开机自启动的方法：它又不是sytemctl enable xxx 这种大的软件且是持续运行的就是叫做服务。而不是一次运行的程序。 reboot后测试一下： 以上过程可以写成编译安装的脚本。 下面再装个小软件-黑客帝国的既视感哈哈~ ll 看看 README，看看INSTALL 可以通过./configure --help查看安装路径选项 和 特性启用选项 curses.h，是缺少curses的头 这个头由什么文件提供的呢？ 改为模糊搜索 这个搜到的东西太多了，不仅仅是提供该关键字的包，还有文件，不是一目了然。 或者搜包名这种好一点： 可见是叫ncourses 错误是courses.h安装晚了，应该是configure之前装好的。此时需要make clean一下。也可以把这个目录删了，重新tar xvf解压 重走一遍configure 再make👇： 所以还是删除整个文件夹 脚本写好后，放到网站上，这也是一个常见操作 要想执行往bash里一传就行了 所以将来，你把一键安装脚本放到http网站里面，然后，随便找个机器这么一执行就本地安装成功了。 ★这是个法宝啊 复习下 Ubuntu软件管理 .deb类似.rpm包 dpkg 类似rpm安装 APT类似yum du -sh *查看所有文件和文件夹大小 这就可以看到.deb后缀的包了 dpkg -i xxxxx 安装即可。 -l列出了所有安装的包类似rpm -qa 上图的这个大箭头挺抽象，几个月后也半天(5s)才看明白， 类似于rpm -ql centos如果是minial最小安装，后来又想要GUI，于是可以安装一个包组GNOME。 带空格和不带空格的区别：是grouplist[空格]不是group[空格]list 这个如果你最小安装tab不出来的哦。 16.04以后apt基本整合取代了之前的3个。 但是这个虽然是CN的网站，但是还是不快，所以很多人都替换成阿里的。 类似centos的GNOME的ubuntu里叫ubuntu-destop yum list installed也能看，但是不知道是哪个 友情提示，yum 安装的过程种或者脚本执行的过程中，等等如下图👇 不要敲任何键盘，否则后果比较危险，证明👇 等10s后就发现 复习 补充： tree 编译安装的其他问题处理记录 root@vpn tree-2.0.2]#make gcc -O3 -pedantic -Wall -D_LARGEFILE64_SOURCE -D_FILE_OFFSET_BITS=64 -c -o tree.o tree.c In file included from tree.c:20:0: tree.h:63:1: warning: C++ style comments are not allowed in ISO C90 [enabled by default] // Start using PATH_MAX instead of the magic number 4096 everywhere. ^ tree.h:63:1: warning: (this will be reported only once per input file) [enabled by default] tree.c:47:1: warning: C++ style comments are not allowed in ISO C90 [enabled by default] //off_t (*listdir)(char *, int *, int *, u_long, dev_t) = unix_listdir; ^ tree.c:47:1: warning: (this will be reported only once per input file) [enabled by default] tree.c: In function ‘main’: tree.c:100:3: warning: ISO C90 forbids mixed declarations and code [-Wpedantic] bool needfulltree; ^ tree.c:124:29: warning: ISO C90 forbids compound literals [-Wpedantic] lc = (struct listingcalls){ ^ tree.c:138:3: warning: ISO C90 forbids mixed declarations and code [-Wpedantic] char *stddata_fd = getenv(ENV_STDDATA_FD); ^ tree.c:145:33: warning: ISO C90 forbids compound literals [-Wpedantic] lc = (struct listingcalls){ ^ tree.c:263:30: warning: ISO C90 forbids compound literals [-Wpedantic] lc = (struct listingcalls){ ^ tree.c:271:30: warning: ISO C90 forbids compound literals [-Wpedantic] lc = (struct listingcalls){ ^ tree.c:279:30: warning: ISO C90 forbids compound literals [-Wpedantic] lc = (struct listingcalls){ ^ tree.c: In function ‘usage’: tree.c:659:2: warning: string length ‘3348’ is greater than the length ‘509’ ISO C90 compilers are required to support [-Woverlength-strings] \" -- Options processing terminator.\\n\"); ^ tree.c: In function ‘patignore’: tree.c:668:3: error: ‘for’ loop initial declarations are only allowed in C99 mode for(int i=0; i 上面error说这个只能用c99编译，结果你的MakeFile 注意，在我的一台centos8里是CC=gcc，没问题的，但是在另一台centos7里，报错c99， 网上搜了下，说gcc默认是使用c89，然后我rpm -ql看了一下 果断修改Makefile里的CC=c99就好了，不明觉厉~ 所以不管怎么说，人家要c99就给他c99好了 改成 再次make就好了 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-01-04 16:23:02 "},"12-磁盘存储和文件系统/12-磁盘存储和文件系统.html":{"url":"12-磁盘存储和文件系统/12-磁盘存储和文件系统.html","title":"第十二章 磁盘存储和文件系统","keywords":"","body":"第十二章 磁盘存储和文件系统 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-03-31 16:26:33 "},"12-磁盘存储和文件系统/1-磁盘工作原理详解.html":{"url":"12-磁盘存储和文件系统/1-磁盘工作原理详解.html","title":"第1节 磁盘工作原理详解","keywords":"","body":"第1节. 磁盘工作原理详解 设备类型 一般将数据存到文件里，就是说的存到磁盘上了，不要较真说proc也是文件，你存到proc里就是存到内存里。 通常这里理解：1-存文件-存盘，2-生效-就是在内存里运行 块存储是一块一块（比如512为一块单位），当你读到内存里必须是块为单位512 512 地去取，，cpu就可以1bit1bit的处理了。 数据的访问时随机的，块设备的读取，你打开文件就是随机的一个数据，你也不知道存在哪里位置。怎么可能不知道具体在哪呢，inode是吃干饭的啊。 随机的意思是和顺序相对的，块设备和字符设备，一个是看磁盘空间空闲块，然后这些inode快bitmap是空的，然后就可以用来存放数据了没有像磁带那样的一个顺序读取，而是指针地址读取。写还有一定意义上的随机性，读可没有哦。 磁带就不能跳过，只能顺序的快进。 光盘可以跳过，也实现了随机读写 块有缓存，因为是随机的，所以将数据缓存了， 光驱和硬盘里面都有缓存，提供读取效率。 字符设备，比如键盘，就是一个字符一个字符的输入的，且是按照顺序的。字符设备没有缓存~ 块设备要么硬盘、要么光盘 其他都是字符设备，比较多 下图👇是字符设备 这两个数据表示的是设备的类型，8类型，第5个。类型下的编号。 如果两个数字相同，就判定为同一个设备，并不看名称。 比如，构建一个光盘 11 0 创建一个同样编号，名称不一样的 mknod 创建设备 创建了光盘，然后将这个/dev/sr0同类型同编号的设备/dev/cd就是光盘了，挂载到/mnt，可以看到mnt下光盘内容了就： 不同接口命名不同 https://blog.51cto.com/u_12958700/1933385 并行理论OK，但是电磁干扰没办法目前，所以串行才是优选。 redhat 5 添加IDE硬盘 centos 6上加普通的SCSI硬盘 加了好几个 题外：家里搞个NAS？貌似这这样玩的。 上图IDE口在red5红帽5的显示： 除了IDE接口的都判定为sd---这是老的红帽5的做法👆 centos从 6 开始就不一样了，不管是什么接口的IDE SCSI SAS的MVNE的都是sdxx同一个命名 但是工作中不一定是物理介质，还有阿里云等，云服，虚拟机可能是dev/vd /dev/xvd xvd一般是zen虚拟化技术，vd一般是kvm的。 如果是1就是机械，如果是0就是固态--适用于物理机--虚拟机不能这么判断 sda就是第一块硬盘， sdb就是第二块硬盘 sdaa...sdaz sdza...sdzz就这么排下去。 机械盘才是旋转的，所以是1 当然这种方法只能看物理机上的情况，如果是虚拟机就不行了。 MBR方面：单块硬盘最多4个主分区（可以没有主分区），多块硬盘只要有一块有主分区，其他可以全部都是扩展分区， 扩展分区不能直接使用，需要再次创建逻辑分区才能使用。 主分区不能再继续划分成小的分区了，就是独立使用的。 注意sda4是一个扩展分区，下面的所有sda5 sda6（如果继续分的话），都是属于sda4扩展分区的一部分。 这个1K不是真的是1K，只是显示效果。扩展分区不能存数据，所以这里判定为1K，可以用fdisk来看真实大小 上图的红圈是起始位置，还有后面的结束为止，在 centos7里，起始位置和结束位置是以扇区为单位。从start扇区开始到end扇区结束(扩展分区里面分出的小逻辑分区一定是在这个扇区316672000-419430399内的--也就是sda5在sda4扇区里面的。)，Blocks的值是它的真正大小。而1block是1K。所以上图的扩展分区就是50G大小的容量。 sda5就是4G的大小，还剩下40G+的空间未使用。 51379200单位是block，1个block是1kB。这个其实也是扇区512B/1024自然就是kB了。 然后1个block就是2个扇区，读取是整数倍也就是blocks是吧 ------ 这是centos6的，对比上面的7的发现，6比7多了Heads和cylinders。下面开始介绍硬盘结构，从来了解这些现象。 友情提示，硬盘是密闭的，不是真空的~真空早就压扁了。当然你要说是那个真空我也无话可说。 PS：数据是左上图框选的地方放一点，右上图框选的地方放一点，所以要读出来，磁头就要换道了。比如从内圈读完换到外圈，那估计盘片就转走了，就不是同一个扇面了，要等下一圈了就。 磁头换内外圈，就会影响速度了 硬盘的转速就是体现出来速度了。 磁头正反都得有，因为盘面就是正反的 不灵活，整体旋转的。 盘面数=磁头数 不可能是255个磁头，100多个盘片？物理上没这么多，这个head是逻辑上，早期确实就是这样的，后来保留了这种表达方式。 最外圈是0磁道，往里圈编号。 硬盘属于块设备，组织硬盘空间不是一个磁道来整合的。磁道切成一块块扇区。 早期扇区划分(就是在磁道上划分)是同心圆划分的，内外磁道的扇区数一样。这是早期的划法。 一个扇区的大小512字节固定的，整个硬盘要存放更多的数据，就要划更多的扇区。 上面的扇区划分，内圈磁道太短，存放数据有限，随着磁盘密度增大，内圈逐渐可用度越来越差。里圈以达到了工艺极限单位面积存放数据越来越多，但是外圈仍然富裕。同心圆的划分就不行了。 为了解决内圈拥挤外圈富裕的问题，所以产生了下面的扇区划分方法。 拽个名词ZBR zbr 区位记录 法 磁盘扇区划分 这种外圈和里圈放的扇区数量不一样了。 磁头放在外圈数据读取块，放在里圈读取慢。 数据放外圈处理就快些(怎么放外圈啊？⚪)，将来优化系统性能的思想。这是现有的硬盘基本都用ZBR划分的。 如果早期磁盘内外圈速度一样的。 通过磁道来识别外圈还是里圈，0磁道在最外圈，不过实际操作种你看不到磁道号吧，应该都是扇区号。 其实有N个0磁道，和N个n磁道：👇下图有6个0磁道，6个1磁道，6个. . . 所有的0磁道，1磁道，2磁道。。。都是各自组成了柱面 8bit来表示head 255个磁头heads的上限，0不用； 10bit来对应track磁道，1024个磁道上限； 6bit的扇区，63个扇区sectors上限，0不用。 ​ 63个扇区就是一圈 1cylinder（柱面的大小）= 512（1个扇区512个字节）* 63个扇区*255（磁头数也就是盘面数）=8M不到的样子 上面👆这些等到下一章节里就可以对应到MBR里的具体字段就知道怎么算的怎么由来的了。 其实就是这张图 CHS，cylinder柱面，H head，s sector扇区，这就是硬盘的三维 CHS,24bit的局限性 整个硬盘多大？512*63*1024(柱面的上限)*255≈8G，所以传统的磁盘最大8G。这就是CHS的极限。 LBA的容量大 所以又产生了LBA来表达磁盘大小的方式 LBA，只有扇区，全是扇区了就。所以centos7上就只有扇区，没有head和track以及cylinder了。👇 28位寻址就是👉28bit来表示扇区，一个扇区512，所以128GB=2^28*512B 128GB也不够用了 centos6实际上也是支持LBA的，只是为了兼容老版本，所以才是按CHS的方式显示的。 centos7也能够按CHS的方式显示👇 Units = cylinders of 16065 * 512 = 8225280 bytes 的意思是 一个柱面的大小，说明如下： 上文已讲过一个磁盘的容量怎么计算的，当然是最早期的磁盘。CHS，1024个磁道也就是柱面，255个磁头，63个扇区。一个扇区的大小是512B。所以，一个柱面的大小=63*255*512=16065*512 早期red5分区就是按柱面来分的（不是以扇区、磁头、磁道来划分的），就是最小单位是柱面cylinder。整个柱面为单位来划分。就是必须是1个柱面道100个柱面算一个分区，不能是0.5个柱面来划分，然后一个柱面的大小也是8M左右，所以分区的大小也是这个8M的整数倍。 centos6就打破了以柱面为单位，而是以扇区为单位进行划分了。但是centos6为了兼顾centos5，还是以柱面为单位显示的 如上图，第一个1柱面到131个柱面，但是可以打破单个柱面的。说的是partition1分区1跨了柱面了。也就是打破柱面为最小单元了。131到底属于sda1还是sda1,131都属于，说明131柱面跨分区了。也就是说分区的边界线切在了131柱面里面了。 下图就是centos6支持扇区分区，但是兼容柱面，所以显示最小单元是柱面，但是如果存在131这种切到柱面里面的，就会做个提示出来。Partiton 1 does not end on cylinder boundary 上图👆就很明显，分区1不在柱面的边界，那说明就是柱面中间切了一刀。 centos5不能这么干的，7彻底都是扇区了也就不提示这种信息了。 分区的话，扇面或者柱面必须是连续的--也就是单块硬盘的连续空间来作为某个分区。 windows的所谓的跨区卷，但不是分区，也不能跨硬盘。 100G分一个区在一个连续空间中，后来空间不够了，它前后的空间被别人占用了，就算没有被占用，我们统统认为分区不可扩展，不可缩小。后面有些技术LVM、RAID类解决此类问题。 windows某些软件号称可以扩，但是也就是玩一玩，很危险的操作。生产中统统认为分区不能扩！ Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-01-05 11:31:45 "},"12-磁盘存储和文件系统/2-MBR和GPT分区管理.html":{"url":"12-磁盘存储和文件系统/2-MBR和GPT分区管理.html","title":"第2节 MBR和GPT分区管理","keywords":"","body":"第2节. MBR和GPT分区管理 三步：分区、格式化、挂载 为啥要分区 分区 隔离数据，系统分区，数据分区，系统坏了，数据不受🦅影响， 分区的格式也可以不同。对于修复来说提高了修复的速度，没必要针对总体硬盘修复了。 一个小小重点 日志和DATA要分开来，性能得以优化。不然写日志可能导致东一个扇区西一个扇区，造成了文件的碎片化，将来读取不是太顺畅，性能就不好。这个如果是真的，影响很大的话，确实是个关键点★。 MBR 所以说，分区对读取速度有帮助的，简单来讲就是分门别类提供效率。 △结合上一章，搞清楚几个问题哦，①8G、2T、16B、32位、CHS这些东西分别说的啥，谁的上限，怎么得来的②同样的MBR里有两台表达方式CHS和LBA，这两个自然存在不同的上限的。上面的32位是LBA表达法用了4个B，所以是32个位也就是2^32来表示扇区的，所以MBR的分区上限是这么来的，当然CHS要小咯。然后CHS是3个字节也就是24位来表达扇区的，自然分区就更小了。 主要上次提到2^48*512B是在磁盘空间表示上见到的。而这次是分区空间上限表示的计算方法。计算公式一样，但要注意说的不是同一个东西。本质上是一回事，都是多少位来表示多少个扇区，一个说的是分区，一个说的是硬盘。 你看哦这就是完全错误的理解了，错啦，往下看吧，MBR-如果用LBA它支持的硬盘最大就是2T，如果是CHS，最大硬盘支持的就是8G。不是说的一个分区最大值哦。 [root@vpn ~]#echo 2^28*512/1024/1024/1024 |bc 128 👈128G [root@vpn ~]# [root@vpn ~]#echo 2^32*512/1024/1024/1024 |bc 2048 👈2T [root@vpn ~]# 进一步总结，那么为什么还有大把的人讲MBR单个分区最大支持2T呢，因为如果你将3T的硬盘划分区MBR的哦，划了2T作为第一个主分区，那么剩下的1T空间就用不了了，就灰掉了，说单个分区最大2T的也对，但是不准确，因为单个分区用掉了整个MBR格式的硬盘的2T上限，所以剩下的空间无法划分了。举例 MBR目前依旧是主流的 、 55AA就是标记位。 MBR分区结构 -------------------------- 这0磁道0扇区的512B，不属于任何分区，既然不属于任何分区就没有任何文件系统，没有文件系统自然就没有文件的概念。 最后标记为就是55aa 四个分区，每个16个字节。 活动和非活动，所谓活动分区，就是计算器启动的时候找80标记的分区，从该分区上找操作系统（引导操作系统的相关文件）。如果有两个80，就找不到了。就启动不了了。 这个磁头、柱面(也就是磁道数track)、扇区都有了也就是CHS定位了起始位置就有了，就是该分区从哪里开始。磁头从1开始，扇区也是从1开始的，因为扇区0就是上图拉，MBR和分区起止位啦。所以8bit的磁头不是256而是255，6bit的扇区不是64个而是63个。 在上图👆中指出8bit的磁头head、10bit的track磁道也就是柱面、以及6bit的扇区的具体位置。 第五个字节为0表示空间未使用。都不是0上图，就是分区都使用了，都分区了。 CHS如图才3个字节，也就是3*8=24个bit，也就是2^24*512/1024/1024/1024=8G的空间上限。问这是分区最大值还是所有分区-整块硬盘最大值。就算你不知道直接的答案，使用现有的肯定的知识也能得出来，来，3个字节来表示CHS是吧，假设是表示的单个分区最值，那么3个字节全部设置为1，也就是FF FF FF，好00 00 00-ff ff ff 表示8G一个分区，那么第二分区同样也是00 00 00 - ff ff ff ，第三个 第四个都这样，你觉可能吗，CHS是什么是那张硬盘结构图cylinder磁道也就是柱面，磁头也就是盘面，sector扇区，比如C-H-S值为1111111111-11111111-111111，这个东西是啥就是磁盘上的唯一的个扇形拉扇区对吧，我柱面定了-磁头定了-扇区也定了，东西就一个东西，还能在4个分区里出现4次？！扯淡吧，所以_ ___ __ 三个字节是4个分区整体计算分配的空间，比如分区1 CHS是1-10,分区2 CHS就是11--20，3就是21-30 ，4就是31- 40这样的。就像你写word里的序号是续的，不是重新编号的，当然我用10 20 30 便于理解，其实是下面这些值👇，同理LBA也是一样，所以LBA的2T上限就是整个磁盘的。 8个字节是换LBA玩法了。 所以2T也就是MBR的上限了，“也就是MBR可以表达的一个分区的最大容量”，这句话也是错的，我上面已经解释过了。 EBR表达起始位置和下一个EBR的位置，自然就能知道自己的起止位置了。 EBR不固定，是因为扩展分区不固定，第一个EBR不固定，自然后面的EBR都不固定。 但是MBR是固定的，整个硬盘的第0个扇区就是MBR所在，自然是固定的。 上图👆最左边一列是偏移地址，也不知道是怎么意思？⚪不管他参考基准是什么，反正对不上号和下图：是什么，是你大爷，看东西不会思考，第三次过的我来告诉一年前的你， 以前两行为例： 00000000 00000010 等价于 0000-0010 等价于 0000-001F 也就是2^5=32，也就是32个B字节，你数数前两行是不是32个字节，中间段是不是8*4=32个。 所以下图的红框就是位置，就是上图的位置，只不过下图统一用10 20 30 F0来表示，人家就是行开头了， 比如00000000-00000010，就是0000-0010，就是0000、0001、0002、0003、... 000F、0010就是2^4=16就是一行16给字节咯。 这个在MBR分区结构里也有小字表示的见下下图 上图的Error就是出错信息数据区。 ================ 备份分区表 需求来了，分区表的备份。emm，如果分区没了，上面的数据也没办法读取了。所以分区也有必要备份一下。 如果全公司的硬盘都是一个分区方法，基本也无需备份了。有一个导出分区表就行了。 也可以把这个512字节都拷贝出来 现在只备份这个64B的分区表，因为不是文件 所以cp拷不了，所以用dd把二进制读出来。 看二进制的方法来了：od、xxd、hexdump 举例，删除分区表-不是删除分区 就是把最后的标识位清了，但是skip用的有问题，skip是跳的if的设备，跳of=/dev/sda设备，要使用seek。 fdisk和lsblk的区别来了-一个看的硬盘上的，一个看的是内存中的 一旦重启，内存中的分区表就没了，硬盘里的分区早就没了，重启就起不来了。 当前真正生效的还是内存中的数据（分区表） ps：不管你skip510还是seek510，skipxxxx要得到的是/data/dpt里的55aa，显然dpt只有66B，skip写错了，下面改过来了。 这样就恢复了55aa标记位 举例-破坏分区表-保留了标志位 有些是0，就给你用*省略了，不显示了，详细看的就加参数 因为标志位55aa还在，所以还有个分区标题 虽然fdisk有这些磁盘标题Device Boot Start End Bloks Id System，但是没有东西，因为分区表清零了 系统判定有55aa标识位，觉得有分区，但是又不知道分区的起始结束位置。 此时重启，就起不来了，不重启是可以的，因为当前分区表是用的内存中的，也是说分区表还有的。救援模式来恢复可以吗？刚才的备份数据在/data里，但是分区没了/data个毛啊。 所以要备份一定要scp到远程主机上。当然如果你有可以用两块硬盘，分区破坏了一块，可以从另一块硬盘上手动挂载后获取分区备份（加入你的备份在那块上）。 重启模拟故障处理，重启之前先把分区表备份到远端机器上。 提示没有找到分区了 进入救援模式，硬盘起不来，光盘起。 如果硬盘分区还在，就会看到挂载到mnt/sys里面的，由于我们之前将硬盘的分区删了，所以这里自然也看不到了。 但是好像救援模式没有网络，你的分区备份还在远端主机上呢， 可以拿U盘，其实还可以临时配个IP地址的 这就就完成了救援模式下的scp 同时你要知道，此时是光盘加载的，数据拷贝过来都是放在内存里的，重启就没了。 上图👆注意 ：sdb、sdc、sdd都不管，是刚才加的。 再看下a硬盘 上图是看了全部了，下面只看前512一个扇区的内容 55aa前面的64确实是空的（注意中间*省略了，其实是64B的0）。 写硬盘的话：工作原理，是把内存的数据先放到缓冲区里，过一会再放到硬盘里。 dd 命令你看到提示ok了，但其实还在缓冲区里呢。你立马重启缓冲区内容就清了，此时就造成了数据写失败。所以不能捉急。 手动sync同步一下：多次sync就是担心sync没有立马执行。还是要等等。 此时硬盘已经还原，系统已经能识别了--系统就是装在硬盘里的，能识别自然就说明硬盘分区恢复了。 dpt disk partition table ======================================================== 实际上整个硬盘都不能超过2T，不是说分区不能超过2T。超过MBR就没办法了。为啥，分区表里的的bit位算出来的不是针对单个分区的，为啥说是整个硬盘呢。你再看下原来的图 他那个4字节“分区起始LBA”里填写的是起始和结束位，结束位本身就是2^32*512B=2T的上限，2^32个bit位用来多次表达分区起始位置，所以怎么算整体的表达能力就是2T空间。这个好理解，我们拿两个bit位类比来表示空间，00-01,01-10,10-11,11-00，没了，是不是一共也就会2^4个分段。它是续接的，不是每次都重新编号的。 每块硬盘可以有独立的分区格式，下面一块就是MBR ▲面试题有了：问：windows硬盘分区底色是绿色是啥情况？哈哈哈，气死人不偿命~ 变色，就是自动将第4个分到一个扩展分区里面了，然后自动创建了一个逻辑分区。 删除里面的逻辑卷 、 这就是扩展分区划分逻辑分区 再说会GPT分区 UUID是国际标准，微软发布的GUID属于UUID的具体实现。 UUID后面写的是16进制。128bit，就是32个16进制。 IPv6也是128位，这个UUID也是128位。 题外话： [14:54:45 root@pyConsole ~]#cat /etc/fstab | grep UUID |cut -d \"=\" -f 2 | cut -d \" \" -f1 |cut -d \"$\" -f1 |cat -A 07507cea-e91c-42ff-9cc9-ca3eb61212f0$ [14:54:48 root@pyConsole ~]#cat /etc/fstab | grep UUID |cut -d \"=\" -f 2 | cut -d \" \" -f1 |wc -c 37 wc这个算字符是把最后的$也算上去了哦，我输过了是36个~对输过了，要赢回来的 UUID生成工具uuidgen,▲各种生成工具可以整一波~ Protective MBR完全是保护后续的GPT分区信息的。 👆一组4个分区的定界信息。 Partitioin Header头部和分区表 都 有备份 早期的BIOS启动的蓝色界面操作，现在不是这个颜色了，到后面的支持鼠标操作的启动界面 固件接口， 否则BIOS不支持GPT分区作为引导操作系统的 UEFI启动就得配合GPT分区。 BIOS+MBR与UEFI+GPT 这样的，BIOS启动，UEFI启动，这两个启动，启动的时候要引导操作系统的，①而引导如果安装在GPT，就只能用UEFI启动；②BIOS启动的只能MBR分区方式里的引导。③BIOS可以使用GPT分区，只是用来存放数据而不是OS，这个其实是搞笑的说法，因为BIOS通过MBR分区里的引导操作系统启动后，然后就是通过windows/linux操作系统来识别GPT，从而达到在GPT分区中存放数据的效果。 启动的时候只能靠BIOS和UEFI本身去引导操作系统的。 虽然UEFI也支持MBR，但是没有意义了，UEFI虽然支持MBR启动，但必须要有UEFI引导文件存放在FAT分区下；UEFI是无法使用传统MBR引导来启动系统的。 你要把操作系统装在GPT上，就有要硬件的UEFI支持（就是新的硬件已经不用BIOS咯）才能启动。 常用的BIOS+MBR分区里安装系统+另一块硬盘GPT来支持超过2T的空间。这个可以有，不过直接UEFI+GPT不更香么。这是家庭电脑才需一块磁盘超过2T吧，工作中一般来讲服务器-装软件用不了多大空间，而大数据的话用mysql-mysql本身达到T级别早就分库了--拆成好几份，每个机器上放点。也不需要单硬盘超过2T的场景吧。 开始搞命令：lsbk这些cli lsblk（list block） 在centos 6 和 7上都可以用。 👆就是5的util-linux这个工具集咯应该，里面不带lsblk软件，6\\7 带的。 man fdisk👇 👆man 可见fdisk就是不支持gpt分区的，所以生产中肯定不能用fdisk来分GPT的。 man下gdisk👇 man parted👇 parted工具 分区时即时生效的 操作时要小心，很容易因误操作把你的分区表破坏了就。 partprobe同步的问题，后面再说。 parted使用要小心 fdisk查看分区，了解什么字眼代表什么分区 当前硬盘里啥都没有，所以也不存在什么446B的bootloder，这不废话嘛，它都不是活动分区，哪来的引导。 这条命令就是创建个GPT，就是说这个盘是GPT格式的了。下面可以继续用GPT的命令进行分区了。 这是个假的MBR，呵呵 打印分区表 上图单位M是MB 所以可见分区必须是连续空间。 虽然删干净了，但是还是认为有分区表，因为protection mbr的分区标识位55aa还在 你这个512B看的是protectionMBR字段内容，是不包括GPT分区表信息的 上图也看到了UEFI PART。 下面重点看fdisk和gdisk Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-01-06 11:57:49 "},"12-磁盘存储和文件系统/3-MBR和GPT分区管理工具详解.html":{"url":"12-磁盘存储和文件系统/3-MBR和GPT分区管理工具详解.html","title":"第3节 MBR和GPT分区管理工具详解","keywords":"","body":"第3节. MBR和GPT分区管理工具详解 fdisk和gdisk基本一样， 上图说明虽然分区删了，但是分区的类型还在（protection MBR里的55aa还在，可以通过dd将整个b硬盘的512B清空，这里B盘就啥信息也没有了）。 此时就是没有任何信息的硬盘了，初始接进来的硬盘就是这样显示的了。 这个时候就可以用一些工具对其重新管理（比如分区）。 保存退出，没有做任何设置 扩展分区是5，swap82，主分区是83 默认都是83，将来可能根据实际情况修改ID 只是一个标签，并不是功能性的强制标识。 就是说当前0个主分区，0个扩展分区，4个都是空闲的。 如上图，可以直接划分e扩展分区，从2开始，也不一定非要从1开始。 划分之后一个p就能看到当前划分的结果 上图是以扇区起始位置标记的，再一个就是ID是5，就是扩展分区的标识。 而且上图观察p和l，以前是p和e，其实就是说扩展分区就一个嘛，然后都是在其上划分逻辑分区了。 注意上体逻辑分区是从扩展分区的4096个扇区开始而不是2048个扇区开始的，所以你要知道每个逻辑分区的头部还有一个EBR字段里面都是本段分区的元数据来着。 逻辑分区也是ID85， 上上图的5也是自动的，固定的 扩展分区上的逻辑分区都是从5开始编号的。 上图就说明一个问题，逻辑分区的设备名是不稳定的。 你将来设备名你写到磁盘配置文件里面，你后来分区调了一下，很可能分区名就变了。 所以逻辑分区不适合写到配置文件里。 这就需要找一个不变的东西来应对。后面会讲到。 同时上图带来的问题就是，如下图： 这才2G的最大空间，所以超出了，注意2G是扇区相减后乘以512B可得出。 # 这句话也是错的，上图是1G的空间，算法是对的，结论是错的。 下面修改一下分区ID L是你记不住了就看下ID有哪些可以选择的。 关注上图的82 83 8e fd是软raid 还有一些淘汰的技术 上图是修改分区id之前的sdb3的id为83 下图是修改为82 此时还未存盘退出(w)，此时是否真的分区成功了没？👇 3种看分区的方法 上面4个方法都是没看到b硬盘上有分区的。 然后w存盘退出后，再观察 硬盘里的分区表和内存里的分区表并不是时时同步的，也就是说fdisk 分区的时候，w保存退出后并不是时时同步的。很多时候硬盘上的分区表分好了，但是内存中的没有。 ========================== centos6，以柱面为分区单位的，一个柱面8M 观察上面WARING，告诉你reboot后就同步了、partprobe或kpartx也行。 此时centos6的磁盘确实分区了，但是内存中同步不了。 不跟选项，但是要跟同步的设备哦 上图就是centos6的bug命令，不好使。记住了！！！partporbe在centos5和7上都可以，就是在centos6上不行。 可以kpartx，或者只直接partx 其实centos8是有-h的 报警error不用管，就看结果对不对-sda6出没出来就行了 上面partx -a是添加分区同步，删除分区同步用-d 但是内存里还在 ==================================== centos7也同样出现了waring ------------------------------------------------ 但实际效果应该是没有的，即使partprobe同步了。 虽然对分区再分区，且同步了，但是最终还是看不到的。 ---------------------------------------------------- 需求：将B硬盘分区分的和A一样 思路：复制A的分区表就行了。 操作：不就是A的那个64字节么，扣出来复制到B那边就行了。 所以克隆只能克隆主分区和扩展分区。但是没有办法克隆逻辑分区，因为512B里的64B是MBR，而逻辑分区是EBR是再扩展分区里的。 1、克隆的目标硬盘空间要大于等于原硬盘； 2、无法克隆逻辑分区，只能克隆主分区和扩展分区。 不过怎么看图上EBR也是可以克隆的啊。估计就是EBR比较多分散，MBR固定好操作。EBR还要计算。 再来，B硬盘和A硬盘一样大，此时克隆MBR就很OK了。 EBR的位置不在MBR那边，你克的是512的MBR里的64B，EBR在后面的扩展分区里面的EBR头 这个就是永久保存了，不存在再write，w写的动作了。 ======================================== gdisk 主要用来分GPT格式的区 都是和fdisk一样的 82\\8e这些都在 分区太多了，清一下，fdisk肯定可以清，就是太慢了 这么记笔记太慢了，体会不到学习的乐趣和快感！，，，i need fly，时隔1年，no u need 跬步 上图hexdump -C -n 512 /dev/sdb -v加个v就能看全部的0，上图默认是省略连续的0了。 不过为啥中间有28 c7 86 4a这几个值，而且我的centos 8 的情况也不符合这里所讲的，但是肯定centos8是使用正常的，那是因为我sb了，因为下图看错了，应该是sda而不是sda1。 如果把数据放在硬盘的磁道的外圈，速度读取和写入就快，如果是内圈就慢。所以再看看内外圈。 如果是centos-6的话就很清楚，本身有柱面，数字越小就越在外圈。越往里数字越大。 所以分区划分编号越小数字越快。6和7就是偏内圆了。 如果你希望数据读取快点，就将数据放到前面的分区。能提高个百分之几就不错了。 sda6里面全是0，你把数据放进去也只能0101往外读，因为还它没有文件概念。 创建完文件系统才有文件的概念，目录、属性、分门别类这些东西才会有。 注意力，持续 不同的文件系统除了必备的功能-文件管理功能，有的可能还有一些额外的功能。比如，NTFS除了文件管理，还有加密、 这就是windows的NTFS加密，只要看到 \"安全\"选项 就是NTFS系统 右键-属性-高级-加密就行了。 这是对别人是打不开的，而本人是无需的还是正常操作，没有影响（打开时自动解密，保存的时候自动解密）。 ext\\xf系统的没有这个额外的加密功能。 但是基本的管理文件功能必然都是有的。 对于linux 来说 xfs 、 ext 文件系统： linux支持的文件系统👇 当然也可以 这是目前linux里支持的文件系统类型。 在centos6上都是ext的 ubuntu用的也是ext centos 7用了个xfs，而ubuntu用的是ext4 ext1没有存在感，ext2存在重大bug，容易奔溃无法恢复，所以后来有了ext3 ext3的日志出现的优点：当系统写数据之前是先写日志的，日志一定是先于数据写，写好日志信息以后再把日志信息同步到磁盘里去，好处就是： ①万一日志写完了，还没来得及存盘，系统突然奔溃没关系有日志可以还原。②如果写日志的时候突然奔溃了，没关系，日志大不了不用了，数据又没破坏。 三刷的时候发现其实本质还是，目录和内容的关系，日志和内容都是数据，只不过日志是内容的简述，日志可以很短的时间内完成写同步的操作，内容量大的时候就比较耗时，所以加了日志容错变好些了。 读取文件，内存中修改，写到日志里，再写到磁盘里。 如果③和④中间断电，系统起来后，磁盘同步日志就好了。 如果③没完成，大不了日志丢了，数据还是完整的。大不了没更新嘛。 但是要注意，如果②没写完，写了30%假如断电了，那么日志里是有30%更新的，而系统后面起来后，磁盘同步日志，那么还是有70%数据没写进去的。 ext3的问题，性能问题在大磁盘中得到凸显，大磁盘T级别的比如，健康检查耗时达数小时之久。 为了解决这个 问题就推出了ext4，相对于ext3性能得到了巨大提升。以前小时级别的，现在分钟级别了就。 但是ext4支持的文件大小有局限性。家庭都是T级别了，生产中高达P级别。 于是xfs文件系统更大了，性能更高，但是linux上单一文件不会超出ext4的局限是，所以unbuntu上还是继续使用的ext4。 插入，在生产中拷贝大量数据时要限速，否则后果兜不住！找个空闲的时候，加上限速复制就差不多了。 上图的btrfs xfs：SGI是老牌的UNIX的厂家。早期的大片泰坦尼克号就是用SGI工作站做的。 btrfs是oracle的号称很优秀的文件系统。centos7上有不过是测试阶段，centos8就不在支持了，该文件系统就没有流行起来。 jfs在AIX小机上用的文件系统。 swap 和 iso9660光盘 FAT12是软盘， 这些是windows的文件系统。 exFAT是U盘的文件系统 U盘右键格式化的时候可以看到 refs是新的了看来 除了上面的单机的文件系统，还有网络文件系统 还有 还有就是分了区但是没有创建文件系统的情况，就是RAW。空文件系统、裸的文件系统。oracle，为了高性能，把数据库的data直接放到RAW上，就是0101010没有文件系统直接存盘，利用oracle自家软件直接利用010101去访问磁盘，由于中间没有文件系统这层，所以读取速度更快，缺点就是没有文件系统，如果oracle软件出问题，运维管理是个麻烦。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-01-09 11:10:45 "},"12-磁盘存储和文件系统/4-文件系统管理实战.html":{"url":"12-磁盘存储和文件系统/4-文件系统管理实战.html","title":"第4节 文件系统管理实战","keywords":"","body":"第4节. 文件系统管理实战 文件系统的格式化咯 这是centos6和7上的分区，sdb1和sda6\\7，都还没有创建文件系统，而创建文件系统就是所谓的格式化了。 一般就是ext4或者xfs，其实还是看系统默认支持什么（centos6默认ext4，centos7默认是xfs），就用什么。 管理工具就是mkfs这个工具 注意，文件系统本身是属于操作系统的功能，由内核来完成的。内核支持这些个文件系统，就是说内核提供了（内核级的）关于这些个文件系统的驱动模块。这点可以通过locate确认 locate xfs.ko，文件系统都是ko文件，查看有没有xfs文件系统的内核驱动。 查看ext4文件系统的驱动：xz就是压缩格式 这些都是属于内核级的功能。 那么问题来了ls，cat这些命令，对于用户来讲他访问文件，ls、cat去访问这些文件的时候，其实是通过文件系统来存放到硬盘上的。 那么这些命令是怎么和文件系统交互的呢？要知道底层用的文件系统有很多种，这些命令又是如何对应N个文件系统的呢？是不是意味着针对xfs有个ls.xfs子模块，针对ext4有一个ls.ext4子功能呢？显然不是这么干的！不可能让一个软件开发者考虑这么多种文件系统的。 所以为了让用户更专心的访问磁盘文件而不是考虑文件系统的差异，让开发或使用人员更透明的使用各种文件系统，就提出了VFS概念。 什么是VFS虚拟文件系统呢 题外话，其实从上图可以看出来一点点，就是cache缓存偏向于VFS，buffer偏向于硬件了； 还有一个简单得说法--缓存是读，缓冲是写磁盘得时候。其实这种说法里得缓冲也是说得磁盘，这就和上图不谋而合了，冲 更多是针对硬盘或是针对硬盘驱动得，缓存更多是偏向于VFS文件系统得。至于读还是写，这个我暂时人为是不分得。 对于用户cat ls cp mv等命令不会直接跑到磁盘上去操作磁盘文件。用户空间的程序是没有权限没有能力直接访问硬件的（而文件就是放在磁盘硬件上的）。 所以要用系统调用，让操作系统内核帮其完成访问磁盘上的文件 对于fat、ntfs、xfs、ext4 而VFS就是一个集大成者：把各种各样的文件系统通用功能收集起来，对外让用户来访问，用户就无需关心下面各种文件系统的区别，因为统一都是用VFS这个文件系统来访问。 这样用户开发的软件都是和VFS打交道的（比如ls、cat、mv等都是和VFS打交道的），而这个VFS文件系统再和底层的不同文件系统打交道就不用我们关心了，这是有内核来完成的，是操作系统本身来完成的。 这样就开发一个诸如ls for vfs就行了 如图可见当前不支持NTFS这种windows的文件系统，因为用的少，内核就没有内置添加这个功能，你要用自己编译到内核里。 源码编译见上文http的操作。 正常用不到这么大，用到了性能就不行了，虽然支持这么大。 创建文件系统 mkfs.ext4=可能还不等价于=mke2fs好像是默认格式化ext2的！！ 还可以这么写，mkfs -t xfs 、mkfs -t ext4 mkfs 格式化后怎么知道具体是什么文件类型 mke2fs /dev/sbd1 默认是ext2 上图的 因为本质上ext2和ext3是相同的，就是3多了日志，所以这两个是兼容的。 硬盘分区的空间可以理解成两大块内容，一个是metadata元数据-节点表（存放文件的大小、权限、时间、所有者、还有一个指针指向数据存放的位置），一个是数据。 实际上还要更加复杂，分区划分成多个组group，每个组是由多少个块组成。 而每块多大？ 不同地方的blocks意义不同 文件系统的blocks意思和磁盘分区里的blocks的意思不同 存放文件的时候，必须以block的整数倍来计算。哪怕一个字节的文件，你也要给我4K字节的空间。 分区里的block就是1个block就是1k。 如果磁盘里都是大量的1k，2k的小文件。此时4k块大小，空间就浪费了很多。如果文件都小，那么文件系统的block最小单元就别默认4KB了。 而目前文件系统，块大小支持：1K\\2K\\4K这3个单位。 4K是系统根据硬盘分区自动分的。如果分区偏大，自动给你4K的block，如果硬盘小自动给你1K\\2K的block。比如你分区就100M，默认肯定不会4K的、 也可以手动指定，-b 1k ，就是手工指定block大小了。 在磁盘上组织空间的时候，是把若干个连续的块blocks组织成一个group 这样把磁盘划分完。分出来后，每一组group里面在有自己的节点表。 superBlock：①分组的描述 从第几个块到第几块是一个分组，算是一个分组的起始位描述。②自身的元数据，比如块大小比如4K，这是文件系统的属性也要放在超级块里。 还可以手动去查超级快superblock： 这个就是最早提到的元数据 磁盘上每个文件都有元数据。这一条记录就是存放的一个文件的元数据信息。也是节点表的一条记录。 这一条占的空间就叫节点的大小。 256B，就是这一行占256个字节。 当然256B不是固定的，可以再添加属性，比如ACL这种扩展属性，这样一行的空间就变大了。 与此对应的就是节点表inodetable空间占用大了，后面真正存放数据的空间就少了。 DateBlocks数据块，一块4KB；然后inode table里的一行也就是一个节点信息占256B大小的空间。 每个文件分配一个节点号，这里66384个节点号，就代表了该分区一共可以放66384个文件。 所以上图可以反推出磁盘空间大小：所以4096单位是B字节，一般block size就是4KB的大小。 话说回来，虽然块很多，但不代表所有的空间都能真正用起来。 如果你也分100G的空间，那么5G是保留下来的。这个5%是默认的行为。 5G是干嘛用的呢？是给root用的，留给0 ID的人用，防止非root用户把磁盘空间占满导致root没有空间了，改个文件，加个字节都加不进去。保证了运维人员的可维护空间。 5%的预留不一定合理，如果10T的空间，500G的预留就很夸张了。可以调节百分比，支持0.1%。 superBlock超级块还记录了分组情况，只是上面的tune2fs -l /dev/sda1命令还看不出来。 换个命令可以 0 - 8 共9个groups 如果superBlocks坏了，文件系统就完了（因为分组分到哪都不知道了，属性也没了！）。 所以superBlocks需要备份，实际上也有备份 superBlocks备份了好几个地方：32768\\98304\\163840\\229376这四个地方都有备份。 所以利用超级块是可以修复出故障的文件系统的。 比如掉电、软件故障造成文件系统的元数据破坏，实际上是可以修复的，因为有备份的。 貌似是奇数有超级块的备份，偶数没有。但是这不是统一的规律，去看看别的。 dumpe2fs /dev/sda3 |less 分页看下 到group9，后面就没了。就是备份那么多就够了，不需要太多。 ------------------------------- 块位图blockBitmap 就是blocks，一个group里有32768个blocks，总共也有很多个块。 将来使用的时候 存放文件的时候 就需要挑出空闲块出来给到文件存放用。 所谓位图就是1bit1bit的图，0表示对应的block为空，1表示对应的block已使用。将来文件用的时候，就找出位图为0的block给它用就行了 这就是整个ext2为例的文件结构，其他相同的，差不多。 xfs的结构不太一样 meta-data 元数据区 data 数据区 naming 是啥？ log 日志区 realtime 实时区 isize=512是节点inode size，和上面ext4不一样（ext4是256B），这里大小是512B。 sectsz 扇区512B bsize块大小也是4KB log 也有日志功能，日志也有块大小 数据的realtime实时空间，每创建文件的时候，先把数据放到实时空间，等写完了，再放到真正空间中。 xfs查看的方法 xfs_info: /dev/sda is not a mounted XFS filesystem 👈需要挂载后才能查看 [root@centos7 ~]# xfs_info /dev/sda1 meta-data=/dev/sda1 isize=512 agcount=4, agsize=65536 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0 spinodes=0 data = bsize=4096 blocks=262144, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal bsize=4096 blocks=2560, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 [root@centos7 ~]# -j 等价于-O has_journal等价于直接-t ext3。-O ^has_journal 是删除日志功能 -i，inode和磁盘空间有对应关系，多大空间对应一个inode。一个文件是要消耗一个inode的，而一个文件有要消耗至少一个块，一个块如果是4K，也就是说以一个文件要消耗至少4K空间，同时消耗一个inode，而inode又被你对应成了1K，也就是说，此时一个文件要消耗可能4个inode才能对应上，而inode本身又是占空间的，inode之前说了一行一个inode信息消耗256B，所以就造成了空间的浪费，积少成多也是可观的浪费了。 -N 指定分区中创建多少个inode，同样也是摆脱不了-i的默认值的，也就是说你指定的一个值，系统并不会精确到你指定的-N的，而是考虑到-i的大小的。 -I 一个inode占用多少磁盘空间，默认256B -O FEATURE ：ext文件系统了除了2，3和4都是由日志功能的， tune2fs只能看ext系列的superBlock信息，xfs的看不了 一般直接创建ext4就好了，不要创建ext2然后-O FEAUTRE没事找事，除非是已经有一个ext2了，然后再追加一下。注意mke2fs是创建的命令，对于已经格式化成为ext2的硬盘分区，需要使用tune2fs命令来追加。 例子：创建ext2 块大小1024B、预留0.1%、inode大小128B、卷标/mnt/sda6 👆上图bolck size是1024B字节，一共是1048576个块，所以这个sda6大小只有1MB。 这个ext2是没有日志的，所以查看下 👇此时sda6的ext2后面就追加了ext3字段。其实ext3就是比ext2多了一个日志功能，此时就是ext3了。 关于acl的功能来源-挂载选项 centos6系统(7除外)后面分的区--不是安装操作系统时分的区，是没有这个Defeault mount options选项的。 某人看到这 就要怼了，“你的沟通有问题，不是没有这个选项，是这个选项的值为none”，所以跟这些人讲话，要小心些，唉~不要碰枪口，除非你比他牛，他就不怼你了，他会反过来将就你，这其实是有问题，客观来讲有一说一，但怼人是不对的(你Y的沟通才有问题，逮着机会怼人你牛逼~操)，这些人的态度两极分化的厉害所以不喜欢他们。不过反过来，你自己要是凶一点(不是让你怼人哦，就是态度明确硬朗、正)，工作上可能会轻松点这倒是事实，一些喜欢借力、甩锅的人就不太愿意和你怼，因为你凶啊，哈哈~。 没有的，可以通过-o acl添加该功能 再查看就有了，此时就可以用FACL了 会加也要会删 补充说明，这里既然是挂载选项，那么就有这个mount -o acl，不过就是centos 6需要这里的两种方式来处理（上面的一种tune2fs，还有这里的mount -o），现在都是7不需要的。 一个分区可以用三个名字来表示它 UUID具有固定唯一性，其他不具备唯一性。 早期都是些卷标，从centos6开始推荐开始写UUID了。 根据UUID查分区名、根据卷标查分区 blkid -U 等价命令 给ext系统加卷标 xfs系统的卷标使用xfs_admin，不过需要先卸载 不带-h就是超级快和group分组全看 dumpe2fs -h /dev/sda7 等价与tune2fs -l /dev/sda7 xfs_info必须要挂载才能看，上文应该有说过了。 # 这个具体看了，centos8和rhel8不同， fsck 可以修复ext和xfs。 [20:41:23 root@localhost ~]#fsck. 👈两下tab补全 fsck.cramfs fsck.ext3 fsck.fat fsck.msdos fsck.xfs fsck.ext2 fsck.ext4 fsck.minix fsck.vfat [20:41:23 root@localhost ~]# 提示可以看到支持修复的文件系统类型，但实际上直接fsck不带后缀更好，因为万一敲错了，反而坏事，不加会自动判断对应的什么系统。 修复xfs文件系统举例 超级块一般多大，在一个分区上都是些描述信息，应该很小，但是具体多少不清楚。 上图的三个选项一个都不用，-f 是修复文件、-d是修复根。 直接xfs_repair /dev/sda3，一定不要挂载的时候修复。 修复后就可以挂载了 但是数据确实丢掉了，看来dd前10M破坏比较严重的，修复估计也就是修复超级块吧，因为有备份，可能也能修复些其他的，具体还需要研究下。 例子2，修复ext文件系统 bad magic number， 超级块没了已经 取消挂载 修复 输入 -y就行了，自动帮你输入yes 修复后挂载，看下空间大小 如果破坏的不是太严重，可以修复一些数据回来的，备份的都是元数据、分区信息、超级块之类的，用户数据是不会备份的。 这是二次破坏！👇 使用一个磁盘空间的3步骤： 以上就讲解了 1、分区；2、创建文件系统、3下面就要讲挂载了。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-01-09 17:07:19 "},"12-磁盘存储和文件系统/5-文件系统挂载.html":{"url":"12-磁盘存储和文件系统/5-文件系统挂载.html","title":"第5节 文件系统挂载","keywords":"","body":"第5节. 文件系统挂载 挂载的理解 一些相关信息梳理 sda是硬盘，123是分区号。 1、硬盘格式化也就是创建了文件系统xfs\\ext4之类的之后，就需要挂载了，这里的挂载应该是带着各自独立的文件系统和VFS打交道了吧，反正硬盘空间还需要挂载到文件系统上， 2、/dev/sda1挂载到了/根上后，根下的所有当前存在的文件会在/dev/sda1里看到么？我们知道安装系统的时候根是挂载到剩余分区 https://www.linuxidc.com/Linux/2019-04/158216.htm 10.4.2.95的前2个盘位各装2块固态硬盘做RAID1，最小化安装CentOS7.9，分区biosboot 2M , /boot 500M,剩余分区/ 。 一旦把sda2设备挂载到data后，后续在data里创建的文件都会出现在sda2中。 1、一开始是sda2挂载到data里，并创建了一个/dir/f2.txt文件 2、然后再将dir挂载到sda3里，这个时候进到dir文件夹实际上就是看到的是sda3分区， 之前的f2.txt文件还在sda2分区里，所以现在挂载到sda3下了，所以就看不到f2.txt文件了。 如果再将sda2挂载到/home目录下后，就又可以通过/home看到f2.txt文件了（看到个屁，看不到的哦，想想就不对，做了实验也一样看不到的），而且还看到dir文件夹，一旦进入该文件夹，就等于进入了sda3分区。所以从/home也是可以一路顺下来到dir里的。同样\"/根下面的放的都是一级目录\" 说的就是这个道理，因为很多一级目录都是自己另立门户的。 一种理论上的循环挂载 sda2挂载到/home文件夹，sda3挂载到home下的wang文件夹，sda1挂载到wang下的dir 这样，进入到/home就看到sda2里的wang，进入wang，就看到sda3上的dir，然后dir再挂载到sda1，于是进入dir就看到了sda1上的/home，如此就完成了理论上的循环，linux不允许，windows时可以实现这个效果的。 就是D盘挂D:\\test文件夹，然后循环点击效果看看 右键更改挂载点 继续点，层级还会增加 数一下多个层 复制到linux里然后grep一下 31个层级就是循环挂载后的 套娃上限。 挂载操作 umount 直接跟设备就行了 这种挂载重启后就丢了 挂载选项-只读挂载 此时就👇 重新挂载成rw读写，没必要unmount 在mount，可以用命令mount -o remount,rw ，它不是真的取消挂载。效果上是重新挂载，但并不是取消挂载的。 来了，一般分区可以取消挂载unmount再mount挂载，而/根不能unmount。 根/ 不支持unmount，但是可以remount。 因为/根要是取消了，/proc这些内存中的东西不也都是在/根下面嘛，如果根取消，那么内存的东西也就没有FS支持，也就看不到了，也许当前操作界面都没了。 此时重点来了，如果/根要修改挂载属性，就得用remount命令，所以remount可不是真正意义上的先unmount在mount。 和挂载密切相关的文件mtab 该文件就是显示的当前挂载情况 这个文件貌似/etc/下面的，而/etc/下面一般是配置文件，一般莱昂配置文件固定不动得，但是该文件确实实时和当前的挂载信息保持一致的，通过ll /etc/mount可见其实是proc内存文件里的软连接👇--这话不对，centos7上是软连接，而centos6上就是普通文件 mtab是实时挂载信息文件，而fstab是实现自动挂载autofs的配置文件？没错吧，错了，fstab何autofs服务并无关系。fstab是独立的系统加载的挂载文件，autofs是个独立的自动挂载的软件需要安装的,autofs和/misc这个神奇文件夹有关系。 挂载推荐使用UUID设备名来挂载 起个卷标 此时可以通过卷标来挂载 上图注意-L /mnt/sdb1是起的个卷标名 故意和文件夹/mnt/sdb1同名的。 使用UUID挂载 写到配置文件需要使用UUID，即时性的cli还是不会写UUID，而是写名字就行了。 伪文件系统 上图其实是共享内存等内存信息。 这些不用管，都是自动挂载。 一个设备能否挂载到不同的文件夹(挂载点) 可以，将已经挂载的sda7，再次同时挂载到dir1和dir2文件夹下，此时dir1下创建的文件，dir2同样可见。 但是一个挂载点也就是文件夹，只能同时挂载一个设备, 助记来了：一个文件夹只能挂一个硬件设备；一个硬件设备可以挂多个文件夹；好比一个房间可以有多扇门，一个门他不能属于多个房间，对吧，别抬杠~ 存在分区被顶掉和被顶掉的回来的这个一个逻辑。 注意上面几张图是连起来的，中间没有任何其他操作，所以此时/dev/sda7不仅仅挂到了/mnt/dir1上，还同时挂载/mnt/dir2上呢。 被隐藏的文件 ①本来/mnt/dir1/sda7/sda7.txt是存放在/dev/sda7分区的，②现在将/mnt/dir1/sda7文件夹挂载设备/dev/sda1。此时/mnt/dir1/sda7文件夹下面显示的就是/dev/sda1分区的内容，所以原来的sda7.txt不可见。理解思路，相当于只要你进到/mnt/dir1/sda7想看sda7.txt文件时不可能的，因为一进来就到了另一个分区了。 该文件就永远无法访问，除非取消挂载一次，恢复到前一次的挂载。所以当前该文件就变成了无法访问，但是又占着磁盘空间，于是就成了垃圾文件了。呵呵不一定，也许人家就是要这样的私密文件呢，哈哈 方法论：挂载点也就是文件夹，一定要是个干净的空文件夹▲ 这里有个问题，你不图形化，后面不能一下子记住，还是会忘记。 要找一个生活中的场景：有了，房子有多扇门，多个门能进入同一个房子，但是一扇门不能进入2间房子。房子就是设备\\分区-用来存放东西，门就是挂载点文件夹-只是个入口。 其他挂载选项 一般不用写挂载的文件系统类型，mount会自动判断分区设备的文件系统类型，会自动补上-t vsftype选项的 这个时候写不如不写，就和上一节的fsck修复文件系统会自动发现是什么格式的。▲ 上一节竟然将重要索引字段写在了图片里，不利于搜索，以后图片上面尽量别写字。 默认就是可读可写的，所以一般也不用加这些选项。 加上-n选项就不会自动更新了 实际上确实挂上了，但是mnt里没有，所以df 也看不到 这个可以理解成隐藏挂载 mount、df都看不到 有个地方全都看得到，就是内存里，但是centos7下没有这个-n功能，因为7里面的/etc/mnt就是/proc/mounts内容，所以你-n在centos7下没有意义。哈哈 -a 和fstab有关，后面再说 一般是设备往文件夹上挂载，还支持 文件夹 往文件夹上挂， mount -B /boot /mnt/boot 要求文件夹得是个块设备 解决了硬连接不支持文件夹的问题。莫名其妙的，用软连接不行吗。 也支持 文件 往文件夹上挂 要求文件必须符合一定的文件系统要求 前面都是针对分区做格式化 也就是做成ext4\\xfs之类的，现在找一个大文件来弄 1、生成一个文件/data/disk 2、针对该文件创建文件系统 直接查看确实有的 这个disk文件上面就有了文件系统，既然有文件系统，就可以和分区一样挂载到文件夹里 挂上后的显示效果不太符合预期 PS：在系统中，本身挂载时不允许 一个非设备(分区自然算设备的)往文件夹上挂的。现在时文件往文件夹上挂，就分配了一个loop0环回设备，用loop0设备和文件关联，然后再用loop0设备往文件夹上挂载，这样就间接实现了文件往文件夹上挂载的结果。这一点在centos6上需要手动加选项来实现loop设备的分配 然后再看下centos6上面的情况 centos6直接显示的就是/data/disk2文件，而不是loop设备。7是不需要手动指定，显示的是loop设备。 可以通过losetup -a查看分配的到底是loop几？ loop的个数，centos6最多支持8个文件挂载，7没有这个限制 centos7是自动生成的。/dev/loop0就是自动生成的 如果centos6的loop设备消耗光了，也有办法，mknod自己创建就行 7 100是设备编号类型 b是块设备 上面是命令手动添加，可以修改内核实现开机即得 重启就会得到100loop设备，centos7用不着这样 进一步 实现人工指定loop几，而不是自动分配， 题外话，我不知道为啥老师要讲这么久loop，有毛用啊？ 上面重启过了，所以之前mount的应该丢了，就不需要unmount了 上图报错，排查下,loop写错了是66不是6 拷点文件过来 然后unmount后复制到其他机器，去挂载查看文件 然后到192.168.37.7上去 告诉你了，上面有ext4的文件系统 相当于U盘了，不过要这么麻烦么，直接复制不香吗？哦，具有一定的隐藏效果，别人打不开这个/data/disk2，也不知道怎么看，你一挂载就可以看了。 mount 选项复习 通过tun2efs -l /dev/sdb1看下当前分区有没有支持默认acl的挂载功能 挂载后，复制文件过去 可见centos6默认是不支持facl的 两种方法上一节也讲过，①就是修改文件系统的挂载属性，②就是这里的mount -o带上acl 取消acl的也是用mount -o remount,noacl /mnt/sdb1 这个和fstab有关，稍后再说 这是，设备(分区)里面的执行文件能否执行。 这个厉害的，挂U盘的时候，▲如果U盘里放一个带有suid的vim二进制执行文件，然后拷进去，这样就很危险了，相当于继承了管理员权限了。 此时考虑安全，所以挂载U盘都是就要mount -o nosuid 其他： 同步，就是立即写磁盘，内存改了磁盘也改了。异步就是放到缓冲区里等会再写到磁盘里。 异步 速度快，因为对于程序来讲 放到缓冲区里就算存储就结束了。这时候如果掉电就GG了 同步 更可靠些，速度慢点。 mount 后面的选项啥也不跟就等于： 以上都是临时性挂载，稍后介绍持久性挂载。 fdisk gdisk parted partx partprobe e2fsck e2label blkid dumpe2fs mkfs.xxx mkfs mke2fs mknod tune2fs xfs_info xfs_repair losetup findmnt uuidgen Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-01-09 17:45:51 "},"12-磁盘存储和文件系统/6-持久挂载实战故障排错和swap空间管理.html":{"url":"12-磁盘存储和文件系统/6-持久挂载实战故障排错和swap空间管理.html","title":"第6节 持久挂载实战故障排错和swap空间管理","keywords":"","body":"第6节. 持久挂载实战故障排错和swap空间管理 如果是别的终端，或者是别的app使用了该分区，就同样无法unmount wall 广播通知功能，也只能通知到登入用户，那些不登入的应用是无法收到wall通知的。 wall没啥用 通过fuser -km /mnt/sda7杀掉所有占用该文件夹的进程 1、通过fuser -v 判断文件夹是否被占用，这虽然是说unmount的前提，但实际上判断文件夹是否被使用 本身就是一个独立的动作，不要和unmount强相关。 2、通过lsof判断文件夹是否被占用 如何判断一个文件夹是一个普通文件夹还是一个挂载了设备的文件夹呢 df 可以看，但是centos6上看的不全--因为挂载的时候可以隐藏的。 通过findmnt /mnt/sda7来查看给文件夹是否为挂载点 而findmnt 的$?的结果也是0表示true--挂载，1表示false--未挂载， 这是脚本方面使用的特点 永久挂载 永久挂载不是自动挂载，autofs才是自动挂载的工具--才是神奇的文件夹/misc 下图可见/etc/fstab是安装操作系统的时候生成的，因为anaconda就是安装系统项目的程序名-应该是应答文件吧。 查看fstab来自于哪个包，再看下该包里有一些其他什么文件 可见setup包都是必装的基础文件 man 5 章可见具体帮助信息 UUID=字段是设备名，还可以用LABEL=\"XXX\"或/dev/xxx来替换，不过一般还是UUID，因为字段稳定不变。 第二列是挂载点，也就是文件夹 第三列是文件系统 要注意必须和设备分区自身的文件系统匹配 第四列 defaults是挂载选项，前面讲过 mount -o ro,acl,nodev,等等，不写也是有很多默认值的，上一章有讲。 最后两列 0 0，在centos7上意义不大，在centos6上有用 倒数第二列是备份频率，需要专门的备份工具配合的 备份工具是专门备份整个分区的，类似于dump，然后这里会记录下来 这种备份工具用的少，更多的还是tar打包文件夹 没必要对整个分区进行备份。 1就是dump了一次，0就是没有备份分区，因为没啥用，所以centos7上都是0了 最后一列 是文件系统的检测顺序，开机的时候会用fsck.工具来检查，因为centos7上都是xfs，所以也不用了。 举例centos6上 先blkid看下设备分区，将/dev/sdb1挂载到/mnt/sdb1文件夹 然后编辑/etc/fstab文件 写/dev/sdb1设备名不推荐这里实验无所谓了 acl,noexec写出来的就是人工设置的，没写的就是按defaults里面默认的一些选项，有冲突的还是按前面写出来的设定。这里算是mount -o和tun2fs -o 一共3个挂载选项修改点了▲ 要是fstab文件生效，就需要mount -a重读此文件 然后验证下noexec挂载选项的效果 删掉noexec就vim /etc/fstab里面删掉noexec就行了 上图去掉noexec后，mount -a 想去掉noexec选项，是不好使的👇 mount -a什么时候好使，不得好死~哈哈，人求得好死是吧，mount -a是原来没挂过，然后mount -a就会是选项acl,noexec生效，但是原来挂过，再修改选项就不会生效。 unmount 再mount -a就好了，更好一点得就是使用remount ，也会自动读取/etc/fstab里得配置的 此时就可以执行了 演示以下fstab 设备名不存在的情况 上图👆注意上图的 最后一行0 3，是要做文件系统检查的 上图可见，fsck 做文件系统检查了就出问题了因为没有这个UUID。 ctrol + d还是重启，没用 输入root口令进去 发现只挂载了个根/ vim 进去 搞定开机OK 但是存盘发现写不进去 发现目前就是只读状态，不仅仅是/etc/fstab写不进去，整个根/都写不进去 mount看下 👆确实写的是rw可读可写--但是有warring告警，但是实际结果就是只读的。 重新挂载一下根/ 此时，再去vim /etc/fstab修改最后一列为0，wr就可以保存了 此时就可以正常启动了，不用reboot，直接切换到5模式(图形界面)就行了。 进入系统后，修改正确的UUID就行。这里顺便测试一下LABEL卷标的效果， 然后mount -a就行了 所以/etc/fstab最后两列还是写成0 0 吧，别做检查了就，能不能挂上去再说，先把系统启动起来。▲ 对于centos7不存在这类问题 拿sda6做实验，重新格式化为xfs，为啥要重新格式花，ext2不行吗？不懂 此时就得到了一个xfs格式的sda6 然后取出UUID字段，保持格式上同就行了 修改后保存 确保挂载点存在 如果存在会提示不能创建的，就像这样 [11:20:23 root@localhost ~]#mkdir /root mkdir: cannot create directory ‘/root’: File exists 可见挂载成功， 故意写错fstab里sda6的UUID，重启看能否重启成功？ 上图说要等1min 30s，还是起不来的，又到了和centos6一样的界面 同样通过root口令进去 因为：👇 mount看下就是rw可读可写的，也没有告警提示。所以就可以rw的。 然后直接启动就行了 SWAP df里看不到swap，但是lsblk里可以看到 一般linux服务器上用也不会休眠 如何新建SWAP分区， SWAP是分区，分区时无法扩容的，所以只能新增一个SWAP分区，两个加起来用 SWAP模拟内存，硬盘应该放在磁盘的外圈，所以下图的磁盘，SWAP分区应该放在哪？ 新的SWAP是创建到sda8还是创建到sdb上？答：创建到新硬盘sdb上好，因为新硬盘还没有分区，新分区时从外圈开始划的。 通过fdisk -l 看下swap的编号时82 开始分区 w后没有告警，所以连同步都不用做了。 可见👆多了个新的硬盘分区 分区以前都是mkfs.xxx但是tab补出来可以看到不支持swap类型的 得用mkswap来创建swap分区 创建之前通过blkid /dev/sdb1看下现在是：没有文件系统的--虽然显示了个dos。 mkswap /dev/sdb1，可见👇一些告警：说没有删除一些引导扇区标记，就是保留了硬盘之前的信息，不用管。 此时就可以看到文件系统为swap了 之前分区的时候使用的时默认从sdb硬盘的2048字节开始分的， 这就是swap之前的信息，前面几行到55aa是MBR分区表，后买面是加的SWAP分区的信息。然后SWAP是空的，所以很多都是00。 这块遗忘了就搜一下大概情况如下 然后就是挂载--且是持续挂载： 两个swap，挂载点是swap，文件系统也是swap mount -a 对于swap是不起作用的 此时内存文件中看swap只有sda5没有sdb1呢 使用swapon -a 读取/etc/fstab里的记录是swap生效 等价命令swap -s 和 cat /proc/swap 然后两个设备sda5和sdb1都能放swap的数据，但是sdb1是外圈磁盘，所以速度更快些，所以希望调整一下优先级。 测试一下看下当前哪块分区优先 消耗内存的方法▲ dd往null里写数据，一个bs就是2G，而此时内存空闲只有1G不到，所以肯定会用到swap，此时看谁优先。 此时就很慢，理论上这个命令dd if=/dev/zero of=/dev/null 都是在内存里处理的，都是内存往内存里扔数据，应该很快的，但是现在很慢，是因为内存空间不够，用到了swap也就是硬盘，所以就慢了。 👆而且可见优先级是-2优于-3的，大的优先咯。上下图片都可见用了448M了。 之前修改fstab 然后mount -a是不会对修改某个选项生效的--要么是一行都没有的新挂载的情况才会mount -a生效，此时swapon -a同样不会生效 swap的生效方法如下： swapoff xxx禁用 然后再启用就行 再来测试swap的优先级 可见swap里的sdb1优先得到使用。 一些不规范的操作，举例-由于开始分区没有规划swap，没地方放swap了，只能拿文件来补一个。 看下当前根/的空间利用率比较低，所以将来做swap的文件就放在/下 格式化 blkid看不到没关系，加上文件名/swapfile去查看下，再直接用blkid此时就能看到了 同样写UUID到/etc/fstab实现持续挂载，这里要注意了针对文件作为swap的不能用UUID，这里先用UUID演示看下问题出在哪里。 swapon -a 读fstab进行 挂载，此时swap就多了一个/swapfile 文件实现的swap了。 644就谁都能看这个数据，内存数据建议600 重启后发现： 文件作为swap的丢了，要写设备名也就是文件 重启后再看 swap除了建议放到机械盘的外圈，更加推荐使用固态盘。 有人说现在用不到swap，蓝鲸的平台base和扩展，你看看内存要多大，swap好歹能图个安心对吧，举例别不服--数据检索：针对56台agent查询了1个月的CPU使用率，然后就OOM了。 检索量太大了导致的，正常情况下，没有这个需求，所以如果swap上来，也能解决这种非常规性业务。 下图是蓝鲸base里的pass平台点，有点奇怪没有swap 不管了，暂时不管它了。 之前的 \"文件夹挂载到文件夹\" 如何写到fstab里 注意，文件夹没有文件系统一说，都是硬盘分区是什么文件格式，所以这里写none就是没有文件系统，然后defaults那里就写bind。 然后 mount -a 再，mount查看 可见已经挂上了 fstab如果持久挂光盘 光盘可以直接写设备名也没问题，写UUID也行。 /etc/fstab里写这一行：光盘的文件格式就是iso9660 fstab挂文件，类似用文件做swap (把衣服挂到钩子上，叫做挂衣服，把文件挂到文件夹上，所以叫做挂文件) 将下图稍作变动就可以实现文件往文件夹上挂载了 /dirName/fileName /mnt/dirName ext4 defeaults 0 0 这样就可以了 fstab还可以挂载网络资源：nfs，samb。后面讲 图形界面会自动挂载光盘 如果是开机进入的是字符命令行界面，就不会自动挂载。 普通用户没有权限挂载 神奇文件夹不管你是普通用户还是root，只要一访问呢/misc文件夹，就能实现自动挂载。 这个神奇文件夹，过一段时间不访问，就会给你取消挂载，一访问再次挂载，其实这个是autofs软件实现的，在《linux就该这么学》中有详细讲，其实很简单，哈哈。 删除swap其实上面已经有了，这里再写一下方面看 1、fstab里删掉 2、swapoff /dev/sdb1 如果是文件swapoff /swapfile 名字无所谓，就是意思一下；swapon -s看下确认下 3、删分区，fdisk--->p ----> d ----> 1 意思意思不要照抄；删文件rm -rf /swapfile 4、partprobe同步下 删掉后，再创建/dev/sdb1的时候blkid里会看到之前的swap类型，无所谓，按部就班就是①分区②格式化，格式化就是mks.xfs /dev/sdb1就可以覆盖掉blkid里的原先数据了，然后再③挂载mount或者swap的话就是swapon -a Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-07-19 14:47:51 "},"12-磁盘存储和文件系统/7-外围设备使用.html":{"url":"12-磁盘存储和文件系统/7-外围设备使用.html","title":"第7节 外围设备使用","keywords":"","body":"第7节. 外围设备使用 案例：home本来是在/下的，现在home越来越大，要迁移到一个新的分区 首先找一个新的硬盘分区 👆这种有提示的，要同步分区表 否则分区sdb2出不来 centos7的同步就一个方法， 然后创建文件系统，并确认 现在就是要将home文件夹挂载/dev/sdb2，要考虑/home下的当前文件，直接挂过去home当前的文件就看不到了--因为现在是挂的/目录关联的设备。这点第5章讲过了。 要把当前的数据迁移过来 数据迁移 要把/home下的文件复制到新的分区，需要中转一下 先用一个临时文件挂一下 确认下文件是否都复制过来了 题外话，复习下： 原/home下的文件可以删除了，否则等你挂载后，这些文件没有入口进去找不着就删不掉了，还得取消挂载从/进入home去删。 使用持久挂载 刚才其实还有一个临时挂载，把/dev/sdb2挂到了/mnt/home下，上图是后挂的覆盖了，mnt可见👇 这里有个问题，原来/home文件夹里的东西被隐藏了，要删掉的，否则一直占着空间。如果前面没有舍得删，这里需要unmount回去删掉的 有个问题，在cp -a /home的时候，文件夹可能有人在用，别人可能在往里写数据。 一般需要把系统处于维护状态--init 1 --单用户模式 进去看下可见是从5 切到 1的 可能有点问题，就是终端那边命令输入有问题， 重启直接进入单用户模式 按任意键 上图输入a， 然后进入下图输入1，进入单用户 单用户模式，就是不联网的，网络都是down的👇 这是建议的维护状态下进行操作；只要别人不能访问就行，比如防火墙deny也可以。 移动设备的使用-光盘-U盘 eject后，光盘就弹出了 弹光驱这件事，有意思在 早期服务器主机都是带光驱，机房里面找机器，可以弹出光驱就能一下子找到了。呵呵~~~现在呢，谈个屁，谈恋爱吧。 eject -t 是弹进去，台式机可以，笔记本不行，VMware Workstation VM虚机更不行了。 把光盘制作成iso文件 这个可以用来挂载iso文件，没光驱，就可以这么玩，挂载iso，一样做yum源。 联系前面的章节： windows里制作ISO是用工具比如这玩意 linxu就一条命令的事： 上图时间较长，你想windows一样要读进度条的，不过你可以ctrl c结束也能看到下面内容，不过数据就不全了。 还一种方法，是把文件夹打包成iso文件 打包成iso 并不会压缩，原来也是这么大差不多 挂载看下 注意这种挂载是read-only，光盘嘛iso就是只读的，不过windows的UltraISO好像可以往里写东西，没用过。 centos6上的一个问题 光盘是3243个包，yum上看到是6713个包，剩下的还有3000+的包在第二张光盘上呢，centos6是两张盘来着。 可以考虑把centos6的两张盘和成一张盘 弄一个大文件夹，然后把两张光盘解压进去攒成一个大文件夹就行，不过这样可能没有引导文件，还需要工具，不过只是做yum源应该没关系吧，安装可能不行。 有个官方脚本\"mkdvdiso.sh\"可以把两个centos6的ISO合成一个iso同时具有启动功能 看下U盘 U盘的系统查到linux上，如果是FAT32可以识别，如果是NTFS就不行了。 wmware workstation 插上U盘后会提示 如果选择主机，那么linux这些虚机识别不聊了，所以选择虚机连接 我们选择主机先看下👇，待会再连到虚机上 把U盘从\"主机连接\" 转到 \"虚机连接\" 👇注意tail -f /var/log/messages监控着： 点击后同时观察后面的messages日志 开始弹出信息：usb xxx 设备名也出来了[sde]。 下面就是和硬盘一样的用法，创建文件夹，挂载 因为是2个分区，所以创建2个文件夹 将来挂载 发现sde1是ntfs的，挂不上去，sde2是vfat的可以 因为linux默认不支持ntfs，所以挂不上去 通过locate xxx查找内核文件可以证明确实不支持，👇没有ntfs文件系统的驱动 👆这是看有无驱动的文件，至于是否加载到内存中了没，还要通过lsmod查看 虽然有vfat.ko文件表示系统支持fat格式，但是并没有加载到内存中👇 因为已经mount在用了，所以系统就给你加载内存里面 fat文件系统虽然在linux里支持挂载，但是有问题的，umask貌似没有起作用 完全改不了 改所有者、所属组也不允许 说明fat文件系统的功能太少，连基本的权限rwx和所有者、所属组都不支持。 还有一个fat文件系统不区分大小写👇 这里就可以说这么一句话:linux区分大小写这种说法不准确，显然上图的linux系统存在不区分大小写的情况，所以讲 区分大小写 它是文件系统的事情，linux一般xfs或者ext这两个区分大小写，如果非要用linux也支持的fat文件系统(fat本身不支持权限umask和所有者\\组)--此时就表现出不区分大小写了。 👇下图人家df定义了别名，所以\\df来使用原来的命令，注意原来的df就是以block块为单位的，1个block就是1KB字节。 -h 是human人类可读性好的选项 -h是以2^xx 也就是1024算的 -H 是10^ 也就是1000算的 -T 显示文件系统 -i inode节点使用情况 -P 是格式化好看些的意思 centos7是优化过了，看看centos6就知道了 这个错位，cut就不能取了啊，要注意。加个-P 就解决了 厉害厉害，上图--skip-alias 细节啊， 所以说7就不需要-P了，因为7上的df的rpm包版本更高，6的版本低还需要-P 查看文件夹大小 du 不带选项，就是/boot目录下，每个子目录的占用空间，单位是KB；最后一行/boot是汇总信息。 这个du看到的和df看到的不太一致 du 算的空间是目录数据本身站的空间，而元数据是不算在内的，还有日志、实时运行区？一些额外的东西。 dd count=0就是数据为0咯，但是会产生元数据的，所以多少会有点空间占用的👇 不过多了点元数据 上图最后一行的命令解释：seek是跳过10个bs，也就是10G开始写数据，结果写0个bs。所以前面0-10G的数据为空。也就是有头有尾，中间没东西。 跳过的也占空间的👆 毛的元数据，说好的一点点呢，啥也不占啊， 应该还是有一点点，文件元数据确实有的啊。但是没看到也是奇了怪了，不管了，反正文件ll都看到肯定元数据占用跑不了的。superblock也在分区上的啊。可能du就看不到元数据的空间占用情况。 回到这种10G大小确一点空间不占的问题上来，图①，下面要引用对比 这种文件称之为 稀疏文件--有头有尾，中间时空的。与之相反的是稠密文件。 这个文件将来学虚拟化有用的，提前接触下这个东西。 显示上都是0，要要注意前面空的虽然也用0表示，但实际上没有数据，然后 后面的1G确实写了数据--0。元数据里加了标记，从哪到哪加了标记没用 是空的 硬盘上没有数据的；后面1G真正的写了0的是有数据的。 ▲所以恶心的事情来了，上图是有1G数据的，和上面的\"图①\"是不同的，图①里的是一个数据都没有的。貌似没法区分咯，，，⚪？ du 可以指定深度 除了/boot本身，再深入2级👇 文件大小空间ls -l f看的不对了就，du可以看的准确点。 du看的是真正的占用空间，而ll看的不是，有点像是真实或者预定规划的空间。 ibs和obs是读和写的块大小各自定义，不像bs统一的。 👆表达了，文件系统的最小存储单位是4K，所以即使你文件只有3个字节Byte，占用空间也是4KB。然后注意以下bs=1说的也是块，不过这个块大小上图设定的是1Byte，加上count=3就是3Bytes。▲块这个词真的是到处乱用。对，我理解不好的，都是词名称起的不好，希望内向的同学多一点这样的观点。 空文件不会分配空间👇 空文件不分配空间，现在不需要空间，只需要元数据就行。而元数据的空间占用 看来并不是通过du查看的。▲ 一个换行也会占用一个文件系统的最小存储单元4K👇 所以，如果都是小文件，就会浪费磁盘空间了，这个小就是相对于文件系统的存储单元来讲的。所以文件系统创建的时候 可以指定块大小的：mks -b。 准备两个文件 请问最终效果是啥，结果是： 默认行为就是，从f1.txt取数据写到f2.txt的时候，默认f2.txt多出来的就截断了。 可以修改这个默认行为，使之不截断，这里使用了我讨厌的之乎者也的之，因为书写简洁。 👆这样就f2.txt多出来的就不截断了。不管截不截断，它都是覆盖的写法，不存在插入哈，插入那是insert键盘的效果哈哈~这里是往固定位写数据肯定会覆盖的。 还有转换大小写可还行，可还行--网络用语，在永生里小郡主说出来就很可爱。 还可以目标存在就覆盖，不存在就不创建 👇这个469MB/s是先放到缓冲区里的速度，它这个是先把2G的数据写到缓冲区，再写到硬盘里。 然后有个参数就是直接写硬盘的，就是命令结束前，先写到磁盘上，然后出统计结果比如时间啊、速度啊。 👆这就是真实写入磁盘的速度了，▲这个也是基本思维咯，写数据往往写的都是内存。能给你一个写到磁盘的统计--这里是统计，或给你一个写到立即写到磁盘的开关nginx还是mysql里有这东西的，也是阔以的，否则我就不知道怎么保证立刻写入磁盘--其实应该不必担心，一般都是非常快同步的，少数比如分区划分需要同步到磁盘。 就是从if=xxx中读取100个字节，但是xxx中只有90个字节，所以剩下的10个字节用NUL补齐。懂了没榆木脑袋SYM。非要顺一遍才能理解。 复习下： dd工具其实就是相当于windows里的ghost工具 有个问题，文件备份一般tar一下对吧，那这里的dd又是否合适呢，显然dd覆盖面会广，占用空间会多。然后网上有一些cp dd tar cpio dump来备份的比较说明。 网上的一些信息：就是说类似dump去做增量级别的备份 https://blog.csdn.net/ether_lai/article/details/12656219 把内存里的数据进行备份，内存修改软件--改游戏角色属性的好像有这个东西。 制作iso镜像，除了这里的dd，通常cp一条命令就行了--上一章有讲。 销毁磁盘用dd，还能找回吗？⚪多写几次unrandom随机数进去，即使硬盘支持几次数据找回应该也没办法了。 练习 RAID 避免单点故障，单块磁盘损坏。 原来随着技术演变或者说应用场景的演变、需求的演变，原来的东西的名字也是会改的。 现在主板上都自带raid卡的--内接式。 游戏笔记本做软RAID提升性能？ Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-07-20 11:29:58 "},"12-磁盘存储和文件系统/8-raid工作原理.html":{"url":"12-磁盘存储和文件系统/8-raid工作原理.html","title":"第8节 raid工作原理","keywords":"","body":"第8节. raid工作原理 RAID0的空间大小计算： 取成员最小值*磁盘块数； raid是物理上实现的，所以对于OS来讲，分区还是像以前一样，挂在300G上的连续空间的单块硬盘上。 ①以上就说明了总容量大了 ②下面是数据切片后成条带方式存储在成员磁盘上的。而切片的单元叫做chrunk。它这个3块磁盘同时读写就提高了IO速度。 ③RAID0，单单一个RAID0一般工作中不用，家里可能用的。 图中100M的数据切成多个512K，这是举例假设，不一定是512K。 RAID1 1、RAID的硬盘冗余，是针对硬盘损坏的冗余备份，如果上图RAID1你删掉文件，就删掉了，disk1作为备盘，你操作disk0上的数据，删掉其上的f1文件，disk1上作为备份也会删掉的。而raid1，如果坏了一块盘，会导致磁盘IO飙高的吧？还是你拔出坏的，插入新的才会IO堵塞⚪。不查比较合理吧，否则会同步数据IO就高了，它又不像raid5坏一块就开始算故障盘的数据。同样raid5坏一块读写效率下降，新盘顶上来IO肯定要东西向恢复数据，所以IO也是会高的，留给业务的IO就少了。 2、RAID1叫镜像，RAID0叫条带。 RAID4 raid2 3 4 都是消失的技术，不过4具有典型代表，所以了解一下 ①上图是在说raid4，100M数据存放的规律，条带+校验位(异或校验得到的) ②如果条带中某个数据块的磁盘损坏了，是可以算回来的👇 ③raid4的至少3块硬盘(n≥3)；空间利用率是(n-1)/n。牺牲一块硬盘的空间来实现一定的容错性，容错也只能坏1块。 ④raid4淘汰的原因，是校验盘的压力比较大，损坏几率较高。谁当校验盘谁老坏，这个位置不养盘啊，哈哈就想有的工作不养人一样，教师这个行当是养人的，有利于身心健康的保持。 为了解决raid4的缺陷产生了raid5 raid5 ①和raid4类似，但是校验位是分散在每块盘上的，还是条带+校验 一行。分散带来的好处是--原来raid4的时候数据较多就会频繁访问校验盘，校验盘压力大。 ②如果坏了一块硬盘，再插上新的，就会发现此时由于要算新磁盘上的数据，性能下降的非常明显。此时属于降级设备不是正常的raid5了，如果业务反满磁盘IO本来就高的情况下，坏了一块 导致降级，此时就惨了因为👇会计算故障盘数据的，会导致本来脆弱的磁盘即使是好的还能再坏1块~哈哈。 为什么RAID5系统的磁盘组降级情况下，读写效率会下降：因为磁盘每时每刻都在进行数据的写入，当有一块硬盘发生故障RAID会一直在根据剩余每块成员盘的校验码和数据来计算出故障盘内的数据，这样才能使整体数据不会丢失，也导致硬盘在读写的情况下多了一项计算，所以整体上硬盘的读写效率就会下降。 https://forum.huawei.com/enterprise/zh/thread-351133-1-1.html https://cloud.tencent.com/developer/article/1828247 ③spare disk应该说的是热备盘吧 raid6 ①比raid5多了1个校验 ②利用率(n-2)/n;n≥4 ③以前压缩文件bz zip，是用cpu的损耗--假如你是crontab这种持续性的压缩打包任务，来换磁盘的空间节约。现在就是用磁盘空间来换数据的安全。反正都是要换，要么你用身体换钱，要么要钱换身体，唉，唉~我竟然不知觉的情况下开车了。我说的是工作久坐等一些不好的情况。 raid-10 not十而是壹零 解释为什么raid01不好，首先jd上的产品就告诉你raid01不好了👇都不支持，没市场： 原因： raid-10，坏1块盘 后，再坏一个块盘导致整体不可用的几率小于raid-01，下图说明👇 disk0坏了，剩下的3块中disk1坏了就整体不可用了，其他disk2坏或者disk3坏都不会影响整体，整体不可用几率是1/3。 disk0坏了，剩下的3块中disk2或disk3坏了就整体不可用了(因为是raid0坏一块就右边整体不可用了)，整体不可用几率是2/3。 ▲所以raid-01的容错性较raid-10的差。 0这种东西就是提高IO速度的，与冗余无关，5、6就是冗余+速度、1纯冗余 速度一点点。 jbod就是写完一块，写第二块就是整合一下多个块当1块用。比raid0节约些。 raid7 了解下软RAID 想用百度吧，没啥意义应该。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-07-20 14:22:10 "},"12-磁盘存储和文件系统/9-LVM管理详解.html":{"url":"12-磁盘存储和文件系统/9-LVM管理详解.html","title":"第9节 LVM管理详解","keywords":"","body":"第9节. LVM管理详解 1、创建管理 分区一旦划分好，就没法扩了。而LVM就能扩和缩 操作的时候LVM的底层可能就是以部署raid为主，当然也可以是多块硬盘和分区。 10块组成raid10，OS看到的就是sda一块盘，以前就直接sda上分区，一旦分区就固定了，分区不够用也不能扩(不能扩的原因是，要删除分区后再重新划分和格式化，这样原来的数据就没了，所以才说不能扩，把数据移走，不就行了，不就可以扩了，蛋疼，一般来讲说的是软件应用在使用着这个分区，所以生产环境你没法，而LVM可以支持在线就是热扩，哎~，我发明词汇热扩，反正天下名词各种飘，我也来冒一个，增加读者的难度，对吧 呵呵 悲哀)，所以就再sda上做LVM来管理，如何管，假设一组raid10得到sda，还有一组sdb、再来一个sdc1分区，这些raid也好、硬盘也好、分区也好，都是linux Block Devices。这些块设备大小不限，无所谓。 把这些块设备第一步通过pvcreate变成Physical Volumes物理卷，所以物理卷就是打上标签--意思就是这些块设备不作为独立硬盘用，将来要做逻辑卷的。 有几个块设备(硬盘或分区)就生成几个物理卷，就是打标签吗，原来设备叫啥名，生成后还叫啥名。 然后通过vgcreate将物理卷们 组成一个大的集合 也就是卷组。此时卷组就是一个大的硬盘咯。 然后通过lvcreate将卷组 分成一个个 逻辑卷出来。 逻辑卷不关心上面的数据存放在哪块物理设备上， 逻辑卷的地位就是分区了，该创建文件系统就创建文件系统，该挂载就挂载。 如果LVM1 500G ，LVM2 200G，下面的卷组是1T，将来LVM1满了不够用了，还可以在线扩展到800G。所谓在线就是用户无感--使用不受影响，无需取消挂载，直接在线挂载的状态下，一条命令就挂上去了。 如果lvm1 800G也满了，怎么办，可以再底层块设备上再加入新的硬盘。这一套还是在线扩展吗？⚪ 所以linux默认安装的时候默认就是逻辑卷。 逻辑卷的概念了解后，还有一个PE，叫物理盘区physical Extent。在创建卷组的时候要指定PE，假设PE是16M，卷组就会显示有多少个PE，创建LVM逻辑卷的时候可以从这么多个PE中取出多少个PE来作为逻辑卷。扩展的时候也可以增加多少个PE。PE就是分配的最小单元了。 到现在已经是LVM2代了，LVM2。 在IBM AIX系统unix小型机，就只用LVM，不用分区。 LVM要建立在raid之上，硬盘坏了有冗余。①担心LVM多了一层逻辑层，硬盘坏了导致整个卷组出问题②多一层逻辑层，不是直接面对硬盘，性能是否不好。据说2点担心都是多余的。反正很多企业在用，也有企业不用。 学完再来这里补充发表自己的观点，和网上搜一下。 下面开操作 第一步 准备好块设备 要注意修改分区的ID为8e 存盘退出 同步下 第一步，物理卷的生成-pvcreate x y z\\pvs\\pvdisplay pvs查看下，当前pv是空的 把上面的一个分区、一个硬盘变成物理卷 👆因为sdb1之前做个swap，所以有标记位，所以先dd清空前10M就能覆盖到了。也可以直接敲y就wipe一样也擦掉了。 然后再pvcreate /dev/sdb1 /dev/sdd也可以合起来些。 这样pvs和pvdisplay就能看到了 pvs就是summary概况，其中lvm2就是逻辑卷2代；VG列是空 表示卷组没组建呢还。 pvdisplay同样可见VG是空；PE Size也是0 这个只有创建VG的时候指定才会出现。 第二步 vgcreate创建卷组 vg开头的也是一大堆命令 同样有vgs和vgdisplay，然后pvdisplay肯定也能看VG和PE也就是vgcreate后的信息。 使用帮助看下 -s 指定PE的大小 pe--physical extent size 上图忘记加单位了，不过有默认值的pvdisplay可见。 vg整合好后 ①pvs看 PE的默认值也看到了是4MB，上图PE size是4MB，total PE 1023就是1023个的意思。总容量也就是4G咯。同样/dev/sdd也就是4MB*2559=10G ②然后通过vgs 和vgdisplay看看 👆vgs可见，vg0这个卷组里有2个PV--物理卷，LV还未划分，大小是两个PV的总和14g的样子。 全部PE个数3582个，Alloc PE / Size 0 / 0就是没有分配出去呢--因为逻辑卷lvm还没有分配呢。 由于逻辑卷lvm还没有创建，所以还看不到vg0这个设备 第三步 lvcreate创建lvm lvcreate --help可见用法：从哪个VG--卷组里 通过-L取 多大size ；通过-l 取多少个PE，这是个数 上图有striped和raid1|mirror，这就是raid了，完全可以用lvm再做一层raid，实际上底层物理设备做raid后，上层lvm不会再做raid了。 👆起个名字mysql，-L 直接写大小，-l数个数还要算--不用，从vg0里面划分lvm。 lvs 和 lvdisplay 上图说明： 这个就是完整的设备名，这其实是软连接👇 实际上叫dm-0，还有一个和它一样指向的软连接 所以待会可能看到的是上图这个名字/dev/mapper/vg0-mysql 看下现在的dm设备有几个：如果再创建一个lvm，这里就会多一个dm-1了 上图的Current LE 2048是说的LE的个数。 上图的8G到底用的哪个物理卷，通过pvdisplay可以看到的 可见/dev/sdb1全部空闲就是没有用，所以这个8G都用的/dev/sdd的空间4MB*2048也就是8G。做raid也是不关心具体到底存在那块盘上的，都是当作整体在用的。 2048个PE，在LVM叫LE，就是PE在LVM逻辑卷里的名称。 一旦LVM划分了，blkid就能看到了 现在由于还没有在LVM上创建文件系统呢，sdb1和sdd的UUID肯定是各归各的。[ 所以还看不到一个sdb1和sdd合成一个的情况，其实合成一个情况是blkid是看不清楚那几个合成一个了 ，这个说法不对的，是sdb1和sdd里PV化和VG后再取出PE们来合成的，不是简单的sdb1和sdd直接合成的，之前我想当然的是不好显示的 ] 。只能再下面的格式化看到多出来一个mysql的逻辑卷。而sdb1和sdd是逻辑卷的成员而已，具体是哪个lvm的成员还需要具体去看的。 第四步 mkfs.xfs格式化 这个时候就看到，增加了一个新的记录，mysql这个逻辑卷就有文件系统了。 lsblk是你fdisk后 再 partprobe就可以看到的块设备出来了就 而blkid不一定看到，因为lsblk看到这个块设备后，还需要进一步格式化才能看到的。所以blkid是看带文件系统的块信息的。 第五步 挂载 挂载的时候，要写设备名，可以写这里的/dev/mapper/vg0-mysql可以写当初创建的lvm起的名称/dev/vg0/mysql，这两个都是可以的，因为都是软连接。 上面是临时挂载，永久挂要写fstab 刚才挂过了，所以就行了，reboot也不怕了，正常就是mount -a就行了。 看看性能 上图是不是有点夸张了，逻辑卷能提速这么快的？逻辑卷反正不会比物理分区慢就行了。 上图就是conv=fdatasync就是结果显示的是已经同步到硬盘里的了。上上图的是写到内存里了就显示结果了。 所以lvm + raid，是很好用的。慢也不慢，底层用raid冗余物理设备。 2、管理详解 下面看下逻辑卷的空间扩展 假设这个8G用满了，下面对其进行扩展 这里少了一步看mysql这个lvm到底来自于哪个卷组，其实这里就可以发现人家用vg0-mysql作为自动生成的软连接 来作为设备名 本身就是要告诉你mysql来自于vg0。 逻辑卷扩展 要先看 卷组里有没有空闲空间 可见卷组里还有6G空闲 lvextend -l 小写的l在扩展全部剩下空间就特别好用，可以写-l 1534就是剩下全部的Free PE个数，也可以用上图的+100%free来直接搞定剩下空间的100%。 不需要指定vg卷组，因为mysql这个lvm系统知道从哪个卷组来的，所以无需指定，直接命令就写/dev/vg0/mysql就行。 回车后可见已经扩展到13.99GB共3582个PE。 此时再看vgdisplay可见已经没有剩余了 vg用光了，vg整合的pv自然也就用光了 但是此时确发现df -h 里看到的逻辑卷的空间还没有刷新 注意，这不是没有刷新哦，这是因为 你虽然把lvm扩展了6G，但是这个6G的空间还没有文件系统(还未进行格式化)，不是简单的格式化，而是格式化后并进去，其实确实是一个命令就同步了，也算是笼统的刷新了。 df看到的是文件系统的大小。 现在就是要将扩展的6g空间的文件系统同步到既有的8g空间里去，不是简单的mkfs.xfs哦。 👆可见data blocks 变大了。此时df -T再看文件系统的大小就扩上去了👇 总结下扩展其实就两条命令（在vg卷组有空闲空间的时候） 而用户是无感的，扩展的的时候也没有取消挂载，一直都是挂着的。 再来看看我的centos8的默认就是使用的逻辑卷的 vg没有空闲空间的扩容步骤 此时要扩vg0-mysql，但是vg0已经没空间了怎么办。就再加一块新硬盘。 ①pvcreate 只有分区才要加标签8e，硬盘无需改 pvcreate后再blkid就看到了，就和mkfs.xfs 格式化后就看到了一样，blkid是看带文件系统的块信息的 此时pvs就能看到多了个20g的pv ②vgextend扩展卷组 上图可见现在vg0有两个成员Cur PV 2，再加一个。 vgextend vg0 /dev/sdc 此时卷组就又有空闲空间了，扩展就一样了。还是两条命令的事，可见扩展lvm确实无需取消挂载。 同一个卷组里创建新的逻辑卷 再后面学习中可以把mysql的日志放到专门的逻辑卷或分区中，这里就专门创建一个binlog的lvm ①lvs,lvcreate -n binlog -L 10G vg0 lvdisplay就可以看到有两个lv了 ②mkfs.ext4 /dev/vg0/binlog 格式化逻辑卷为ext4 ③挂载 此处省略了持续挂载fstab的编写，上文有的。 针对binglog逻辑卷扩容，-l +1000个pe 一个pe4MB 此时逻辑卷确实扩展了 由于增加的部分没有格式化，也没有加入进当前的binlog文一个整体，所以 刚才xfs文件系统用的是xfs_growfs /mnt/mysql，现在ext4得用resize2fs /dev/vg0/binlog，前者跟的是挂载点(文件夹)；后者跟的是设备名。注意下 此时就成功了 由于文件系统的不同，最后同步的命令不同，后面跟的部分也不同，所以自动化脚本就有点麻烦，所以有更好的扩展方法来了 不管是xfs还是ext4都一条命令扩 lvextend -r -l +500 /dev/vg0/binlog 翻看前文可知刚才mysql这个lvm是14G，现在扩了500个PE，一个PE是4MB，也就是扩了2G，达到了16G。 上mysql是xfs，下面继续binlog是ext4的也用这一条搞定 一样成功了 此时就发现上面的同步命令白学了？不是 xfs_growfs 挂载点 --- 这个是扩展用的 resize2fs 设备 --- 这个扩展和缩减 都行 lvextend -r -l +500 /dev/vg0/binlog 这个就是扩展lvm的时候自动同步了。 所以resize2fs后面缩减还要用得到。算不上白学~ 其实通过man lvextend可见 其实-r 就是resizefs，哈哈~ 缩减有风险的，如果一不小心写错了--写成缩减到50G，而此时数据就是100G，那么就会造成数据丢失50G~。 以防工作中用，还是要学一下 缩减 缩减上图ext4的这个lvm空间 扩展是在线扩展，缩减必须离线缩减，意味着取消挂载，用户访问受影响了。 ①unmount /mnt/binlog 回想扩展的时候不管是2条命令还是1条命令，底层逻辑都是先扩展lvm，再同步扩展文件系统 现在缩减的时候就是先缩减文件系统，再缩减逻辑卷大小。 缩减前的lvm大小如下15.86G： resize2fs /dev/vg0/binlog 10G # 缩减到10G 注意这个命令①同步的命令(同步的命令其实就是将lvm扩展后的空间，再扩展到文件系统里去，这个场景其实就是不写多少个G就是全部扩展进去，其实你的需求就是lvm扩展后，再同步到文件系统里，自然是全部了)②缩减的命令，在后面跟上空间即可表达缩减到XXG。 缩减的时候会提示你先检查一遍系统完整性，再让你缩减。 ②e2fsck检查下完整性之类的、③resize缩减文件系统 此时由于是resizefs 缩减的是文件系统，所以lvm还没有缩，通过lvs可见大小没变；然后开始缩减lvm:lvreduce -L 10G /dev/vg0/binlog ④缩减lvm -L 10G，不带+加号的就是直接缩减到10G。man lvextend可见👇 ⑤mount，缩完后重新挂载 注意缩减只能缩减ext的，不能缩减xfs的。 上图命令补齐也可见一斑，只有grow，没有reduce resize这些补齐命令出现。 所以▲xfs哪里比ext好了。 逻辑卷的迁移 迁移操作举例 拿这个b硬盘做实验，看下sdb1有没有用，就是看下有无挂载咯 当时老师做实验的，sdb1报错，肯定是fstab里写东西了， 删掉 dd 干掉分区清一下 发现上图dd掉512B后，分区sdb1还在，那是因为没有同步 partx -d --nr 1 /dev/sdb # 不能用-a，-a是增加，-d是删除 注意提示sdb忙 再次df 发现之前fstab里已经删掉了持续挂载哪一行，现在还是有类似的报错--废话你删掉的是mout的配置文件，又没有取消挂载，现在的df报错就是之前mount过--通过mount可见--然后挂载点估计是删掉了被，现在df报错了。通过mount看发现了问题所在， 视频中老师的排错思路看下 看到说明没有取消挂载 哈哈，还是在，我猜是不是dd 512导致的，还没有取消挂载就dd导致的？ 通过fuser -v /mnt/sdb1也没有人用啊，这会umount没报错，lsblk也看到没有挂载了。 取消挂在后，再同步一下，此时分区sdb1就没了 那上面过程总结，①挂载没有unmount②unmout需要时间③好像是/mnt/sdb1先挂，/mnt后挂，这一类也有问题。 下面开始针对sdb创建lvm，然后演示lvm的迁移 先创建一个和将来要过去 名字 存在冲突的vg0和mysql逻辑卷 下图👇创建物理卷、创建卷组并指定PE、创建逻辑卷指名和指大小和所属卷组。 挂载 复制点文件过去 好了 LVM就有了 下面进行迁移 先取消挂载 考虑到迁过去的卷组也叫vg0，lvm也叫mysql，只要vg0改了就行了，因为整体名称vg1-mysql过去就和vg0-mysql 不 冲突了 改名 禁用卷组 卷组禁用后，所有的逻辑卷也就禁用了： 导出vg1 拆硬盘、插硬盘、识别硬盘 正常服务器就直接拔，这里实验用的是Vmware工作站，先关机 是sdb硬盘要迁移 这就是硬盘啦，把这个文件复制到centos7的虚拟机上去 移动硬盘嘛，就是剪切过去 再centos7上加硬盘之前看下 当前硬盘排号已经到d了 完成 不会自动识别，echo - - - 一下 出来是出来了，但是这边的系统还不能识别其上的LVM lsblk看不到没关系，使用vgdisplay可以看到 上图👆可见此时vg1卷组是出于exported导出状态 导入卷组 使用vgimport vg1导入 此时状态OK 通过lvdisplay可见2个卷组 注意上图的not available 启用逻辑卷vg1 启用后再看 就正常了，lvm有了，就可以挂载了 挂载 此时数据就都过来了 以上讲解了lvm的创建、扩展、缩减、迁移 下面来个例子 假设sdd这块硬盘 指示灯开始黄灯 表示快坏了，还没红，但是要坏了。 此时需要把这个块硬盘剔除下来，问题是其上有逻辑卷，不能直接拔。 问，怎么拆走这个块要坏的硬盘 表示sdd这个物理卷已经被别的逻辑卷给占用了已经。 要想拆走这个sdd，必须先把其上的2559个PE的数据搬到同一个卷组vg0下的其他逻辑卷上，必须是同一个卷组。 但是 vg0 发现只有2059个PE空闲 1、只能加个PV了，为啥一定要同一个卷组呢？因为所谓搬家使用的是pvmove命令，估计这个命令需要同一个卷组。 2、当然你也可以缩一下，然后再搬家。 这里还没有加PV，vg0的所剩空间并不够，只是演示一下： 这是把sdd上被占用的PE搬家到同一个vg0下的其他空闲PE上去，前提是空闲PE数大于占用PE数。 有个问题啊，搬家是搬到其他空闲PE是吧，其他空闲PE是否分散在不同的几个LVM上呢，这样文件又该怎么索引找到呢，难道原来一目录下的分散到好几个目录下了？显然不可能这么玩啊。 实际上数据没多少，但是搬家搬的是空间，硬盘拆走，硬盘其上得lvm当初承诺出去的空间是16G和9.8G，现在sdd一拆，承诺出去的2559个PE差不多10G的承诺空间就没了。 当然你也可以缩一下，然后再搬家。 缩的问题也来了 不知道这2559个PE到底是哪个LVM占用的。 通过lsblk查看 可知是vg0-mysql逻辑卷占用了sdd的全部PE，而且vg-mysql还占用了sdc的PE 只要把vg0-mysql的容量变小，就可以搬家了 此时vg0-mysql lvm才用了很少： 再进一步发现，最终还是缩不了 只能加硬盘了 把sde剩下的18G空间加到vg0里面 不需要太多，👇只需要500个PE，也就是2G的大小。 然后...👇 发现整个sde都在vg1里了，没办法给都vg0了。 重新弄个分区来做吧 以上分析就是关键思路 注意此时blkid还没有呢，需要pvcreate后才有 pvcreate后blkid就看到了 加PV就是贴标签 加到vg0卷组里 至此vg0的容量就扩上去，剩下3338个PE，sdd的2559个PE就可以搬家了 此时sdd的PE们就搬家到同一个卷组vg0下的其他PV上去了，至于是哪些PV不关心，反正有地方，有文件夹入口访问就行了。 注意搬的是空间，不是数据，空间过去了数据自然也过去。 刚才的sdb3的5个G空间用完了，当然还有其他的PV也会分担一部分sdd的空间 sdd上的空间就搬走了 此时sdd上既然没有数据了，就可以考虑移除了 当前vg0里4个PV，计划删除sdd这个已近搬完空间的PV 变成3个了 此时/sdd就不属于任何卷组了。， 然后再删除sdd的PV--物理卷 标签 sdd就没有了 此时sdd就是一个完全和逻辑卷没有关系的硬盘了 就可以拔了~ 上面的分析较多，查看较多，真正的命令就3条--当然前提是空间够 注意，从头到位都是在线操作，没有取消挂载。 扩展、缩减、迁移、拆除 都讲了 LVM的删除 某个vg的所有lvm都不要了 ①取消挂载 如果是fstab里有写，也要删除 ②删lvm 删之前要确定上面的数据不要了 此时vg1里的空间就没人(lvm)用了 vg1没人用了也可删了 ③删vg 此时sde这个pv就不属于任何vg了，也可以删这个PV了 删PV之前blkid可见标签👇 ④删PV 此时sde再PVS中不可见，就成了一个纯粹硬盘了 也可以拔走了。 3、快照管理 逻辑卷还有个功能是分区做不到的--快照 VMware里的快照也是一样的道理 卷组里创建多个lvm，/dev/vg0/mysql是vg0里的一个逻辑卷。500G的数据备份时间很长了，但是快照就秒做。你需求不是备份数据，只是能够回到某个时间节点的数据，所以只需要针对变动的数据做备份就行了。 假设待会有100G的数据要产生修改，要是直接备份着500G很花时间，所以在同一个卷组VG0下再创建一个逻辑卷--快照逻辑卷--mysql_snapshot，本身也是个逻辑卷，只不过是个特殊的逻辑卷。因为假设是将来要改100G的数据，所以创建快照逻辑卷的时候就指定创建的空间为100G。所以快照逻辑卷的大小不用和源逻辑卷的大小一样，这个腾讯云上好像也有建议值，一半吧好像。 快照的原理，区别于普通 的备份，是针对变动的文件做的备份，文件要修改前先备份到快照逻辑卷里，所以性能会有所下降，但是还原快，空间占用小。 1、快照的创建的瞬间，其实只是分配了XXXG的空间，并没有备份任何数据， 2、只有后面数据发生变化的时候才会备份，所以性能是有所下降的。 同样改F2为F2'，也会将F2复制过去 3、只要没改过的数据都是在原来的逻辑卷里，只要改过的都会在快照里存在一份，假设F3改了好多次，问第一次的改动的版本在哪，中间的N多版本在哪，最后一次的版本在哪；要回答这个问题，只要抓住快照的本质，就是拍照片的那个时间点，所以第一次改动的版本在快照里，中间都没了，最后一次版本还是在原来的lvm里咯。从这个角度来讲，F2一旦改动过一次，后面的就不会再推送到快照逻辑卷了，也就是说性能就又回升了，所以说只要所有可能发送变动的数据都变过一次后，快照的性能就回升了。 从使用实际角度来讲，不可能所有文件都变过一次，总有第一次变动的时候，所以快照使用完就干净删除，防止性能损失 4、快照的前提是 ，快照卷和需要镜像的卷 必须在同一个卷组中。 5、快照的空间一般是原lvm的 多少呢，反正大于原来卷是没有意义的。 如何实现快照 举个例子 mysql这个lvm目前是16GB不到， 创建快照逻辑卷 要考虑卷组里有没有剩余空间 弄三个小文件做实验 f1删掉 快照里找回；f2修改 快照里找回；f3不动 快照里没有。 -n mysql_snapshot 起个名字 -s 指定为快照snaphost而不是普通逻辑卷 -L 1G 做实验不讲究了就给了1G，因为原lvm的大小虽然是16GB，但是测试的文件才3个小文件，够了。 -p r 就是属性是readonly只读的，这里不写也行，就是后面快照逻辑卷挂载的时候加只读属性mount -o ro 也行。这样逻辑卷就不能被别人篡改了，正常的快照备份业务显然OK的。 /dev/vg0/mysql就是给谁做快照。 此时👆就看到了 多了一个LV snapshot status属性：mysql_snapshot是active destiantion for mysql是mysql这个lvm的快照。 而且看到LV Write Access是 只读的。 同样的去看原lvm就是做了快照的那个lvm也多了1个属性 然后删除f1，修改f2；创建f4 然后去挂载一下快照看下 快照逻辑卷发现不能挂载，blkid可见👇 快照卷和原逻辑卷的UUID一样，XFS文件系统的一个特点就是同样的UUID的设备不能同时挂载的。 提示不能挂载只读的快照，刚才创建快照逻辑卷的时候-p r了。 即使这里写个rw也没用 因为快照是只读的 没有办法挂载的时候改成rw 只能重新创建一个rw的快照，去挂载了，也许有办法修改 把原来的删了吧 原来的也没挂载，所以直接lvremove删了 这次的快照2创建后，同样需要修改数据，数据没变，所以此时快照里没有数据。 👆同样的问题，UUID一样，又加上是xfs系统，挂载需要忽略UUID冲突。 👆此时lvdisplay就看到这个快照就是rw可读可写的。 发现数据没改过，快照文件夹里就已经有了，好奇怪 属性也一样👇 1、文件没有改，快照里就是没有的， 2、虽然我们从快照挂载的文件夹里看到原来的数据，但这些数据实际上还不在快照里。也就是类似于链接之类的机制。 3、这样做的就是让用户有一个心理安慰，让你看到数据在的，其实不在。 下面对文件做一些变动 f2删了、f3改了、f4没动、f5新建 此时看看快照文件夹里的东西，就是当时创建快照时候的数据。 如何恢复快照的文件 接着上图，可以把快照挂载的文件夹里的数据复制回去，其实有专门的命令。 先取消挂载，所以挂载快照卷其实是没必要的操作，只是为了实验看看，所以创建快照卷的时候确实可以-p r设置为只读的。 1、取消挂载快照卷---这是因为之前的挂载操作，是实验环节的演示，正常生成中不需要。 2、取消挂载原逻辑卷的的挂载，这是确确实实需要的操作。 因为要合并快照和原lvm，所以需要取消挂载 等会就好了 然后再挂回去，数据就恢复了 还原后，逻辑卷的快照卷就没了，使命完成，就是说lvconvert --merge xxx后这个xxx快照卷就没了。快照是一次性的？vmware至少不是。云上好像也不是的吧。 以上就是针对xfs系统的快照制作和还原 上图遗漏一个点，lvcreate 去掉-p r后，挂载就需要加上ro，保证快照的安全性。 针对ext做快照 针对binglog这个逻辑卷来做快照 创建3个文件作为镜像还原的对比 创建快照卷，因为不是xfs，所以额可以-p r设置为只读快照。 UUID依然是一样的，不过这回是ext4的 👆ext4不需要-o nouuid--也就是说UUID一样也能挂，然后也不需要lvm是rw的read-only的也能挂 快照里的数据会有的，虽然这是假象--或者叫优化用户体验的效果--类似链接。 原来lvm的数据👇： 删除f1，修改f2，创建f4 还原 之前先取消挂载 还原-合并就是用snopshort覆盖原lvm 此时lvdisplay就看不到这个快照了 挂回去 此时就回来了 完整的过程如下 上图有点小问题，①快照不用删，恢复后自动就没了，除非你还没恢复呢直接删②-p r是xfs的时候去掉，再结合mount -ro -o nouuid③ext4 可以用-p r。具体上文都有说过了。 练习 注意/boot分区不能挂到逻辑卷里。/boot是启动的时候就要挂载使用的，这样系统才能启得起来。而启动的时候系统还不知道啥叫lvm呢。lvm也是要内核驱动模块支持的，刚启动的系统还没有加载lvm的驱动呢。 排版格式化 df - P选项、关键字：太长、对齐、一排。 通过lvdisplay可以看到LogVol00是给根，还有个给到了swap 同样centos8的lvm看看 删除所有的lvm 1、unmount 2、先删快照(如果有)，再删逻辑卷 一条命令好像可以两个逻辑卷都删了 lv就没了 3、删卷组 3、删除PV物理卷 到此就删干净了。 分区用不着删、硬盘不用了拆。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-07-21 18:39:44 "},"13-网络协议和管理/13-网络协议和管理.html":{"url":"13-网络协议和管理/13-网络协议和管理.html","title":"第十三章 网络协议和管理","keywords":"","body":"第十三章 网络协议和管理 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:34:59 "},"13-网络协议和管理/1-网络基础.html":{"url":"13-网络协议和管理/1-网络基础.html","title":"第1节 网络基础","keywords":"","body":"第1节. 网络基础 系网工，略 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:34:59 "},"13-网络协议和管理/2-网络架构.html":{"url":"13-网络协议和管理/2-网络架构.html","title":"第2节 网络架构","keywords":"","body":"第2节. 网络架构 网工，略 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:34:59 "},"13-网络协议和管理/3-TCP&IP.html":{"url":"13-网络协议和管理/3-TCP&IP.html","title":"第3节 TCP&IP","keywords":"","body":"第3节. TCP&IP 网工，略 略不了，这里面东西有点深，不过一般用不到，先放几个图，后面再说 还有滑动窗口、慢启动、重传机制等 accept()是app及时提取全连接队列的函数吧，如果处理不及时，也会造成全连接队列拥塞。 这块应该叫linux的网络内核参数文件以及调优，需要整理的，可参考小林codding这位的。 还有之前的一个tw内核参数，针对NAT后买的时间序列问题的，也会导致丢包的情况。 还有nginx的限制并发等。 服务器禁ping除了云上的安全组、服务器本身的iptables、还有内核参数 0表示不忽略，就是可以ping通，echo_ignore就是忽略icmp的echo 此时ping就卡住不动了，就是不通了嘛 再改回0就通了，可见中间丢了几十个包 ttl判断系统 之前是64，现在是128了。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:34:59 "},"13-网络协议和管理/4-IP地址规划.html":{"url":"13-网络协议和管理/4-IP地址规划.html","title":"第4节 IP地址规划","keywords":"","body":"第4节. IP地址规划 网工，略 皮一下~ ipv4的link-local地址是：_ https://datatracker.ietf.org/doc/html/rfc3927 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:34:59 "},"13-网络协议和管理/5-linux的网络和路由配置管理.html":{"url":"13-网络协议和管理/5-linux的网络和路由配置管理.html","title":"第5节 linux的网络和路由配置管理","keywords":"","body":"第5节. linux的网络和路由配置管理 修改网卡名-方法1-网卡驱动模块 研究下为什么是eth1，怎么改，这是centos6的： 可见eth0已经被某个mac占用，所以现在看到的就是eth1了。 删除并修改 修改后，重启网络服务是不行的 要修改eth1这个名称，需要卸载网卡驱动，并重新加载驱动。 mii-tool 查看 查看网卡驱动 👇找到了驱动模块 lsmod 是找到加载的所有驱动模块 卸载模块用rmmod或者modprobe -r 网卡模块卸了也就是网卡驱动卸了。 此时网卡就自然看不见了 然后再重新加载模块(驱动)： 此时就改为eth0了 方法2-ip子命令 ip 子命令，在centos6上tab不出来，centos7可以 centos6要额外安装软件包才能支持tab键补全 网卡配置 1、setup 进去选-选-选 等价于system-config-network-tui # 这两种方法就是算了，而且在centos7里setup里也没有网络配置选项了。 2、重点看命令和配置文件 ifconfig过时了，擦 主要是因为net-tools这个工具包过时了，所以包里的很多比如ifconfig、netstat都过时了。 推荐你用iproute这个包 ifconfig直接回车看的是激活状态的网卡 禁用和激活 ifconfig eth1 down 禁用eth1网卡 ifconfig 就看不到eht1，ifconfig -a 可以看到eth1但是IP没了，ip a就看的更清除了 ifconfig eth1 up启用 禁用网卡还可以ifdown eth1 不过这种down和刚才的ifconfig eth1 down又不同了 这个ifdown 后，ifconfig确实可以看到的，但是没有地址。 这个ifdown属于网络层的down，IP没了但是数据链路层是通着的。 对比ifconfig属于数据链路层的down。 所以ip a看就会发现是UP的，所以ip a看的就是L2链路层咯。 1、ifdown\\ifup是L3层的up\\down， 这个ifdown后ip a看还是UP的 2、ifconfig down\\ifconfig up是L2层的up\\down，这个ifconfig down后ip a看就是DOWN的 3、ip a看的是L2的up\\down 4、还一种是物理层的down，就是拔网线了 5、ip link set eth0 down 也是可以的，一样是控制L2的up和down，见下图👇 6、几个关键词：LOWER-UP和UP的区别、NO-CARRIER DOWN和DOWN的区别 https://stackoverflow.com/questions/36715664/using-ip-what-does-lower-up-mean ifup 要起来还需要依赖一些网络配置文件，所以ip a还是看不到地址 没关系，在centos6上用service NetworkManager restart就可以了。 把网线的演示 这就类似拔网线了 1、ifconfig看就没有地址了 2、ip a看就是down 此时上图👆就能判断是网线拔了，而不是其他的，因为有关键词NO-CARRIER。 对比ifconfig eth1 down的描述信息 配地址-临时 清地址-临时 增加地址-临时 就是huawei里的sub地址咯，或者是思科的second ip。还一种是子接口，子接口在linux里是一种别名 ifconfig eth1:123 1.1.1.1/24 ifconfig eth1:321 2.2.2.2/24 ifconfig可见 这里不涉及子接口的vlan id封装解封装，直接就能和外界同样的IP进行通信，所以我感觉更像是second ip而不是子接口。 删除linux的子接口 ifconfig eth1:123 down 这个down掉就是删除子接口了，这里就称之为linux的子接口咯，虽然它没有vlan的概念。 混杂模式 抓包的时候就用的混杂模式 混杂--不管这个数据是否给我的，我都收。 https://cloud.tencent.com/developer/article/1439013 VMwareWorkstation的话有时候需要手动修改centos的接口为混杂，原视频中我没有找到当时老师的操作，不过理解后也能自己设计一个场景，所以这里就仅仅提示下。 https://blog.51cto.com/nizhuan/724081貌似桥接模式就是混杂模式了。 mii-tool 工具 上图说明 capabilities 是支持的能力比如FD就是full duplex；HD就是hafl duplex 第一行就是协商后的当前工作模式是千兆全双工 ethtool 工具 网线8根线，如果断了一根运气好，还能用就是100M，👆这里就可以检查到。但是要注意如果是vmxnet3的网卡，ethtool看到的就是10G速率，虽然实际上是1G的。所以这里的速率显示显然不是实际值。 ehtool可以修改网卡工作模式，一般不改 CMD的grep 例子，查看多少人连到我的VNC上 第三列就是client IP地址 常见服务端口 cat /etc/services 一般客户端电脑不会使用1W6+(65535-49152)个端口，但是如果你这台linux或啥系统的电脑是作为代理上网，比如SNAT，那么1W6+也不是没有可能，因为1台内网的PC大概10连接，1000台PC对吧，再加上手机，还是有可能让你的这台NAT服务器的端口超出1w6+这个默认值的。 如果要当代理，这个端口就要调大👆 实际情况是60999-32768=28231个随机端口。 TCP的序列号问题整理 数据包的序列号，并非0，0是相对编号，应该是初始ISN，好久不碰了有点忘了都，而是下面的97fa6e02 再CISCO的安全方向里ASA的里面有一个SN、ISN的利用。然后linux的tw内核参数 还有一个问题，一般出现在网吧、公司这种NAT环境 https://blog.csdn.net/enweitech/article/details/79261439 文章讲的太细，简单的故障处理就是 “之前的偶尔打不开是因为开启了一个tcp相关的内核参数, 办公网都是nat出去的, 数据包时间戳的抖动会导致服务器把请求给丢弃, 迁移之后的 oa单点登录, 虚宝网等我都把该参数关闭了, oa.sm.xxx 这个不在迁移的机器中, 刚刚修改过了, 后续在观察一下” -- 这个是案例，呵呵。 https://ppabc.cn/1363.html 这个篇针对性强，说的是时间戳。 tcpdump的举例-整理稍后 上图👆是drop后的一个抓包结果，可以看到很多的[S]，这就是SYN包，是重传机制导致的。 其实更多的时候，我一般就是抓个端口然后|grep 哈哈，是不是没想到，哈哈 |前导码+开始符|DA|SA|TYPLE/LENGTH|DATA|FCS| 一共72B的最小值。 ping 默认就是64也即是没有算开头的8B。 附上之前的一个分片解析图 TCP超时重传 TCP的拥塞控制 四个机制 慢启动、拥塞避免、快速重传、快速恢复 https://allen-kevin.github.io/2017/12/21/TCP%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E4%B9%8BCUBIC/ 并发ping-首推方法 seq 1 255 |xargs -i -P 0 bash -c 'ping -w 2 192.168.25.{} &> /dev/null && echo 192.168.25.{} icmp allowed' 还有awk的并发ping，想不起来了，没影响了。 这个也快 ls --hide=proc | xargs -i -P 0 find /{} -name \"sshd\" awk的举例 tcpdump -i eth0 -tnn dst port 443 -c 100 |awk -F \".\" '{print $1\".\"$2\".\"$3\".\"$4}'|sort|uniq -c|sort -rn|head -n20 我之前说过awk和xargs一样快，ping的处理上我怎么不记得有做过呢，肯定是有过的，现在想来是写个for循环awk调用系统命令，但有这么复杂吗，当然其实不复杂，我是说之前的awk实现批量ping 是怎么弄的？ 还有好多工具类的使用iperf 、curl、F12等等，这些就算了，不放到这里了。 广播的情况 👆ping 255广播只有一个37.2响应，因为linux默认是不响应广播ping的，需要开启 1就是忽略，就是不回应，改为0 centos7上一样，centos8也一样 从默认的TTL上可以判断37.2的ttl是128，是台windows机器；37.7和37.6是linux机器。 注意上面这个实验，要在同一个网段做哦，原因很简单，就是跨网段，的192.168.1.100去 ping -b 192.168.10.255，这个广播是不会有任何回应的，因为3层转发广播不转发的，这就是CCNA里的基本概念--广播域--二层广播帧所能到达的范围就是广播域，显然二层广播帧的广播地址全FFFF-FFFF-FFFF显然要比192.168.10.255这种L3广播地址映射到二层的广播MAC地址还要厉害，连这种真广播都跨不了三层，你凭什么能ping通呢，至于为什么垮不了，因为数据要从二层拆包，到三层，再重新封包，这个过程就算3层路由器设备处理广播----其实真可以处理的，CISCO SECURITY 里有个攻击就是用广播做的好像，需要路由器转发广播的。 loopback 略，注意下图 人为将linux的lo环回口改成6.6.6.6/24 ，这样这个段都处于loop，并不是说必须是127。 这里也可以写IP地址，不一定写lo 网卡配置文件 name将来就表现为GUI图形界面里的eth0 改的玩下， BOOTPROTO=none也行都是静态手动配置，BOOTPROTO=dhcp就是动态 1、注意一旦写了dhcp，后买手动配置的IP地址，DNS就会被覆盖了； 2、文件其实就是脚本用的，前面其实就是变量，变量是区分大小写的，然后=左右不能带空格； 这块书上讲的更全，所谓全其实也就是下发明细和下发默认的一些优先级问题。 还能精简成如下3行，再补一个GW和DNS1 改完配置文件后，一般不会立即生效，有时候会立即生效，那是因为NetworkManager服务，不过这个服务不是时刻都能立即发现你修改了文件然后使之生效的。而且这个服务一般也不用都是关掉的。最小化安装好像也是没有的。说反了，一般是我们只用network，但是rocky-linux和centos7最小化安装后好像rocky-linux是没有network服务只有NetworkManager，然后centos7的network是fail的NetworkManager是active的。好奇怪~没事，停用禁用NetworkManager后就可以启用network服务了。 看来rocky-linux不喜欢这个。centos8一样， linux开启路由功能 注意临时修改是用的echo，vim是不能编辑内存里的文件的 vim是改磁盘文件的，不能改内存的数据。 mtr的使用 mtr可以选择icmp tcp udp的，这点要知道，然后我的处理，是通过crontab去弄，大概如下 基本上如果curl的效果不行，就自动触发mtr得到报告，不过with os.popen这种阻塞的方式，在网络质量不好的清苦下，会造成cpu负载高的，因为太多的阻塞等着运行了。网络好就不存在了，30s不到就mtr完了，或者都不会触发mtr。 frr可以弄一下 frr替代quagga了好像 vyos、led、openwrt、strongswan、openswan、routeros、 vyos的ipsec vpn--police的，存在支持上限的问题，未尝试解决、未升级测试是否得以改善，其他功能OK，由于没有大并发，性能未得到测试。 openwrt里的strongswan在旁路模式下，也不知道是我的TP-LINK物理网卡问题还是旁路的问题，反正隧道存在丢包，游戏时存在断线重连的情况，效果不好，未尝试继续改进。 softher vpn这个不多说，emm，真心不错，一键搞定IPSEC、openvpn、pptp、l2tp。其实远程办公，还是要考虑授权、限速的问题，如此衍生出的IP静态分配，等就不是简单使用softehter来实现，从这个角度还不如自己使用开源来弄，顶多写一个脚本来做统一的多协议账号开通。其中openvpn就是要使用radius和mysql或者ldap之类去做，这个不用这么麻烦，直接配置文件里指向一个脚本验证 一个存放用户名密码的文件就行，具体见我的印象笔记的相关模块。 其他还有什么clash、向日葵、vⅡray是吧，哈哈。emm有时间都要整理出来。这些东西可不是仅仅那个作用，可以用来做远程办公，而且客户端软件效果好，openvpn嘛还不必clash的节点测试效果，切换方便，如果公司4个出口，统一到clash就很不错，需要考虑的时clash他后面要自己搞成静态IP，然后用户授权啦--最好是账号密码而不是profile配置文件这种不太好管理的。东西用来做远程办公确实可以研究下的。让技术更好的服务正规需求是我们要考虑的。 不过这里建议大家先从提高收入左手，而不是大量研究这块，恩业务需求的满足，完成就好，完美不好。70个完成远远大于40个完美。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:34:59 "},"13-网络协议和管理/6-网络配置和故障拍错.html":{"url":"13-网络协议和管理/6-网络配置和故障拍错.html","title":"第6节 网络配置和故障拍错","keywords":"","body":"第6节. 网络配置和故障拍错 netstat 那啥ss可能会更好些，netstat也学一下吧，好像mac里用的也是netstat这个命令 套接字socke分2种 1、ip+port，tcp或者udp都是这种； 2、unix domain socket，这种就表现为socket文件。 s开头就是socket文件 这类的socket文件也能实现和tcp/ip 这种Ip+port的类似的通讯效果，可以实现多个进程之间的网络通讯，问题来了：是本地还是远端呢？ 1、两个程序如果处于不同的主机也即是远端通讯，可以使用tcp/udp的socket--ip地址加端口号；这种通讯存在一个封装解封装问题。 2、如果处于本地--同一台机器，就没必要封装解封装的过程了；可以考虑采用这种unix的socket，两个程序想通讯，就把数据扔给socket文件，通过它中转就行了。 netstat说明 -n 不解析地址为域名，端口为服务，这个是常用的 -t和-u就是tcp和udp咯 -l是看监听的，不是看ESTABLISH的。👈 这就是看打开了(监听了)哪些tcp/udp的端口。 1、注意上图，TCP是有状态的，所以显示LISTEN；而UDP是无状态的 所以没有显示什么LISTEN字样。 2、如果发现有些端口不是我们需要的，可以找到该端口对应的应用程序，然后卸载掉。怎么找呢，就是加个-p或者👇 如果知道端口对应的APP lsof 可见6000这个端口是x11这个图形界面软件在用。 netstat -p或者ss -p，当然要辅以其他选项 切到init3就是纯字符界面，就没有x11了， netstat -e 是extend，会显示节点编号inode netstat -ntua ，a就是监听和连接的都会显示 常用组合 这个还挺不错，我是说netstat -nr，它可以看到MSS和window，MSS肯定就是4层传输单元了MTU\\MSS一类的嘛，window就有点不能理解，TCP的滑动窗口也不至于写到路由表里吧，而且窗口还是动态的。网上搜一把没找到，转头进入man netstat 然后\" + -r\"看到👇 然后进入route的man帮助 你看他这个route只有一个8.gz的man，所以不需要man 8 route，哈哈我是不是太无聊了 瞬间找到了，还真是窗口，不过是AX.25的，所以那啥，MSS再看看搞不好也不是动态测试的，而是设置的 默认就不显示咯，MTU1500嘛MSS就是|DA|SA|TYPE/LENGHT|DATA|FSC DATA： |IP|TCP|DATA| MSS=1500-20-20=1460，一般就这么算吧，不过遇到ASA拨号的时候，L2的DATA就是|da|sa|type|pppoeHead|pppHead|ipHead|tcpHead|mss，此时的MTU=1500-6-2=1492这个是对IP层的整个报文限制了，所以MTU是L2对L3的一个限制，你在ASA上要敲的MTU就是1492，然后MSS就是1492-20-20=1452。注意哦MTU是二层对IP层(L3)的一个限制，限制的是整个IP报文长度，限制产生的效果就是IP层会自己去分片，怎么分的上一篇已经讲过了ping -l 1502的分片计算有讲。而MSS的源头也是MTU，但是MSS是TCP里的DATA的上限，这一点不可类比于IP的整体长度限制。恩其他还有PMTU discovery地理发现贫道~恩没有广告~所以在有电视那会还是基本爱调在这个台，哎~俱往矣，属温馨伐木累还看还看还看还看555...哈哈哈我能把人气成这样也是我占着理拿着需，唉得饶人处且饶人啊，别人也是关心你。 我就直接引用别人的博客了https://zhuanlan.zhihu.com/p/139537936 https://blog.csdn.net/lepton126/article/details/70810316 netsta -i 查看接口统计信息，访问量大不大 动态观察的方法 wathc -n1 就是1s刷新一次 netstat -i这个命令的结果 ping嘛就是1sping一个，但是-s 65507后同样也是1s ping一个，但是这一个要切片成N个咯，所以实际上1s发出的包就是N倍，所以此时再去看对端的watch -n1 netstat -i就会发现RX-OK增长的很快。 还可以更快，就flood的ping 这回RX-OK的增长就更快快快了 大包分片+ -f，够了哦~ 这是WIFI，ping -s 打到了32Mbps 去看看有线 哈哈，瞬间打到250Mbps，1G的带宽也就是950Mbps吧，人家要叫了，哈哈。 这种ping -f打出来没有iperf的大，iperf同样的源目1G可打满950M的。 一些个性的命令写法 敲入：watch -n1 netstat -Ieth0 ip命令 ip命令很强，用来替代ifconfig的 ip 后面加 选项，再加 操作对象；操作对象有 link | addr | 等等👆 在centos6或centos7的最小化安装都不能tab补齐，可以通过安装插件bash-completion来实现，centos7没这个问题。 yum完后exit重新登入一下，此时就可以tab两下补齐了 ip命令主要控制的是link数据链路层、addr网络层、route路由 ip link 查看MAC地址、网卡是否启用 MAC地址在网卡的rom芯片里的，真正要改需要借助设备烧入。 所谓修改就是修改配置文件了，关键词MACADDR 发现没变~ 为啥呢？ 注意上上图的提示消息 由于IP地址用着呢，所以MAC地址也不给你变，restart可能不等价down + up哦，down一下IP地址就不是already in use了，试试看，并不是！ 小改动一下MAC，试试 这会就改过来了 真正的原因可能是11打头的,HCIA里有讲，11:22:33:44:55:66正中组播地址。 尝试改一下 验证下 所以没点NA的知识，还真改不了MAC地址。 ip addr查看网络层 这里也能看MTU，支持广播、组播 ip addr 添加地址 这个不是子接口嘛？ 这种方式加的second IP，ifconfig看不到，ifconfig人家加的是子接口形式的 所以子接口+vlan就是我们网工所熟悉的路由器的子接口 然后second IP或者叫sub ip就是第二IP，就好比linux里的ip addr add 添加的地址咯。暂时这里理解先。 使用ifconfig给网卡加子接口，也叫什么别名， man ifconfig可见👇 人家叫别名，叫second address，不叫子接口，哈哈，但是我觉得加上vlan就是子接口了，ip a才是正儿八经的second address。 用ifconfig看下 然后 ip a也能看到， 结论：ifconfig看的没有ip a全，怪不得推荐Ip a呢。ifconfig 创建的网卡别名 ，ip a可看，ip a创建的second address ifconfig看不到。 注意上图1.1.1.1/24 scope global eth1 2.2.2.2/24 brd 2.2.2.255 scope golbal eth1:2这种别名。 然后ip a a也就是ip addr add也能添加ifconfig的别名 上图3.3.3.3加成了ip a 的second 接口没有加成ifconfig 的别名，修正👇 ip a有两种second address，①一种式非子接口②一种是子接口--也就是别名--这种ifconfig可查 注意广播地址ip a配置的，默认是0.0.0.0，哈哈这TM就不是个广播地址啊。 去查一下ip a里的两个second ip的说法 原来这个就是ip a为了兼容以前的ifconfig而设计的。 写到这，发现这一篇其实也可以直接就扔几个命令这就行了，哈哈，算了写完吧，好歹后面看起来舒服些。 清除所有地址 理解下scope 这里其实好理解link-local 对吧，就是Ipv4 和Ipv6 link-local，一个意思。TTL=1嘿嘿。v4和v6的区别就是v6的link-local在下一跳中起作用的，但是v4的link-local实际上没有应用场景--要说有就是网线直连169.x.x.x就通了，哈哈。 hosts是loopback口用的，主机地址，一般/32，也能对外发布路由互通，但是这里更多指的是127.0.0.0/24的回环检测地址，就是真正的本机可用了。所以上图的host更多的指的是127这种地址。 下面看看授课老师大佬的讲解，这就厉害咯 1、global是内核级的 这个就让我想到ASA 和 router的区别(在ping背向网卡地址的时候)，上图的ping在路由器上行，但是在防火墙上就不行，哈哈，可能就是用的link地址特性。 言归正传，上图这种能通，是因为IP1和IP2表面上是配置在网卡上，其实是工作在内核级别的。scope global就是这个意思。 2、link，如果IP2改为scope link，上图左边进来的ping IP2 就不通了。 3、host，网络访问过来的都是不通的，只能自己访问了就。 我们曾今做的loopback为1.1.1.1/32，一般思科的环回口对吧 其实linux一旦你改了地址，他就是global咯，所以主机地址这个称呼 主机地址这个称呼 1、在linux里指的是本地能通，网络不可能通的127.0.0.0/24 2、在华为、华三、思科里面指的是1.1.1.1/32,2.2.2.2/32这种32位主机地址，但在linux看来他们其实都是工作在内核的global地址。 实验看看 诺，scope不是你想改就能改的。所以实验中止~继续整理markdown。 用ip命令修改网卡名称 在centos6上是修改的文件，然后卸载重装了网卡驱动，上文第5节已讲 在centos7上就没有这个文件了，怎么改呢 先禁用网卡 这样就改好了。 ip route 添加ip route add 删除ip route del 加默认路由ip route 0.0.0.0/0 via a.b.c.d或者👇 两个默认，哪个优先 这里还是要注意下metric，不是我们网络工程师常规的默认cost值咯。 手动修改metric---通过man ip route 或者 ip route add help可得 想实现ECMP等价负载均衡，结果发现linux默认不让 SS命令 ss和netstat一样，但是效率高，在服务器访问量大的时候SS显示结果的速度更快，还带一些统计信息，过滤条件比netstat更加丰富。 tcp有11个有限状态机，ss可以显示指定的tcp状态，或者端口号 orhpaned孤儿连接， 还有什么孤儿进程， ss -nta \\ ss =atn 此处顺序无要求 ss -nt 表示正处于连接状态的 查询并发连接数最多的主机 然后sed的做法👇 sed的分组用法，其实就是python里的格式化字符串。 修改主机名 centos6的修改方法 /etc/sysconfig/network + hostname 改成 然后hostname 配置下，再退出下 还有一个地方也要改，就是/etc/hosts文件里👇 本地的DNS解析用的，hostname一样要写到这里。 dns优先级 默认是hosts文件优先级比dns查询 要高，可以修改 方法如👇 /etc/nsswitch.conf files指的就是/etc/hosts文件，它在dns查询之前，调一下个就dns查询优先了 此时ping xxx.com就不是hosts里写的，而是dns请求的了。 domain name 此时ping www是不会自动给你补上后缀的 需要自动补充 .xxxx.com 的 可以在这里添加domain：👇 改为默认路由送出接口的网卡配置文件后，重启网络服务 上图OK的，也可以下图这样 USERCTL是普通用户是否可以启用禁用网卡 这里的HWADDR是真实的MAC地址，真实的MAC地址啥，这里就填啥， 上文改的是MACADDR 两种方法索引 ifcfg-xxx是哪块网卡就看配置文件里的DEVICE或者HWADDR 1、DEVICE=eth1 2、HWADDR=XXXXX 这里写真实的eth1的MAC就行了，两种写一种就行了。上图DEVICE=ethX可以删的 至于反向，这个后面单独讲DNS的时候就知道了，要有反向的mapping的 路由表的静态文件 IFACE是实际的接口名 一般就用10.0.0.0/8 via 172.16.0.1 这种 这里的网卡配置的知识，还是书上整理的比较到位 前面的网卡别名也就是子接口 这些也存不住的，需要单独写一个网卡配置文件 上图提示1.1.1.1已经用在了eth1上了，好奇怪，改成1.1.1.199再次重启，提示归提示，但是已经生效了 问题-一块网卡上的多个地址获取方式不同行不？ 一块网卡的子接口是DHCP的，物理口是手动配置的，或者还有子接口之间是不同的方法，或者反过来。这样行不行？ windows里好像不行； linux里可以做到-物理口是dhcp、接口别名是手动配置，反之不行。 实验 1、修改eth1主接口位DHCP 一但改成DHCP，下面的IPADDR\\PERFIX\\GATEWAY\\DNS1和2都失效 2、发现可以做到物理接口dhcp、子接口手动的效果。 3、反过来，物理网卡使用static，子接口也就是别名使用dhcp是不行的。 👆物理网卡，别名网卡(子接口)👇 重启后发现不行，物理接口静态OK的，子接口依然是下面的手动配置的IP--它根本不认BOOTPROTO关键字，要是DHCP起作用了，就不会拿到1.1.1.199这个IP。 上面虽然拿centos6举例，但是很多都是通用，一些主机名的改法还有NetworkManager的禁用是6独有的。其他无所谓6 7的 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"13-网络协议和管理/7-多网卡集成的企业级应用.html":{"url":"13-网络协议和管理/7-多网卡集成的企业级应用.html","title":"第7节 多网卡集成的企业级应用","keywords":"","body":"第7节. 多网卡集成的企业级应用 数据传输一条龙，从网口进来，到内存、到硬盘，中间还有CPU的运算。 所以看看哪里是瓶颈，iperf就是内存到内存的测试方法，SFTP就是到硬盘的测试手段。 多网卡绑定的模式 👆Mode1其实通过上述，就知道SW那头如果发现只有一个外部端口能看到MAC地址，就说明是Mode1了。 0 2 3 4 都需要SW那头配置portchannel，4还需要动态的协议。 Bonding配置 1、miimon，比如mode1下，就是slave监控master的周期间隔100ms； 2、新建ifcfg-bond0； 3、修改两个网卡配置文件。 实验 VM虚机都改到一个网络里 做bond之前禁用NetworkManager服务，并开机禁用。 删除多余的文件，保证bond成员口的配置干净 创建ifcfg-bond0 这个设备当前是没有的ip a看不到，待会配置完毕后，重启服务器后就有了 配置物理接口加入bond0里 编辑eth0网卡 MASTER=bond0 以及SLAVE=yes，这样，这个网卡就属于bond0了，地址就是bond0说了算，下面的地址就无效了。 再修改eth1网卡配置 然后重启网络服务就OK了 注意，bond0起来后，运来的两个物理成员口的IP就失效了，之前ssh就断开了，只能通过本地终端登入上去看看了。 检查下 eth0和eth1已经不对外了，而且MAC地址是成员口和bond口公用的。 因为做的是bond0，所以有一个主的，通过查看proc确认谁是A谁是S 可见当前是active-backup模式也就是mode1，eth0是主 将eth0断开(前面一个就是eth0)，测试下连通性 发现丢了一个包 两根线都down的样子 cat /proc/net/bonding/bond0 ，下面centos7一样的命令 主备切换，不会抢占。 改成mode3 broadcast看下 37.100就是bond0的IP了，这个DUP就说明broadcast是成员都工作的。 在这个模式下，断开一个接口，发现不通了(在虚拟机环境下)，因为要结合SW配置。 centos7的配置方法 centos7最大区别就是网卡名称不一样，7通常都是ensxxx，一般是cents7是根据网卡插槽定义的，为了稳定，不过一般网卡也不会增加删除，所以更多还是认为改成eth0 eth1 这种方式。 cents7改网卡名称 阔以的，虽然下面的和rocky-linux不同，但是rocky-linx测试一样的操作，就是生成的文件里的ifnames=0的位置不同罢了。 修改/etc/default/grub ubuntu里也是ens33， 切换成root身份： 上面改完还不够，需要利用工具覆盖一个文件 ubuntu需要grub-mkconfig -o /boot/grub/grub.cfg;reboot centos7需要grub2-mkconfig -o /boot/grub2/grub.cfg;reboot reboot即可 不推荐修改，需要借助grub-mkconfig来生成这个/boot/grub2/grub.cfg文件。 grub2-mkconfig -o /boot/grub2/grub.cfg 默认就会读取/etc/default/grub文件来生成最终文件。然后reboot生效。 总之centos7上网卡名称是自动生成的 wlxxx就是wifi网卡， 其实centos7的网卡命名的前因后果是这样的 https://developer.aliyun.com/article/609587 rocky-linux修改大同小异 https://blog.51cto.com/feko/2751292 centos7修改主机名 nmcli nmcli 及时NetworkManger cli的意思，配合NetworkManager服务用的 通过tab键可见有哪些子命令，主要用到的是connection 和 device device是数据链路层 如果网线断掉一根，就会看到如下图情况： 看接口详情 以及 使用connection查看网络层 这里的NAME和DEVICE可以不同，如下 然后systemctl restart NetworkManager可得： nmcli的使用场景和习惯，命令行嘛首先是，灵活 nmcli connection add con-name eth1-test ifname eth0 type ethernet ipv4.method manual ipv4.addresses 1.1.1.1/24 目前针对eth1有两套配置，生效了一套 通过上图过程截图可知，nmcli connection add con-name eth1-test ifname eth0 type ethernet ipv4.method manual ipv4.addresses 1.1.1.1/24 会生成ifcfg-eth1-test网卡配置文件；但是如果是人工创建一份新的网卡文件nmcli默认是不会识别生效的，需要nmcli connection reload一下 网卡的UUDI必须唯一，简单处理方法就是删掉改行就行。 此时eth1-test2就加载了，要是生效同样nmcli connection up eth1-test2 nmcli删除连接 删除在用的连接(也就是网卡配置)，会自动切换到另一个。 nmcli connection delete eth1-test2后/etc/sysconfig/network-scrips/下的ifcfg-eth1-test2网卡配置文件就没了。 手动删除网卡配置文件，nmcli不会自动切，还需要reload 所以总结来了 1、nmcli就是命令行来直接配置网卡配置文件的，nmcli删除创建的连接，就是网卡的配置文件。 2、如果不是使用nmcli创建\\删除connection(其实就是配置文件)，而是手动创建\\删除的ifcfg-xxx配置文件，就需要nmcli connection reload加载一下 nmcli强大在显示信息 nmcli修改接口位DHCP 这样配置文件里的DHCP就修改好了 通过nmcli connection show eth1-test可见 这里的auto就是dhcp 然后在启用该配置 这个看DHCPOPTION还是不错的，什么43、150都能见着了。 不过也不是就这一种方法看DHCP的信息，还有 虽然上图是手动韩国的25.44，但是之前的dhcp获取的信息还在。 有个东西比较呵呵①新的旧的命令技术你都会②老工程师新工程师在你面前就没有优势可言③这个时候人际关系就比较和谐了 nmcli 增加IP地址 这个nmcli connection modify eth1-test +ipv4.addresses 3.3.3.3/24其实就是修改了配置文件 再加一个地址 这加的second ip，ip a可以看ifconfig 看不了，这个在上一节重点讲过了。 其他补充 注意哦加载(reload)是指配置文件的重新同步下：比如人工修改创建的，同步到nmcli这里 这是不需要reload的哦。 nmcli实现bonding 实验 1、将两个网卡都接到一个SW上，WMworkstation就是接入一个网络里 清除之前的网卡配置 开始配置 type很多啊，好友adsl、wifi、vxlan nmcli connection add con-name mybond0 type bond ifname bond0 mode active-backup ipv4.method manul ipv4.address 192.168.37.100/24 但是已经发现远端可以ping通这个额bond0的IP地址了 其实原因是scope global属性导致的，只要这个设备上的接口带global属性，那么就可以背向/朝向都能ping通的。 工作在内核级别，只要流量能发到这个设备上，比如ping 192.168.37.100的ICMP到了这个设备上，那么就可以响应的。 这个ping通不代表bonding绑定成功，而是虚拟的一个网卡通了，还需要进一步绑上物理成员接口的。 上图type 后两个tab里没有bond-slave自动补齐，我的可能版本较高有的 此时就出来了，但是没有起作用，也先不捉急启用 脸厚，你没看错脸厚我们就激活一下 由于现在只加了一个eth1，所以 然后再把另一个接口加进来， 这个，如图就断了，因为ssh的这个机器的这个网卡，现在加进了bond0里了，所以自然就断了。这也是实操bond0的时候要知道的，没事，保证bond0起来就能ssh那个地址就行了。 去终端看下，已ok 同样看下 /proc/net/bonding/bond0 然后测试一下断开的效果，eth1是后面一块网卡 发现丢了1个包哦icmp_seq=309这个。 此时eth1就down，eth0就active了 删掉mybond0这个连接，两个成员的连接就下来了。 网络组 centos7比centos6多了一个网络组 新技术 network teaming和bonding一样，性能据说更好，底层技术实现不同。 创建网络组接口 创建port接口 示例 具体命令和bonding一样，效果一样，就是关键字改了，技术更优。 所以centos7建议用team而不是bond，6嘛只能bond了吧。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"13-网络协议和管理/8-网桥实现和ubuntu网络配置.html":{"url":"13-网络协议和管理/8-网桥实现和ubuntu网络配置.html","title":"第8节 网桥实现和ubuntu网络配置","keywords":"","body":"第8节. 网桥实现和ubuntu网络配置 linux实现sw 网桥 vmnet8和vmnet0按理说是VMwareWorkstation的两个网段是不通的，但是通过VM虚机的网桥实现二层互通。 实验环境如上，下面开始配置 配置好两头的IP地址就行，请不要配置网关 我们在做二层实验 配置中间的机器为网桥 方法1：传统命令配置，采用工具集，缺点不能存盘 确认已经安装了bridge-utils工具集，最小化安装时没有的 其中有一个/usr/sbin/brctl工具 将原有的IP地址等三层信息干掉，以内要实现的是二层SW的二层口 btctl show查看当前信息为空 brctl addr br0创建桥接设备br0这个sw brctl addif br0 eth0 eth1将接口加入网桥设备 此时就其实实验就搞定了， 还可以启用STP 查看sw上的mac地址 还没有学到两头的MAC地址，自然还不通，找下故障原因，其实故障原因上图👆可以看到一个br0是DOWN的，肯定不行了啊。所以只需要ip link set br0 up就行了，哈哈大佬竟然没看出来~ 两头都ping这，然后中间的sw上tcpdum抓包结果没有，看来问题不是在中间设备，这话说的，中间设备的br0没起来，就好比a----sw-----b的sw两个网口是down的，你说是不是中间设备问题，问题就是br0没有UP，ip link set br0 up即可。重要的事说两遍~ 方法2：centos7的专门工具nmcli，可以存盘 上次方法1 的配置 然后开始使用nmcli方法进行配置 创建br0接口 nmcli connection add con-name mybr0 type bridge ifname br0 加入成员口 nmcli connection add con-name mybr0-eth0 ifname eth0 type bridge-slave master br0 nmcli connection add con-name mybr0-eth1 ifname eth1 type bridge-slave master br0 其实就是新建了配置文件 加入两张网卡并启用网桥br0 nmcli connection up mybr0-eth0 nmcli connection up mybr0-eth1 ip link br0 set up 你看上图的mybr0是黄色对吧，其实在终端里是红色，也就是说是down的，是有问题。不管是什么颜色，都要up起来的。 此时br0拿到了个地址，就是DHCP的了，这个地址就是管理IP咯，类比于二层交换机的SVI口，类比于透明墙的L3地址。 其实我在做实验的，发现一样需要ip link set br0 up 的，即使用nmcli 来做br0，一样默认也是DOWN的。 以上就可以了，均测试OK Ubuntu网络配置 网卡名的修改和centos 7一样： 网卡配置 切到root 查看IP地址 nmcli 还看不到，ip a是有接口的 目前处于down状态 尝试启用接口，并未拿到地址， 查看网卡配置文件 cat /etc/netplan/01-netcfg.yaml yaml文件和python一样，缩进必须严格统一，否则报错。 查看网卡配置文件，发现写的是ens33而不是eth0，之前改过名字了，所以配置文件里的名字也要改 改成eth0，注意缩进两个空格 重启服务，netplan apply类似于systemctl restart netowrk。 此时就能DHCP动态获取地址了 https://ubuntu.com/server/docs/network-configuration 按图配置好后，重启服务netplan apply，后cat /etc/resolv.conf里是没有DNS信息的，但是实际上是在的 使用systemd-resolve --status进行查看具体配置的DNS信息 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"14-进程、系统性能和计划任务/14-进程、系统性能和计划任务.html":{"url":"14-进程、系统性能和计划任务/14-进程、系统性能和计划任务.html","title":"第十四章 进程、系统性能和计划任务","keywords":"","body":"第十四章 进程、系统性能和计划任务 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"14-进程、系统性能和计划任务/1-进程管理和内存分配.html":{"url":"14-进程、系统性能和计划任务/1-进程管理和内存分配.html","title":"第1节 进程管理和内存分配","keywords":"","body":"第1节. 进程管理和内存分配 进程概念 进程，正在进行的程序，正在内存中运行的程序；若没有运行，只是安装的系统中的一个软件而已。 ls如果不运行，只是一个文件；当输入ls回车的时候，就会把这个文件读入到内存中，通过CPU读取ls程序里的一条条指令进行执行，最终命令执行完毕，结果输出，程序退出，程序在内存中占用的空间就释放，这个进程也就结束了，所以进程的启动、运行、终止，就是进程的生命周期。 此外有些程序是随着计算机开启后就自动运行的，这种进程一般叫做守护进程，表现为随着计算机启动而运行，随着计算机关闭而终止执行。也可以人为通过工具干涉自动的行为。 进程，不管是普通的进程还是守护进程，本质上都是消耗系统资源的一个单元。 此外还有线程、协程。 每个进程都会分配相应的资源： ①分配独立的内存空间 ②操作系统分配唯一的编号PID进程ID ③其他属性，比如哪个用户运行的此进程 task struct ，进程运行的时候，系统会给他分配一个task struct任务结构表，这个表里存放了进程的PID、谁运行的、占用了哪些内存空间等其他信息。 task list，任务列表，就是多个相关联的task struct互相调用吧 第一进程，centos6上市initd，centos7上是systemd了 systemd不在PATH路径中，是在👇这个路径下 centos7上的init其实没了，只是systemd的软连接 而centos6就是真实的init 第一进程开启之后，然后子进程一般都是fork()函数创建，clone()很少用；创建子进程后，一般采用CoW写时复制机制。 所谓CoW写时复制机制就是 1、父进程已经分配了一定的资源，当创建子进程的时候不会立即给这个子进程分配内存空间，也就是说👇两个父子进程都采用的相同的内存空间 。 2、当子进程涉及到数据修改的时候，就会立即复制父进程的内存空间，然后将子进程指向这块新的内存空间 这就是CoW(copy on write)，只有数据发生变化的时候才会产生复制的行为。 这样就比较节约内存空间。 在cp命令的说明中有提到CoW 进程、线程、协程 进程时独立占用资源的单位，进程A占用的资源和进程B占用的资源时不相干的。 进程相当于项目小组； 线程相当于完成项目的人，所以进程里至少得有一个人--线程。项目复杂了就需要多个人来完成工作，进程里就有多个线程了。 一个进程的任务切成多个小任务，每个任务由单个线程来完成。 线程从哪里可以看到，pstree -p可见 花括号就是线程，其实花不花括号无所谓，一个线程也是线程，如下： 这种就没有多个线程，因为进程下面就一个线程，所以没有花括号。 进程、线程的资源分配都是由操作系统来完成的。 协程和开发语言相关，有的就没有协程的概念，python里有。 协程相当于线程里独立执行的一个语句块；协程的之间的调度由程序员来控制的。 ▲进程和线程的控制由操作系统来完成的；协程的控制是由程序员来完成的。 进程运行必然要分配内存空间，而内存空间的分配是以页page为单位进行分配的。 之前学习文件系统的时候，磁盘上保存文件的最小单位也是4K，那里也有一个最小单元。4K是默认值，额可以修改，一般不改。 内存中给进程分配内存大小，也有一个最小单元，也就是page=4K。这个页最小单元不能改。 ▲磁盘给文件分配磁盘空间是4k4k的给；内存给进程分配内存空间也是4k4k的给。 进程在运行的时候以为自己拥有所有计算机的内存空间，它并不知道还有别的程序在运行。 MMU是CPU里的一个固件单元，就是CPU的一部分咯，复制计算虚拟内存和物理内的映射关系，而这个关系要存下来方便快速取用的，TLB就是这个存下来的映射表。 在一个进程看来，使用的是系统所有的内存就是那么多；而实际上只是物理内存里的一部分，这一部分可能是连续的 可能是离散。所以虚拟内存空间自然也是线性的连续的空间了。虚拟内存空间也叫线性内存空间。 1、用户空间3个G、内核空间1个G 2、用户空间就是给应用程序用的，每个进程都使用的是虚拟地址空间 3、每个进程的虚拟空间又可分为： ​ ①代码段：比如ls二进制程序代码，放在这里； ​ ②数据段：比如程序运行需要的变量，放这个空间； ​ ③BSS:Block Started by Symbol segment: 也是存放变量，不过是一些没有初始化过的变量，比如申明了int或者flat的变量，但是没有赋值。 这个变量n就放在BSS里 这个n就放在数据段里 很好记，有值了就是有数据了，就放在数据段里了。 4、堆：存放系统中需要使用到的一部分内存空间，该空间可动态调整，算是公用的空间；需要时分配，不需要是释放。比如某些进程比如排序类的就比较占用内存，就需要分配一些堆的空间，大概这个意思咯。 5、栈：函数里用到的变量，和堆head不同在于--看下面这段吧，讲的看起还不错 程序的运行场所是内存，栈和堆是进程的虚拟内存中的两部分区域。 当程序被执行时，程序代码，你所创建的变量、常量等都会被压入栈空间里，栈是程序代码的执行区域。栈的内存地址是连续的且被一一记录，所以说当你创建了一个变量(比如int var = 1)，我们就可以通过var这个变量来访问变量的内容。在这里，var就存放在栈中，它的地址已经默认被编译器计算好了，调用过程也不需要你涉及到有关地址的操作。更直观的感受是数组，数组里的元素在栈里面是连续排放的，相邻两个元素的地址相差1。 而堆是不同于栈的另一部分区域，系统会给每个程序分配一部分栈空间让他们能够运行起来，问题就是栈空间必然存在不够用的问题，而堆不属于程序，堆是独立的，是公用的。只要你new，就可以得到相应一部分的堆空间。 有栈，为什么用堆？ 栈里面的东西有生命周期，说俗点就是变量作用域，你在函数内部创建一个变量，函数调用结束这个变量就没了。而堆里面的东西独立于你的程序，new之后，除非你delete掉，否则一直存在。 有什么要注意？ 堆里面申请的东西，是随机分配的，不像栈里面的地址都已经计算好了。所以申请了堆空间之后一定要创建一个指针保存你所申请到的堆空间的地址。不然就找不到你申请的空间了。 堆空间的东西申请好，在用完之后一定要delete掉，以防止堆溢出。 ———————————————— 原文链接：https://blog.csdn.net/u012460314/article/details/52355668 1、创建：fork()函数创建一个程序，先进入了就绪态(ready)； 2、就绪态ready：就是进程需要的资源都准备好了比如内存空间、文件、变量、代码等，准备好了CPU就可以来执行这个程序了。 3、执行态：如果进程执行时间较长，多个进程之间就存在 进程调度 ，而每个进程会分配时间片，时间片用完就回到就绪态，等待下一个时间片的分配。因为时间片特别短，所以即使是单核CPU给人的感觉也是多个程序同时跑的。 ​ 时间片用完，没有执行完，进程就得停止(注意这里不是阻塞哦 不要理解错了，然后这里的停止不是普通意义上的停止就是不断地保存现场和继续执行地过程)，就需要保存现场--将执行的状态保存下来，待会下一次时间片分配了继续执行。这存在一个状态切换的过程，就会带来一点资源的损耗，比如CPU的寄存器的值的存储和清空以及再次读入。 4、阻塞态：进程执行中如果涉及磁盘IO，磁盘IO的耗时远远大于CPU的，所以这个进程就停在这--阻塞态，等磁盘IO的结果出来 再继续执行。 ​ 注意阻塞态完了后 也就是得到结果了 I/O完成了，程序是进入就绪态，才能得到时间片继续运行，所以说阻塞态的进程停在那，实际上也就是现场保存在那，等I/O的结果在继续要时间分片。所以阻塞态必然是进程停止的--这个停止不是kill也不是systemctl stop xxx，而是“不再续杯时间片”的保存现场，I/0有了结果才会去进入就绪态去要时间片去继续执行程序。 5、终止：此时程序执行完毕，所有占用的资源得以释放，比如内存、占用的文件等。 LRU介绍 Least Recently Used 近期最少使用算法，释放内存 在系统中很重要的一个内存使用算法 https://zhuanlan.zhihu.com/p/34989978 不管是大佬讲的还是博客写的，其实主要的理解思路就是：读取数据时从硬盘--写入内存---从内存读取到屏幕打印或者其他输出， 然后PPT也好，博客也罢的图片，都是站在从内存读取数据的角度出发去谈这个事情的，比如读取4 内存中有就调到最优，读取1 内存中没有就压栈的方式，垫底的淘汰掉。 上图的物理块 说的就是内存块的意思。 LRU这个近期最少使用就释放掉的短发，经常用于缓存的处理， 数据从硬盘里读入到内存，再从内存中读取到所需之处，为了提高效率 就会在内存中开辟一处空间用来存放数据，LRU算法就应用于这个内存空间，从而就得到了常用数据就放在了这块空间。而这个空间就叫缓存cache。 面试官-问：常说的经常用的数据放到缓存中，是怎么就做到的，怎么就把经常用的放进了？ 你-答：LRU及变种，回答完毕。 面试官-心里想：被他装到了。 其实这会我学到这，我想搜索LRU及其变种还有之前看到的LFU的具体解释的，但停了一下，判断了一下，不是懒的去查，而是继续往下看，后面看需要再 在这个点上继续深入就好，进一步思考，很多时候大脑需要的是停一下也就是冷静的思考能力，不是被某一个情绪左右，这其实就是真正的自由 学到这，思考一个问题，既然内存都是虚拟内存\\线性内存，也就是每个进程认为是独享的内存-是独立的，那么进程之间要互相通信，也就是内存要互相能访问才能互相通信对吧，所以就需要进一步在内存空间上做文章。 在进程内部的多个线程之间通信还是比较容易的，因为它们都是公用一块内存空间的。而进程和进程是互相独立的内存空间。 进程之间通信分两种 1、两个进程在同一台主机上 ①pipe管道： 比如没有名字的--匿名管道，如：|，题外话这个\"|\"念啥你们知道么，哈哈~ 比如有名字的管道--表现为一些文件，如p打头的 具体就是，进程A把数据传给管道，进程B从数据读取管道。这样两个进程之间就可以交互信息了，思考--这里面是否存在半双工问题啊？是的，是半双工的。 如果希望同一时刻，两头都可以发送数据--全双工，就要用到socket了。 ②socket套接字： socket套接字也分两种 a、unix套接字文件s打头的文件，这是一个全双工的管道 b、ip+port socket，这个写到下面的两个进程不在一台主机上片段里 ③signal 信号 通过一些命令可以给进程发信号，而进程收到这个信号以后，会按信号的定义去操作。 比如，sleep 100的时候 这个ctrl c 就是向这个sleep发送了信号导致其退出。 至于信号有哪些种类，有什么作用，第4节再说。 ④shm: share memory 共享内存，进程和进程之间共享内存 堆是不是就是共享内存呢？ ⑤semaphore：信号量，一种计数器 比如有10个资源，100个进程使用，当然一个资源同时只能被1个进程使用； 如果此时10个资源全都被占用，此时这个semaphore计数就为0； 如果有个资源释放出来了，此时semaphore技术就为1； 以此类推，通过这种方式，进程之间也能通过信号量这种计数器知道资源的使用情况，从而合理分配资源，从而实现了资源的使用上的进程之间的沟通。 2、两个进程不在一台主机上 更多情况下，两个进程并不在同一个主机， ①其中就有socket里的ip+port这种方式。 提到ip+port，就会想到\"面向连接\"和\"无连接\"这两个叫法，一个是tcp一个是udp，而连接就是双方的信息在彼此的内存中进行动态的持续的维护；无连接--就是仅仅初始化 但是不维护咯。比如TCP的滑动窗口，重传这些都是连接这个概念里的内容，UDP显然没有维护这个概念。 https://www.ietf.org/rfc/rfc793.txt里搜索connections关键词可到标准定义 国外的文字表达再翻译国外，往往需要咀嚼一下，比如面向对象编程，面向过程编程，面向连接的TCP，这里的面向XXX，可以体会一下 而面向连接，这连接在了、初始化了，面向它，就意味着要表达它维护它；UDP才不会面向连接，自然不会维护它。了解，这就是最底层的思维，丝滑了把，舒服了吧，无用了吧，费时间了吧，有点点意思了吧。 IP是确定主机，port是确定进程服务，这种sockt是比较底层的方式，一般开发不这么用，比较多地是使用RPC和MQ来实现不同主机进程之间的通信。当然PRC和MQ的底层还是socket(ip+port)。 ②RPC: remote procedure call远程过程调用 情形如下，A上的程序执行一段；然后把数据发给B，调用B上的程序继续执行，得到结果 回传给A；A拿这个结果继续执行。这就是远程过程调用。 ③MQ： 消息队列 左边每个进程A B C 想互相通信，可以通过右边的MQ消息队列来中专，你写我读，就可以了。 进程优先级 注意，在实际系统上优先级不是0-139，而非实时进程的优先级100-139转成了nice值-20到19同样也是比小的。 优先级分为 实时优先级和非实时优先级； 是这样表达的，进程分为两种 紧迫性高的和不高的，高的就是实时处理的，就叫实时进程，不高的就是普通进程。针对实时进程需要优先调度也就是优先级高0-99，这种优先级也叫实时优先级。 1、realtime实时进程的调度方式： ①优先级高的会抢占优先级低进程的资源，0-99比小，0最高； ②如果两个进程优先级一样就遵循FIFO或RR。 ​ FIFO：谁先来，就先处理谁；RR：轮询 每个同优先级的进程互相轮着来。 2、非实时进程也就是普通进程的调度方式 应该也是一样的队列机制肯定也有FIFO\\RR的。 优先级也是按时间片的规则来的，也是存在时间用完就要暂停的情况的。 原则优先级的比较也是存在一个排序的，而排序就要用到什么冒泡、插入等排序的方法，这样就导致花费CPU花费时间的 效率较低，所以实际会存在1-139个队列，将对应的进程划分到不同的队列里去，从而直接达到了排序效果。 当P1进程时间片消耗完后就把P1放到过期队列里，P2时间片用完也移入过期队列；当运行队列1的进程都没了之后，该队列空了 从运行编程过期，此时将过期队列2变为运行队列。 显然这里的队列机制，和我们网工学的QoS的队列类似的，但是这里大佬讲的太浅了，有机会所谓机会就是需要用到的时候，可以再搜一下相关资料。 centos中优先级情况，主要是显示和修改方式 system的优先级 和 命令查看的结果 并不一致，下图是大佬总结的 chrt命令用来修改realtime的，全称就是change realtime， 注意一下👇centos chrt写99就代表0优先级，0就对应上面的99优先级，其实就是centos 优化了一下变成越大越优╮(╯▽╰)╭ 问题来了：上图中，值是越大越优，还是越小越优。回答：越左越优，屌不屌~。 system优先级是0-139区间，但是对应到命令后往往不是这种大小，这个要注意的。 centos的命令 1、chrt命令：是修改realtime； 2、nice命令：就是修改nice值得； 3、top命令里的PR列：看法又不一样了； 4、所以有这里有个小市场--就是写个脚本统一下，哈哈。 TOP里的PR，别看错了，不是NI。 上面讲的PPT如下“： Big O是啥哦？ 进程数量不同，最终的比较的效率存在高低的，存在一个时间复杂度，和软件开发的效率有关，大佬如是说。 工作效率是 当数据量达到一定规模，很多以前正常的工作的，后面就开始出现莫名奇妙的问题了，这就是时间复杂发生了变化，计算不过来，自然各种问题就出来了。这确实挺吓人的哦，你想从故障找规律好像是不可能的了，因为没规律可言了就是处理不过来了。 抢占式多任务和协作式多任务 抢占式多任务：是按照时间片分配资源，进程的时间片消耗完，CPU理解被内核拿回来，然后继续分配，不会被某一个进程卡死了就一直占着资源。 协作式多任务：早期的dos，就是没有时间片的概念，就是一个进程执行，就等他执行完，才释放资源。这样会导致某个进程出问题，连整个操作系统都僵在那了。所以以前老版本的windows动不动就蓝屏死机。 前台进程和守护进程 前台进程依赖于tty线程，所以有2中处理方法 注意console就是本地终端登入的不存在这个情况哦，你怎么关，无非是关闭控制台嘛，关了再进去ping还在的 1、nohup xxxxx & 记得exit安全退出终端，否则不生效 2、screen稳当就是显然没有nohup一条命令帅气 守护进程不是用户登入上来运行的，所以不存在tty关闭就终止的情况。 进程状态除了上面已经讲过的，还有 睡眠态： 可中断--睡觉，叫一下就醒来了； 不可终端--冬眠，回暖才会醒过来，就等着你的IO结果，放到内存里了拿到结果了，它才会继续工作否则只能在这等着。 停止态：冻僵了？消耗资源不，既然暂停于内存 还是消耗点点资源的吧？不过不会消耗CPU，因为不会有时间片分配给它。 僵尸态：异常状态，正常就会释放资源，但是僵死，还是占用内存资源的。因为已经死了，kill也杀不掉了，也激活不了，只能重启计算机处理这种异常状态。 举例mingetty就是 登入界面 的提供程序 上图一直不登入，这个程序虽然还在运行，CPU是否消耗-否，内存是否消耗-是。 ready是什么都准备好了，就等CPU的时间片了。上图是还差输入ID的，显然还没有准备好所有条件，还不是ready就绪态，还不给它分配时间片也就是CPU的使用权。 所以大部分的进程都是睡眠态。可以唤醒，键盘输入回车后，就发送一个 让他进入就绪态。这里应该有个点，就是睡眠态如何进入ready态。一旦进入就绪就等待CPU的时间片进入运行态。 进程分类 1、CPU密集型：CPU消耗大，内存硬盘消耗小，比如数据计算、编译安装等 2、IO密集型：磁盘靠大文件，CPU就发个指令就完了，但是大量数据需要从磁盘考入内存，然后内存到网卡发送出去，这就涉及IO。 早期的时候CPU是参与IO的，说明如下： 1、CPU发送cp f1 f2复制指令后 2、这个过程中，所有的数据全部要经过CPU，当然这是在说以前 3、现在内部架构发生了大变化 CPU只需发送一个指令给DMA，然后DMA就去完成磁盘和内存的数据交互。 这里后面重新画图吧。 DMA有了，CPU就不忙了 到底是CPU忙、IO忙还是网络忙，通过命令去排查。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"14-进程、系统性能和计划任务/2-进程管理工具.html":{"url":"14-进程、系统性能和计划任务/2-进程管理工具.html","title":"第2节 进程管理工具","keywords":"","body":"第2节. 进程管理工具 进程启动后，相关信息会自动放到/proc里 上图的1，就是systemd这个系统启动后的第一个进程。进去后一堆信息(比如内存、挂载等信息)通常不直接查看分析，而是通过命令去看。 ps 默认只显示当前这个tty线程的进程 再开第二个终端跑一个sleep 再开第三个终端跑一个ping 但是在第一个tty里，ps只能看到自己的进程 ps 特殊在，它是一个老牌Unix命令，支持3种风格的option选项 man 帮助种也是如此写道 - h unix风格 -- help GUN风格 h BSD风格 tar xvf 和 tar -xvf 都行 ps a查看各个终端窗口下的进程 a看不到守护进程，和终端没有关系的进程是看不到的。 ps x 查看并非所有进程，包含守护进程这种和终端无关的，也包含终端下运行的进程 ？就是和终端无关的；终端下的也会给你显示出来的。 ps ax会多一些 ps u显示进程所有者的信息 顺便看下列标题 ping 一直在运行，但是不消耗CPU，time这一列0:00就是说占用CPU的时间片少。 ps aux 看所有进程的信息，包含守护、终端进程、带进程所有者 ▲插播-1 iptables如何实现代理 这种方法有时候不生效，所以后来我还是用的softether去搭建的 这种方法不用动路由表，其实就好比windows的代理，就好比clash的“非tun虚拟网卡模式”，现在看下来这种方案更为灵活： iptables -t nat -I SHADOWSOCKS 1 # 添加用 iptables -t nat -D SHADOWSOCKS 1 # 删除用 iptables -t nat -D SS -p udp -d 0.0.0.0/0 -j REDIRECT --to-ports 1080 # 删除具体 iptables -t nat -A SHADOWSOCKS -d 167.xxx.xx.xxx -j RETURN # vpn的建立隧道地质得走本地网络出去 iptables -t nat -A SHADOWSOCKS -d 10.0.0.0/8,172.16.0.0/12,192.168.0.0/16 -j RETURN # 私网 iptables -t nat -A SHADOWSOCKS -d 127.0.0.0/8,169.254.0.0/16 -j RETURN # 本地回环和linklocal iptables -t nat -A SHADOWSOCKS -d a.b.c.d/n -j RETURN # 公司出口IP iptables -t nat -A SHADOWSOCKS -d a.b.c.d/n -j RETURN # IDC公网IP iptables -t nat -A SHADOWSOCKS -d a.b.c.d/n -j RETURN # 云上公网IP iptables -t nat -A SHADOWSOCKS -d a.b.c.d/n -j RETURN # 本地APP访问或者调用的外部IP，这些都是走本地网络，不走代理的。 iptables -t nat -A SHADOWSOCKS -d a.b.c.d/n -j RETURN # 你要是闲的蛋疼，还可以加上所有国内IP地址段，你不怕CPU不忙对吧。 iptables -t nat -A SHADOWSOCKS -p tcp -d 0.0.0.0/0 -j REDIRECT --to-ports 1080 # 剩下统统走代理，注意UDP其实也需要代理，不过要排除UDP 53，同样TCP53也要排除的，这样一些新的QUIC协议就能应用了。 还差一个排除注意点，单个APP的她可能也会本地调用外界的公网IP(这个是不走代理的)，所以也需要排除。 ▲插播-2：业内趋势QUIC体验 H3介绍：https://blog.51cto.com/u_14888059/3790697 https://network.51cto.com/article/625999.html https://new.qq.com/omn/20210504/20210504A01Z1T00.html 谷歌开启H3：https://zhuanlan.zhihu.com/p/108198664 插件下载：https://chrome.google.com/webstore/detail/http2-and-spdy-indicator/mpbpobfflnpcgagjijhmgnchggcjblin 插件显示对比：绿色是H3，蓝色是部分H3没有H1，灰色是有H1。 企业微信有用QUIC也就是H3，CDN里也支持，谷歌youtube都支持--速度快很多 插播结束，继续linux的ps命令 ps aux看的较全，注意用户通常是root，也有非root，就是以系统账号运行的 切换用户看下 再来看下普通用户运行passwd的情况 发现竟然是root运行的，其实这就是SUID的原因，前文已讲 所以ps aux看到的用户严格来讲是有效用户，是wang运行passwd后实际生效的运行的该命令的那个用户。 再看下ps aux的CPU占用百分比，基本都是0，搞一个不是0的。 单核是100%，两核就是200% 内存情况： RSS是常驻内存，进程申请内存的时候，说是这么多，但并不是马上使用，所以RSS就是目前使用到的内存空间，而VSZ就是申请操作系统承诺给到的内存空间。 VSZ和RSS的单位都是以KB为单位的 tty ？就是和tty无关，不是终端上来的 STAT 状态就是进程的状态，运行态、就绪态等，其中 运行态表现为R，基本上看不到 因为你敲这个ps aux的时候肯定是运行态的嘛，同理 敲的就是这个命令，肯定会给你一个grep 的进程的，啊，ps aux里是没有sssss的，但是你既然grep sssss了就是要运行grep程序的，所以当下就有grep的进程了。 sleep 100 跑起来后也不是R运行态 pts/0就不是当前的pst/0窗口 当前是pts/1终端， 好奇这个“TTY是?号非当前终端”的sleep 60哪来的啊？ 这个sleep不是bash命令，估计是系统默认的，之前没关注过，我这个是centos8的，我去其他centos7上去瞧瞧还真有，rocklinux没有 最小化安装的centos7没有sleep这个东西 然后回到这个STAT 的R这些状态 大部分处于S休眠状态且是可中断的， 还有不可中断的休眠 T：stopped是停止态 Z：是僵死态 +：表示前台执行 l:多线程 会话表现形式有qq的一个窗口，浏览器的一个页面，而这些都是涉及到进程的，具体解释如下： https://blog.51cto.com/u_15015138/2555390 这个命令很棒，不过要区分一些ps f 和 ps -f ps auxf 可见看见树形结构的，同级的进程，父子进程等信息👇 ▲插播-3 hostname你真的不会改，具体如下： https://blog.csdn.net/zhaogang1993/article/details/82769439 ps继续，START是什么时候开始的，TIME就是总的CPU时间(是按时间片分配的) 排序功能以及部分显示功能 ps o过滤 加上ax选项进一步显示所有终端的信息 按CPU排序，先搞一个消耗CPU的进程 ps aux k %cpu 可见排序是升序的--根据CPU的占比 降序怎么排，tac咯 cat和tac以及rev对不对~ 上图是关闭图形界面的程序gnome，降低一些内存的消耗。 降序还可以这样 上图的--sort可以换成k的 再到centos6上看下具体的命令 -e等价于ax，在行数上，但是列上👇少一1列： 配合-F显示多一些 PID是进程id，PPID是父进程ID。 C列，表示CPU的百分比，不过是取整的。 STIME是开始时间 TIME是CPU的分配到时间片换算的累计使用CPU的时间 这个占用CPU的时间就比较多了。 老实讲有效和真正，并不能很好的区分两个选项的意思 -u就是程序最终谁来运行的，最终 执行 的 用户 -U就是程序开始时谁来发起运行的，开始 发起 的 用户 ps aux就看所有咯，然后单看wang用户的就用ps -u wang u， -u wang是最终以wang用户来运行的程序 -U wang就是wang敲的命令，通常是SUID这种passwd带SUID所以wang敲命令，但是是以root运行的程序。 所以常见组合有 ps aux ps -ef 其他就看上面的具体需求用哪个了 这是查命令的，敲的命令，如果时脚本呢？ 直接ps -C f1.sh就行，还挺不错的 我的测试 再开一个终端，发现 并没有，赋予x执行权限再看，其实很简单，你是bash f1.sh跑的，自然要看bash进程，而不是f1.sh，你给了执行权限，直接f1.sh跑的就能看到了👇 注意. f1.sh这样也是看不到的 必须是f1.sh作为命令一样敲入的，而不是通过source bash 或者.来运行。具体再看看下面 bash xxx是通过bash执行的f1.sh，然后f1.sh里面又执行了ping ./f1.sh是通过文件本身什么的shell申明的类型直接执行的，ps -C f1.sh所以查得到 将bash改成sh测试把 看到没，./f1.sh就是直接执行f1.sh文件的，只不过是依据文件里定义好的shell类型去执行的，所以ps -C f1.sh就认 而换成source和. 的话又不一样了 也好理解，这两个家伙是直接在当前bash下以当前bash执行f1.sh的，不会再开启子shell进程。所以这两个家伙source和.你用ps -C bash是看不到的，因为这两种方式运行的程序他直接在当前bash跑的，所以层级比上面少一层，ps -C bash不会增加。就是这么个道理，老哥我研究得到位了把。可惜咱环境不care这些东西，呵呵。也不对，基本功也确实要有的。 再来，如果f1.sh里面就是光秃秃的一行ping 127.0.0.1 对比定义文件的shell后，就知道了，👆上图是文件里没有定义shell于是自动给你用当前的bash，下面是文件里定义了shell的👇，所以其实是跟着文件的shell走的， ps -C bash和ps -C f1.sh分别查看上下两种情况，上图会多一个bash，下图是bash不多，多一个f1.sh，因为下图的shell是集成在f1.sh里的，是通过f1.sh开启的shell。 然后ps -C f1.sh上图👆肯定看不到，因为开了一个子bash；下图👇可以看到是因为是直接运行的f1.sh文件自然看得到，虽然文件里申明了shell的。 所以说一万到一千， 1、文件无执行权限 bash就是开启bash子进程 source或.就是直接当前bash跑的 2、文件有执行权限：①申明了shell；②未申明shell ./xxx.sh执行有申明，就是直接跑的是文件当命令执行的，利用里面的shell,跑的是文件本身； ./xxx.sh执行无申明，就是开启当前shell类型的子进程通常就是bash来执行文件的，跑的是bash； 查看nice优先级 -是用的系统优先级 -20这种就是nice，只是对应system priority的后面一部分[上一节里有讲] 这个不管是centos8还是centos7都是这个样子的，nice是-20~19没毛病 但是pri这个它实际上是翻转过来的system优先级，上图-20对应的就是39。 看到这我TM已经不知道优先级比小还是比大了，NND，搞这么乱的，不能统一下的吗！ 通过renice调整ni值，既然是nice就只能是-20是到19之间了 -n是指定新的优先级 所以▲总结一波，ni是-20最优--比小，pri是139最优--比大。 但是官方自己都疏忽了 altime就是实时进程的优先级--实时优先级。 大部分进程都是nice优先级，实时优先级的少。 直接以某个优先级运行程序，有个无聊的点，下图ping的是127.2，系统会自动识别为172.0.0.2 ps axo pid,ni,pri,cmd 可见ping以优先级10开始运行的，如果是负10，就是nice --10 ping 127.0.0.2 上面的-10和--10都不太好，正规写法是 查看进程跑在哪颗CPU上 通过ps axo pid,cmd,psr查看 上图可见敲的dd命令当前是绑定在cpu 3上的，也就是第4颗CPU。 但并不是固定在CPU3上跑的。 再来看一个ping 多用ps axo pid,cmd,psr看几次，就可以看到不是固定在CPU4上跑的 如上图，ping 172.0.0.1，进程的CPU切换了，就会导致 缓存失效 CPU里 也 有缓存，有L1、L2、L3 CPU以两颗举例，各有各的L1、L2，但是L3是共用的 理论上L1缓存最快，L2次之，L3最慢 它可以把内存中的数据放入缓存中，下次取就直接从缓存中取了，速度就快了很多。 问题来了，如果一个程序跑在CPU1上，那么L1和L2也肯定用起来了，如果该程序跑到CPU2上了，此时之前的L1和L2缓存就无法利用了，所以CPU一切换，就导致效率大大下降， 解决方法，将进程就绑在某个CPU上。 同时也会带来CPU的利用率可能不均衡，就是你绑的那个CPU负载就比较高，这个可以将nginx的多个进程分别绑到不同的CPU上，然后这个机器就跑nginx。这样就比较好了 nginx的配置文件中，是可以把nginx的进程和CPU做绑定的。 怎么绑，taskset可以 这是一个外部命令 用这台机器，就两个CPU，来做实验 dd下 通过ps axo cmd,pid,psr可见当前是跑在CPU0上的 由于现在没有进程和它竞争，所以CPU不会飘，再来一个ping -f 去抢CPU 然后可见dd命令的cpu飘走了 然后视频中老师的xshell崩了，就用终端去演示了 现在是两个dd，然后不断地通过ps axo pid,cmd,psr去看CPU切换， 发现两个没切，于是再加一个dd if=/dev/zero of=/dev/null 然后继续用ps axo pid,cmd,psr去观察 结果半天没看到CPU切换的情况，不过上面有两次已经切换了，就是没有出现频繁换的现象。 通过taskset -p xxx可见当前进程ID可以跑在哪个CPU上，注意下图，跑在CPU0上，但是看到的事mask 3 mask 3就是11，就是说当前是2个CPU，11就是打开开关，两个CPU上都可以跑。 如果是下图，就是当前是4个CPU，这个1332进程可以跑在4个CPU上。 下面开始绑定 ping 127.0.0.1这个进程，绑到CPU1上去 绑定的命令为taskset -cp 1 xxx，注意这里的1就是1号cpu，如果你想绑到0号cpu，就写0，如果你想绑两个，就写0,1，这就没意义了，缓存又不能固定了，所以绑就是绑一个cpu号的。 此时进程29654就变成1了，并固定在1了 taskset -cp 0,1 xxx就是0号cpu和1号cpu都可以用，最终taskset -p 查看就表现为11也就是3了。 再看个CPU多的情况 0-7号CPU ff就是对于7969这个进程来说，8个cpu全部可以用。 现在希望该进程就跑在0号CPU和4号CPU上 0,4对应的affinity mask就是0001 0001 上图其实就是一张图拆开来讲，原图如下 绑到0号和4号CPU了，原来的3就跑到0或者4了👇 现在有个问题来了，上面的taskset -cp x xxx都是绑的进程ID，进程ID这个是会变的，所以还需要优化 用pidof去获取进程的ID，前提是这个命令dd就对应一个进程编号。 如果是bash，就会看到好几个进程ID： 所以进程绑CPU的命令为taskset -cp NO. `pid xxx` 这是taskset优化的手段，当然有些软件比如nginx本身就可以绑CPU，无需手动执行taskset命令。 以上就讲了ps的一些常见组合 示例 pgrep=grep for process 感觉pgrep就可以了，上图的那个ps -C httpd,sshd -o pid=没啥用。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"14-进程、系统性能和计划任务/3-进程管理和性能相关工具.html":{"url":"14-进程、系统性能和计划任务/3-进程管理和性能相关工具.html","title":"第3节 进程管理和性能相关工具","keywords":"","body":"第3节. 进程管理和性能相关工具 查看某个终端tty下的进程 区分u和U，这个ps命令，上一篇里也有。 pgrep还支持正则 加上-l或者-a显示进程 pidof 虽然是软链接，但是功能不一样，也就是说，可以创建多个软链接指向同一个文件，但是每个软链接的功能不一样。 uptime dd if=/dev/zero of=/dev/null来消耗CPU然后uptime观察看下 load average这个数值也是进程数量的意思。 一个内核，一搬load average不大于3，所以24是可接受范围以内。 超过24就认为每个内核有3个以上的进程在排队，系统就非常慢了。 uptime一个是命令，一个是proc/uptime文件 单位都是秒，一个系统启动时长，一个是空闲进程总时长(按总CPU数计算的)。 平均下来每个CPU的空闲时间就是/8，7717秒空闲，8604s开机时间，所以大部分时候是闲着的。 w 命令和uptime也是重叠的 top的一行也是uptime 所有进程个数是223个， 3个运行的，220睡眠的，0个停止，0个僵尸态。 cpus的分配情况，us用户空间占用了2.1%，sy内核空间占用了10% 其实us用户空间占用高才是好的，因为这代表着应用程序占用内核率高，而应用程序代表着生产力。 各种软件都是工作在用户空间的 从这个CPU的两个值就可以看出来，你的系统忙不忙，合不合理。 ni是进程的优先级调整 id是空闲，100就是cpu100%空闲，没事干。 wa是wait等待时间，有些进程需要等待资源的访问，准备好了才能运行。 hi是硬终端 si是软中断 st是被盗取的时间片 中断，就是打断了CPU的正常工作。中断什么时候发生呢？ 看下用户空间-内核-硬件的模型图， 内核kernel和硬件的沟通就是通过 中断，比如键盘按一个键，内核就会捕获这个操作，用中断方式响应用户的请求。 当你每次在键盘上按下一个按键后，CPU 会被中断以使得 PC 读取用户键盘的输入。这就是硬中断，还有软中断，比如程序的异常 st：steal，被盗取 早期的计算机操作系统，不支持不理解虚拟机里运行的进程， windows任务管理器打开，看到当前进程，这些进程只是windwos里的进程，然后VMwareWorkStation里跑的进程占用的时间片，就被称为ST-被盗取的时间。 后面会讲KVM，类似于windows的VMwareWorkStation。 内存，总的、空闲、用了多少、被buff/cache占用了多少 然后top下面的主体部分 3s默认的刷新间隔，可改按s建后改。 默认是按CPU利用率高到低，显示的，测试，跑个dd ，top里就看到第一个了。 PID、用户名、优先级PR--这个PR是TOP的PR，它在linux优先级里的情况如下 NI就是nice优先级 VIRT是系统承若的内存、RES是实际使用的物理内存、SHR是共享内存 TIME+是总的CPU分配时长 OOM：out of memory内存泄漏 一般某个进程的内存不断在涨，就认为可能发生了OOM了。 -H显示这个进程下面打开的线程 使用pstree -p 找个多线程的进程PID 花括号就是多线程 这就打开了某个进程里的线程。 top -H -p `pidof xxx` # 这个pid会不会pidof xxx取出来多个啊？就会出错 free看内存 centos6和7不一样 6的buffer和cache是分开的，7是合二为一的 buffer是写，改一个文件后，要写数据， 要先放入buffer缓冲区的，然后buffer里按一定的队列次序写入磁盘。可能就是改一个字符不会给你存盘 就是放在buffer里，等你改了很多字符后才会统一从buffer里给你写入磁盘。这样能提供效率。 cache是读，数据的读取，放入缓存里，下次读取直接从缓存里读取就行了。 默认是KB单位 cp一样会增大cached 看下内存使用情况的计算 used - buffers - cached = 真正使用的内存空间 free + buffers + cached = 真正可用的内存空间 但其实你用echo 3 > /proc/sys/vm/drop_caches释放也不可能将buffers和cached全部释放掉的，所以也没有上面说的那么富裕。 下面是centos7的内存计算方式 total = used + free + buff/cache available 是系统自动给你算的，它不是简单的free + 部分buff/cache，你看上图的available就小于free，这看起来就不科学，因为空闲的竟然不是全部可用的。之所以出现free 注意-g的使用 不会四舍五入 1s刷一次，有助于动态观察 图形界面是很占用内存的 上面的gnome-shell,gnome-software,X,gnome-terminal都是属于图形界面的应用。 通过init 3关闭图形界面后，free大大地增加 所以工作中一般不开图形 vmstat 解释上图 procs列：r b,1 0,这些地意思，r是运行或者可运行的进程数，b是可中断睡眠态的进程数存在阻塞了，这是被阻塞的队列的长度。1 0，1个，0个，这些是动态变化的，不是固定的。 -----memory---- swpd：被交换的内存空间 free：空闲的内存空间 buff和cache：上图buff空间小，cache空间多，说明数据上目前没有什么写操作。 ----swap----- si：进，数据进swap，就是说把内存中暂时不用的数据放到swap里，对于swap来讲是进，对于内存来讲是出。 ​ 可惜我们通常字面意思的理解就错了，这里的swap和后面的---io---都是以内存为参照物的in和out so：出 测试下si so值，构建一个大内存的使用情况，超出内存，然后才会使用swap 此时内存不够用了，就会将内存中不用的数据往swap里写，so就会增长 如图，内存不够用，一开始就是so暴涨，到后面就有进有出了就。 -----io----- io理论上也是磁盘的io，其对应的bi和bo理论上都是说的磁盘的in和out，但这里就不是，这就是统一指的内存的in和out。 如图从硬盘上读数据，表现在vmstat的bi暴涨：因为读数据时先读入内存 如果从内存中读数据，/dev/zero是个内存数据，写到硬盘上，此时---io---里就是bo暴涨 这个命令一会就能把硬盘打满。测试的时候要小心。 ----system------ 进程切换过多会影响效率的 ----cpu---- 这里的us sy id wa st和top里的一个意思 iostat iostat 1s刷新一次 开始读磁盘 读操作瞬间暴涨 对于系统来讲CPU、内存、硬盘、网卡，这是比较关注的4个，和性能密切相关 iftop 需要epel源安装 iftop 可以指定监听的网卡的 iftop -n -i eth1 -n就是不做域名解析 q退出 pmap，显示进程占用的内存空间 每个进程使用的资源都是在/proc下看的很清楚的 比方说，这里开启一个dd命令 这个dd命令的pid呢看下是多少 那么在/proc/11425下去看看 其中就有内存的使用情况 也就是maps文件，打开看看 显示的内容不是特别容易看懂，所以不太使用这种直接看maps文件的方式，而是使用pmap命令去看 这样就可以看到 dd就是程序本身的内存占用 stack就是栈，和堆很相似，都是每个进程占用的内存空间，这个内容讲解在本章 第1节中有讲，了解下就够了。 栈：先进后出， 一般函数，变量赋值，都是用栈 而堆heap，一般都是放大的数据的，面向对象开发的，一些创建的对象都是放在堆里的，堆是在内存中分散的数据块， 还有一些anon也就是anonymous匿名的内存空间，就是没有名字的。 每个应用程序会调用二级制的库，这个库也要占用内存空间，不过这个库是共享库，也会被别的程序调用的，所以这部分内存空间应该是共享的， 将来就可以用这个pmap命令来了解某个应用程序占用的具体的内存空间，比如某个JAVA程序运行的时候内存比较大，还存在不断增长的情况，你就看看，发现 唉~里面的某个模块在不断的消耗内存，这就是OOM的可能了，你就告诉他你的程序某个模块存在OOM内存泄漏的情况。 pmap工作中经常用到据说，回头我就问问应用运维 系统调用 strace可以跟踪 某个进程运行的时候 调用的 \"系统调用\", 就是看看进程占用了哪部分 系统调用 比如说cat这个命令，运行的时候（命令也是程序啊，敲回车就开始运行了） 通过程序运行中调用的 系统调用，就可以发现一些异常，这其实很底层了，这需要经验积累，需要对开发了解。俺没有哦，我就是写下来了解个方向。 上面可能还要cat一些具体的文件 可以看到open的这个系统调用，而且还是RDONLY猜也知道就是readonly了。 这个其实就是 with os.popen('cat ', 'r') as p: z = p.read() strace是看的系统调用， 还有一个ltrace， 看函数库的调用，不是strace看的系统调用 函数库一般就是C语言自己的库， 还有一个ptrace 不太清楚了，哈哈视频中老师就提了这个名字而已， https://bbs.pediy.com/thread-265812.htm https://www.cnblogs.com/tangr206/articles/3094358.html 看不懂，不过知道了strace也是基于ptrace来实现的。 glance可以实现跨网络的监控 然后去到远程的机器上，同样要安装glances 然后client端输入 glances -c a.b.c.d 就可以看到server端的性能 信息丰富、支持跨服务器查看 配合iptables安全策略，可以指定固定来源查看本机信息 dstat 可以替代vmstat,iostat usr用户空间 sys内核空间 idl空闲 wai等待 hiq 硬中断 siq软中断 读写 网卡 swap的分页 int csw 进程的内容切换 这里的int和csw应该就是vmstat的in和cs iotop iostat显示是某个硬盘块设备的I/O使用情况，但是不能精确到进程；此时就可以使用iotop 和TOP很相似，显示的是某个进程的磁盘读写情况 将来发现磁盘很繁忙，进一步想知道哪个进程导致的， 结果肯定是看不到的/dev/zero 是内存里的，/dev/null也是在内存里，所以读写都是在内存里，iftop自然看不到，换一个命令 nload查看网络实施吞吐量 输入nload后回车可见： 当前上图所示没有流量，开始制造流量 上图可见流量开始有了，但是图形显示不是太易读，因为curr 71.63MB/S是这么个图，curr是122MB/S也是这么个图 流量不直观啊有点 lsof 查看某个文件夹是否被挂载或使用 查看某个文件被哪些进程打开 查看某个进程打开了哪些文件 工作中存在 不小心删除 正在使用的文件 制造一个打开的文件效果 注意，这里我们之前讲过使用 > /data/m.txt这种重定向的方式来删除，这个就无法恢复了，因为这个瞬间就将空间释放掉了。 发现正在使用的文件也可以删，当然正在使用的删除就属于误删除了，现在要修复 lsof直接回车，就会显示系统中所有的正在被打开的文件 注意PID 11863，同时此时进程没有停哦 去内存中proc里看 可见4这个文件描述符是删除状态，没关系，可以直接看 照样能看，因为是加载到内存里的 恢复一下就行了 这就找回来了使用中被误删除的文件 尤其日志，经常用这种方法处理。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"14-进程、系统性能和计划任务/4-进程信号和前后台管理.html":{"url":"14-进程、系统性能和计划任务/4-进程信号和前后台管理.html","title":"第4节 进程信号和前后台管理","keywords":"","body":"第4节. 进程信号和前后台管理 在本章 第1节中提到了信号 可以实现 进程之间的通信 信号有很多种，trap -l或kill -l可见信号的种类 每个信号都带有特定的含义，这种废话以后不要说， 如何向一个进程发送指定的信号呢，可以使用kill命令发送信号 1、信号的名称如上图，你可以写全名，也可以省略掉SIG这种所有信号都有的前缀，比如SIGINT可以写成INT还可以用前面的数字编号 1 SIGUP 无需重启服务，重新读取配置文件 这个一些服务里有命令的，估计十有八九就是用的这个UP信号实现的。 有个什么reload的命令来着，记不得了 准备将首页信息放到这个地方 这就需要修改配置文件： centos6这样就行了，7可能还要加一段代码 配置文件改完，一般就是重启服务，但是现在可以这样 查看httpd的进程ps aux： 其中root那个是父进程，可以通过ps auxf 就能识别 所以PID就是2778 kill -SIGUP或kill -UP或者kill -1 都行 2 SIGINT 相当于ctrl c 一些需要ctrl c的情况 然后那边的ping就终止了 3 SIGQUIT 相当于ctrl \\ 相当于quit退出 所以用信号测试一下，下面bc挂起来 然后就quit退出了： 上面就看到INT和QUIT可以关闭进程，但有些进程不一定能关闭 vim 一个文件 进去后 踢不掉的， 再发3信号，发现可以的 kill -3 后vim里的内容就 没了？不一定，你在他kill 之前w!保存了就可以。 如果是vim下按i进入了编辑状态且有修改内容，那么kill了就会产生.xx.swap文件 15 SIGTERM 终止进程，kill的默认信号 kill `pidof xxx` 等价于 kill -15 `pidof xxx` 同样15信号也可以杀vim进程，也不是所有进程都能被其关闭的。 比如bash的进程，kill -15就杀不掉 不会报错，但是实际上杀不掉的，还在： 可以换一个强力kill就是-9 9 SIGKILL 强制杀死正在运行的进程 进程就是正在运行的程序，正在运行的进程本身就是废话 这个2827是bash，所以xshell的登入的一个窗口 直接就没了。 这个是窗口多开后进行的操作，杀的是别的窗口，自己的窗口查看方式： ps aux 可见 直接就把自己的bash就干掉了，不过上图是有个1s的重连才会自动连接上的。 -9是否能杀掉所有进程 比如说systemd是否可以被-9强杀 kill 1肯定不行，等价于kill -15 1, 这是15的默认值，kill -9 1也一样杀不掉 虽然杀不了，但是存在问题的。 pgrep -l mingetty 杀了，又再生了， 这种进程就叫再生进程--respawn ，杀不死没事，看下父进程 pstree -p看下mingetty的父进程是init 这种重生进程，其实可以杀，通过kill 1 一下父进程--父进程虽然不会被杀(kill -9 1也杀不掉)，但是你继续看 此时就杀掉了，所以init和systemd不是说杀不掉就可以杀的，还是会有影响的。 mingetty其实就是登入的终端，ctrl_alt_f3对应的就是tty3已经被杀掉了，所以下面的界面就卡住了，输入回车都没有反应了。 换一个ctrl_al_f4可以的就是tty4 有后台的进程才有再生功能，mingetty能再生，是因为有init做后台。 批量杀进程 killall httpd # 使用进程名称来杀 所以到这里就学习了 1、按PID杀，kill 2、按进程名称杀，killall 下面学习3、按模式也就是正则杀，pkill。 pkill的模式和选项和pgrep是通用的，它俩的帮助都是在一块的。 然后就杀掉了 t就是看控制终端的tty的 杀掉pts/1行运行的所有进程 其实图中要用-9,pkill -9 -t pst/1就可以删掉所有能杀掉的了。否则bash杀不掉。 然后去到运行ping的窗口上看到，就看到被杀掉了。 这两个只有pgrep有，pkill没有。 进程的前后台 这个就是占用了终端资源的前台命令 放后台的方法 这就已经放后台运行了的，但是输出还是在前台输出的。 前台执行是占用终端资源的，后台不占。 此时跑是在后台跑了，但是输出还是在前台，所以ctrl c结束不掉了就，ctrl c只能结束在前台跑的进程 怎么关呢，①再开一个窗口，kill掉ping就行了，②将后台运行的进程再次调到前台来就好了。 手速要快 fg 命令就是front groud 既然在前台了，ctrl c就可以了结束了 fg可以把后台的进程也可以是没在执行中的后台程序调到前台来。 再次研究这个现象 ping 127.1挂着，当前ping的状态是可中断的休眠 然后按ctrl z，此时就放入后台，但是不在是运行状态了 T就是后台，处于停滞状态，冷冻？ 如何恢复:1、恢复到后台运行bg；2、恢复到前台运行fg 开始操作，当前通过jobs可见是后台stopped 使用它bg命令back groud，此时就恢复到前台运行了 所以此时ctrl c不起作用，ls看看的 下面是通过fg直接恢复到前台的。 再来一个问题 已经是后台如何让他stopped 如何将已经后台的进程--正在跑着的，变成继续后台但是是休眠态 由于此时已经是后台了，ctrl z发不到后台了。 发19 SIGSTOP，后台休眠信号。 killall -19 ping 确实停止了，达到了ctrl z的效果。 还可以让他继续运行，除了bg或者fg，还可以发送18 SIGCONT信号，由于现在是后台stopped，所以18发过去就是后台运行 但是没有办法说 发个信号让他从 后台stopped变成前台运行哦。 kill的0信号 0信号是不属于信号列表的，通过kill -l可见没有0信号的 killall和kill是共用信号数字的 这说明ping当前是工作的 如果ping没有运行，就是这个结果 案例：如果http服务没有启动，就重新启动 这个可以放到crontab里1分钟跑一次，确保一些进程莫名奇妙挂了，这个情况也是存在的。 假如某个APP挂了，等个1分钟也就自动好了，就是这里的crontab，不过前提是systemctl start httpd要能起的来哦，如果配置文件有问题自然就起不来了。 关于screen和nohup ping & 两种后台执行，直接搜全文，都有的。 这个默认行为不好，因为文件会越来越大 需要丢到/dev/null里。 窗口一关，bash就没了，ping也就没了，其实不是 父进程bash8292没了，但是ping这个8401子进程还在，父进程没了，重新找了个父进程systemd。 其实视频里漏掉了exit安全退出，否则有时候不会后台运行的。当然这里的实验没有问题，但是我以前必须①nohup cmd > /dev/null $ ②exit才行的。 作业操作 kill %xx # 注意是是作业编号，不是进程编号 并发 这么些是按顺序，而且由于linux默认就是永久ping的，所以结果只会有127.1 注意ping -c 3这钟不好，我们一般都是ping -w 1，其实就是我啦，因为-c 1 万一不通，就会等好久才会给你一个结果说不可达，-w 1就是1s没有结果就认为不可达了，这个就够了，就是合适的。 并发-方法1 bash all.sh瞬间出来下图 改成-c 3 多ping几次看看 方法2、3就是子进程后台、线程后台 注意上图看着以为是脚本，其实可以是命令 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"14-进程、系统性能和计划任务/5-计划任务实现.html":{"url":"14-进程、系统性能和计划任务/5-计划任务实现.html","title":"第5节 计划任务实现","keywords":"","body":"第5节. 计划任务实现 一次性任务用的少：at这个包提供了at和batch两个命令 at用的多一点，batch基本不用。其实at也不怎么用 atq和atrm是at的扩展用法 atd.service必须是启动状态，这是前提 centos6上的atd服务： at一般用法就是跟一个时间执行cmd at -t的格式1和at 后不带-t的格式2 at回车会等STDIN，at -l查看计划任务，ctrl d 安全退出 1就是第一个任务 at -c 1可以查看具体任务细节，上面都是各种变量，最下面才是任务明细 等到时间了，任务执行完毕，就没了 at了3个命令，第一个创建文件执行了，但是后面两个ls和hostname怎么理解呢，在哪里体现呢 计划任务是在未来的时间执行的，ls和hostname是在当前终端tty上运行的。 而你不能确定你将来就在这个tty上，说不定别人正好撞到这个tty上了，就看到了ls和hostname执行的结果了。就是你执行的命令，别人看到了，这就不合理了。 所以基于以上道理，计划任务的STDOUT标准输出不会在屏幕上打印的。虽然没有输出到屏幕，但是以邮件的形式发给你了。 由于刚才是以root用户执行的，所以邮件就发到了root： 所以方法论来了，计划任务的脚本，一般不推荐有输出，而是所有输出都扔到日志或在/dev/null里，这话我就不认同哈哈，因为我的py脚本很多还是保留了print的，这些屏幕上看得到的，当然crontab去执行的化，自然屏幕看不到了。 不对，视频老师的意思的，crontab里的脚本不要有标准输出，否则会给你发送大量邮件，emmm，这话也不对，有时候正要考这些邮件当作日志来分析是否运行了。 不过，确实很多文章上的crontab都是由 /xxx/xxx/ /xxx/xxx > /dev/null的，看来不要发邮件才是比较好的一个做法。 ctrl c是强行终止 然后reboot重启，这些计划任务还在吗？ 重启后发现at -l还在 说明重启也不会影响at的任务，说明肯定是找一个地方存起来了。肯定不是内存里放了，肯定是放到磁盘上了。 磁盘上哪里呢？👇 a00003xxxx和a00004就是at -l看到的3和4编号。 这个cat /va/spool/at/a00003xxx文件看到的正是at -c 3看到的 这个路径的权限只有root 换个普通账号创建计划任务也是可以的 然后wang账号的计划任务也是放在/var/spool/at路径下的 对于wang账号来讲，/var/spool/at路径是没有权限的，但是确实将任务写进去了，说明at由SUID权限👇 删除atrm或者at -d一个意思 atrm -4说白就是把/var/spool/at的对应的文件删了 同理，可以直接删文件， noon：中午12点 midnigth：午夜12点，0点 teatime：下午茶时间，4点 tomorrow now + xxx：现在往后多久时间 -f 创建一个文件 -f 其实也就是利用重定向的效果：at 18:00 -m 告知计划任务有无执行 把原来邮件删掉 1分钟后执行 就是个空邮件告诉你执行了 白名单优于黑名单，如果wang既在白名单也在黑名单，白名单里有就不看黑名单了。 如果user2黑白里都没有，我分析就可以执行。 周期性任务用的多：crontab 对应的软件包比较多 cronie是主要工具包 上图的 crontd是主程序，运行后会自动周期运行计划任务。 上图的 /usr/bin/crontab # 是创建用户自己的计划任务的工具，区别于全局的/etc/crontab文件 centos6下的情况： crontabs是创建计划任务的工具 用户自定义的计划任务 通过crontab创建，后存放在/var/spool/cron下 这个/var/spool文件夹也是一个常用文件夹 除了刚才的at和马上正在学习的cron还有mail邮件也都在这里。 cronie-anacron补充性的包，用的不多 使用场景举例： 在家用电脑中安装了一个linux，这种PC台式机不像服务器一样24小时开机的，可能定期就会自动重启的。而加入计划任务是半夜执行的，而此时你关机了，就会导致计划任务没有执行，此时就有cronie-anacron来执行。 ​ 当你开机后的一段时间，会自动检查时间已过了没有执行的任务，找个时间给你执行了。 通过查看/etc/crontab可知，里面的存在各种环境变量的 而直接crontab -e去编辑用户自定义的任务，有时候就需要手动补上变量，比如我这种 这都是报错，后来解决的方法👆， 然后/etc/crontab还有个地方说明下 这个文件只有root才能读写，所以普通用户无法编辑，所以上面的user-name是root指定，意思就是这个计划任务是以某个普通用户来执行的。 写个磁盘空间告警 以前不太理解为什么sed 要先找到再查找替换，为什么不直接查找替换，现在案例就来了 先找到/dev/sda开头的(相当于做了一步过滤)，再针对这些开头进行替换。它不是说真的要替换，如果真的要替换直接s#a#b#就好了，它是要过滤显示出结果，所以需要查找到再替换显示。 这就找到最大值了。 将脚本写到crontab里 第一个*号的意思： 1,10,30 表示每小时的第1、10、30分钟 * 表示每分钟 */10 表示每10分钟 待会用wang普通账号去执行crontab，就是user-name写成wang，所以要看下脚本是否有权限 这样脚本wang用户就可以执行了。 然后就是 每分钟，1-5工作日，wang 去执行脚本，0或者7表示周日 然后跟踪下cron的日志 解释下面的任务 就是 30分 2点 1，10，20号 每月 周六或周日 问题来了，这个1号10号20号万一不是周末了，他们之间是并取还是或的关系呢？ 通过man 5 crontab可以找到逻辑关系，搜下note either就是也，plus就是加上，这些就说明了是 或的关系。 所以每个月的1、10、20号会执行，然后每周的周6和周日也会执行。 问题来了，如果我就要并且呢，计划任务没有这功能，就需要在脚本里去判断 然后脚本里去判断是否为周末，如果是就执行。这就是且的关系的落地。 用这个命令获得今日是周几；👇man date 通常计划任务不会放到这个/etc/crontab里，一般就是crontab -e那个用户就是哪个创建的。 crontab -e创建的时候，就系统就自然就知道是哪个用户创建的，所以格式上就有个默认的user-name不用写了，直接 * cmd 该文件已经有执行，所以就是CMD搞定 不通用户创建的crontab -e其实就是/var/spool/cron下的不同文件 crontab -l看自己的，看别人的加上 -u 删除某某用户的所有计划任务 文件下的脚本都执行 每分钟，执行/data/scripts下的所有脚本，然后验证确实执行了： 这个次序就是按ls的次序执行的 验证上面的次序判定 可见/usr/bin/run-parts /data/scripts 确实是按脚本存放路径的ls次序执行的。 系统本身就有的周期性任务 mlocate就是locate的依赖的默认数据库，而这个数据库是每天刷新一次的。就是靠这里。 为什么放到/etc/cron.daily下的这些脚本(这些logrotate、man-db.cron、mlocate都是独立的脚本)，为啥这些就会daily每日执行呢，其实还需要有个cron去执行他们的。 上图就是cron.hourly文件夹下的脚本都会执行的原因，因为有/etc/cron.d/0hourly去执行的。而daily文件夹下就不会执行，因为/etc/cront.d下没有对应的周期命令。 但其实上面的可能是执行的，因为还有 日志可以观察，也可以帮助还原误删除的计划任务 /var/log/cron 下次开机执行的方法，应该是等价于rc.local的。 crontab -e 便捷 重启后可见，确实执行了 因为wall看不到广播效果，因为没法提前进到那个终端去等到广播信息 换一个方式 多任务时间一致，可以用分号隔开，呵呵，要考虑前一条执行花费时间哦，第二条执行有延迟的。 anacontab 1表示1天执行一次，开机5分钟后自动运行 cron.daily 每天就是1 每周就是7 每月就是@monthly， 5 25 45就是开机后的5、25、45分钟后执行后面的脚本。 45分钟随机延迟 服务器上这个anacron用的少 管理临时文件 centos6上的一些文件 makewhatis就是手动做了makewhatis.cron mlocate.cron相关的信息，手动就是updatedb。 tmpwatch是清除垃圾文件 10天清理一次/tmp 30天清理一次/var/tmp windows没有定时清理的功能 到了centos7就是一个服务专门来做这事了 原来centos6这个路径下，在7上就没有哪个tmpwatch文件了： 不希望wang执行计划任务 再写一个/etc/cront.allow 白的黑的都有wang，其实就只看白的了 crontab -e就进去了👇 这个deny只是说不能编辑，原来如果有权限的时候编辑的计划任务还是会正常工作的。 crontab精确到s的方法 sleep可以精确到0.1s好像 但是你用sleep控制周期，就不是crontab里的每分钟--其实是到整点就执行了。sleep是真的等1s执行，那么如果之前的脚本本身执行就要花4s，那么用with os.popen阻塞的方式，其实就是5s钟才能一个周期了。而且存在队列不断加大的风险。 usleep是微妙级别的睡眠 利用crontab定期同步时间 这个是取之我们的extmail里的一个案例： 这是视频里老师的写法： 上图有错误，所以wq退出会报错 y重新edit为： 据说&> /dev/null是一个好习惯，否则一堆垃圾邮件。 习题 说是*/7不行，因为60/7除不尽，需要用sleep 420 来做，但你想想就是我说的，脚本执行如果要化10s，没关系，那也是脚本执行后sleep了7分钟才继续执行啊。所以两次周期就是严格的7分钟过了。 sleep也是有单位的 crontab里不要用%，这个踩过坑，当然%如果在py脚本里是没有问题的， 有人想在crontab里写date +%F，这种就不行，换个思路，将date +%F写到脚本里，然后crontab里调用脚本就可以了。 还有就是上文提到过变量问题，或者叫二进制的执行文件要写绝对路径--但是有的遗漏的就是通过邮件看到日志提示 之前的坑记录如下，emmm原来慢慢吞吞都1年半下来了。太慢啦，不过这事写脚本，不算linux系统学习，也还说的过去。 这个还是python脚本里调用了mtr命令，然后crontab报错找不到PATH变量 而且，我都在py里的mtr也是写了绝对路劲的，但是就是不认，哈哈，最后还是加了一行path变量才好的。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"15-shell脚本编程进阶/15-shell脚本编程进阶.html":{"url":"15-shell脚本编程进阶/15-shell脚本编程进阶.html","title":"第十五章 shell脚本编程进阶","keywords":"","body":"第十五章 shell脚本编程进阶 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"15-shell脚本编程进阶/1-循环01.html":{"url":"15-shell脚本编程进阶/1-循环01.html","title":"第1节 循环01","keywords":"","body":"第1节. 循环01 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"15-shell脚本编程进阶/2-循环02.html":{"url":"15-shell脚本编程进阶/2-循环02.html","title":"第2节 循环02","keywords":"","body":"第2节. 循环02 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"15-shell脚本编程进阶/3-函数详解01.html":{"url":"15-shell脚本编程进阶/3-函数详解01.html","title":"第3节 函数详解01","keywords":"","body":"第3节. 函数详解01 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"15-shell脚本编程进阶/4-函数详解02.html":{"url":"15-shell脚本编程进阶/4-函数详解02.html","title":"第4节 函数详解02","keywords":"","body":"第4节. 函数详解02 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"15-shell脚本编程进阶/5-信号处理和函数组详解.html":{"url":"15-shell脚本编程进阶/5-信号处理和函数组详解.html","title":"第5节 信号处理和函数组详解","keywords":"","body":"第5节. 信号处理和函数组详解 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"15-shell脚本编程进阶/6-高级变量和expect.html":{"url":"15-shell脚本编程进阶/6-高级变量和expect.html","title":"第6节 高级变量和expect","keywords":"","body":"第6节. 高级变量和expect Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"16-系统启动和内核管理/16-系统启动和内核管理.html":{"url":"16-系统启动和内核管理/16-系统启动和内核管理.html","title":"第十六章 系统启动和内核管理","keywords":"","body":"第十六章 系统启动和内核管理 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"16-系统启动和内核管理/1-系统启动流程和故障排错.html":{"url":"16-系统启动和内核管理/1-系统启动流程和故障排错.html","title":"第1节 系统启动流程和故障排错","keywords":"","body":"第1节. 系统启动流程和故障排错 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"16-系统启动和内核管理/2-启动流程和服务管理.html":{"url":"16-系统启动和内核管理/2-启动流程和服务管理.html","title":"第2节 启动流程和服务管理","keywords":"","body":"第2节. 启动流程和服务管理 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"16-系统启动和内核管理/3-启动流程详解.html":{"url":"16-系统启动和内核管理/3-启动流程详解.html","title":"第3节 启动流程详解","keywords":"","body":"第3节. 启动流程详解 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"16-系统启动和内核管理/4-linux启动流程grub管理和故障排错.html":{"url":"16-系统启动和内核管理/4-linux启动流程grub管理和故障排错.html","title":"第4节 linux启动流程grub管理和故障排错","keywords":"","body":"第4节. linux启动流程grub管理和故障排错 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"16-系统启动和内核管理/5-自制linux和源码编译内核.html":{"url":"16-系统启动和内核管理/5-自制linux和源码编译内核.html","title":"第5节 自制linux和源码编译内核","keywords":"","body":"第5节. 自制linux和源码编译内核 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"16-系统启动和内核管理/6-systemd特性.html":{"url":"16-系统启动和内核管理/6-systemd特性.html","title":"第6节 systemd特性","keywords":"","body":"第6节. systemd特性 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"16-系统启动和内核管理/7-systemd和grub2管理.html":{"url":"16-系统启动和内核管理/7-systemd和grub2管理.html","title":"第7节 systemd和grub2管理","keywords":"","body":"第7节. systemd和grub2管理 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"17-Security-Enhanced/17-Security-Enhanced.html":{"url":"17-Security-Enhanced/17-Security-Enhanced.html","title":"第十七章 Security-Enhanced","keywords":"","body":"第十七章 Security-Enhanced Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"17-Security-Enhanced/1-SELinux实现安全加固.html":{"url":"17-Security-Enhanced/1-SELinux实现安全加固.html","title":"第1节 SELinux实现安全加固","keywords":"","body":"第1节. SELinux实现安全加固 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"18-文本处理三剑客3_awk/18-文本处理三剑客3_awk.html":{"url":"18-文本处理三剑客3_awk/18-文本处理三剑客3_awk.html","title":"第十八章 文本处理三剑客3_awk","keywords":"","body":"第十八章 文本处理三剑客3_awk Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"18-文本处理三剑客3_awk/1-文本三剑客3_awk详解01.html":{"url":"18-文本处理三剑客3_awk/1-文本三剑客3_awk详解01.html","title":"第1节 文本三剑客3_awk详解01","keywords":"","body":"第1节. 文本三剑客3_awk详解01 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"19-加密和安全/19-加密和安全.html":{"url":"19-加密和安全/19-加密和安全.html","title":"第十九章 加密和安全","keywords":"","body":"第十九章 加密和安全 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"19-加密和安全/1-安全和各种攻击方法.html":{"url":"19-加密和安全/1-安全和各种攻击方法.html","title":"第1节 安全和各种攻击方法","keywords":"","body":"第1节. 安全和各种攻击方法 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"19-加密和安全/2-安全加密算法体系详解.html":{"url":"19-加密和安全/2-安全加密算法体系详解.html","title":"第2节 安全加密算法体系详解","keywords":"","body":"第2节. 安全加密算法体系详解 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"19-加密和安全/3-PKI和证书安全体系详解.html":{"url":"19-加密和安全/3-PKI和证书安全体系详解.html","title":"第3节 PKI和证书安全体系详解","keywords":"","body":"第3节. PKI和证书安全体系详解 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"19-加密和安全/4-互联网安全通讯协议HTTPS详解.html":{"url":"19-加密和安全/4-互联网安全通讯协议HTTPS详解.html","title":"第4节 互联网安全通讯协议HTTPS详解","keywords":"","body":"第4节. 互联网安全通讯协议HTTPS详解 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"19-加密和安全/5-建立私有CA和颁发证书.html":{"url":"19-加密和安全/5-建立私有CA和颁发证书.html","title":"第5节 建立私有CA和颁发证书","keywords":"","body":"第5节. 建立私有CA和颁发证书 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"19-加密和安全/6-证书管理和SSH服务工作原理详解.html":{"url":"19-加密和安全/6-证书管理和SSH服务工作原理详解.html","title":"第6节 证书管理和SSH服务工作原理详解","keywords":"","body":"第6节. 证书管理和SSH服务工作原理详解 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"19-加密和安全/7-SSH服务配置和基于KEY验证.html":{"url":"19-加密和安全/7-SSH服务配置和基于KEY验证.html","title":"第7节 SSH服务配置和基于KEY验证","keywords":"","body":"第7节. SSH服务配置和基于KEY验证 默认的ssh登入方式 关于SSH第一次链接的安全性，即解决方案： 你可以见Server端的公钥用HASH算一下，将值公布在网站上，CLIENT去链接的时候对比一下一样再yes。SSH后续连接就是安全的了。（*其实谷歌AWS等都不是这种方式了，都是用的公钥文件，下文讲) yes的作用就是，就是把对方的公钥放到的.ssh里。 -b 比较牛哈，ping知道怎么带源，ssh也要知道哈。 关于Xclock所代表的X协议 xclock代表的client端 xServer就是服务端 两者是通过x协议沟通， 图形的显示是通过server上的显卡实现。 xClient和xServer不在同一台电脑的场景，比如我A ssh B 登入后，输入xclock这个谁是server谁是client呢 A是server，B是client，因为登入到B上进行xclock，而要显示时钟图形界面是在A这个server上的。 A和B的X协议是通过ssh协议封装传递的。 注意：如果server端不是xshell，而是scrt软件，就不行了，因为scrt没有给你安装X协议server。xshell是xmanager一套软件安装的，是默认安装了x协议的。 windows没有xServer，xshell安装的时候默认安装了xServer，secureCRT没有xServer要额外安装软件的要注意的。 xshell不是单装的 xshell而是安装的xManager，所以带了xServer软件 改MAC地址的一个案例 当你改完网卡配置文件后还是改不过来的时候可以试试下面的方法： modprobe -r e1000，-r是remove掉网卡驱动，通过ip a发现没有卸掉网卡 ethtool -i eth0 ， 年后看下是哪种模块，请认真学习噗冬伐 modprobe -r pcnet32，找到驱动了，进行删除 modprobe pcnet32 重新安装驱动，mac得以刷新 一跳一跳地ssh上去 server会看到是192.168.37.101连上来的。 下面讲基于KEY的ssh 这里的key就是RSA里的密钥对，其实上面默认的ssh其实也是有公钥的，只不过之前的是单向公钥加密码；现在是双向公钥，并且弃用了密码。 安全性方面注意： 私钥拷走就有大问题 1、私钥拷走 2、修改私钥文件的属性 公钥交换，这个说法就很奇怪，听起来加上看上图，都觉得没错，但是实际上，res=ID^xxx这套东西通常是DH算法，而DH算法，就是在交换密钥，SSH加密可能试用非对称密码来加密传输的数据， 1、加密通道的形成，肯定不是公钥的传递，这个图片只是理论上的非对称做法，实际应该略微修改成对称密钥的传递。 2、所以从实际应用出发，上图的client PBULIC-KEY是不存在的。 3、所以下图的SSH加密通信应该改成对称密码加密而不是非对称。 在上面加密隧道形成后，于是开始认证，包括认证成功后的数据传递 同样上图得改，改成用户名+密码 然后通过对称密码加密发送过去，而不是Public key。 图中倒数第二步的 13579传输可不是明文传过去的，是基于对方公钥加密后传递的，其实这图是第二个阶段了，第一阶段是公钥的交互，交互后以后所有的通信都是使用公钥进行传输的了。 上图这个key的认证倒是对的，另附一图佐证 然后参看资料 https://juejin.cn/post/6844903685047189512 http://www.h3c.com/cn/d_200805/606213_30003_0.htm 密钥认证的实验 ssh-keygen -t rsa 默认就是rsa 注意密钥对存放路径，上图中有，然后上图是切到wang用户去生成密钥的。 生成了公钥和私钥文件 接下来要去弄server端的authorized_keys文件 该文件自动生成 ssh-copy-id -i /home/wang/.ssh/id_rsa.pub root@192.168.37.6 注意即使你敲错了id_rsa，也不会传私钥过去的，会自动给你传公钥的。 确实是写的私钥，实际系统给你传的也是公钥。ssh真贴心 现在直接登了就 scp走的就是ssh协议，所以复制也不要输密码了 直接不用输密码了 也挺安全 但是这台电脑的安全一定要保护好，这台机器的账号要是泄露了就危险了。 以上总结 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 16:08:58 "},"19-加密和安全/8-SSH基于key的expect自动化脚本.html":{"url":"19-加密和安全/8-SSH基于key的expect自动化脚本.html","title":"第8节 SSH基于key的expect自动化脚本","keywords":"","body":"第8节. SSH基于key的expect自动化脚本 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"19-加密和安全/9-SSH端口转发功能详解.html":{"url":"19-加密和安全/9-SSH端口转发功能详解.html","title":"第9节 SSH端口转发功能详解","keywords":"","body":"第9节. SSH端口转发功能详解 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"19-加密和安全/10-SSH安全实践配置.html":{"url":"19-加密和安全/10-SSH安全实践配置.html","title":"第10节 SSH安全实践配置","keywords":"","body":"第10节. SSH安全实践配置 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"19-加密和安全/11-dropbear编译安装和文件完整性检查.html":{"url":"19-加密和安全/11-dropbear编译安装和文件完整性检查.html","title":"第11节 dropbear编译安装和文件完整性检查","keywords":"","body":"第11节. dropbear编译安装和文件完整性检查 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"19-加密和安全/12-sudo实现管理授权详解.html":{"url":"19-加密和安全/12-sudo实现管理授权详解.html","title":"第12节 sudo实现管理授权详解","keywords":"","body":"第12节. sudo实现管理授权详解 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"19-加密和安全/13-TCPWRAPPER和PAM安全模块.html":{"url":"19-加密和安全/13-TCPWRAPPER和PAM安全模块.html","title":"第13节 TCPWRAPPER和PAM安全模块","keywords":"","body":"第13节. TCPWRAPPER和PAM安全模块 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"19-加密和安全/14-PAM模块使用.html":{"url":"19-加密和安全/14-PAM模块使用.html","title":"第14节 PAM模块使用","keywords":"","body":"第14节. PAM模块使用 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"20-加密和安全/20-加密和安全.html":{"url":"20-加密和安全/20-加密和安全.html","title":"第二十章 加密和安全","keywords":"","body":"第二十章 加密和安全 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"20-加密和安全/1-时间计时和同步.html":{"url":"20-加密和安全/1-时间计时和同步.html","title":"第1节 时间计时和同步","keywords":"","body":"第1节. 时间计时和同步 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"20-加密和安全/2-时间同步服务.html":{"url":"20-加密和安全/2-时间同步服务.html","title":"第2节 时间同步服务","keywords":"","body":"第2节. 时间同步服务 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"21-运维自动化系统部署/21-运维自动化系统部署.html":{"url":"21-运维自动化系统部署/21-运维自动化系统部署.html","title":"第二十一章 运维自动化系统部署","keywords":"","body":"第二十一章 运维自动化系统部署 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"21-运维自动化系统部署/1-系统自动化安装.html":{"url":"21-运维自动化系统部署/1-系统自动化安装.html","title":"第1节 系统自动化安装","keywords":"","body":"第1节. 系统自动化安装 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"21-运维自动化系统部署/2-DHCDP服务实现.html":{"url":"21-运维自动化系统部署/2-DHCDP服务实现.html","title":"第2节 DHCDP服务实现","keywords":"","body":"第2节. DHCDP服务实现 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"21-运维自动化系统部署/3-实现基于PXE安装centos7系统.html":{"url":"21-运维自动化系统部署/3-实现基于PXE安装centos7系统.html","title":"第3节 实现基于PXE安装centos7系统","keywords":"","body":"第3节. 实现基于PXE安装centos7系统 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"21-运维自动化系统部署/4-实现基于cobbler的自动安装.html":{"url":"21-运维自动化系统部署/4-实现基于cobbler的自动安装.html","title":"第4节 实现基于cobbler的自动安装","keywords":"","body":"第4节. 实现基于cobbler的自动安装 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"21-运维自动化系统部署/5-实现基于cobblerweb的管理.html":{"url":"21-运维自动化系统部署/5-实现基于cobblerweb的管理.html","title":"第5节 实现基于cobblerweb的管理","keywords":"","body":"第5节. 实现基于cobblerweb的管理 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"22-DNS服务和BIND/22-DNS服务和BIND.html":{"url":"22-DNS服务和BIND/22-DNS服务和BIND.html","title":"第二十二章 DNS服务和BIND","keywords":"","body":"第二十二章 DNS服务和BIND Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"22-DNS服务和BIND/1-DNS服务简介.html":{"url":"22-DNS服务和BIND/1-DNS服务简介.html","title":"第1节 DNS服务简介","keywords":"","body":"第1节. DNS服务简介 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"22-DNS服务和BIND/2-DNS只缓存服务器实现.html":{"url":"22-DNS服务和BIND/2-DNS只缓存服务器实现.html","title":"第2节 DNS只缓存服务器实现","keywords":"","body":"第2节. DNS只缓存服务器实现 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"22-DNS服务和BIND/3-DNS主服务器实现.html":{"url":"22-DNS服务和BIND/3-DNS主服务器实现.html","title":"第3节 DNS主服务器实现","keywords":"","body":"第3节. DNS主服务器实现 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"22-DNS服务和BIND/4-实现反向区域和主从复制服务.html":{"url":"22-DNS服务和BIND/4-实现反向区域和主从复制服务.html","title":"第4节 实现反向区域和主从复制服务","keywords":"","body":"第4节. 实现反向区域和主从复制服务 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"22-DNS服务和BIND/5-实现DNS子域委派和转发.html":{"url":"22-DNS服务和BIND/5-实现DNS子域委派和转发.html","title":"第5节 实现DNS子域委派和转发","keywords":"","body":"第5节. 实现DNS子域委派和转发 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"22-DNS服务和BIND/6-CDN和GSLB工作原理及智能DNS实现.html":{"url":"22-DNS服务和BIND/6-CDN和GSLB工作原理及智能DNS实现.html","title":"第6节 CDN和GSLB工作原理及智能DNS实现","keywords":"","body":"第6节. CDN和GSLB工作原理及智能DNS实现 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"22-DNS服务和BIND/7-实现internet架构和DNS服务.html":{"url":"22-DNS服务和BIND/7-实现internet架构和DNS服务.html","title":"第7节 实现internet架构和DNS服务","keywords":"","body":"第7节. 实现internet架构和DNS服务 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"23-MYSQL数据01/23-MYSQL数据01.html":{"url":"23-MYSQL数据01/23-MYSQL数据01.html","title":"第二十三章 MYSQL数据01","keywords":"","body":"第二十三章 MYSQL数据01 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"23-MYSQL数据01/1-数据库基础原理1.html":{"url":"23-MYSQL数据01/1-数据库基础原理1.html","title":"第1节 数据库基础原理1","keywords":"","body":"第1节. 数据库基础原理1 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"23-MYSQL数据01/2-数据库基础原理2.html":{"url":"23-MYSQL数据01/2-数据库基础原理2.html","title":"第2节 数据库基础原理2","keywords":"","body":"第2节. 数据库基础原理2 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"23-MYSQL数据01/3-mysql安装和基本使用.html":{"url":"23-MYSQL数据01/3-mysql安装和基本使用.html","title":"第3节 mysql安装和基本使用","keywords":"","body":"第3节. mysql安装和基本使用 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"23-MYSQL数据01/4-mysql基本使用.html":{"url":"23-MYSQL数据01/4-mysql基本使用.html","title":"第4节 mysql基本使用","keywords":"","body":"第4节. mysql基本使用 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"23-MYSQL数据01/5-mysql二进制和源码编译安装及多实例.html":{"url":"23-MYSQL数据01/5-mysql二进制和源码编译安装及多实例.html","title":"第5节 mysql二进制和源码编译安装及多实例","keywords":"","body":"第5节. mysql二进制和源码编译安装及多实例 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"23-MYSQL数据01/6-sql各种语句1.html":{"url":"23-MYSQL数据01/6-sql各种语句1.html","title":"第6节 sql各种语句1","keywords":"","body":"第6节. sql各种语句1 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"23-MYSQL数据01/7-sql各种语句2.html":{"url":"23-MYSQL数据01/7-sql各种语句2.html","title":"第7节 sql各种语句2","keywords":"","body":"第7节. sql各种语句2 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"24-MYSQL数据02/24-MYSQL数据02.html":{"url":"24-MYSQL数据02/24-MYSQL数据02.html","title":"第二十四章 MYSQL数据02","keywords":"","body":"第二十四章 MYSQL数据02 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"24-MYSQL数据02/1-sql语句DQL单表查询.html":{"url":"24-MYSQL数据02/1-sql语句DQL单表查询.html","title":"第1节 sql语句DQL单表查询","keywords":"","body":"第1节. sql语句DQL单表查询 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"24-MYSQL数据02/2-sql语句DQL多表查询和视图.html":{"url":"24-MYSQL数据02/2-sql语句DQL多表查询和视图.html","title":"第2节 sql语句DQL多表查询和视图","keywords":"","body":"第2节. sql语句DQL多表查询和视图 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"24-MYSQL数据02/3-函数存储过程和触发器和用户管理.html":{"url":"24-MYSQL数据02/3-函数存储过程和触发器和用户管理.html","title":"第3节 函数存储过程和触发器和用户管理","keywords":"","body":"第3节. 函数存储过程和触发器和用户管理 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"24-MYSQL数据02/4-mysql架构和存储引擎详解.html":{"url":"24-MYSQL数据02/4-mysql架构和存储引擎详解.html","title":"第4节 mysql架构和存储引擎详解","keywords":"","body":"第4节. mysql架构和存储引擎详解 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"24-MYSQL数据02/5-mysql服务器选项变量和性能优化.html":{"url":"24-MYSQL数据02/5-mysql服务器选项变量和性能优化.html","title":"第5节 mysql服务器选项变量和性能优化","keywords":"","body":"第5节. mysql服务器选项变量和性能优化 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"25-MYSQL数据03/25-MYSQL数据03.html":{"url":"25-MYSQL数据03/25-MYSQL数据03.html","title":"第二十五章 MYSQL数据03","keywords":"","body":"第二十五章 MYSQL数据03 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"25-MYSQL数据03/1-索引类型和结构原理.html":{"url":"25-MYSQL数据03/1-索引类型和结构原理.html","title":"第1节 索引类型和结构原理","keywords":"","body":"第1节. 索引类型和结构原理 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"25-MYSQL数据03/2-索引管理和并发访问的锁机制.html":{"url":"25-MYSQL数据03/2-索引管理和并发访问的锁机制.html","title":"第2节 索引管理和并发访问的锁机制","keywords":"","body":"第2节. 索引管理和并发访问的锁机制 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"25-MYSQL数据03/3-事务特性和四种隔离级别.html":{"url":"25-MYSQL数据03/3-事务特性和四种隔离级别.html","title":"第3节 事务特性和四种隔离级别","keywords":"","body":"第3节. 事务特性和四种隔离级别 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"25-MYSQL数据03/4-各种日志管理.html":{"url":"25-MYSQL数据03/4-各种日志管理.html","title":"第4节 各种日志管理","keywords":"","body":"第4节. 各种日志管理 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"25-MYSQL数据03/5-二进制日志管理.html":{"url":"25-MYSQL数据03/5-二进制日志管理.html","title":"第5节 二进制日志管理","keywords":"","body":"第5节. 二进制日志管理 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"26-MYSQL数据04/26-MYSQL数据04.html":{"url":"26-MYSQL数据04/26-MYSQL数据04.html","title":"第二十六章 MYSQL数据04","keywords":"","body":"第二十六章 MYSQL数据04 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"26-MYSQL数据04/1-数据库备份和还原原理详解.html":{"url":"26-MYSQL数据04/1-数据库备份和还原原理详解.html","title":"第1节 数据库备份和还原原理详解","keywords":"","body":"第1节. 数据库备份和还原原理详解 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"26-MYSQL数据04/2-mysql备份还原mysqldump使用.html":{"url":"26-MYSQL数据04/2-mysql备份还原mysqldump使用.html","title":"第2节 mysql备份还原mysqldump使用","keywords":"","body":"第2节. mysql备份还原mysqldump使用 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"26-MYSQL数据04/3-mysqldump实战和xtrabackup介绍.html":{"url":"26-MYSQL数据04/3-mysqldump实战和xtrabackup介绍.html","title":"第3节 mysqldump实战和xtrabackup介绍","keywords":"","body":"第3节. mysqldump实战和xtrabackup介绍 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"26-MYSQL数据04/4-mysql主从复制原理和实现.html":{"url":"26-MYSQL数据04/4-mysql主从复制原理和实现.html","title":"第4节 mysql主从复制原理和实现","keywords":"","body":"第4节. mysql主从复制原理和实现 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"27-MYSQL数据05/27-MYSQL数据05.html":{"url":"27-MYSQL数据05/27-MYSQL数据05.html","title":"第二十七章 MYSQL数据05","keywords":"","body":"第二十七章 MYSQL数据05 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"27-MYSQL数据05/1-主从服务故障恢复和级联复制.html":{"url":"27-MYSQL数据05/1-主从服务故障恢复和级联复制.html","title":"第1节 主从服务故障恢复和级联复制","keywords":"","body":"第1节. 主从服务故障恢复和级联复制 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"27-MYSQL数据05/2-mysql主主和半同步复制.html":{"url":"27-MYSQL数据05/2-mysql主主和半同步复制.html","title":"第2节 mysql主主和半同步复制","keywords":"","body":"第2节. mysql主主和半同步复制 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"27-MYSQL数据05/3-mysql复制过滤器和基于SSL的复制加密.html":{"url":"27-MYSQL数据05/3-mysql复制过滤器和基于SSL的复制加密.html","title":"第3节 mysql复制过滤器和基于SSL的复制加密","keywords":"","body":"第3节. mysql复制过滤器和基于SSL的复制加密 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"27-MYSQL数据05/4-基于mysql5.html":{"url":"27-MYSQL数据05/4-基于mysql5.html","title":"第4节 基于mysql5","keywords":"","body":"第4节. 基于mysql5 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"27-MYSQL数据05/5-基于proxy实现mysql的读写分离.html":{"url":"27-MYSQL数据05/5-基于proxy实现mysql的读写分离.html","title":"第5节 基于proxy实现mysql的读写分离","keywords":"","body":"第5节. 基于proxy实现mysql的读写分离 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"27-MYSQL数据05/6-mysql的主从复制高可用性解决方案MHA.html":{"url":"27-MYSQL数据05/6-mysql的主从复制高可用性解决方案MHA.html","title":"第6节 mysql的主从复制高可用性解决方案MHA","keywords":"","body":"第6节. mysql的主从复制高可用性解决方案MHA Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"27-MYSQL数据05/7-实现galaracluster和性能测试.html":{"url":"27-MYSQL数据05/7-实现galaracluster和性能测试.html","title":"第7节 实现galaracluster和性能测试","keywords":"","body":"第7节. 实现galaracluster和性能测试 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"28-运维自动化之ansible/28-运维自动化之ansible.html":{"url":"28-运维自动化之ansible/28-运维自动化之ansible.html","title":"第二十八章 运维自动化之ansible","keywords":"","body":"第二十八章 运维自动化之ansible Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"28-运维自动化之ansible/1-自动化运维介绍.html":{"url":"28-运维自动化之ansible/1-自动化运维介绍.html","title":"第1节 自动化运维介绍","keywords":"","body":"第1节. 自动化运维介绍 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"28-运维自动化之ansible/2-ansible安装和架构介绍.html":{"url":"28-运维自动化之ansible/2-ansible安装和架构介绍.html","title":"第2节 ansible安装和架构介绍","keywords":"","body":"第2节. ansible安装和架构介绍 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"28-运维自动化之ansible/3-ansible常见模块.html":{"url":"28-运维自动化之ansible/3-ansible常见模块.html","title":"第3节 ansible常见模块","keywords":"","body":"第3节. ansible常见模块 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"28-运维自动化之ansible/4-ansible相关常见工具.html":{"url":"28-运维自动化之ansible/4-ansible相关常见工具.html","title":"第4节 ansible相关常见工具","keywords":"","body":"第4节. ansible相关常见工具 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"28-运维自动化之ansible/5-playbook的实现软件配置和部署.html":{"url":"28-运维自动化之ansible/5-playbook的实现软件配置和部署.html","title":"第5节 playbook的实现软件配置和部署","keywords":"","body":"第5节. playbook的实现软件配置和部署 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"28-运维自动化之ansible/6-playbook的高级用法模板template.html":{"url":"28-运维自动化之ansible/6-playbook的高级用法模板template.html","title":"第6节 playbook的高级用法模板template","keywords":"","body":"第6节. playbook的高级用法模板template Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"28-运维自动化之ansible/7-ansible的高级用法role1.html":{"url":"28-运维自动化之ansible/7-ansible的高级用法role1.html","title":"第7节 ansible的高级用法role1","keywords":"","body":"第7节. ansible的高级用法role1 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"28-运维自动化之ansible/8-ansible的高级用法role2.html":{"url":"28-运维自动化之ansible/8-ansible的高级用法role2.html","title":"第8节 ansible的高级用法role2","keywords":"","body":"第8节. ansible的高级用法role2 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"29-HTTP协议和APACHE/29-HTTP协议和APACHE.html":{"url":"29-HTTP协议和APACHE/29-HTTP协议和APACHE.html","title":"第二十九章 HTTP协议和APACHE","keywords":"","body":"第二十九章 HTTP协议和APACHE Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"29-HTTP协议和APACHE/1-httpd基础知识.html":{"url":"29-HTTP协议和APACHE/1-httpd基础知识.html","title":"第1节 httpd基础知识","keywords":"","body":"第1节. httpd基础知识 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"29-HTTP协议和APACHE/2-http协议各种版本详解.html":{"url":"29-HTTP协议和APACHE/2-http协议各种版本详解.html","title":"第2节 http协议各种版本详解","keywords":"","body":"第2节. http协议各种版本详解 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"29-HTTP协议和APACHE/3-httpd软件工作模型.html":{"url":"29-HTTP协议和APACHE/3-httpd软件工作模型.html","title":"第3节 httpd软件工作模型","keywords":"","body":"第3节. httpd软件工作模型 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"29-HTTP协议和APACHE/4-httpd2.html":{"url":"29-HTTP协议和APACHE/4-httpd2.html","title":"第4节 httpd2","keywords":"","body":"第4节. httpd2 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"29-HTTP协议和APACHE/5-httpd2.html":{"url":"29-HTTP协议和APACHE/5-httpd2.html","title":"第5节 httpd2","keywords":"","body":"第5节. httpd2 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"29-HTTP协议和APACHE/6-多虚拟主机实现.html":{"url":"29-HTTP协议和APACHE/6-多虚拟主机实现.html","title":"第6节 多虚拟主机实现","keywords":"","body":"第6节. 多虚拟主机实现 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"29-HTTP协议和APACHE/7-基于主机头的多虚拟主机和实现HTTPS加密.html":{"url":"29-HTTP协议和APACHE/7-基于主机头的多虚拟主机和实现HTTPS加密.html","title":"第7节 基于主机头的多虚拟主机和实现HTTPS加密","keywords":"","body":"第7节. 基于主机头的多虚拟主机和实现HTTPS加密 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"29-HTTP协议和APACHE/8-http的安全加固和重定向.html":{"url":"29-HTTP协议和APACHE/8-http的安全加固和重定向.html","title":"第8节 http的安全加固和重定向","keywords":"","body":"第8节. http的安全加固和重定向 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"29-HTTP协议和APACHE/9-http协议详解和相关工具.html":{"url":"29-HTTP协议和APACHE/9-http协议详解和相关工具.html","title":"第9节 http协议详解和相关工具","keywords":"","body":"第9节. http协议详解和相关工具 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"29-HTTP协议和APACHE/10-httpd源码编译安装.html":{"url":"29-HTTP协议和APACHE/10-httpd源码编译安装.html","title":"第10节 httpd源码编译安装","keywords":"","body":"第10节. httpd源码编译安装 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"30-实现LAMP架构/30-实现LAMP架构.html":{"url":"30-实现LAMP架构/30-实现LAMP架构.html","title":"第三十章 实现LAMP架构","keywords":"","body":"第三十章 实现LAMP架构 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"30-实现LAMP架构/1-实现LAMP应用phpmyadmin.html":{"url":"30-实现LAMP架构/1-实现LAMP应用phpmyadmin.html","title":"第1节 实现LAMP应用phpmyadmin","keywords":"","body":"第1节. 实现LAMP应用phpmyadmin Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"30-实现LAMP架构/2-LAMP应用部署.html":{"url":"30-实现LAMP架构/2-LAMP应用部署.html","title":"第2节 LAMP应用部署","keywords":"","body":"第2节. LAMP应用部署 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"30-实现LAMP架构/3-实现FCGI的LAMP架构.html":{"url":"30-实现LAMP架构/3-实现FCGI的LAMP架构.html","title":"第3节 实现FCGI的LAMP架构","keywords":"","body":"第3节. 实现FCGI的LAMP架构 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"30-实现LAMP架构/4-编译安装LAMP环境部署应用01.html":{"url":"30-实现LAMP架构/4-编译安装LAMP环境部署应用01.html","title":"第4节 编译安装LAMP环境部署应用01","keywords":"","body":"第4节. 编译安装LAMP环境部署应用01 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"30-实现LAMP架构/5-编译安装LAMP环境部署应用02.html":{"url":"30-实现LAMP架构/5-编译安装LAMP环境部署应用02.html","title":"第5节 编译安装LAMP环境部署应用02","keywords":"","body":"第5节. 编译安装LAMP环境部署应用02 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"31-日志管理rsyslog/31-日志管理rsyslog.html":{"url":"31-日志管理rsyslog/31-日志管理rsyslog.html","title":"第三十一章 日志管理rsyslog","keywords":"","body":"第三十一章 日志管理rsyslog Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"31-日志管理rsyslog/1-日志管理实现远程日志.html":{"url":"31-日志管理rsyslog/1-日志管理实现远程日志.html","title":"第1节 日志管理实现远程日志","keywords":"","body":"第1节. 日志管理实现远程日志 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"31-日志管理rsyslog/2-通过loganalyzer展示数据库中的日志.html":{"url":"31-日志管理rsyslog/2-通过loganalyzer展示数据库中的日志.html","title":"第2节 通过loganalyzer展示数据库中的日志","keywords":"","body":"第2节. 通过loganalyzer展示数据库中的日志 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"32-网络文件共享服务/32-网络文件共享服务.html":{"url":"32-网络文件共享服务/32-网络文件共享服务.html","title":"第三十二章 网络文件共享服务","keywords":"","body":"第三十二章 网络文件共享服务 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"32-网络文件共享服务/1-文件共享服务FTP01.html":{"url":"32-网络文件共享服务/1-文件共享服务FTP01.html","title":"第1节 文件共享服务FTP01","keywords":"","body":"第1节. 文件共享服务FTP01 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"32-网络文件共享服务/2-文件共享服务FTP02.html":{"url":"32-网络文件共享服务/2-文件共享服务FTP02.html","title":"第2节 文件共享服务FTP02","keywords":"","body":"第2节. 文件共享服务FTP02 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"32-网络文件共享服务/3-FTP常见配置和基于DB文件的虚拟用户.html":{"url":"32-网络文件共享服务/3-FTP常见配置和基于DB文件的虚拟用户.html","title":"第3节 FTP常见配置和基于DB文件的虚拟用户","keywords":"","body":"第3节. FTP常见配置和基于DB文件的虚拟用户 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"32-网络文件共享服务/4-基于mysql的FTP的虚拟用户和NFS服务介绍.html":{"url":"32-网络文件共享服务/4-基于mysql的FTP的虚拟用户和NFS服务介绍.html","title":"第4节 基于mysql的FTP的虚拟用户和NFS服务介绍","keywords":"","body":"第4节. 基于mysql的FTP的虚拟用户和NFS服务介绍 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"32-网络文件共享服务/5-基于NFS共享服务器.html":{"url":"32-网络文件共享服务/5-基于NFS共享服务器.html","title":"第5节 基于NFS共享服务器","keywords":"","body":"第5节. 基于NFS共享服务器 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"32-网络文件共享服务/6-NFS网络共享和自动挂载.html":{"url":"32-网络文件共享服务/6-NFS网络共享和自动挂载.html","title":"第6节 NFS网络共享和自动挂载","keywords":"","body":"第6节. NFS网络共享和自动挂载 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"32-网络文件共享服务/7-SAMBA共享服务实现01.html":{"url":"32-网络文件共享服务/7-SAMBA共享服务实现01.html","title":"第7节 SAMBA共享服务实现01","keywords":"","body":"第7节. SAMBA共享服务实现01 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"32-网络文件共享服务/8-SAMBA共享服务实现02.html":{"url":"32-网络文件共享服务/8-SAMBA共享服务实现02.html","title":"第8节 SAMBA共享服务实现02","keywords":"","body":"第8节. SAMBA共享服务实现02 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"32-网络文件共享服务/9-利用infotify和rsync服务实现实时同步.html":{"url":"32-网络文件共享服务/9-利用infotify和rsync服务实现实时同步.html","title":"第9节 利用infotify和rsync服务实现实时同步","keywords":"","body":"第9节. 利用infotify和rsync服务实现实时同步 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"33-linux防火墙/33-linux防火墙.html":{"url":"33-linux防火墙/33-linux防火墙.html","title":"第三十三章 linux防火墙","keywords":"","body":"第三十三章 linux防火墙 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"33-linux防火墙/1-linux防火墙基础.html":{"url":"33-linux防火墙/1-linux防火墙基础.html","title":"第1节 linux防火墙基础","keywords":"","body":"第1节. linux防火墙基础 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"33-linux防火墙/2-iptables防火墙实战.html":{"url":"33-linux防火墙/2-iptables防火墙实战.html","title":"第2节 iptables防火墙实战","keywords":"","body":"第2节. iptables防火墙实战 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"33-linux防火墙/3-iptables防火墙扩展模块实战.html":{"url":"33-linux防火墙/3-iptables防火墙扩展模块实战.html","title":"第3节 iptables防火墙扩展模块实战","keywords":"","body":"第3节. iptables防火墙扩展模块实战 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"33-linux防火墙/4-iptables防火墙扩展模块实战和策略优化.html":{"url":"33-linux防火墙/4-iptables防火墙扩展模块实战和策略优化.html","title":"第4节 iptables防火墙扩展模块实战和策略优化","keywords":"","body":"第4节. iptables防火墙扩展模块实战和策略优化 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"33-linux防火墙/5-网络防火墙和SNAT原理.html":{"url":"33-linux防火墙/5-网络防火墙和SNAT原理.html","title":"第5节 网络防火墙和SNAT原理","keywords":"","body":"第5节. 网络防火墙和SNAT原理 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"33-linux防火墙/6-网络防火墙DNAT实战和端口重定向.html":{"url":"33-linux防火墙/6-网络防火墙DNAT实战和端口重定向.html","title":"第6节 网络防火墙DNAT实战和端口重定向","keywords":"","body":"第6节. 网络防火墙DNAT实战和端口重定向 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"33-linux防火墙/7-firewalld新式防火墙实现.html":{"url":"33-linux防火墙/7-firewalld新式防火墙实现.html","title":"第7节 firewalld新式防火墙实现","keywords":"","body":"第7节. firewalld新式防火墙实现 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"33-linux防火墙/8-firewalld实现防火墙功能.html":{"url":"33-linux防火墙/8-firewalld实现防火墙功能.html","title":"第8节 firewalld实现防火墙功能","keywords":"","body":"第8节. firewalld实现防火墙功能 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"34-LinuxVirtualServer/34-LinuxVirtualServer.html":{"url":"34-LinuxVirtualServer/34-LinuxVirtualServer.html","title":"第三十四章 LinuxVirtualServer","keywords":"","body":"第三十四章 LinuxVirtualServer Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"34-LinuxVirtualServer/1-LVS工作原理和NAT模型.html":{"url":"34-LinuxVirtualServer/1-LVS工作原理和NAT模型.html","title":"第1节 LVS工作原理和NAT模型","keywords":"","body":"第1节. LVS工作原理和NAT模型 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"34-LinuxVirtualServer/2-LVS工作原理DR等三种模型.html":{"url":"34-LinuxVirtualServer/2-LVS工作原理DR等三种模型.html","title":"第2节 LVS工作原理DR等三种模型","keywords":"","body":"第2节. LVS工作原理DR等三种模型 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"34-LinuxVirtualServer/3-LVS和NAT模型实现.html":{"url":"34-LinuxVirtualServer/3-LVS和NAT模型实现.html","title":"第3节 LVS和NAT模型实现","keywords":"","body":"第3节. LVS和NAT模型实现 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"34-LinuxVirtualServer/4-LVS的DR模型实现.html":{"url":"34-LinuxVirtualServer/4-LVS的DR模型实现.html","title":"第4节 LVS的DR模型实现","keywords":"","body":"第4节. LVS的DR模型实现 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"34-LinuxVirtualServer/5-LVS跨网段DR模型和FWM多服务绑定.html":{"url":"34-LinuxVirtualServer/5-LVS跨网段DR模型和FWM多服务绑定.html","title":"第5节 LVS跨网段DR模型和FWM多服务绑定","keywords":"","body":"第5节. LVS跨网段DR模型和FWM多服务绑定 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"34-LinuxVirtualServer/6-LVS实现健康性检查功能.html":{"url":"34-LinuxVirtualServer/6-LVS实现健康性检查功能.html","title":"第6节 LVS实现健康性检查功能","keywords":"","body":"第6节. LVS实现健康性检查功能 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"34-LinuxVirtualServer/7-keepalived实现高可用性原理介绍.html":{"url":"34-LinuxVirtualServer/7-keepalived实现高可用性原理介绍.html","title":"第7节 keepalived实现高可用性原理介绍","keywords":"","body":"第7节. keepalived实现高可用性原理介绍 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"35-高可用集群keepalived/35-高可用集群keepalived.html":{"url":"35-高可用集群keepalived/35-高可用集群keepalived.html","title":"第三十五章 高可用集群keepalived","keywords":"","body":"第三十五章 高可用集群keepalived Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"35-高可用集群keepalived/1-keepalived实现浮动的VIP.html":{"url":"35-高可用集群keepalived/1-keepalived实现浮动的VIP.html","title":"第1节 keepalived实现浮动的VIP","keywords":"","body":"第1节. keepalived实现浮动的VIP Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"35-高可用集群keepalived/2-keepalive实现LVS的高可用性.html":{"url":"35-高可用集群keepalived/2-keepalive实现LVS的高可用性.html","title":"第2节 keepalive实现LVS的高可用性","keywords":"","body":"第2节. keepalive实现LVS的高可用性 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"36-高性能WEB服务nginx01/36-高性能WEB服务nginx01.html":{"url":"36-高性能WEB服务nginx01/36-高性能WEB服务nginx01.html","title":"第三十六章 高性能WEB服务nginx01","keywords":"","body":"第三十六章 高性能WEB服务nginx01 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"36-高性能WEB服务nginx01/1-IO五种模型和select与epoll工作原理.html":{"url":"36-高性能WEB服务nginx01/1-IO五种模型和select与epoll工作原理.html","title":"第1节 IO五种模型和select与epoll工作原理","keywords":"","body":"第1节. IO五种模型和select与epoll工作原理 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"36-高性能WEB服务nginx01/2-nginx编译安装和功能介绍.html":{"url":"36-高性能WEB服务nginx01/2-nginx编译安装和功能介绍.html","title":"第2节 nginx编译安装和功能介绍","keywords":"","body":"第2节. nginx编译安装和功能介绍 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"36-高性能WEB服务nginx01/3-nginx全局配置和性能优化.html":{"url":"36-高性能WEB服务nginx01/3-nginx全局配置和性能优化.html","title":"第3节 nginx全局配置和性能优化","keywords":"","body":"第3节. nginx全局配置和性能优化 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"36-高性能WEB服务nginx01/4-nginx实现web服务器01.html":{"url":"36-高性能WEB服务nginx01/4-nginx实现web服务器01.html","title":"第4节 nginx实现web服务器01","keywords":"","body":"第4节. nginx实现web服务器01 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"36-高性能WEB服务nginx01/5-nginx实现web服务器02.html":{"url":"36-高性能WEB服务nginx01/5-nginx实现web服务器02.html","title":"第5节 nginx实现web服务器02","keywords":"","body":"第5节. nginx实现web服务器02 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"37-高性能WEB服务nginx02/37-高性能WEB服务nginx02.html":{"url":"37-高性能WEB服务nginx02/37-高性能WEB服务nginx02.html","title":"第三十七章 高性能WEB服务nginx02","keywords":"","body":"第三十七章 高性能WEB服务nginx02 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"37-高性能WEB服务nginx02/1-nginx常见配置.html":{"url":"37-高性能WEB服务nginx02/1-nginx常见配置.html","title":"第1节 nginx常见配置","keywords":"","body":"第1节. nginx常见配置 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"37-高性能WEB服务nginx02/2-nginx第三方模块echo和自定义json.html":{"url":"37-高性能WEB服务nginx02/2-nginx第三方模块echo和自定义json.html","title":"第2节 nginx第三方模块echo和自定义json","keywords":"","body":"第2节. nginx第三方模块echo和自定义json Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"37-高性能WEB服务nginx02/3-nginx的压缩和https加密实现.html":{"url":"37-高性能WEB服务nginx02/3-nginx的压缩和https加密实现.html","title":"第3节 nginx的压缩和https加密实现","keywords":"","body":"第3节. nginx的压缩和https加密实现 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"37-高性能WEB服务nginx02/4-nginx的rewrite模块实现.html":{"url":"37-高性能WEB服务nginx02/4-nginx的rewrite模块实现.html","title":"第4节 nginx的rewrite模块实现","keywords":"","body":"第4节. nginx的rewrite模块实现 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"37-高性能WEB服务nginx02/5-nginx反向代理实现.html":{"url":"37-高性能WEB服务nginx02/5-nginx反向代理实现.html","title":"第5节 nginx反向代理实现","keywords":"","body":"第5节. nginx反向代理实现 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"38-高性能WEB服务nginx03/38-高性能WEB服务nginx03.html":{"url":"38-高性能WEB服务nginx03/38-高性能WEB服务nginx03.html","title":"第三十八章 高性能WEB服务nginx03","keywords":"","body":"第三十八章 高性能WEB服务nginx03 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"38-高性能WEB服务nginx03/1-nginx反向代理缓存和IP透传等功能.html":{"url":"38-高性能WEB服务nginx03/1-nginx反向代理缓存和IP透传等功能.html","title":"第1节 nginx反向代理缓存和IP透传等功能","keywords":"","body":"第1节. nginx反向代理缓存和IP透传等功能 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"38-高性能WEB服务nginx03/2-nginx实现fastcgi反向代理.html":{"url":"38-高性能WEB服务nginx03/2-nginx实现fastcgi反向代理.html","title":"第2节 nginx实现fastcgi反向代理","keywords":"","body":"第2节. nginx实现fastcgi反向代理 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"38-高性能WEB服务nginx03/3-nginx反向代理实现负载均衡及调度方法.html":{"url":"38-高性能WEB服务nginx03/3-nginx反向代理实现负载均衡及调度方法.html","title":"第3节 nginx反向代理实现负载均衡及调度方法","keywords":"","body":"第3节. nginx反向代理实现负载均衡及调度方法 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"38-高性能WEB服务nginx03/4-nginx四层代理功能和tengine编译安装.html":{"url":"38-高性能WEB服务nginx03/4-nginx四层代理功能和tengine编译安装.html","title":"第4节 nginx四层代理功能和tengine编译安装","keywords":"","body":"第4节. nginx四层代理功能和tengine编译安装 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"38-高性能WEB服务nginx03/5-keepalived实现反向代理的高可用.html":{"url":"38-高性能WEB服务nginx03/5-keepalived实现反向代理的高可用.html","title":"第5节 keepalived实现反向代理的高可用","keywords":"","body":"第5节. keepalived实现反向代理的高可用 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "}}