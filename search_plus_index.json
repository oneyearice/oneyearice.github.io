{"./":{"url":"./","title":"Introduction","keywords":"","body":"Introduction 课程介绍和·小·目标 linxu~PY，-go~> 目录生成的方法： 打开pycharm里的windows/summary/list/directory_generate.py，运行 将运行结果去头掐尾后，复制到nodepad过滤一遍格式，然后再复制到SUMMARY.md中即可。 然后再gitbook init初始化目录结构。 github 创建项目的提示备忘： …or create a new repository on the command line echo \"# oneyearice.github.io\" >> README.md git init git add README.md git commit -m \"first commit\" git branch -M main git remote add origin https://github.com/oneyearice/oneyearice.github.io.git git push -u origin main …or push an existing repository from the command line git remote add origin https://github.com/oneyearice/oneyearice.github.io.git git branch -M main git push -u origin main …or import code from another repository You can initialize this repository with code from a Subversion, Mercurial, or TFS project. 多终端pull和push注意点： 1、首先pull下来，得到最新的版本，如果是第一次git clone即可 2、复制oneyearice.github.io并重命名为gitbook；如果是git clone的就复制文件夹里的内容到gitbook下，选择替换原文件，得到最新的版本。 注意gitbook是本地编辑目录，oneyearice.gitbhu.io是pull和push目录 3、进入gitbook下运行gitbook install安装插件 3、在gitbook里编辑md文件，也就是主要工作内容 4、运行脚本自动上传 1、进入D盘 git clone https://github.com/oneyearice/oneyearice.github.io.git 如果有Oneyearice.github.io文件夹，进去后git pull 2、将oneyearice.github.io文件夹复制，并改名为gitbook 3、进入gitbook，删除node_module文件夹，cmd在gitbook文件夹下运行gitbook install ---开始编写md文章---完了就👇--- 4、我的笔记本电脑需要注释掉book.json里的\"-anchor-navigation-ex\"👈这样注释，运行脚本自动push--如果push失败，看报错，一般就是需要先git pull一下然后再运行脚本，因为可能最近的一次push是别的终端push的。这是合理的机制。 后面再看吧，是否可以进一步弄成两个脚本，pull和push，pull就上面的1 2 3，push就是4 云服推荐：原生、靠谱干净的IP👉https://www.dmit.io/aff.php?aff=5321 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-11-27 10:24:16 "},"序.html":{"url":"序.html","title":"序","keywords":"","body":"一声叹息解千愁 风中再无少年游 华发霜鬓难回首 万般滋味在心头 仰天长笑忆往昔 终究哪般得自由 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-01-18 10:34:18 "},"1-基础知识介绍/1-基础知识介绍.html":{"url":"1-基础知识介绍/1-基础知识介绍.html","title":"第一章 基础知识介绍","keywords":"","body":"第一章 基础知识介绍 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:34:58 "},"1-基础知识介绍/1-计算机基础.html":{"url":"1-基础知识介绍/1-计算机基础.html","title":"第1节 计算机基础","keywords":"","body":"第1节. 计算机基础 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:34:58 "},"1-基础知识介绍/2-操作系统基础.html":{"url":"1-基础知识介绍/2-操作系统基础.html","title":"第2节 操作系统基础","keywords":"","body":"第2节. 操作系统基础 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:34:58 "},"1-基础知识介绍/3-linux介绍.html":{"url":"1-基础知识介绍/3-linux介绍.html","title":"第3节 linux介绍","keywords":"","body":"第3节. linux介绍 https://www.kernel.org/ slackware:SUSE debian:ubuntu redhat:REHEL、CentOS [11:02:17 root@pyConsole ~]#uname -r 4.18.0-193.el8.x86_64 linux只是一个内核，加上GNU工具、附加软件和软件包管理组成的操作系统才是发行版。 CentOS https://wiki.centos.org/Download http://mirrors.aliyun.com http://mirrors.sohu.com http://mirrors.163.com https://mirrors.tuna.tsinghua.edu.cn/centos/ Ubuntu http://cdimage.ubuntu.com/releases/18.04.1/release/?_ga=2.56783850.1533668672.1544323446-1412352718.1543052421 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:34:58 "},"2-linux基础和帮助/2-linux基础和帮助.html":{"url":"2-linux基础和帮助/2-linux基础和帮助.html","title":"第二章 linux基础和帮助","keywords":"","body":"第二章 linux基础和帮助 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"2-linux基础和帮助/1-linux安装前准备.html":{"url":"2-linux基础和帮助/1-linux安装前准备.html","title":"第1节 linux安装前准备","keywords":"","body":"第1节. linux安装前准备 1、 在windows是怎么安装的，类比一下， 分区、C盘、D盘，系统、数据文件。 2、 在linux同样类似思路，逻辑卷、raid， 大多数企业选择的是分区方式，而不是逻辑卷和raid。 3、 linux一切皆文件，不同类型的资源都命名为文件了 linux的目录结构 windows的C盘，D盘，里面格式有很多文件夹 C盘的顶级目录 在windows里有几个分区，就有几个顶级目录，或者叫根目录 在linux只有一个根root，而且用的是正斜线，linux不管你是几个分区，它的目录结构都是不变的。 /usr 类似于windows里的C盘下的windows目录，都是存放操作系统文件的。 /root或者/home/xx 类似windows里的C盘下的users目录，都是存放用户自己的文件的。 此外在linux还有/boot目录，存放启动文件，比如linux内核就是放在该目录下的。 日志信息在/var/log，/var本身就是变化的意思。 /tmp存放临时数据的。 /proc是个假目录，是映射成内存数据，就是看到的是内存里的数据。正常的数据是放在磁盘上的，真正的目录都是对应磁盘上的文件夹，里面的数据都是放在磁盘上。这就是一切皆文件。 /etc就是windows里的注册表，注册表并不是单一的某一个文件，是二进制的若干个文件，不是存在在磁盘的某一处的。/etc就是各种配置文件也是文本文件。 linux分区和目录结构无关 linux有个目录叫/dev，存放设备的，包括，硬盘、光盘、u盘等。都是在dev下。比如机器上多块硬盘，linxu自动会出现多个文件。命名方式为，命名硬盘的方式sda,sdb,sdc这是centos6和7的命名方式， 在硬盘上还可划分分区，涉及分区类型，在windows上的分区是用盘符来命名的。分区还有扩展分区和逻辑分区。 分区类型： 1、 分区跟你的硬盘分区策略有关，GPT只支持主分区，暂不做讨论 2、 MBR是传统的分区法，支持主分区、扩展分区、逻辑分区（逻辑驱动器） 主分区，在单块一个硬盘上只能最多四个。如果有两块硬盘，其中一块可以没有主分区。在windows里主分区通常可以安装操作系统。不仅仅存放数据，如果有多个主分区，就有且仅有一个激活的主分区，OS启动的时候会去寻找激活的主分区，一个硬盘上最多有一个。 扩展分区：仅仅是主分区的话最多是4个，所以还需要扩展分区。在一个硬盘上最多一个扩展分区。不能直接存放数据，必须先将其划分成更小的分区-逻辑分区， 逻辑分区，扩展分区里更小的单位，这个小分区才能存数据，逻辑分区的个数可以很多。 3、 一块硬盘，主分区、主分区、大的扩展分区（里面分成若干个小的逻辑分区） 4、 linux一切皆文件，硬盘是有文件的，分区同样也是。分区是有编号的，主分区是1-4，扩展分区也是1-4，主分区+扩展分区一共最多4个，因此都是用1-4来表示的。 主分区的文件名：/dev/sda1 /dev/sda2，这个就是a硬盘上的第一个分区，第2个分区。这是主分区，扩展呢，一样也是1-4，比如/dev/sda3就可能是扩展分区。 5、 逻辑分区的编号，是从5开始编号的，/dev/sda5 /dev/sda6 dev/sda7，这三个就是在/dev/sda3上面的分区的。这个逻辑的序号是自动分配的，不能像主分区和逻辑分区那样可以人为的命名。 6、 扩展分区删除，意味着里面的逻辑分区也没了。 7、 存在不同分区的同名文件。讨论分区和目录的关系。windows是C盘下的test文件，D盘下的test文件。linux呢？是从根下面开始描述的。此时就需要把分区和某一个文件夹做关联，将来这个test就是这个关联好的目录下的文件了。 8、 将第一个硬盘分区和boot关联，boot就是对应/dev/sda1，所以要访问第一个硬盘的第一个分区就访问/boot就行了。此时第一个分区里的test就在/boot/test。第二个分区要想访问，就得先把他映射成一个目录比如叫/data，把第二个主分区/dev/sda2挂载到/data下，第二个test就在/data/test 9、 这种挂载在windows里是存在的，windows的分区也可以挂载到文件夹的。windows的e盘的盘符可以删了，此时这块空间和目录结构就没有关联没有映射了，磁盘管理就看不到e盘了，但数据还在，再加回去，可以叫其他F盘之类，还可以挂载到NFS文件夹中的这就跟linux的挂载文件一样了。 10、 没有独立出来挂载分区的文件夹，都是跟在根下的，都在根所在的分区里，有些是不能独立挂载的，必须和根在一起，比如/etc /dev ， /proc是虚拟文件夹内存来着更加不能独立了。 11、 理论上一个分区也是阔以的，但是肯定不安全，一个分区挂了，就完了。 12、 一般分区这样 /dev/sda 200g硬盘的推荐分区： /dev/sda1 mount /boot 1G 这是引导目录不需要太多空间200M的实际占用，也不是给你存放数据的，你的数据也别扔这里面，1G空间足足有余了。这个目标文件夹就叫mount point挂载点。 /dev/sda2 mount / 100G 根上，根下存放的数据就比较多了，如果linux安装不是最小化安装，光是系统本身就要几个G的数据，如果是最小安装，至少1g。 /dev/sda3 mount /data 50G 测试练习用的文件夹，学习用的，工作中，用户会用来存放数据库单独占一个分区。 /dev/sda4 swap 4G，这里不能叫mount挂载，因为swap不是个文件夹，它是分区，不能叫挂载，挂载都是设备往文件里挂。 如果这样划分的话，我们知道一个硬盘上最多4个主分区，意味着200G剩下50G的空间用free，将来不能再分区了，因为4个分区满了，逻辑分区是在扩展分区里分的，扩展分区是占主分区的1-4这个编号的，现在没地儿了。所以上面的分区得改。 /dev/sda4 extend 剩下的所有空间（除了上面分的所有空间剩下的45G） /dev/sda5 逻辑分区 swap 4G sda5就是在sda4上面分的了 还可以继续分小的逻辑分区。比如/dev/sda6等。 13、 swap 交换 早期机器内存小2G 4G swap就是4g 8g的分配， 现在服务器你的内存都很大256g 512g，swap肯定不能乘以2了，swap一般就是8g 16g就足够了。 14、 linux的swap和windows里的pagefile.sys文件是一回事 15、 GPT不支持扩展分区和逻辑分区 4、 在使用vmware worksation安装镜像的时候，光盘需要最后挂载，不然系统自动安装不会让自己分区的，而且还是最小化安装。 5、 os下载，可以到阿里云上下载， 6、 vmware的lck缓存文件注意一下，突然断电关机了，lck可能需要手动删除才能保证VM正常开机。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"2-linux基础和帮助/2-centos7和rocky_linux安装详解.html":{"url":"2-linux基础和帮助/2-centos7和rocky_linux安装详解.html","title":"第2节 centos7和rocky_linux安装详解","keywords":"","body":"第2节 centos7和rocky_linux安装详解 1、安装前最好校验一下，防止iso损坏。 2、密码不符合安全要求，需要点击两次done。 3、文件格式化，linux centos6默认是ext4，也支持windows里的vfat，也支持centos7里的xfs。就用默认的就行 4、分区的sda1或sda2对应/还是/boot，这个序号对应关系不大，只要空间够就行。 5、ctrl + alt f2切到命令行界面，f6切回图形界面，cat /proc/meminfo 便于你在装机阶段查看内存大小。shift pageUp往上翻，memTotoal可见总内存大小。当然你要说 | less | more ，我也没办法。 6、在分区的时候，扩展分区是自动给你分的，你只要知道你在划分sda5的时候，会自动给你划分sda4—扩展分区就行了。 7、cat /proc/partition 可见当前只有一个sda 8、ls /dev/sda* 可见只有一个以sda开头的文件 9、等你的分区，确定格式化，werite chages to disk或done的时候，再去看ls /dev/sda*去看就看到分区开始实施了， cat /proc/partitions 也有了。 10、boot loader环节后面再说，这跳过 11、工作中一般都是minimal最小化安装，节约资源。学习选择Desktop或Server with GUI。 12、desktop，图形默认是GNOME，还有一种是KDE，一般不用KDE的（选择customize now—Desktops—KDE Desktop）。 13、centos7的安装注意： 1、内存2G，1G会导致系统安装报错-内存不够。 2、分区一样的，选择I will configure partitioning -Done-进入分区界面 单位可以输入比如1G 3、KDUMP别管，内核分析记录用的，系统崩溃查看用的，不是一般人玩的。默认是enabled，建议关掉，反正用不到。 4、关于ens33将来要改成eth1的 5、安装后，做好快照 14、ubuntu-18.04.1的安装 略，开发的，我看到的 智能小车，图像识别什么的用的就是ubuntu系统。 15、在安装过程中，可以 ctrl + alt f1 f2去切命令行界面 如果需要的话 16、centos允许你用root登陆，ubuntu不允许使用root，可以改passwd使能root的。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"2-linux基础和帮助/3-linux入门操作和基础命令.html":{"url":"2-linux基础和帮助/3-linux入门操作和基础命令.html","title":"第3节 linux入门操作和基础命令","keywords":"","body":"第3节. linux入门操作和基础命令 入门操作 1、看版本 cat [root@localhost ~]# cat /etc/os-release NAME=\"Rocky Linux\" VERSION=\"8.5 (Green Obsidian)\" ID=\"rocky\" ID_LIKE=\"rhel centos fedora\" VERSION_ID=\"8.5\" PLATFORM_ID=\"platform:el8\" PRETTY_NAME=\"Rocky Linux 8.5 (Green Obsidian)\" ANSI_COLOR=\"0;32\" CPE_NAME=\"cpe:/o:rocky:rocky:8.5:GA\" HOME_URL=\"https://rockylinux.org/\" BUG_REPORT_URL=\"https://bugs.rockylinux.org/\" ROCKY_SUPPORT_PRODUCT=\"Rocky Linux\" ROCKY_SUPPORT_PRODUCT_VERSION=\"8\" [root@localhost ~]# cat /etc/centos-release Rocky Linux release 8.5 (Green Obsidian) [root@localhost ~]# cat /etc/redhat-release Rocky Linux release 8.5 (Green Obsidian) [root@localhost ~]# cat /etc/rocky-release Rocky Linux release 8.5 (Green Obsidian) [18:27:16 root@pyConsole ~]#lsb_release -a bash: lsb_release: command not found... Install package 'redhat-lsb-core' to provide command 'lsb_release'? [N/y] y * Waiting in queue... * Loading list of packages.... Failed to install packages: Could not depsolve transaction; 1 problem detected: Problem: conflicting requests - nothing provides ncurses-compat-libs(x86-64) needed by redhat-lsb-core-4.1-47.el8.x86_64 [18:27:22 root@pyConsole ~]#cat /etc/centos-release CentOS Linux release 8.2.2004 (Core) 2、看内核 uname -r 3、关闭GUI，free可见 700M+的内存使用量，关闭前后的内存使用对比，init 3 关闭GUI，进入纯字符界面。再来看free 还剩200M+，一下500M的量省了。linux的图形界面相当于linux的一个软件可以开关。 5、runlevel 可见 5 3，说明之前是5模式切换到3的。 6、init 5如果你有图形的话，可以切回去。 7、who 不仅看当前登入的人 who -r可见这用户用的哪个运行模式，如果上一次是其他模式，也有last关键字看到 基础cli-1 1、root也不一定就是管理员，这是由UID的设置来影响的，UID=0就是超级用户 也就是管理员。 2、id 就能看到，id -u 显示当前用户的uid，id -u xx 显示xx用户的uid（从1000开始的） 3、centos6 新建用户默认从500开始，centos7和ubuntu默认冲1000开始 4、1000或500以内是特殊保留的数字 5、xx账号的uid改成0，xx就是超级用户了。 6、ll /dev/console 救援模式用的就是console终端，一般用不到 7、cat /etc/shells 可见目前支持的shell类型，在ubuntu上支持的并不相同。 8、/sbin/nologin 是一个特殊shell，禁止登入，当用户使用这种类型的shell的时候，就是不能登入的，软件运行的时候是后台运行的，但是不需要用户登入就能运行的。nologin其实就是无需登入就能运行的意思。 9、主机名：bj-yz-k8s-node1-100-10.XXX.com，北京亦庄k8snode1节点X.X.100.10.域名 10、echo $PS1 可见默认值，\\u就是用户名 \\h主机名 \\w当前目录 ，可以加上颜色 11、字体颜色 31-37 7种颜色，背景颜色 41-47 也是7种颜色 ， 1和5 就是亮色和闪烁。 PS1=\"[\\u@\\h \\W]$\" 这是默认值 PS1=\"[\\e[1;5;41;33m][\\u@\\h \\W]\\$[\\e[0m]\" PS1=\"[\\e[1;32m][[\\e[0m]\\t [\\e[1;33m]\\u[\\e[36m]@\\h[\\e[1;31m] \\W[\\e[1;32m]][\\e[0m]\\$\" 12、配置文件のPS1，ls /etc/profile.d/xx.sh 名字无所谓后缀要求是sh。 13、ubuntu切root, sudo -i 输入当前用户的口令就行了。 14、centos的PS1配置文件可以放在/etc/profile.d/xx.sh 或者和ubuntu一样放到/etc/profile文件下，unbutnu实在~/.profile，在每个账号的家目录下。 15、/etc/profile是统一的配置文件，这个文件影响范围大，配置要小心。 16、sleep 10，然后看pstree -p可以看到bash下面有一个sleep 17、还有很多程序不依赖于bash，不需要和人进行交互，后台直接运行了。 18、shell自身提供的内部命令、非shell自身提供的，磁盘上其他程序 19、bash里面集成了很多工具，就是内部命令，bash运行了，这些内部命令是加载到了内存中的。 20、cat /etc/profile.d/env.sh，这个cat就是bin下的cat cat就不是bash下内部命令了。是独立的二进制程序，这就是外部命令。 21、外部命令需要找到磁盘的存放路径，内部命令不需要会开机加载到内存中的 22、type用来查看命令是内部还是外部。 23、内部命令是集成在shell中的，而shell用户一登入就加载到内存里了；而外部命令表现为磁盘上的某个文件，所以内部命令速度更快。 24、如果有一个命令即使内部命令又是外部命令，那么内部命令优先生效，比如echo 当执行echo命令的时候，系统自动选择第一个内部命令。 25、为啥有一个内部命令了，还需要一个外部命令存在呢？因为内部命令是存在某个特定shell里的，echo在bash里，但是不一定在csh等其他shell里，所以需要外部命令来保证命令的普遍适用性。 26、切换shell 27、help可以列出所有内部命令的帮助。不多 28、外部命令就多了，表现为磁盘文件，ls /bin/ 或ls/sbin/ 29、enable会列出所有内部命令的列表 enable -n echo禁用echo后，echo就只有外部命令了，就表现为磁盘文件了，所以如上图。 禁用后，就看不到echo了 help里还可以看到一个*号 enable echo就再次启用了 30、enable -n enable enable enable不可能了，因为enable已经禁用了，退出重进就行了，或新开一个终端。 31、which专用用来查看文件的路径，自然可以查看外部命令了（外部命令就是磁盘的一个二进制bin文件） 32、bc了解一下 obase=2输出为二进制或10进制 ibase=2输入为二进制，默认都是obase=10，ibase=10. 32、whereis不仅仅显示文件（外部命令）的存放路径，还显示了相关文档帮助也显示出来了， 这是man帮助 33、外部命令，系统是怎么找到的，PATH变量了解一下 PATH变量就是存放了一个个文件夹， 1、当你输入一个命令，系统首先判断是否有别名，是执行，不是继续。 2、如果是内部命令，执行，如果不是，继续 3、如果是外部命令，就搜索PATH变量里的路径。前面的目录找到了，后面就不会找了。 4、其实也不是每次执行外部命令，都搜一遍PATH变量的路径的。为了加快访问速度，比如有一个文件我经常访问，linux就会将其缓存在内存中，因为内存中已经有了，就直接在内存中访问就行了。这也是linux的一个经常的思路。这就是所谓的缓存技术。 5、第一次执行hostname的时候，会按PATH变量里的路径来搜，一旦找到后，就会把hostname的路径缓存在内存里HASHE。下次执行hostname的时候，先从内存的HASH表里去搜索，如果查到内存中有这个路径，就不按照PATH变量搜索了，直接按HASH的记录的上次缓存的路径直接去到那个路径找到hostname文件去执行。 6、这里面还有一个细节，就是除了HASH，其实还有一个HASH对应的明文（路径的明文），这个一般不会给你讲这么细，网工会有这个思路可能。 7、这样的一个漏洞或缺点就是，如果外部命令hostname被移动了，那么HASH缓存的路径就不对了，这样命令执行就会报错。如下图 图示为hash记录的上一次hostname的路径。 再移回去就可以了， 疑点：我明明移动的是/bin/hostname而不是/user/bin/hostname，为啥一个效果！ 因为bin就是/usr/bin的快捷方式-软连接，所以一回事了。 再来一遍完整的： 8、上面的也可以不将外部命令移回去，可以清一下缓存就行了。 hash -d hostname 就行了 hash -r 全删 删掉了后，由于缓存没了，所以就会重新搜索，然后再次hash缓存到内存中了。 9、上面就意味着，自己做的程序，就要放到PATH变量里的路径或加一个新路径。 基础cli-2 1、内部命令和外部命令的本质区别，首先都会放入内存中的，本质区别是，内部命令在shell（bin/bash）二进制文件中；外部命令不在二进制文件里，是独立的文件。还一个内存方面一个是登入加载，一个是首次运行加载。 内外之分在于是否在/bin/bash文件里，在就是内部，不在就是外部。 2、问题：内部命令放在/bin/bash下，那么外部命令放在哪？首先放哪都行，关键是外部命令要运行，就得保证PATH变量里有该路径，然后规范行为是，外部命令放到PATH变量下的路径里去。所以外部命令一般来讲就在PATH下。 3、除了内部命令和外部命令，还有别名。 alias cdnet=\"cd /etc/sysconfig/network-scripts/\" 退出后失效，要想存住，就要将其放到文件里，别名的文件在家目录里的.bashrc里 重新登入后依然有效 4、alias列出所有别名，unalias cdnet可以临时删掉，但由于之前写在了配置文件里，所以重新登入后，还是没删掉 还在。所以配置文件的需要进配置文件删除 5、如果有一个字符串，既是 别名、又是内部命令、还是外部命令，那么执行的顺序是什么，这就是命令的执行优先级问题。 以echo（这个即使内部又是外部命令）为例，将其定义成别名，进行测试 说明，别名优先 总结：命令的执行顺序： ①首先判断是否是别名，如果是别名，别名是在内存中定义的，所以直接就执行了。所谓直接就是指已经在内存中了，不像外部命令那样首次执行还需要在PATH变量里进行查找。 助记词alias别名 ②其次，如果不是别名，判读是否是内部命令，如果是，直接执行内部命令（因为内部命令是内置在shell中的，用户登入就已经加载到内存中了）， 助记词 内部命令 ③最后，如果既不是别名也不是内部命令，那就按外部命令处理，就会看HASH表（表里记录了已经被执行过了外部命令的路径），如果HASH表里有该命令，就按表内记录的路径去搜索该外部命令去执行；如果HASH表里没有，就在PATH变量里查找，找到后执行。当然所谓执行也是加载到内存中执行的。对于首次运行的外部命令，也会产生的新的HASH表项。 助记词 外部命令（hash $PATH变量） ④如果找不着，就报错，此命令不存在。 PS：缓存为王，如果想提供一个慢速设备上（比如硬盘）的数据的执行效率，就把它放到内存里，下次从内存访问，速度就提升了。外部命令就是该逻辑思想。后面还有很多次这种套路。 6、加别名用~/.bashrc，这是只针对当前用户有效，家目录嘛，肯定的了。 对所有用户有效是编辑/etc/bashrc 7、别名修改后使之生效的方法，这也是很多配置文件修改后使其生效的通用方法： source /path/to/config_file #就是source 后跟你的配置文件路径 . /path/to/config_file # 就是. 后跟配置文件全路径 比如 . ~/.bashrc 比如： 8、之前的echo既是别名又是内部命令还是外部命令，如何不执行默认的别名优先呢， \\ 和 ‘ 以及 “ 或者 路径 再次command都是可以的 9、命令的格式，COMMAND [OPTIONS…] [ARGUMENTS…] 这点可以联系网络设备的cli 以及python argparse 自定义命令的格式或者规范问题。 -c 这种短选项，以及bsd风格的只有c没有-的用法，freeBSD这种好像cisco的wsa esa底层是这个。 ls -l 这个l就没有长格式 很多命令使用风格已经变了 可以理解成多层子命令的嵌套 10、ctrl+d 是正常退出 sleep 100就不能ctrl+d正常退出，得用ctrl+c强行退出。 11、ctrl+z 12、多个命令写在一行里用分号隔开 上图就是命令太长后认为换行用的。比如pycharm里面也是这么玩的。不过pycharm后来新版本直接回车也没有\\了，也能实现一套命令认为换行的效果。 13、date 系统时间：有软件操系统内核维护，通过CPU的工作频率维护的，date查看 硬件时间：主板上的CMOS，有块小电池（银币状）可供电5年。clock查看 timedatectl 看的最全 clock -s 将system time改一下，改成硬件时间 clock -w 将hardware time改一下，改成系统时间。 date -s ‘20200101 12:02:01’ 系统时间和硬件时间 或者date 010101012008.01 缺点就是看着乱七八糟，优点就是不用写引号便于python调用时的字符串拼接入库啥的。 上图GMT+8 14、时间其实内部一般用NTP去同步的 这里我先停掉ntpd服务，再去同步时间就好了 注意，ntp只会同步系统时间，不会同步硬件时间。 如果硬件时间不对，就先ntp保证系统时间准确后，再clock -w让硬件时间去同步系统时间就可以了。 15、ntp后面细讲，如果企业里时间不同步，涉及加密、集群就会出问题。 16、查看隐藏文件的方法 推荐第一种 l. -l ll -ad .* ll -a |grep -E \" \\.\" a alias b basename bc c cal 9 1752 chkconfig iptables off cd command clock(hwclock) cat /etc/rehat-release /proc/maminfo /proc/partitions d dir类似ls dirname df du date e enable enable -n exit echo f free -h g getenforce disabled h hexdump -C halt history hostname help hash i iptables -vnL init 3字符模式 5图形 0是关机 6是重启 info ifconfig id j k l lsblk logout ls lsb_release -a lshw m mount /dev/sr0 /mnt挂光盘到/mnt下 man mv mandb n ntpdate o p ps pwd poweroff ping pstree q r rpm -ivh rm rz runlevel查看当前运行模式的 s systemctl disable firewalld stat shutdown screen sleep source(.) sz sudo -i t touch tty 看在哪个终端里 type u uname -r unalias v vdir类似ll w which whereis whoami who -r whatis x xxd 等价于hexdump -C y z rz后再按esc可以产生如下图效果，并排两个提示符😶 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"2-linux基础和帮助/4-linux帮助用法.html":{"url":"2-linux基础和帮助/4-linux帮助用法.html","title":"第4节 linux帮助用法","keywords":"","body":"第4节. linux帮助用法 查看帮助相关整理 帮助有这些 whatis command –help -h man and info /usr/share/doc Red Hat documentation 其他网站和搜索 whatis是外部命令，是用来告诉你去找man手册第几页的 以及 该命令的简要说明 如果系统是刚刚装好，whatis是没有结果的，就会出现如下提示，我就不还原系统了。 whatis数据库存放的帮助的简要说明，在刚装好操作系统是没有的，是需要过一会自动生成。如果你不想等，只需要执行 centos6上 makewhatis centos7上 mandb 这样就能生成whatis数据库了。 whatis只是简单说明，详细用法还得参考其他帮助 -----------↓-----Unicode字符集和UTF-8编码--------↓----------- 1、有关文件类型 cat是查看文本文件的，二进制文件看不了，常见的二进制文件有：图片、视频、可执行文件，bash也是 2、二进制的怎么看，二进制太长了，一般就是以16进制形式查看。 hexdump /bin/bash hexdump -C /bin/bash 在linux保存处理都是二进制的，上图的A就是41这个十六进制对应的二进制进行存放在磁盘上的。 阔以的，这排版都得倒一下的~ 3、这些英文或者汉字对应的都有二进制表示的，这种就需要编码表来实现。ASCII就是早期著名的编码表。ASCII（American Standard Code for Information Interchange） 4、ASCII只能表达128个字符，只适用于欧美国家，后来就有了GB2312、GBK我国自己的编码表，以及还有韩国自己的。每个国家的编码都不一样。可能存在都是55这个十六进制，代表的字符不一样，这就产生了冲突。为了统一，就有了统一命令的Unicode， 5、Unicode只是一个规范，定义了全球所有文字或者叫字符和二进制的对应关系。它并没有明确下来这个二进制在磁盘上保存到底是什么形式（用哪种风格）并没有确定下来，比如具体这个二进制在磁盘上占几位，Unicode就没有明确下来，为了具体明确下来（磁盘上存放某个字符占多少位、在网络上传输的时候转成二进制占多少位）就推出了编码的具体实现—比如UTF-8，UTF-8就是Unicode的具体实现。 6、Unicode属于字符集（字符和二进制的对应关系）、UTF-8是编码方式（站位的明确定义）。还有UTF-16和UTF-32，UTF-8使用的最多。 UTF-16用2个或4个字节来表示某个字符。工作中，用得少 UTF-32，所有的文字全都占4个字节。工作中，用的少 UTF-8，使用1-4个字节来表示字符。比如UTF-8兼容ASCII码就是一个字节就够了。生僻字3个或4个字节，常用文字占1-2个字节。 7、Unicode（UTF-8）处理的逻辑机制是这样的，我们vim或nano处理某个文件的时候，在编辑的时候，vim是个软件，自然会在内存中运行这个vim程序。vim打开比如xx.txt这个文件，就会把xx.txt里的字符就转化成了Unicode。你在xx.txt里就可以编辑修改，此时注意这些字符都是在内存中以Unicode形式存在的，当然显示的时候是转换成人类看懂的文字的（这是计算机内部处理的）。 然后你一旦保存，就是存到磁盘上去了，保存到磁盘上就表现为具体编码形式UTF-8了。 后面你再次读xx.txt文件的时候，就是读入内存中，那么此文件在内存中又是以Unicode形式存在的。 8、在网络传输的过程中，PC----请求----Server。比如PC请求http://www.xx.com/index.html, 这个文件在server的磁盘上保存时UTF-8形式，读取到server自己的内存中就是unicode，在网络上传输就是UTF-8，读取到PC处的内存就是unicode，存到PC本地的磁盘就是UTF-8了。当然我记得还有一个BASE64，也需要了解一下。在加密数据的时候就有先使用对称加密后在使用BASE64进行网络传输的，图片在网络传输也是使用BASE64的。 ---------------------↑---------帮助的用法-------------↑------------------------ 9、命令帮助，内部命令和外部命令的help是不一样的 内部命令：help COMMAND 或 man bash 只要是内部命令，都可以通过man bash查看，（当然man也可以看外部命令） 因为/bin/bash文件里集成了所有内部命令，所有man bash就能看到所有内部命令的详细帮助。 bash的man手册有4000多行，有人对其进行了翻译，就是普通学员做了这个事。当然网上也有人汉化也可以参考。 外部命令帮助用法： ①COMMAND -help -h ②man COMMAND ③info COMMAND ④README INSTALL ChangeLog这些程序自身的帮助文档 ⑤程序官方文档 也就是官网的Documentation ⑥发行版的官方文档 ⑦Google bing baidu等搜索引擎 [OPTIONS]...就是选项可以有多个，FORMAT就是在下面列出了很多的FORMAT 10、date 1970-1-1是Unix诞生日 11、显示前天是周几 date 010210102020.300 unix的诞生日，很多时间计算都是从这个点开始的，比如 显示前天周几 12、man手册 manual的意思，利用man可以查看很多外部命令的帮助 上图whereis列出了man帮助的文档。gz压缩文档，不用解压后查看，直接用man命令查看即可。 13、man对应的文档基本都是放在/usr/share/man下的。 man1：linux命令基本都在第1章，是我们常常需要的； man2：系统调用，OS对 外部APP提供内核调用的接口，开发用的；就是应用程序需要和操作系统内核打交道，就得系统调用来完成，在第二章里。man socket 一般看到的就是man 2，属于网络方面的系统调用。不过为啥我的腾讯云上的VPS默认是man3的socket。另外就算是开发也不会直接进行这种底层调用，一般也是通过C库或者python库去调用。 man3：C库调用 man4：设备文件及特殊文件 man5：配置文件格式，也是我们关心的，linux好多配置文件，配置文件有很多格式，这些说明就在第5章里。 这个issu文件怎么配置，他的帮助就在第5章里。然而VPS上并没有 换成我自己的vm虚机就有了 应该VPS是最小化安装，当然也不是都没有，最小化安装man ls，man bash都有的。 man6：游戏 man7：杂项 man8：管理类的命令，管理员，root身份进行一些管理型的命令。 man9：和开发相关的linux内核API。 14、man使用注意点 man xx 默认看的是man1，1以外的章节 需要特别指定第几章才行。比如passwd这个文件配置说明。 /etc/passwd是个文件，/usr/bin/passwd是个命令，这两个passwd不是同一个东西。 显然whatis查看的不仅仅是命令，而type只是查看命令是内部 还是外部 亦或是alias。 man passwd看的是第1章，看的是passwd命令（/usr/bin/passwd） 如果要/etc/passwd配置文件帮助，就需要：man 5 passwd 总之，先whatis xxx看一下在那一章节，然后man n xx去看 man也是个外部命令，可以用whatis去看一下有哪些章。 1p都是和开发相关的。 man man可见 15、man搜索和vim搜索一样 或者 ”?second”，n 和 N是下一个或者上一个。方向键上下，一样调用历史记录。 man -a 查看所有，q+enter进入下一章 man -k passwd查看包含passwd的帮助类似whatis passwd，但明显要比whatis passwd多得多。 man -f passwd 等价于whatis passwd man -w date查看帮助文件在磁盘的路径，类似whereis date，区别在于man只是看man手册在哪，而whereis date还显示命令（文件）的路径。 16、man举例 \\S就是OS版本 Kernel就是Kernel \\r内部版本 \\m X86架构 这个issue就定了用户登入提示信息。 现在需要：显示用户在哪个终端登入上来的，（原本是tty查看的），还要显示时间、显示主机名，此时就需要查看帮助 说明了issue只有第5章有，是预登入和标识文件。 直接man issue就行了，因为只有1个 第5章 上图是man issue的所有信息了（就这么多行，到底了），其中并没有看到什么\\S \\r \\m的解释 不过有一个SEE ALSO可以参考 于是man motd 我们issue是登入之前，而motd是登入之后，不是此时需要的帮助，换一个 man 8 agetty 都找到了 再来对比一下 都找到出处了, welcome…是自己加的 修改为： ​ 17、linux的语言默认是英文，不建议转成中文，但是可以转，如下 有些地方就是中文了 但是man里面还是英文的， 还需要安装如下的中文的包 才能在man手册中显示为中文。 安装的话，我准备使用本地安装光盘里找一找相关软件包，所以不适用VPS了，换成本地CENTOS7 上图表示现在光盘没有挂载，可是我已经在WmwareWorkstation上勾选了connect了。此时只需要在GUI界面上使用和cli同样的账号，此时是root，登入一下就行了 进到光盘的路径下，里面就是所有的安装的软件文件，而且后缀都是.rpm。找到man开头的 发现了zh-CN的中文包了，这个就是可以修改man手册里的中文的包。 使用rpm -ivh 安装，注意ls man按tab补全后ctrl a切换到头将ls改为rpm -ivh，因为rpm 不带自动补全功能 此时在修改一下LANG，localectl set-locale LANG=zh_CN.UTF-8，退出再登入，然后就可以看到man手册里的中文了 但是man 1 passwd就是命令的帮助手册还是英文的 说明中文支持的还不是非常全。不过只是了解一下怎么切中文，一般也不会切的。 所以，切回英文 localectl set-locale LANG=en_US.UTF-8。 18、info 命令一般不用，不过info里面的都是一个个链接，更像是一个网页，是*号开头的，按回车就会跳转，挺有意思的，了解一下，比如info ls 光标停在*号行，按回车，就会跳转 19、man帮助使用较多，info基本不用，此外还有一些不怎么用的帮助，了解一下 GUI里的Applications\\help里面点开可以查看的，这是CentOS7的。CentOS6实在GUI的system/help下。 20、不怎么用帮助之/usr/share/doc 每一个安装好的软件包，都有一个对应的文件夹放在/usr/share/doc下，你可以进去查看软件的说明。 这些文档大部分都是文本，PDF\\HTML\\TXT 都能打开看基本上。 21、linxu只是一个操作系统，常规操作掌握后，更多精力是放在linux系统之上的应用程序—这些第三方软件（apache、nginx、mariadb等），这些软件就要去官方网站查看文档。 第三方应用官方文档举例 http://httpd.apache.org http://www.nginx.org https://mariadb.com/kb/en https://dev.mysql.com/doc http://tomcat.apache.org http://www.python.org 点击documentation后，可以看到 这个软件有很多moduels模块组成，其中有core模块，点击进去可以看看该模块里的各个指令directives。 点击root命令 要学会看懂这里面的说明，因为官方文档才是最权威的一手资料。 22、现在还没进入都linux上层应用的学习阶段，现在还是在学习操作系统本身，系统本身也有官方网站以及documentation的。 红帽知识库和官方在线文档 http://kbase.redhat.com http://www.redhat.com/docs http://access.redhat.com https://help.ubuntu.com/lts/serverguide/index.html 比如现在需要看centos8的安装指南 http://www.redhat.com 如图就找到了CentOS8的安装手册，有升级的、基本安装、定制化、高级安装（kickstat自动化安装），而且右边栏还可以选择查看的文档格式（pdf or web） 23、搜索引擎 http://tldp.org http://www.slideshare.net # 这网站是很多国外的人在研究技术的时候写成了PPT，可以拿下来改吧改吧。 http://www.google.com 搜索的技巧 https://segmentfault.com/a/1190000038432191 https://funletu.com/12851/.html openstack filetype:pdf rhca site:redhat.com/docs #这种站内搜索，受限于对方的安全措施，应该叫反爬机制 https://www.ibm.com/developerworks/cn/linux/index.html 要知道IBM已经收购红帽了，所以该网站也是阔以的。 24、帮助举例 ASCII 字符集 在编码的时候使用 八进制、十进制、十六进制。 然后，man ascii ASCII码总共128个字符，每个字符对应的八进制、十进制、十六进制分别是什么，分两列展示。 想用echo一下ascii，不知道怎么玩，可以man echo在搜oct就行了 所以echo -e “\\0xxx”还有echo-e “\\x21” 25、ascii查看举例 \\x0a是十六进制的，是不分大小写的 26、\\r和\\n 这是\\r的回车return的效果，没有换行，所以还在本行，就会把之前的xxx覆盖了前两位。 这是换行+回车的效果，linux的\\n就是微软的\\r\\n linux也认\\r是回车的意思，所以\\r就是回车、\\n就是换行在回车，这里两个回车了，效果还是把车停到了最左边，就是100个\\r也就是1个\\r的效果，一个\\r也被集成在\\n里了。 所以，在python使用paramiko非交互模式获取H3C的dis cu inter | I inter后，详情如下 如果上图re.split处这么写：portPer1.split(‘\\n’)，在print(i)的时候你会看到显示都是OK的，但是一旦将这些i传入list里后，就会出现xxx\\r\\r如下情况： 此处需补图，回公司才有环境，还得自己整一个网络环境出来，用eve吧明天搞。 所以H3C的display 看到的分行，其实里面是xxx\\r\\r\\n，我猜它这么做为了，为了个屁，就是强迫症，多次回车保证车必然停在最右边，然后\\n换行，所以我改成了re.plit(xxx)如上图。 27、对比一下MS和Linxu的\\r\\n 我们已经知道\\r\\n是MS的换行，\\n是linux的换行，这里说换行自然就包含了回车了。 下面看实验 传到桌面，在打开 可见linux的\\n到MS里是没问题的，结论MS兼容\\n 反过来，来一波 在windows新建f2.txt 使用rz传到linux里或直接拖进去 carriage return简写了 结论 MS的\\r\\n到linux下linux只需要\\n就能进行换行回车，所以多了一个\\r，当然cat的时候是看不到的，或者说python处理的时候可能print也是看不到的，但是\\r确实留在了文本里面，确实会为后面的数据处理带来麻烦的。 相对的，linux下的\\n到了MS里，MS处理的就很好，奇了怪了。我明明记得很多txt文本在windows里看到的都是xxxx\\nxxxx\\nxxxx\\n不换行的格式错乱啊，难道是sz工具对其进行处理了？ 尝试不使用sz工具，而是用sftp进行linxu->ms的文件传输，结果一样还是MS里显示OK。 尝试不用echo -e \"ABC\\nabc\" > f1.txt的方法创建内容，而是使用vim 依然在MS里显示OK，好了此问题不研究了。MS你优秀~ 我明明小写abc后面在linux里就没有换行，传过来结果换行了。 方法论：在文本处理的时候，文本从linux->MS，\\n前加上\\r；从ms->linux，\\r\\n去掉\\r。 以上就说明了：二进制在磁盘上保存机制不同，不可见的符号是看不到的，但是在磁盘上保存确实有的。 xxd和hexdump -C一样的效果，专门看不可见字符。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"2-linux基础和帮助/5-linux入门命令.html":{"url":"2-linux基础和帮助/5-linux入门命令.html","title":"第5节 linux入门命令","keywords":"","body":"第5节. linux入门命令 1、localectl list-locales查看所支持的语言 [11:45:53 root@localhost ~]#localectl list-locales | grep ^en_US en_US en_US.iso88591 en_US.iso885915 en_US.utf8 [11:46:02 root@localhost ~]# [11:46:02 root@localhost ~]#localectl set-locale LANG=en_US.utf8 这是界面风格是英文，不是说不支持中文，因为UTF-8全球语言都支持，之前的文章也讲过UTF-8是unicode全球文职字符集的编码格式。 2、时区文件/etc/localtime 这个时区文件Shanghai也是个二进制文件 3、timedatectl list-timezones 4、cal显示日历 -h看一下就好 [11:49:22 root@localhost ~]#cal 9 1752 September 1752 Su Mo Tu We Th Fr Sa 1 2 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 5、halt，poweroff，reboot，shutdown 关机：halt,poweroff 重启：reboot ​ -f: 强制，不调用shutdown ​ -p: 切断电源 关机或重启：shutdown shutdown [OPTION]... [TIME] [MESSAGE] -r: reboot -h: halt -c: cancel TIME: 不指定，默认就是+1（CentOS7），相对当前时间过一分钟后执行相关动作 ​ now: 立刻关机，等于+0; ​ +m: 例如+3，表示3分钟后； ​ hh:mm: 绝对时间表示，特定时间执行相关动作。 哈哈哈，shtudown -h查看帮助？想当然了，小心误操作哦。 [11:50:25 root@localhost ~]#shutdown Shutdown scheduled for Fri 2022-01-07 11:53:15 CST, use 'shutdown -c' to cancel. [11:52:15 root@localhost ~]#shutdown -c [11:52:22 root@localhost ~]# [11:52:36 root@localhost ~]#shutdown -h Shutdown scheduled for Fri 2022-01-07 11:53:38 CST, use 'shutdown -c' to cancel. [11:52:38 root@localhost ~]#shutdown -c [11:52:41 root@localhost ~]# 6、windows也有shutdown命令 1小时后关机 取消 还支持远程关机 7、who 和 who am I 以及w who，当前有哪些用户登入上来 who am I 或who x x只看当前用户 w 显示谁在登入，运行了那些程序 有点监控的意思了,并没有。 8、screen的用法 虚拟多个屏幕用 首先找到光盘进行安装，当然也用直接yum VmwareWorkstation 连接光盘后，使用非GUI界面相同账号登入(这里是root)，即可完成挂载光盘。哈哈，就这么挂，怎么滴~，当然我现在是mini没GUI。 rpm有tab自动补齐啊，上次怎么没有呢，不管了。 举例1：防止ssh断开导致ping或tftp断开 如果ping着的时候，关闭ssh窗口，ping就停了，证明方法ps aux |grep ping 问题就来了，如果我在备份数据的时候，ssh断了，那备份就失败了，所以screen有用武之地了。 screen -S ming # 创建ming命名的新的屏幕 screen -ls # 查看开启的屏幕有哪些 screen -r ming 进入ming命名的屏幕 举例2：屏幕协助 screen -S ming # A开启一个屏幕 screen -x ming # B进入这个屏幕，此时两个人就共享一个屏幕了。 screen -x ming # C同样可以可以进入该屏幕，此时就三个人共享一个屏幕了，那么问题来了上限是多少人呢？没兴趣知道。哈哈 ctrl+a+d # 注意手法，不能先按ctrl+d，因为ctrl+d是退出的快捷键（等价于exit）；临时剥离该屏幕，但是其他共享屏幕的人看不到的，此时可以干一些不想共享给别人知道的事，然后完了再screen -x ming切回去，就有成了大家共享一个屏幕的情况了。 exit # 一人退出共享屏幕，全部菜单都退出了。 9、echo，回显用 尝试使用帮助看echo，①type echo 发下是内部命令，②所以使用help echo看帮助 [root@centos7 ~]# type echo echo is a shell builtin [root@centos7 ~]# help echo echo: echo [-neE] [arg ...] Write arguments to the standard output. Display the ARGs on the standard output followed by a newline. Options: -n do not append a newline -e enable interpretation of the following backslash escapes -E explicitly suppress interpretation of backslash escapes `echo' interprets the following backslash-escaped characters: \\a alert (bell) \\b backspace \\c suppress further output \\e escape character \\f form feed \\n new line \\r carriage return \\t horizontal tab \\v vertical tab \\\\ backslash \\0nnn the character whose ASCII code is NNN (octal). NNN can be 0 to 3 octal digits \\xHH the eight-bit character whose value is HH (hexadecimal). HH can be one or two hex digits Exit Status: Returns success unless a write error occurs. 功能：显示字符 语法：echo [-neE][字符串] 说明：echo会将输入的字符串送往标准输出，输出的字符串间以空白字符隔开，并在最后加上换行符。 选项： ​ -E （默认）不支持\\解释功能，也就是\\的转义功能； ​ -e 启动\\解释功能，也就是启动转义； ​ -n 不自动换行，类似python的print(‘xxx’,end=’’) 显示变量的值 ​ echo “$VAR_NAME” # 显示变量的值 ​ echo ‘$VAR_NAME’ # 这里讲的其实不是echo的事情了，是引号的用法，单引号就是里面都是原封不动的字符串，不会给你查找变量或命令的。 单引号，最笨，里面是什么就是什么 双引号，普通，里面的变量能够解释出来，里面的命令不识别 原样输出； 反向单引号，最聪明，里面的变量、命令，统统给你识别并解释运行个结果出来。 echo只是结合echo来回显而已。 举个栗子 echo -e “\\a” # 可以发出声音，一般用在代码跑完后滴一声提示。 注意这个linux是在远端PC上，不是本地，但是声音却是本地声音 10、echo显示颜色 echo -e '\\033[43;31;5mICE\\e[0m' 前景颜色43、背景颜色31、5是闪烁‘ 注意43和31位置互换效果一样的，看的其实是4X就是背景色、3X就是字体色 注意\\e也就是\\033前后都有。颜色数字顺序不重要，然后上图是大家喜爱的红配绿。 1m的1是亮色 注意\\033等价于\\e linux里很多信息都是带颜色的，比如 我们自己也可以做出该效果 比如echo： 上图是1是加亮，下图5是闪烁 将来shell脚本，需要屏幕上显示一些东西带颜色，就这么玩。 11、一些编码转换和查询 之前一篇说过字符集和编码也就是unicode和UTF-8的事情，下面是工具网站 http://www.chi2ko.com/tool/CJK.htm https://javawind.net/tools/native2ascii.jsp?action=transform http://tool.oschina.net/encode 类似的网站 12、命令行扩展、被括起来的集合 很多时候会用到3种引号 ‘’ 单引号 “” 双引号 `` 反向单引号 等价于 $() 注意凡是在word或execl中的引号不能直接复制到linux或python里运行，不管你是否是英文的，复制过去就是不对，基本上需要重新键入引号。后面才知道word本身可以设置引号为英文的，这样就可以统一了。 花括号 echo file {1,3,5} rm -f file{1,3,5} echo {1..10} echo {a..z} echo {000..20..2} 花括号里面的就是选择或者递增的关系，花括号外面的_是必然有的。 批量创建文件、用户等。 双引号、单引号、反向单引号，针对不同的场景，作用不同， 针对echo的，针对shell编程的，不同应用地方的作用是不同的。 1、引号在echo处的作用 单引号：里面全是字符串，他大舅他二舅都是他舅。 反向单引号：能识别里面的命令和变量。 双引号：不能识别里面的命令，只能识别里面的变量。 2、一个命令调用另一个命令的结构的时候，经常使用反向单引号。 问题来了 data后面的要引起来，所改成双引号，但是问题如下 结合下图 结论date ‘+%F %T’得到的是两个值，所以touch的时候才会创建两个文件 都是空格惹的祸 所以最终的方法如下 结论：touch创建一个文件的时候不能带空格，有了就是两个文件了。上面的’+%F_T’可以不用引号了，因为本身就是一个整体了。 但文件名应该可以带空格的，虽然不太好，windows就是 3、反向单引号和$()是等价的 结论：反向单引号作为一个单元在其他引号内部出现，不影响效果。 所以上面的也可以这么写 4、每晚12点01分执行备份日志等操作，并保存为前一天的时间 5、tab补全 命令补全（命令的option也是可以补全的，按两下tab会出来一推） 路径补全 文件补全 虽然没神马用。 6、命令行历史 linux输入的每个命令默认都是有历史记录的，除非在键入命令的时候加入特别选项（也很方便做到）。 这些输入的命令记录会放在内存的缓存区里。内存里有一个历史列表，存放了输入的这些命令。 突然断电，或者直接关闭xshell，这些记录就有可能没了，可能就没写到.bash_history文件里。 一般系统会自动保存到文件里， history的ctrl r快速搜 上图的操作为：!然后按ctrl r，输入echo，就会从history里找到最近的一次包含echo的命令，我经常用来做snmpwalk -v -2c xxx 10.1.1.1 .1.3.6.1 x.x.x.x.x 这种历史的调用。 这是包含，下面的水以什么开头的最近的一次历史命令 下面是包含什么的最近的一次历史命令 10、把上一条命令的前面的换掉 11、上面的ctrl r修正一下 不需要输入history在按ctrl r直接ctrl r就行ctrl g是退出 12、非常实用的命令,把前一个命令的最后一个参数调出来 上面的!$调用比较方便，还有交互式下的快捷键可用来替代!$，比如 按esc松开不松开都可以再按. 或者按alt . 考虑到xshell的默认快捷键冲突，所以建议改一改，这么改就行 需要更加多样的调用，实际上!$是上一个命令的最后一个参数，!^是就是第一个参数，其他还有很多类似用法，但是我觉得没必要了，其他的不实用。 13、history命令选项用法继续 ①history会默认记录命令，现在考虑安全，可以清除历史 这个history -c是清楚的内存中的历史，而历史命令不仅仅是内存中有，还有磁盘文件也有。 但是这个文件放的是以前的历史命令。不是现在的几条。退出重进，发现echo passwordxxx确实不在，其实就是趁着内存中的命令还没自动放进./.bash_history里history -c直接就清掉了。 但是腾讯云上显然不是这样，应该是有了优化（内存中的命令会立刻存到.bash_history文件中的，如下图。） ①history会默认记录命令，现在考虑安全，可以清除历史 这个history -c是清楚的内存中的历史，而历史命令不仅仅是内存中有，还有磁盘文件也有。 而且腾讯云的VPS，内存里的命令清了，立即退出，重进，会发现命令还在的，说明内存和.bash_history磁盘文件是实时同步的。 为了确认一下，可以cat看一下 注意#1587828143这些是时间应该 上面写错了，不是腾讯云的优化，是这个原因： 我把历史命令前面的时间格式取消后，发现内存的命令不会自动同步进.bash_history了。 果然又再次秒同步了。 最后再验证一下 懵逼了， 终于知道什么因果关系了：将将将将~ 一般情况内存的命令不会实时同步进.bash_history文件里的。 想要实时同步，可以这么做，在history显示行首加上时间格式就能促使命令的实时存盘。 但是需要注意的事 即使注释了这行，还是会实时同步的，如下图， 但是如果你使用；去注释改行，那么 export HISTTIMEFORMAT=\"%F %T \" ①没有做时间格式的历史记录，但是命令实时同步进.bash_history ②做了时间格式，命令也是实时同步的 ③用#注释时间格式，命令还是实时同步的 ④用;号注释时间格式，命令就不再实时同步了。 什么鬼。。。睡觉 反正记着有办法让内存的命令实时同步就行了。方法之一就有上面的思路。 上面瞎折腾，靠谱的还是参考下面人家的 https://developer.aliyun.com/article/637427 14、history默认是1000条最近的记录 也可以在/etc/profile里写 退出重登，发现还是3000的历史记录，说明etc/bashrc优先 验证，去etc/bashrc下注释掉那行，退出重进，发现此时是10条记录了 history -d 36就是清第36条 怎么删除一个范围？ -a ，追加经磁盘文件 -r , 将历史文件的记录读到内存中的history记录下，默认用户登入的时候就会读取，执行该动作。 -w , 将当前的history内存记录存到指定文件中，比-a多了个路径，-a是默认的.bash_history 所以 -p 是不存在历史内存列表中，而且是将命令按空格展开成多行。 -s 是制造虚假的历史命令，实际未执行。 15、history命令历史的相关环境变量 HSITSIZE：命令历史的记录条数是内存中的记录条数 HISTFILE：指定历史文件，默认为~/.bash_history HISTFILESIZE：命令历史文件记录历史的条数，这个其实用HISTSIZE控制内存中的记录条数，就能控制文件的条数了，对了，默认HISTFILESIZE多大？也是1000条。 HISTTIMEFORMAT=”%F %T ”，显示时间，指定格式，也可以写到/etc/profile.d/env.sh下。PS1就是写在这个下面的 HISTIGNORE=”str1:str2*:...” 忽略str1命令，str2开头的历史命令。用法如下 安全敏感的不记录 HISTCONTROL：控制命令历史的记录方式，该环境变量的值如下： ​ ignoredups 默认值，忽略重复的命令，连续且相同的为“重复”.不过腾讯云主机是unset没有默认值的： 如图，不赘述 ​ ignorespace 忽略以空白开头的命令（类似HISIGNORE=”str1:str2*...”），如下图 ​ ignoreboth 相当于ignoredups,ignorespace的组合 ​ ​ erasedups 删除重复命令，不同于ignoredups(连续的相同命令只留一条随机的？)。erasedups是不连续的也删。 这些变量的赋值，上图是直接HISTCONTORL=XXX，这种不会保存在配置文件里，退出用户丢失。可以保存在/etc/profile或/etc/profile.d/env.sh或~/.bash_profile或/etc/bashrc，可以看看云主机的一些环境变量的保存路径，初步总结下来，只要大的路径对了，就行了，比如tab.vimrc不一定非要独立的文件的。感觉腾讯云这么做也无所谓规范不规范的。 16、快捷键 在xshell里没问题，但是在摸粑粑里有的不灵 ctrl + l 等价于clear清屏 ctrl + o 执行键入的命令，并重新显示出来，这玩意有延迟的，需要将命令打在屏幕上等一会，在按ctrl + o 才对，不让出来的命令是之前的 ctrl + s 锁屏，用来盲敲的 ctrl + q 解锁，恢复输入可见 crtl + c 强制退出 ctrl + d 规范退出，正常退出 ctrl + z 挂起命令 bg 恢复后就停不下来了，除非退出xshell。 fg 比较好，可以退出ctrl c ctrl z在挂起都行 17、一些有用的快捷键 ctrl+w，往前删除，一段一段的删，就是遇到空格就停下了 ctrl+k 和 ctrl+u相反，光标处删到行尾 alr+r 删除整行 和xshell冲突 ctrl + xx 光标在行首和当前位置切换 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"3-文件管理/3-文件管理.html":{"url":"3-文件管理/3-文件管理.html","title":"第三章 文件管理","keywords":"","body":"第三章 文件管理 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"3-文件管理/1-文件系统.html":{"url":"3-文件管理/1-文件系统.html","title":"第1节 文件系统","keywords":"","body":"第1节. 文件系统 1、文件系统结构元素 就是文件目录结构， /boot 启动相关文件，例如内核 /etc 配置文件，比如之前的/etc/issue /etc/profile.d/ /etc/bashrc等 /dev 硬件设备 b开头，表示块， c开头，字符文件， 都是设备文件 tty，字符设备，是一个个字符来进行输入输出的 块设备，光盘、硬盘，是以一块一块为单位，而一块代表N个字节，比如4096Byte表示一块。如果是块设备，每次输入输出就是4Kbyte。一下子读入4K或写入4K。 比如硬盘分区都是BLOCK为单位， 比如issue该文件里面存放了点数据，如图才346byte，但是由于磁盘分区上保存数据是以块为单位的，哪怕你只是修改该文件1个字节，实际上读取的也是以块为单位的，所以 假设4KB一个block，那么，读动作 就是一下子读取4kbyte到内存中，改完了写入磁盘分区也是也是 4kbyte的空间站位。 总之，实际的数据量虽然不大，可能把这个数据写入、写出的时候，实际会大很多，就是这个意思。 2、/bin 给普通用户用的 /sbin给系统管理员用的 还有/usr/tmp 都是软连接， ll的细节注意一下 ls /bin和ls /bin/效果一样，都是现实/bin下的所有文件 # 这里还是要用ll -d去看文件夹，反正有些py模块里，文件夹就要用XX/来标识。实际操作需要验证一下的。（带不带/，要不要-d，之类的） ll /bin 和 ll /bin/不一样，前者是显示文件夹本身，后缀是显示该文件夹下的文件。 # 这话也是错的，因为/bin是个软连接，本身是文件。 ll /bin -d 和 ll /bin/ -d 不一样，虽然都是显示文件夹metaDate。前者是显示软连接的元数据，后缀是显示源文件的medaDate。 这两个都是等价的 这两个显然不同。 所以总结，看文件夹的信息，就是ll /bin -d，这样最靠谱。 靠谱的原因就是-d看起来是看文件夹，其实对文件一样有效。所以看文件本身不进入子层，正确的使用方法就是ll /bin -d ll / -d这种了。 上面仔细看图就好，其实还是软连接造成的操作上的细微区别。 3、/usr 下很多文件夹和/很像， /usr 像是个二层根。 结构是有规范的无论是什么linxu版本，都基本符合这一套目录结构。 FHS：Filesystem Hierarchy Standard http://www.pathname.com/fhs 文件要存放规矩 4、两个特殊目录/proc 和 /sys 这两个目录大小为0 虽然是0，但是在/proc下是可以看到数据的。 说明proc下有很多数据的，但是proc文件夹的大小就是0。这是因为proc看到的是内存中的数据，内存数据不占磁盘空间，所以ll /proc -d显示的是磁盘空间占用大小。 /sys 是映射的硬件信息 /proc是放进程process相关信息的 5、以/sys为例，可以用里面的一些文件来管理硬件 这里换本地的VM来做实验—增加新的硬盘 当前只有一块硬盘和一个光盘 现在要实现加硬盘不重启的效果，以VmwareWorkstation为例，直接在VM里添加即可(略)。 但是添加完了，一般需要重启才行。不过可以这样： 在/sys 此时就新加的硬盘就出现了，也不需要重启系统。 一般就是host2或host0就行。 可以考虑将上面的两条命令定义成别名 现在再加一块硬盘，就可以利用别名快捷实现了 6、linux文件名最长为255个字节，验证如下 创建一个256字符（一个字符对应一个字节？），利用ALT + NUMBER 在输入字符即可 按住alt不动，紧接着输入256，然后松开后输入x，这样就完成256个x的输入。 一个x字符对应的就是一个字节，UTF-8格式规定的。不信可以这么检查 vim test，里面写一个x，然后hexdump test -C 看一下： 再man一下ascii找到小写的x 确实是16进制的78，而16进制78就是一个字节的空间。 所以，touch xxxx...xx 256个x就是256个字节的长度了，验证方法有效。 7、包含路径在内文件名最长4095个字节。 蓝色-目录 绿色-可执行文件 红色-压缩文件 其实就是看后缀，系统一看后缀是.gz的就给你打上红色了 天蓝色-链接文件 灰色-其他文件 黄色-设备文件，有的是b块设备、有的是c字符设备。 ​ b的单位是块，是随机读写，不是顺序的，是随机的放在磁盘的某些位置。而c的单位是字符，是顺序一个个字符进行输入输出的。块设备通常是有缓存的，硬盘有缓存，而字符设备是没有缓存的，就按照顺序进行访问就行了。 粉色-socke文件，套接字文件，s开头的，是为了实现网络通讯的。后面讲mysql会用到。 /run下面又很多粉红色文件 棕色-管道文件，p开头的，是实现进程间通信的，就是同一台PC上的不同APP互访，用的不多，用socket用的比较多。 文件的颜色和后缀的关系，实在/etc/DIR_COLORS下定义的 看下一个pip40,33确实是棕色 试一下上图DIR_COLORS的效果 01,31就是红色没跑了 然后在试一下exe文件，默认是注释了的， 现在打开 还是没有变，不急，执行一下DIR_COLORS文件，执行不了，退出重进就行了 搞不懂为什么.bashrc可以. ~/bashrc直接跑一遍，是修改的配置生效，无需退出重进。 而. /etc/DIR_COLORS却不能这样。 8、文件名规则 1、上面说了255个字节的文件名 2、说了4095个字节带路径的文件名 3、说了颜色 4、还有，除了斜杠和NULL，所有字符都可以用来作为文件名，但是使用特殊字符的目录名和文件名不推荐， 5、标准Linux文件系统（如ext4），文件名称大小写敏感，如果是linux挂载了fat的硬盘（ntfs，需要额外装软件，才能挂到linux下），则给硬盘下大小写不敏感。总之文件名称的大小写是跟着文件系统走的，而文件系统就是你格式化硬盘分区所选择的xfs、fat32、ntfs这些。 验证方法：linux关机，添加硬盘-使用现有的物理磁盘-选择磁盘1（假设你的fat分区在1下，这里看到的0和1就是物理硬盘的编号）-分区2（假设fat格式的是分区2），启动centos 这里的0就是硬盘0，1就是你电脑的第二块磁盘。我就一块0. 确定即可 但是我的实验不能加载物理硬盘 没什么意义，有时间可以换个机器试试，成功开机后，然后接着下面操作： lsblk -f 可见是这个硬盘是vfat格式 文件系统，需要挂载到一个目录才能使用 所以mount /dev/sdd2 /mnt df 可见sdd2已挂载 cd /mnt ls 可见各种windows下的格式， 此时该/mnt下的文件就不再区分大小写了。 这个实验就是说，标准linux文件系统(如ext4)，文件名称大小写敏感。 然而你可以挂载fat32硬盘上去，这个就不区分大小写了。 理论上可以，但直接创建是失败的。可以这么做： 删除一样， 或者 带上路径就行了 9、文件类型 - 普通文件 d 目录文件 b 块设备 c 字符设备 l 符号链接文件 p 管道文件pipe s 套接字文件socket 共7种类型，联系上文 除了-普通文件，其他的文件操作都要小心。特性不一样 p和s 主要是为了两个应用程序之间互相通信用的临时文件。比如两个软件交换数据，一个往pipe里写，另一个从对应的pipe里读。 10、CentOS 7的bin和usr/bin实际是同一个东西了 同样的，lib和/usr/lib， 这些在早期的centos6里不是这样的，都是独立。就是很相似，所以干脆合在一起了。 lib是放库文件的。 11、pwd -P 显示原文件路径 -L 显示的快捷方式就是软链接文件的路径 pwd默认带-L 同样需要注意的是，ll -d 看到的情况也要验证一下，是否是软链接的还是原文件的。 12、有些场合下，相对路径不是相对当前的cwd（current work direction）当前工作目录 比如前文提到的软连接，以及练习-2里也有提到， 就是相对于你要存放软连接的路径的 相对路径 13、basename和dirname， 创建和之前文件相同目录下的另一个文件，可以将下图中的/data/dir1/通过其他方式取出来，比如py里的os.gold、os.walk还是os.list都有方法的。或者你直接将/data/dir1作为变量。 14、cd备忘 cd ~ 等于 cd 进入当前用户的home目录 cd ~user1就回到了user1的家目录 cd – 上一次的路径，效果就是当前和上一次路径返回切换，原理就是OLDPWD这个变量里保存了上一次目录 之所以回得去，就是因为有一个变量保存了上一次的pwd信息。 15、ls备忘 ls -a 包含隐藏 ls -l 显示metadata ls -R 递归，应该有用，os.walk估计还没这个ls -R原生的优秀呢 ls -d 虽然是directory，但是ll -d通常用来看单个文件或文件夹都可以的 ls -1 文件分行显示？啥意思 ls -S 按从大到小排序，这个好 ls -t 按mtime排序 ls -u 配合-t选项，显示并按atime从新到旧排序 ls -U 按目录存放顺序显示 ls -X 按文件后缀排序 ls其实现在也是alias别名了，想用原始的ls只需要\\ls就行了 关于atime 所以正如练习-2里提到过的，atime并不是实时更新的 Access：最近访问时间acces time (atime)，这个不是实时更新的，为了防止大量的写accesstime这个操作，节省资源 但是当你当前读取的时间比上次atime超过1天了都，所以肯定给你立马更新了。最小差值多少，这个可以测一下。 由此可见，还正就是日期从25号变成了26号， 且时间跨度有一个值大概在12小时， 总结一下，hours在12小时，day + 1，基本就会cat后立刻更新时间了。当然可能12小时都嫑。我只是无聊，至于到底几个小时，who care。 clock -s 记得还原 16、ctime 文件的属性发生改变的时间 属性就是：一行里的各种数据，包括 文件的权限、inode数量（硬链接个数，注意软连接不算在meta data里）、所有者、所属组、大小。 这些通通都是元数据 上图cli写错了，直接stat /etc/motd就行了，不要time stat meta data发生改变，ctime就变了 注意atime 各种time不属于元数据。文件名是属于元数据的 17、selinux和防火墙 先不管，关闭即可 上图是selinux 防火墙也是启用的 关闭selinux 原来是enforceing，改成disabled 改完后，需要重启才能生效，不过可以结合cli方式临时关闭selinux就不用重启了。 不过可惜，disabled没有对应的值，0-permissive，1-enforcing。所以我还是老老实实重启吧。 systemctl disabled firewalld.service # 开启不启动 systemctl stop firewalld # 关闭防火墙 最后这样： Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"3-文件管理/2-文件管理.html":{"url":"3-文件管理/2-文件管理.html","title":"第2节 文件管理","keywords":"","body":"第2节. 文件管理 1、centos6以前的版本禁用selinux vi /etc/selinux/config SELINUX=disabled chkconfig iptables off service firewalld stop # 应该是这个吧，如果不是，上面一条重启不自启动就行了 2、文件通配符 ★文件通配符，顾名思义，就是匹配文件名称的，别想多了。 * 匹配零个或多个字符 ? 匹配任何单个字符 ~ 当前用户家目录 ~haiwang 用户haiwang家目录 ~+ 当前工作目录 ~- 前一个工作目录 # 等同于cd -，但是ls 不能ls -这么用，要ls ~-这样 [0-9] 匹配任意一个数字 [a-z] 任意小写字母一个 [A-Z] 任意一个大写字母 [haiwang] 匹配列表中的任何的一个字符 yingxiong 匹配列表中的所有字符以外的字符 y开头的 包含x的 .txt结尾的，但是不包括.txt，因为*不会包含隐藏文件。 *在文件名通配符领域里，表示该位置有一个或多个，或者没有，都可以 要在非隐藏文件里找需要的文件名，就可以用ls *来做 而要在隐藏文件里找，就用正则就行了 而查看隐藏的我现在想到的就可以用正则来做，后来又发现还有l.（列出当前所有的隐藏文件和文件夹）。 查看隐藏文件 l.只能看当前文件夹下的隐藏文件/文件夹，如果是看其他路径，就需要参考l.这个alias里的原来语法： ls -d /data/.* 只看文件夹 ll |grep \"^d\" ll -d */ ls ??? 表示就看3个字符的文件 汉字unicode，一个汉字也是一个字符。只是一个汉字这一个字符 在磁盘上保存不是占一个字节。 unicode 汉字，可能占2-4个字节。 在通配符里面没有^[xxx]这种写法，和正则regex相似又不一样 文件里面过滤字符串，这是不是通配符的活，通配符是匹配文件名称，文件内容交给regex 注意事项 ls /data/f[a-c].html表示啥 [a-c]代表aAbBc，这个regex又不同了 [A-C]等价于AbBcC 见下图 如果就是想要小写或大写，可以这么写 [:digit:] 任意数字，相当于0-9 [:lower:] 任意小写字母 [:upppere:] 任意大写字母 [:alpha:] 任意 大 小 写字母 [:alnum:] 任意数字或字母 [:blank:] 水平空白字符 [:space:] 水平或垂直空白字符，垂直空白字符是啥？回车？还是↓ [:punct:] 标点符号 [:print:] 可打印字符 [:cntrl:] 控制（非打印）字符 [:graph:] 图形字符 [:xdigit:] 十六进制字符 注意两个[[:lower:]] 方括号的意思，里面的[:lower:]是一个整体表示一个小写字符，外面的表示任意一个字母。 等价于正则里的[a-z]写法。 只看隐藏文件的方法，和上面的对比一下 l.的缺陷，只能看当前文件夹，下图就是，明明cli里写的ls -d /data/ .*但是看得还是当前目录的 上图有一个思路对了，手残敲错了，应该如下 只看文件夹的方法 一个是看非隐藏，一个是看隐藏的文件夹 通配符，在py的os.xx模块里，好像就不是regex而是通配符 按理说练习应该放在外面，但是这是课堂视频里的练习，不是作业，就不放在外面单独文章了 1、显示/var目录下所有以l开头，以一个小写字母结尾，且中间出现至少一位数字的文件或目录 ls /var l*[0-9]*[[:lower:]] 2、显示/etc目录下任意一位数字开头，且以非数字结尾的文件或目录 ll -d /etc/[0-9]*[^0-9] 这里可以考虑吧-d去掉，为的就是遍历一下/etc下文件夹下的文件或更深层次 3、显示/etc目录下以非字母开头，后面跟了一个字母及其他任意长度任意字符的文件或目录 ll -d /etc/[^[:alpha:]][[:alpha:]]* 注意些通配符的时候，有根弦--通配符不是正则。然后一个字母要有大小写[a-zA-Z] 4、显示/etc/目录下所有以rc开头，并后面是0-6之间的数字，其他为任意字符的文件或目录 ls -d /etc/rc[0-6]* 5、显示/etc目录下，所有以.d结尾的文件或目录 ls -d /etc/*.d # 注意.d文件也算是.d结尾的，这样就看不到了 ls -d /etc/*.d;ls -d /etc/.d 6、显示/etc目下，所有.conf结尾的，且以m.n,r,p开头的文件或目录 ls -d /etc/[mnrp]*.conf 7、只显示/root下的隐藏文件和目录 ls -d /root/.* 8、只显示/etc下的非隐藏目录 ls -d /etc/*/ 3、touch 1、创建文件 2、如果文件存在，只是修改时间（atime、ctime、mtime）都给你改当前时间了 补充： 默认ll的时间是mtime 3、总结，touch是安全的创建文件的方法 还有个创建文件的方法 > echo >> f5.txt 追加内容也是一个道理 以上的> 或 >> 是依赖于shell的， 上图换成csh就不行了 > 、>>不是命令，其实是重定向。 > 常用来快速给文件清空，无论文件有多大，都给你快速清空。据说灰常好的小功能。 touch [OPTION]... FILE... -a 仅改变atime和ctime -m 仅改变mtime和ctime -t [[CC]YY]MMDDhhmm[ss] 指定atime和mtime的时间戳 -c 如果文件不存在，则不予创建，这个一看就不错 4、保持日志为前一天 生成昨天日期作为文件名，上图是错误的写法，会自己坑自己 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"3-文件管理/3-cp和mv.html":{"url":"3-文件管理/3-cp和mv.html","title":"第3节 cp和mv","keywords":"","body":"第3节. cp和mv 1、cp命令 cp的三种语法 前两种用的多， cp [OPTION]... [-T] SOURCE DEST # 复制并改名 cp [OPTION]... SOURCE... DIRECTORY # 复制多个源文件到一个文件夹中 cp [OPTION]... -t DIRECTORY SOURCE # 同上，多了个-t 其实第三种用的也很多，因为通常会将rm，alisa成mv，此时就需要将目的文件夹放到前面，如下图： cp 复制文件的meta data会改变的 cp复制文件的时候，可能有一些信息会丢失（时间） cp复制文件的时候，可能有一些信息会丢失（时间，所属用户 用户组） 文件拷过来了，但是所属者、所属组，也包括时间都变了。 这就是信息丢失了，很可能导致文件复制过来不可用了。 cp赋值普通文件是可以的，除了上面的说的问题。但是cp不能复制特殊文件 之前讲过7种类型的文件 ll看最前面的符号就是类型了 zero也是一个常用的字符文件 cp复制文件的时候，cp复制问题-文件内容变了，拷的就不是你要的文件 下图注意复制的其实不是软连接，而是真是的文件被复制的。 cp复制文件的时候，cp了一个/dev/zero设备文件，如下图，什么都不一样了（文件类型、权限、大小）都变了 其实zero好像通常用来产生固定大小的文件的，一般你测试网速，就可以用zero产生一个大文件提供下载。 所以 cp主要针对普通文件的。要复制特殊文件，需要加一些选项，就算普通文件，如果需要保留原来的时间也需要cp加选项。 2、复制文件夹的注意事项 复制到文件夹，不改名字 复制多个文件，复制到文件夹下 如果是复制文件夹 需要递归选项 如果文件夹不存在，自动给你创建 如果文件夹存在，会覆盖？！不是，看清楚下图，①sysconfigbak文件存在，②所以会把sysconfig文件夹的内容全都复制到sysconfigbak文件夹下。③而再次cp -r的时候由于sysconfigbak下已经有sysconfig整个文件夹的内容了，所以会问你是否覆盖。 这就是传说中的：幂等性 多次重复执行一个命令，效果一样，这就叫做幂等性。 所以cp命令不具有幂等性的特点。 源 目标 不存在 存在且为文件 存在且为目录 一个文件 新建DEST，并将SRC中内容填充至DEST中 将SRC中的内容覆盖至DEST中 注意数据丢失风险！ 建议用-i 选项 在DEST下新建与原文件同名的文件，并将SRC中内容填充至新文件中 多个文件 提示错误 提示错误 在DEST下新建与原文件同名的文件，并将原文件内容复制进新文件中 目录 须使用-r选项 创建指定DEST同名目录，复制SRC目录中所有文件至DEST下 提示错误 在DEST下新建与原目录同名的目录，并将SRC中的内容复制到目录中 3、CP常用选项 -i 覆盖前提示，默认就有 需要注意 这是因为root账号有自己的alias别名定义，user1没有定义，别名的定义在家目录的.bashrc里写的。在root账号的家目录里有定义的别名，这里 -n 不覆盖，注意两者顺序 -r, -R 递归复制目录及内容 -a 归档，相当于-dR –perserv=all -d --no-dereference –preserv=links 不复制原文件，只复制链接名 --preserv[=ATTR_LIST] ​ mode:权限 ​ ownership:属主属组 ​ timestamp: ​ links ​ xattr ​ connext ​ all 4、cp的技巧 cp通常是需要加上-i ，cp – i 作为alias别名存在，但是存在下图情况，一个个问就很烦了。也不能取消别名的安全措施 所以可以利用\\前缀来还原成原始的命令，不用别名 不要想当然以为是cp -f，并不是这样的 -n 不覆盖 -d 不复制原文件，只复制链接名 默认是复制原始文件，而不是软链接本身。 --preserv[=ATTR_LIST] ​ mode:权限 ​ ownership:属主属组 ​ timestamp: ​ links ​ xattr ​ connext ​ all !*等价于上一次命令的后面所有参数，不仅仅是下图表示的两个，上图就出现了三个 如果我们希望保留时间属性，就可以 cp xx xx –preserv=timestamp 这会时间就保留住了 如果所有的都保留住 -p 等同于 –preserv=mode,ownership,timestamp #mode是权限、owership所有者所属组、timestamp就是时间了。 -a 前文有，能保留的属性都保留了，最全了。相当于-dR --preserv=all # 这个其实是help里这么写的，但是你不觉得很奇怪吗，r = R, -d只是--preserv=links，所以-a应该是-r 和 --preverv=all这样表示才对。很明显帮助里多了个-d。作为-dr --preserv=all，写法应该就是cli的是偶带了多个参数。所以自然也是and的关系。 -v --verbose # 复制的时候看到过程，如果文件很大，就需要这个直观显示，防止有人以为卡主不动了。 所以工作中推荐av经典组合 -f --force 演示过程中的错误注意事项： ​ root用户将某文件复制到user1用户的家目录下 正确写法是~user1，经常写错的原因是因为cd ~/切到自身的家目录这里是可以有/的。 现在user1家目录下的fstab的所属用和用户组是root的 于是如图所示，不能覆盖了，但是我自己的家目录，我还不能改吗？！-f就是强制措施 -f的思路，就是如果覆盖不了，实际上先删掉后 重新创建新的文件。当然如果删不了就肯定不行了！ 谁复制的，就变成谁的↑，但这话又不全对↓ -f 此时是删了再创建的，所以用户和用户组都是user1。 切到root用户下，cp /etc/fstab ~user1，覆盖掉，发现用户和组还是user1。 -u --update 只复制源比目标更新文件或目标不存在的文件 复制的时候存在一个覆盖的问题，一般都是更新的数据整个文件夹，cp -u 到服务器上的数据，这样就只做 增量更新。 -b 目标存在，覆盖前先备份，形式为filename~ --backup=numbered目标存在，覆盖前先备份加数字后缀 ★工作中，可以做个alias bak=’cp -a --backup=numbered’ 这样就小整合了一下。 所以-a 经常用来做备份的效果，①保留了所有能保留住的属性，②本身-a就集成了-d和递归的功能。 PS：之所以说保留了能保留的，原因见上图，至少有一个ctime是实时的。 简化写法示例 ll grub2.cfg{,.bak} # {}里面被,逗号分隔成两个部分，,号前面是空，后面是.bak，所以就是 ll grub2.cfg grub2.cfg.bak 这个了。用echo可以直观的看 据说这还是常用的备份方法，搞不懂，秀技术吗？ 练习： 1、每天将/etc/目录下的所有文件，备份到/data独立的子目录下，并要求子目录格式为backupYYYY-mm-dd，备份过程可见 cp -av /etc /data/bakcup`data +%F` 2、创建/data/rootdir目录，并复制/root下所有文件到该目录内，要求保留原有权限。 mkdir /data/rootdir;cp -a /root /data/rootdir cp -r --perserv=mode /root /data/rootdir cp -rp /root /data/rootdir cp -a /root /data/rootdir 5、mv 移动和改名 ★可以用mv替代rm，方法就是alias rm=mv ... mv [OPTION]... [-T] SOURCE DEST mv [OPTION]... SOURCE... DIRECTORY mv [OPTION]... -t DIRECTROY SOURCE 常用选项： -i 交互式 -f 强制 -b 目标存在，覆盖前先备份 6、rm删除 rm [OPTION]... FILE... 常用选项： ​ -i 交互式 ​ -f 强制删除 ​ -r 递归 带文件夹一般都带r ​ -no-preserve-root 删除/ 示例： ​ rm -rf /* 有的rm会被alias成rm -i，所以如果需要关闭提示，就用\\rm f1 f2 f3 当然也可以使用-f选项 ★rm -rf / data #这就完蛋了，你带了空格，就是把/下面全删了 rm -rf --no-preserve-root / 在windows里正在使用的文件是不能删除的，但是在linux里没有这个概念。 有些是删不了的，比如media光盘、proc、sys内存、/home /misc /net有些是特殊情况，确实不能删，其他都能。 /删掉后，pwd，cd都能用，原因就是这些都是内部命令，内部命令都已经加载到了内存里。 你删掉的是磁盘文件，内存里的东西都还在。 但是 内部命令依赖的/bin/bash文件已经没了，下次重启后，这些命令就没了。 外部命令那些本次开机后还没有使用过的就不行了，因为外部命令第一次使用后才会加载到内存中，那些本次开机后没有用过的，还都是磁盘文件呢。所以文件没了，就不能使用这些命令了。 rm -rf /* 这个命令误操作的可能性不太大，但是下一个命令就不行了 ★上图就把/data和 /*下的文件全删了。 工作中rm就别用了，别名成mv，其中涉及mv覆盖同名的文件的解决思路 思路就是，rm改成mv mv的时候考虑同名文件，就事前创建一个以当前时间（精确到秒单位,这样只要你的rm命令频率在1s以外，都没有问题）为文件夹名称。然后将要删除的文件移动到该文件夹里。 所以最终的mv替代rm的方法就是： 待填空 7、tree 显示目录树 ​ -d：只显示目录 ​ -L level：指定显示多少层 ​ -P pattern：只显示由指定pattern匹配到的路径，pattern涉及一些正则表达式 mkdir d1/d2/d3/d4 -pv 竟然不是-r,-v 就是建立的过程 -m MODE：创建目时，直接指定权限 rmdir a1/a2/a3/a4 这是删了a4，且a4是空文件夹，rmdir用的不多。 -p：递归删除父空目录 -v：显示详细信息 rm也不是都能删的，报错资源忙，忙的原因是因为/data是个设备挂载点 rm -rf /data确实会把里面的文件都删了，但是当删/data这个文件夹的时候（注意rm -rf /data是删了整个/data文件夹的）由于data是个分区挂载点，所以报错忙。 8、关于磁盘利用率的释放 cp /dev/zero /boot/bigfile # 时间越久，产生的文件越大 ll /boot/bigfile -h >该实验第1遍 现在删除bigfile，该磁盘利用率是否会立刻降下来呢？不一定。这个实验是立即降下来的。 rm -f /boot/bigfile >该实验第2遍 同样上面的实验，现在再rm删除bigfile该文件之前，先用另一个ssh登入打开它。然后在尝试删除观察磁盘利用率是否下降。 然后删除该文件 工作中，很多企业会遇到类似的场景，有些分区要满了，硬盘如果要满了，数据写不进去，就会造成很严重的结果，系统会崩溃，对外服务就挂了。 可能一些log日志文件，就删了不能立刻释放，存在这种情况。 现在关闭之前vim打开的bigfile的窗口 此时空间就释放了 下面 >该实验第3遍 恢复bigfile被占用的情形，就是rm -rf bigfile后磁盘空间不会得到释放的。 推荐的方法为：> fileName ，就是将文件清空 然后再删除该文件就可以了，整个过程完整截图如下 面试题：发现文件删了，空间没释放，正确应该怎么做，面试常见的答案就是上图。 rmdir 删除空目录 ​ -p：递归删除父空目录，就是从内层外外层删，当删除一个子目录后发现父目录也空了，就把父目录也删了。一直删到根。 # 和mkdir -p相反，mkdir -p是先创建父目录，再创建子目录，删除就自然反着删了。 9、rename：改文件名，mv如何改多个文件 rename --help 这样就改了，改文件名称，不仅仅只知道mv，还要知道rename。 再改回去（将.bak删掉） rename .bak \"\" * 练习 第一题的思路，存在一个组合，会想到是大括号的组合用法 ②第二题 ③第三题 这样也可以 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"3-文件管理/4-文件节点表.html":{"url":"3-文件管理/4-文件节点表.html","title":"第4节 文件节点表","keywords":"","body":"第4节. 文件节点表 文件的存放有inode表格和data表格 上图可见，创建一个文件夹后，inode就占掉一个。 touch命令本身不支持这么多个参数，所以换种方式 echo f{1..524288} |xargs touch 节点编号 上图可见分区的空间大小，以及节点数最大值。sda1的inodes最大值为65536。 超出节点编号就不行了 echo f{1..65539} |xargs touch 所以看到没有设备空间不一定是真的，可能是节点编号满了。 删除rm *是不行的，可以删除所在文件夹rm -rf /boot/testdir 或者这么删就行了啊： echo f{1..524288} |xargs rm -rf 节点编号和软连接和硬链接密切相关 ext文件系统的架构 直接指针是12个 ①数据量低于48K，直接指针就可以搞定。 ②超出48K--4M，使用间接指针表示。 ③4M-4GB的采用二级指针 现在centos7是XFT文件系统和ext的文件系统不一样。 不管什么系统都是类似的机制。 对于文件夹来讲他的内容放的是什么 文件名是属于文件夹的内容DATA。是放在数据块空间的。 明白这一点，rm f1本质上是删除他的节点表，指正指向的数据块就没人用了，该空间标记为空闲free状态，但是不会删除数据。如果你新建一个文件可能会覆盖掉的。 此外dir1/下的F1的数据就清了。 所以删除f1是需要有f1所在文件夹的权限就行了。 硬连接，本身就是同一个文件 跨分区了，不同分区肯定不是一个文件了，所以肯定不支持 硬链接不能针对文件夹创建。据说是防止循环现象。 删a1的操作等价上图的示例 备注： 👉以下是vim一个文件，然后echo 然后vim vim 发现indoe在两个数字跳来跳去的(估计和vim打开的时候会自动创建一个.xxx.swp有关，可能是这个原因，也不是swp文件的inode不在那两个反复替换的inode里面，反正vim该文件inode是变的，而且是2个inode数字来回变)。然后echo不会。 [10:54:28 root@localhost data]#echo inode_echo >> test [10:54:43 root@localhost data]#stat test File: test Size: 19 Blocks: 8 IO Block: 4096 regular file Device: fd00h/64768d Inode: 33577448 Links: 1 Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root) Context: unconfined_u:object_r:default_t:s0 Access: 2022-01-29 10:54:20.066021237 +0800 Modify: 2022-01-29 10:54:43.345023132 +0800 Change: 2022-01-29 10:54:43.345023132 +0800 Birth: 2022-01-29 10:54:20.066021237 +0800 [10:54:44 root@localhost data]#ll -i total 8 51325766 drwxr-xr-x. 2 root root 6 Jan 19 19:57 dir 373349 drwxr-xr-x. 2 user1 g12 6 Jan 19 19:58 dir2 33577410 -rw-rw-r--+ 1 root root 7 Jan 29 10:53 f1 33577446 -rw-r--r--. 1 user1 g12 0 Jan 19 19:58 f2 33577448 -rw-r--r--. 1 root root 19 Jan 29 10:54 test [10:54:47 root@localhost data]# [10:54:50 root@localhost data]#vim test [10:55:00 root@localhost data]# [10:55:00 root@localhost data]#vim test [10:55:03 root@localhost data]#ll -i total 8 51325766 drwxr-xr-x. 2 root root 6 Jan 19 19:57 dir 373349 drwxr-xr-x. 2 user1 g12 6 Jan 19 19:58 dir2 33577410 -rw-rw-r--+ 1 root root 7 Jan 29 10:53 f1 33577446 -rw-r--r--. 1 user1 g12 0 Jan 19 19:58 f2 33577450 -rw-r--r--. 1 root root 28 Jan 29 10:54 test [10:55:04 root@localhost data]#stat test File: test Size: 28 Blocks: 8 IO Block: 4096 regular file Device: fd00h/64768d Inode: 33577450 Links: 1 Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root) Context: unconfined_u:object_r:default_t:s0 Access: 2022-01-29 10:55:01.373024600 +0800 Modify: 2022-01-29 10:54:59.985024487 +0800 Change: 2022-01-29 10:54:59.987024487 +0800 Birth: 2022-01-29 10:54:59.985024487 +0800 [10:55:09 root@localhost data]#vim test [10:55:25 root@localhost data]# [10:55:25 root@localhost data]# [10:55:25 root@localhost data]#stat test File: test Size: 39 Blocks: 8 IO Block: 4096 regular file Device: fd00h/64768d Inode: 33577448 Links: 1 Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root) Context: unconfined_u:object_r:default_t:s0 Access: 2022-01-29 10:55:25.695026580 +0800 Modify: 2022-01-29 10:55:25.695026580 +0800 Change: 2022-01-29 10:55:25.697026580 +0800 Birth: 2022-01-29 10:55:25.695026580 +0800 [10:55:27 root@localhost data]# [10:55:35 root@localhost data]# [10:55:35 root@localhost data]#vim test [10:55:44 root@localhost data]# [10:55:44 root@localhost data]#stat test File: test Size: 50 Blocks: 8 IO Block: 4096 regular file Device: fd00h/64768d Inode: 33577450 Links: 1 Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root) Context: unconfined_u:object_r:default_t:s0 Access: 2022-01-29 10:55:44.687028126 +0800 Modify: 2022-01-29 10:55:44.687028126 +0800 Change: 2022-01-29 10:55:44.688028126 +0800 Birth: 2022-01-29 10:55:44.687028126 +0800 [10:55:45 root@localhost data]# [10:57:23 root@localhost data]#stat test File: test Size: 55 Blocks: 8 IO Block: 4096 regular file Device: fd00h/64768d Inode: 33577448 Links: 1 Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root) Context: unconfined_u:object_r:default_t:s0 Access: 2022-01-29 10:57:23.128036141 +0800 Modify: 2022-01-29 10:57:23.128036141 +0800 Change: 2022-01-29 10:57:23.129036141 +0800 Birth: 2022-01-29 10:57:23.128036141 +0800 [10:57:23 root@localhost data]#echo 12 >> test [10:57:29 root@localhost data]#stat test File: test Size: 58 Blocks: 8 IO Block: 4096 regular file Device: fd00h/64768d Inode: 33577448 Links: 1 Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root) Context: unconfined_u:object_r:default_t:s0 Access: 2022-01-29 10:57:23.128036141 +0800 Modify: 2022-01-29 10:57:29.437036654 +0800 Change: 2022-01-29 10:57:29.437036654 +0800 Birth: 2022-01-29 10:57:23.128036141 +0800 [10:57:30 root@localhost data]#echo 333 >> test [10:57:35 root@localhost data]#stat test File: test Size: 62 Blocks: 8 IO Block: 4096 regular file Device: fd00h/64768d Inode: 33577448 Links: 1 Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root) Context: unconfined_u:object_r:default_t:s0 Access: 2022-01-29 10:57:23.128036141 +0800 Modify: 2022-01-29 10:57:35.603037157 +0800 Change: 2022-01-29 10:57:35.603037157 +0800 Birth: 2022-01-29 10:57:23.128036141 +0800 [10:57:36 root@localhost data]# total 20 33577460 drwxrwxrwx. 4 root root 78 Jan 29 10:58 . 128 dr-xr-xr-x. 18 root root 236 Jan 10 18:13 .. 51325766 drwxr-xr-x. 2 root root 6 Jan 19 19:57 dir 373349 drwxr-xr-x. 2 user1 g12 6 Jan 19 19:58 dir2 33577410 -rw-rw-r--+ 1 root root 7 Jan 29 10:53 f1 33577446 -rw-r--r--. 1 user1 g12 0 Jan 19 19:58 f2 33577448 -rw-r--r--. 1 root root 62 Jan 29 10:57 test 33577447 -rw-r--r--. 1 root root 12288 Jan 29 10:58 .test.swp Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"3-文件管理/5-文件链接.html":{"url":"3-文件管理/5-文件链接.html","title":"第5节 文件链接","keywords":"","body":"第5节. 文件链接 硬链接，在同一个分区的不同目录下 不能针对文件夹 不能跨分区 data有3个inode ID的原因，是多一个子文件夹就多一个硬连接。 ll -i查看的连接数是硬连接数，与软连接无关。 硬连接如果使用相对路径是，相对的当前操作的路径。 软连接文件的大小是指向路径的长度决定的 软连接的原始文件要写相对于你要创建的连接文件的路径。 写相对路径，你直接复制/data复制重命名其他的，你的软连接一样使用OK。 软连接可以针对文件夹创建 删除软连接是个危险活~ 因为rm -rf d1.你一个tab键补全就是rm -rf d1.link/ ， 然后你删除的就是d1.link链接的那个源文件夹里的所有东西，而d1.link这个软链接本身并没有删除。 软连接、硬链接区别 1、本质上：硬链接-本质上是同一个文件多个名字；软连接-本质上是不同文件； 2、跨分区：硬链接不支持，软连接支持 3、目录创建：硬链接不支持；软连接支持 4、相互关系：硬链接是相互平等；软连接原始文件删除软连接失效 5、inode编号：硬链接是相同的；软连接不同 6、连接数：硬链接的创建删除会影响连接数；软连接删了这个文件就没了不存在连接数多个的问题。 7、路径问题：原始文件路径：硬链接创建是相对当前工作目录，软连接是相对于要创建的软连接的相对路径。 8、文件类型：软连接时l表示软连接；硬链接就是文件本身是啥类型就是啥。 9、颜色：软连接是蓝色、硬链接看原文件 10、命令实现不同：ln -s和ln linux的文件格式，不存在后缀一说，可以通过file xxx去判断该文件类型。 file -b # 只显示文件名本身 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"4-文本编辑工具vim/4-文本编辑工具vim.html":{"url":"4-文本编辑工具vim/4-文本编辑工具vim.html","title":"第四章 文本编辑工具vim","keywords":"","body":"第四章 文本编辑工具vim Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"4-文本编辑工具vim/1-vim.html":{"url":"4-文本编辑工具vim/1-vim.html","title":"第1节 vim","keywords":"","body":"第1节. vim 大篇幅编辑使用软件如vscode的plugin弄就行了。 会用到的备忘： :set nu 删除100dd,dGG,dgg ^$切换行尾行首w光标移动一个空格 vim +10 xxx # 打开就进入了第10行 vim 颜色也不是都加的，/etc/passwd，复制到/data下再vim就会发现颜色没了。/etc/下的属于系统配置文件，所以给你加颜色了。 vim -m 只读打开 /XXX搜索，nN u撤销 U 改行的修改全部撤销 s/要查找的内容/替换的内容/修饰符 这是正则，后面到了正则再说 整个文件的内容vim里替换用%s :%s/XXX/YYY/g /可以替换的 :%s#/dev#/tmp#g 0的ASCI码 cat也看不到 可以这么看二进制文件 00000000这是位置，后面00 00 00是内容 批量注释会有用 复制到vim里，空行格式错位，可以试试 :set paste 这个比较好用， 跳行同学的福音 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"5-标准I&O和管道/5-标准I&O和管道.html":{"url":"5-标准I&O和管道/5-标准I&O和管道.html","title":"第五章 标准I&O和管道","keywords":"","body":"第五章 标准I&O和管道 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"5-标准I&O和管道/1-标准输入输出和重定向.html":{"url":"5-标准I&O和管道/1-标准输入输出和重定向.html","title":"第1节 标准输入输出和重定向","keywords":"","body":"第1节. 标准输入输出和重定向 三种I/O设备 把I/O重定向到文件 使用管道 标准输入 每打开一个文件，系统都会分配一个数字编号对应该文件， 可见一个文件会有4个描述符与之对应，退出tail后，这里的对应关系就没了。 可以看到tail -f .bashrc，系统分配了一个3的文件描述符-软连接指向。 而0 1 2是输入输出信息对应的设备文件描述符，什么意思，就是你对.bashrc文件进行操作，会存在各种交互信息，正常的，错误的，等等从键盘输入的，打印到屏幕的。 关于输出重定向的小例子 > # 这是标准输出的重定向 以下命令特别的一个：C ls /data /xxx 2> all.log 1>&2 ls /data /xxx &> all.log ls /data /xxx 2>&1 all.log # 打印到屏幕上去了 ls /data /xxx > all.log 2>&1 以上是标准输出 标准输入 tr的一些用法 tr abcde 123 tr -t abcde 123 tr [:lower:] [:upper:] tr -d '135' tr -s 'ace' tr就可以和标准输入结合 所以转换的话，也可以用tr来做 tr可以转换、压缩、删除，也方便了。 上图是CTRL+D结束才会看到结果。是除了a、b、c以外的都删了。 单行重定向举例 此时多开一个窗口可见aaa已近写进去了 多行重定向 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"5-标准I&O和管道/2-管道实现重定向.html":{"url":"5-标准I&O和管道/2-管道实现重定向.html","title":"第2节 管道实现重定向","keywords":"","body":"第2节. 管道实现重定向 如何对错误信息进行管道符传递 上图：管道符|只能处理标准输出，而标准错误无法传递，不过可以下图做法： 上图有两种写法，最后的|&是相对2>&1晚一些时间出来的写法。 换种邮件正文的写法 bc的灵活用法 tee的意义 tee会覆盖 tee的追加效果 tee的意义 计算1+2+3+ ... +100 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"6-用户、用户组和权限/6-用户、用户组和权限.html":{"url":"6-用户、用户组和权限/6-用户、用户组和权限.html","title":"第六章 用户、用户组和权限","keywords":"","body":"第六章 用户、用户组和权限 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"6-用户、用户组和权限/1-用户和组的增删改查.html":{"url":"6-用户、用户组和权限/1-用户和组的增删改查.html","title":"第1节 用户和组的增删改查","keywords":"","body":"第1节. 用户和组的增删改查 AAA authentication、authorization、accouting|audition UID windows看用户和组 windows里user和group 不能同名，但是在linux里是正常情况。 早期密码是放在/etc/passwd里的，后买放到shaow里，可以回归早期的情况 pwunconv # 密码放到/etc/passwd里 pwconv # 密码放到/etc/shadow里 UID才是关键，将root的UID改成1000，它就不是管理员了。 如果没有一个user的UID=0，重启就起不来了。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"6-用户、用户组和权限/2-用户和组的权限管理.html":{"url":"6-用户、用户组和权限/2-用户和组的权限管理.html","title":"第2节 用户和组的权限管理","keywords":"","body":"第2节. 用户和组的权限管理 /etc/shaow字段说明 useradd -r ming [09:19:15 root@localhost ~]#echo cisco | passwd --stdin ming Changing password for user ming. passwd: all authentication tokens updated successfully. ming:$6$AUsIFTgTuY/hWn8Y$0PgiuhWLxBGeGRtbd/Niz5R1EsMRvV3gdSRT45jnXMyZisgBzcCybETswhJzuuUQeIPkO/gMzo3rKyXvRAE6h.:19008:::::: ---上面是rocke-linux复制过来的---下面是centos----- ming:$6$nfkcZ5x7$Le5WQnLSUiJbw2tdXiilhvVZFGy69iuzKQq2XoA84jrHtrOp8fwQgMyunGIt1wQimPf37xdUL7B6rCOvpSaDE0:19008:0:99999:7::: [root@centos7 ~]# 这些字段的帮助信息可通过man 5 shadow获得 $6 ：表示sha512 $1 ：表示md5 👇注意第一个时间字段=0的特殊功效，就是首次登入修改密码 你改口令的时间距离1970-1-1号的时间 date of last password change The date of the last password change, expressed as the number of days since Jan 1, 1970. The value 0 has a special meaning, which is that the user should change her pasword the next time she will log in the system. An empty field means that password aging features are disabled. # 这句其实不对，该字段为空，后面设置了超时，实际还是超的 [09:25:26 root@localhost ~]#echo `date +%s`/86400 |bc 19008 这就是上图ming用户的19008的由来 minimum password age 用户必须等多久才能修改口令，0就是可以立即修改密码，以天为单位，centos8里默认是0，rocke-linux默认为空 maximum password age 用户不改密码，密码多久到期，以天为单位，centos8默认99999，rocke-linux/centos7默认为空 password warning period 上面的最大密码时间意味着过期，而过期前提前7天会提醒你修改密码，但是实际情况是提前6天，因为那个提前的第7天是也可继续用的，而且时间是当天8点0分0秒作为天数24小时去算的，可能是GTM+8估计。估计这2个小点就可以问住一拨人 [root@centos7 ~]# date -s \"+5 day\" # 这个必须root才能修改成功 Fri Jan 21 09:40:55 CST 2022 [root@centos7 ~]# date 然后再将本地时间延后10天，此时在用ming登入看看 [root@centos7 ~]# date -s \"+5 day\" Wed Jan 26 09:44:25 CST 2022 [root@centos7 ~]# date -s \"+5 day\" Mon Jan 31 09:45:03 CST 2022 [root@centos7 ~]# password inactivity period 围绕着密码过期时间--maximum password age，如果超过这个时间X天就禁用该账号，这个X就是password inactivity period的意思。 ming:$6$nfkcZ5x7$Le5WQnLSUiJbw2tdXiilhvVZFGy69iuzKQq2XoA84jrHtrOp8fwQgMyunGIt1wQimPf37xdUL7B6rCOvpSaDE0:19008:0:10:7:5:: account expiration date 账户有效期，前面都是针对密码过期的，这个参数是针对账号的 注意这里和前一张图的区别，已经不再说authentication的事了，直接说的事账号挂了。 /etc/group和/etc/gshadow dbus:x:81: polkitd:x:998: ssh_keys:x:997: sshd:x:74: postdrop:x:90: postfix:x:89: user1:x:1000: ming:x:1001: [root@centos7 ~]# cat /etc/group systemd-journal:!:: systemd-network:!:: dbus:!:: polkitd:!:: ssh_keys:!:: sshd:!:: postdrop:!:: postfix:!:: user1:!:: ming:!:: [root@centos7 ~]# cat /etc/gshadow 组设置口令是给普通用户加组的权限， 附加组显示在/etc/group里的行最后一个字段 ming:x:1001:user1 user1用户就加入进了ming这个组，ming就是user1的附加组 /etc/gshadow 存放组口令的文件 ming:!!::user1,user2,user3 !!组密码禁用的，不能通过组口令来往里加成员，只能是root管理了 ::里放的是管理员账号，每个组可以设置管理员,用来添加删除组成员，默认为空就只有root管理 user1,user2,user3就是和/etc/group一样，加入该组的成员就罗列在这里 随机口令的产生 [root@centos7 ~]# openssl rand -base64 9 rvgumQ+4U67t [root@centos7 ~]# openssl rand -base64 9 328culZ3wpV1 [root@centos7 ~]# yum -y install expect 查看man手册： FLAGS The -l flag defines the length of the password. The default is 9. The following example creates a 20 character password. mkpasswd -l 20 The -d flag defines the minimum number of digits that must be in the password. The default is 2. The following example creates a password with at least 3 digits. mkpasswd -d 3 The -c flag defines the minimum number of lowercase alphabetic characters that must be in the password. The default is 2. The -C flag defines the minimum number of uppercase alphabetic characters that must be in the password. The default is 2. EXAMPLE The following example creates a 15-character password that contains at least 3 digits and 5 uppercase characters. mkpasswd -l 15 -d 3 -C 5 [root@centos7 ~]# mkpasswd -l 15 -d 3 -C 5 \\Dpbel2VZa8Dv9W [root@centos7 ~]# mkpasswd -l 15 -d 3 -C 5 m0hsZaXZ*O1Dap9 [root@centos7 ~]# mkpasswd -l 15 -d 3 -C 5 zBfuS0evQP6x1H/ C:\\Users\\MingYi>net accounts 强制用户在时间到期之后多久必须注销?: 从不 密码最短使用期限(天): 0 密码最长使用期限(天): 42 密码长度最小值: 0 保持的密码历史记录长度: None 锁定阈值: 从不 锁定持续时间(分): 30 锁定观测窗口(分): 30 计算机角色: WORKSTATION 命令成功完成。 真要改这个时间，不推荐上文的直接修改/etc/shadow，而是用命令去改 [12:33:30 root@localhost ~]#chage ming Changing the aging information for ming Enter the new value, or press ENTER for the default Minimum Password Age [-1]: 2 Maximum Password Age [-1]: 33 Last Password Change (YYYY-MM-DD) [2022-01-16]: Password Expiration Warning [-1]: 7 Password Inactive [-1]: Account Expiration Date (YYYY-MM-DD) [-1]: 2023-01-16 [12:34:26 root@localhost ~]# ----改时间---- 这里rockety-linux还弄出个-1出来，呵呵，反正估计也是不限制的意思 [12:36:06 root@localhost ~]#getent shadow ming ming:$6$AUsIFTgTuY/hWn8Y$0PgiuhWLxBGeGRtbd/Niz5R1EsMRvV3gdSRT45jnXMyZisgBzcCybETswhJzuuUQeIPkO/gMzo3rKyXvRAE6h.:19008:2:33:7::19373: [12:36:13 root@localhost ~]# [12:36:26 root@localhost ~]#getent passwd ming ming:x:992:988::/home/ming:/bin/bash [12:36:34 root@localhost ~]# [12:36:36 root@localhost ~]#getent group ming ming:x:988: [12:36:48 root@localhost ~]#getent gshadow ming ming:!:: [12:36:53 root@localhost ~]# [12:36:54 root@localhost ~]#getent passwd ming root ming:x:992:988::/home/ming:/bin/bash root:x:0:0:root:/root:/bin/bash [12:37:02 root@localhost ~]# vipw和vigr 编辑passwd和group的推荐命令 pwck和grpck 检查passwd和group的命令 [12:38:19 root@localhost ~]#pwck [user 'cockpit-ws': directory '/nonexisting' does not exist user 'cockpit-wsinstance': directory '/nonexisting' does not exist user 'ming': directory '/home/ming' does not exist pwck: no changes [12:39:02 root@localhost ~]#grpck [12:39:11 root@localhost ~]#ll /home/ total 0 groupadd 创建组 创建组 [13:39:41 root@localhost ~]#groupadd admins [13:39:50 root@localhost ~]#getent group admins admins:x:1000: [13:40:00 root@localhost ~]# 创建系统组 [13:40:46 root@localhost ~]#groupadd -r mysql [13:40:50 root@localhost ~]# [13:40:52 root@localhost ~]#getent group mysql mysql:x:987: [13:40:55 root@localhost ~]# 修改组名 [13:42:45 root@localhost ~]#getent group admins admins:x:1000: [13:42:50 root@localhost ~]#groupmod -n mgmt admins [13:42:56 root@localhost ~]#getent group mgmt mgmt:x:1000: 删除组 [13:44:06 root@localhost ~]#getent group mgmt mgmt:x:1000: [13:44:08 root@localhost ~]#getent group mysql mysql:x:987: [13:44:10 root@localhost ~]#groupdel mgmt [13:44:18 root@localhost ~]#groupdel mysql [13:44:20 root@localhost ~]#getent group mysql [13:44:23 root@localhost ~]#getent group mgmt 删不掉组的原因 [13:49:33 root@localhost ~]#groupdel ming groupdel: cannot remove the primary group of user 'ming' 是因为有用户将ming作为主组，这个用户就是ming自己。是useradd创建ming的时候自动生成的主组。 [13:49:43 root@localhost ~]#useradd ming2 [13:51:05 root@localhost ~]#getent group ming2 ming2:x:1000: [13:51:23 root@localhost ~]#groupdel ming2 groupdel: cannot remove the primary group of user 'ming2' [13:51:32 root@localhost ~]#userdel ming2 [13:51:39 root@localhost ~]#getent group ming2 [13:51:45 root@localhost ~]#ll /home/ total 0 drwx------. 2 1000 1000 62 Jan 16 13:51 ming2 userdel 删除用户连带组，但不会连带家目录，所以关于创建用户和删除用户的时候要注意家目录是否连带生成和删除 man useradd -r, --system Create a system account. System users will be created with no aging information in /etc/shadow, and their numeric identifiers are chosen in the SYS_UID_MIN-SYS_UID_MAX range, defined in /etc/login.defs, instead of UID_MIN-UID_MAX (and their GID counterparts for the creation of groups). Note that useradd will not create a home directory for such a user, regardless of the default setting in /etc/login.defs (CREATE_HOME). You have to specify the -m options if you want a home directory for a system account to be created. man userdel -f, --force This option forces the removal of the user account, even if the user is still logged in. It also forces userdel to remove the user's home directory and mail spool, even if another user uses the same home directory or if the mail spool is not owned by the specified user. If USERGROUPS_ENAB is defined to yes in /etc/login.defs and if a group exists with the same name as the deleted user, then this group will be removed, even if it is still the primary group of another user. Note: This option is dangerous and may leave your system in an inconsistent state. -h, --help Display help message and exit. -r, --remove Files in the user's home directory will be removed along with the home directory itself and the user's mail spool. Files located in other file systems will have to be searched for and deleted manually. The mail spool is defined by the MAIL_DIR variable in the login.defs file. [14:01:12 root@localhost ~]#useradd ming2 useradd: warning: the home directory already exists. Not copying any file from skel directory into it. Creating mailbox file: File exists [14:01:18 root@localhost ~]# [14:01:18 root@localhost ~]# [14:01:18 root@localhost ~]#getent passwd ming2 ming2:x:1000:1000::/home/ming2:/bin/bash [14:01:22 root@localhost ~]# [14:01:23 root@localhost ~]#ll /home/ total 0 drwx------. 2 ming2 ming2 62 Jan 16 13:51 ming2 [14:01:25 root@localhost ~]# [14:01:26 root@localhost ~]#userdel -r ming2 [14:01:30 root@localhost ~]#ll /home/ total 0 [14:01:32 root@localhost ~]#getent passwd ming2 [14:01:39 root@localhost ~]#getent group ming2 [14:01:43 root@localhost ~]# 用户创建管理 [14:03:53 root@localhost ~]#rpm -q --scripts postfix preinstall scriptlet (using /bin/sh): # Add user and groups if necessary /usr/sbin/groupadd -g 90 -r postdrop 2>/dev/null /usr/sbin/groupadd -g 89 -r postfix 2>/dev/null /usr/sbin/groupadd -g 12 -r mail 2>/dev/null /usr/sbin/useradd -d /var/spool/postfix -s /sbin/nologin -g postfix -G mail -M -r -u 89 postfix 2>/dev/null ------------------------- -g 90 gid -r 指定为系统组 useradd的选项学习 /usr/sbin/useradd -d /var/spool/postfix -s /sbin/nologin -g postfix -G mail -M -r -u 89 postfix 2>/dev/null -u 89 ： 指定用户UID为89 -s : 指定shell类型 -o ： 忽略uid唯一性的检查 [14:12:58 root@localhost ~]#getent passwd root root:x:0:0:root:/root:/bin/bash [14:13:09 root@localhost ~]#useradd -u 0 ming3 useradd: UID 0 is not unique [14:13:20 root@localhost ~]#getent passwd ming3 [14:13:36 root@localhost ~]#useradd -u 0 -o ming3 [14:13:42 root@localhost ~]#getent passwd ming3 ming3:x:0:1000::/home/ming3:/bin/bash [14:13:43 root@localhost ~]#getent passwd root root:x:0:0:root:/root:/bin/bash [14:14:47 root@localhost ~]#id root uid=0(root) gid=0(root) groups=0(root) [14:14:49 root@localhost ~]#id ming3 uid=0(root) gid=0(root) groups=0(root) [14:14:51 root@localhost ~]# 创建系统服务， [14:18:18 root@localhost ~]#useradd -r -s /sbin/nologin mysql [14:18:26 root@localhost ~]#getent passwd mysql mysql:x:991:987::/home/mysql:/sbin/nologin 默认行为是useradd不指定主组，就会自动创建和用户名同名的主组 [14:21:35 root@localhost ~]#useradd alice [14:21:48 root@localhost ~]#id alice uid=1000(alice) gid=1000(alice) groups=1000(alice) 通过-g指定主组，就不会自动创建主组了，指定的组要事先存在 [14:22:33 root@localhost ~]#useradd tom -g alice [14:22:58 root@localhost ~]#id tom uid=1001(tom) gid=1000(alice) groups=1000(alice) -G 是附加组 [14:24:10 root@localhost ~]#groupadd g1 [14:24:13 root@localhost ~]#groupadd g2 [14:24:21 root@localhost ~]#groupadd g3 [14:24:23 root@localhost ~]# [14:24:24 root@localhost ~]#useradd jack -g alice -G g1,g2 [14:24:44 root@localhost ~]#id jack uid=1002(jack) gid=1000(alice) groups=1000(alice),1001(g1),1002(g2) [14:26:44 root@localhost ~]#getent group | grep jack g1:x:1001:jack g2:x:1002:jack [14:26:49 root@localhost ~]#getent gshadow | grep jack g1:!::jack g2:!::jack [14:26:55 root@localhost ~]# -N 不创建同名的主组，也不指定，就默认创建一个users [14:28:06 root@localhost ~]#useradd rose -N [14:28:15 root@localhost ~]#id rose uid=1003(rose) gid=100(users) groups=100(users) [14:28:18 root@localhost ~]# 看下windows的创建用户的默认行为，默认就是和linux的useradd -N一样的，都是将新建用户放到users组下面。 C:\\WINDOWS\\system32>net user test001 passwd001 /add 命令成功完成。 C:\\WINDOWS\\system32>net user \\\\DESKTOP-5T7A4A1 的用户帐户 ------------------------------------------------------------------------------- ___VMware_Conv_SA___ admin Administrator ciscoacvpnuser DefaultAccount Guest MingYi named test001 WDAGUtilityAccount 命令成功完成。 C:\\WINDOWS\\system32>net localgroup users 别名 users 注释 防止用户进行有意或无意的系统范围的更改，但是可以运行大部分应用程序 成员 ------------------------------------------------------------------------------- NT AUTHORITY\\Authenticated Users NT AUTHORITY\\INTERACTIVE test001 命令成功完成。 C:\\WINDOWS\\system32>net user \\\\DESKTOP-5T7A4A1 的用户帐户 ------------------------------------------------------------------------------- ___VMware_Conv_SA___ admin Administrator ciscoacvpnuser DefaultAccount Guest MingYi named test001 WDAGUtilityAccount 命令成功完成。 C:\\WINDOWS\\system32>net user test001 /del 命令成功完成。 C:\\WINDOWS\\system32>net user \\\\DESKTOP-5T7A4A1 的用户帐户 ------------------------------------------------------------------------------- ___VMware_Conv_SA___ admin Administrator ciscoacvpnuser DefaultAccount Guest MingYi named WDAGUtilityAccount 命令成功完成。 关于家目录 不带家目录的方式，useradd -r -s /sbin/nologin mysql [14:35:33 root@localhost ~]#getent passwd | tail -5 mysql:x:991:987::/home/mysql:/sbin/nologin alice:x:1000:1000::/home/alice:/bin/bash tom:x:1001:1000::/home/tom:/bin/bash jack:x:1002:1000::/home/jack:/bin/bash rose:x:1003:100::/home/rose:/bin/bash [14:35:38 root@localhost ~]#ll /home/ total 0 drwx------. 2 alice alice 62 Jan 16 14:21 alice drwx------. 2 jack alice 62 Jan 16 14:24 jack drwx------. 2 rose users 62 Jan 16 14:28 rose drwx------. 2 tom alice 62 Jan 16 14:22 tom [14:35:43 root@localhost ~]# 指定创建家目录 [14:43:13 root@localhost ~]#useradd -d /data/jerryhome jerry [14:43:18 root@localhost ~]#ll /data/jerryhome/ -d drwx------. 2 jerry jerry 62 Jan 16 14:43 /data/jerryhome/ [14:43:29 root@localhost ~]#id jerry uid=1004(jerry) gid=1004(jerry) groups=1004(jerry) [14:43:32 root@localhost ~]# 有个奇怪的行为，就是创建用户的时候指定家目录，但是并不创建 [14:46:22 root@localhost ~]#useradd -d /data/xiaohong -M xiaohong [14:46:36 root@localhost ~]#id xiaohong uid=1005(xiaohong) gid=1005(xiaohong) groups=1005(xiaohong) [14:46:38 root@localhost ~]#ll /data/xiao* ls: cannot access '/data/xiao*': No such file or directory 还有与之相反的思路，useradd -r是系统用户不会创建家目录，-m就是会创建了 [14:47:50 root@localhost ~]#useradd -r zhangsan [14:48:09 root@localhost ~]#id zhangsan uid=990(zhangsan) gid=986(zhangsan) groups=986(zhangsan) [14:48:10 root@localhost ~]#ll /home/ total 0 drwx------. 2 alice alice 62 Jan 16 14:21 alice drwx------. 2 jack alice 62 Jan 16 14:24 jack drwx------. 2 rose users 62 Jan 16 14:28 rose drwx------. 2 tom alice 62 Jan 16 14:22 tom [14:48:14 root@localhost ~]# [14:48:14 root@localhost ~]#useradd -r lisi -m [14:48:33 root@localhost ~]#ll /home/lisi/ -d drwx------. 2 lisi lisi 62 Jan 16 14:48 /home/lisi/ [14:48:38 root@localhost ~]# [14:49:16 root@localhost ~]#useradd -r -m -d /data/ada ada [14:49:20 root@localhost ~]#ll /data/ada -d drwx------. 2 ada ada 62 Jan 16 14:49 /data/ada [14:49:24 root@localhost ~]#id ada uid=988(ada) gid=988(ada) groups=988(ada) [14:49:26 root@localhost ~]# -c : 描述信息，有点用的，讲究人士的专用 [14:51:48 root@localhost ~]#useradd -c \"sbZhuanYong\" sb001 [14:52:21 root@localhost ~]#getent passwd sb001 sb001:x:1006:1006:sbZhuanYong:/home/sb001:/bin/bash [14:52:26 root@localhost ~]# 如果是centos可以yum -y install finger然后查看用户描述信息，rokey-linux好像yum不了finger，yum源rocky的里面貌似没有finger 的rpm包。 [root@centos7 ~]# useradd -c 'dalaozhuanyong' dalao001 [root@centos7 ~]# getent passwd dalao001 dalao001:x:1002:1002:dalaozhuanyong:/home/dalao001:/bin/bash [root@centos7 ~]# [root@centos7 ~]# finger dalao001 Login: dalao001 Name: dalaozhuanyong Directory: /home/dalao001 Shell: /bin/bash Never logged in. No mail. No Plan. [root@centos7 ~]# -----改描述------desc--------- [root@centos7 ~]# chfn dalao001 Changing finger information for dalao001. Name [dalaozhuanyong]: Office []: !wgame Office Phone []: 110 Home Phone []: 110 Finger information changed. [root@centos7 ~]# finger dalao001 Login: dalao001 Name: dalaozhuanyong Directory: /home/dalao001 Shell: /bin/bash Office: !wgame, 110 Home Phone: 110 Never logged in. No mail. No Plan. [root@centos7 ~]# getent passwd dalao001 dalao001:x:1002:1002:dalaozhuanyong,!wgame,110,110:/home/dalao001:/bin/bash [root@centos7 ~]# 所以人家postfix的安装后或者前，跑的脚本里的useradd就能理解了 [root@centos7 ~]# rpm -q --scripts postfix preinstall scriptlet (using /bin/sh): # Add user and groups if necessary /usr/sbin/groupadd -g 90 -r postdrop 2>/dev/null /usr/sbin/groupadd -g 89 -r postfix 2>/dev/null /usr/sbin/groupadd -g 12 -r mail 2>/dev/null /usr/sbin/useradd -d /var/spool/postfix -s /sbin/nologin -g postfix -G mail -M -r -u 89 postfix 2>/dev/null [15:08:55 root@localhost yum.repos.d]#yum -y remove postfix [15:10:09 root@localhost yum.repos.d]#groupadd -r postfix [15:11:58 root@localhost yum.repos.d]#groupadd postfix-1 [15:12:02 root@localhost yum.repos.d]# [15:12:03 root@localhost yum.repos.d]#getent group postfix postfix:x:984: [15:12:09 root@localhost yum.repos.d]#getent group postfix-1 postfix-1:x:1007: [15:12:12 root@localhost yum.repos.d]# [15:12:16 root@localhost yum.repos.d]#id postfix id: ‘postfix’: no such user [15:12:19 root@localhost yum.repos.d]#/usr/sbin/useradd -d /var/spool/postfix -s /sbin/nologin -g postfix -G mail -M -r -u 89 postfix [15:12:23 root@localhost yum.repos.d]#id postfix uid=89(postfix) gid=984(postfix) groups=984(postfix),12(mail) [15:12:28 root@localhost yum.repos.d]#ll /home/pos* ls: cannot access '/home/pos*': No such file or directory [15:12:33 root@localhost yum.repos.d]#ll /var/spool/pos* ls: cannot access '/var/spool/pos*': No such file or directory [15:12:43 root@localhost yum.repos.d]# 其实-M没有意义，就是保险，-r本身就不会创建家目录。 注意下，不管是不是需要userdel -r 加不加r都要去确认下家目录是否真的删除，因为我操作时候发现有时候不加-r，好像也是把家目录删了。这个是在rockey-linux上操作的。 默认useradd的行为有文件定义的 [15:25:22 root@localhost ~]#cat /etc/default/useradd # useradd defaults file GROUP=100 HOME=/home INACTIVE=-1 EXPIRE= SHELL=/bin/bash SKEL=/etc/skel CREATE_MAIL_SPOOL=yes [15:25:27 root@localhost ~]#getent group users users:x:100: [15:26:08 root@localhost ~]# GROUP = 100 默认useradd -N 不创建主组的时候，自动加到users主组里，这个行为就是GROUP=100设置的。 INACTIVE=-1 默认用密码过期后 是否给宽限期，默认是永远宽限。 HOME=/home 默认家目录在哪 CREATE_MAIL_SPOOL=yes 默认用户创建的时候创建它的邮箱， [15:26:08 root@localhost ~]#ll /var/spool/mail/ total 0 -rw-rw----. 1 alice mail 0 Jan 16 14:21 alice -rw-rw----. 1 jack mail 0 Jan 16 14:24 jack -rw-rw----. 1 jerry mail 0 Jan 16 14:43 jerry -rw-rw----. 1 rose mail 0 Jan 16 14:28 rose -rw-rw----. 1 sb001 mail 0 Jan 16 14:52 sb001 -rw-rw----. 1 tom mail 0 Jan 16 14:22 tom -rw-rw----. 1 xiaohong mail 0 Jan 16 14:46 xiaohong SKEL=/etc/skel 默认创建家目录里的隐藏文件的由来 [15:33:50 root@localhost ~]#ls -a /etc/skel/ . .. .bash_logout .bash_profile .bashrc [15:33:53 root@localhost ~]# 所以如果需要创建用户，生成的家目录里自动带上什么文件，就有办法了 [15:36:42 root@localhost ~]#ls -a /etc/skel . .. .bash_logout .bash_profile .bashrc [15:36:51 root@localhost ~]# [15:37:01 root@localhost ~]#ls -a /home/ alice/ jack/ lisi/ rose/ sb001/ tom/ [15:37:01 root@localhost ~]#ls -a /home/alice/ . .. .bash_logout .bash_profile .bashrc [15:37:13 root@localhost ~]#touch /etc/skel/.vimrc [15:37:22 root@localhost ~]#ls -a /etc/skel/ . .. .bash_logout .bash_profile .bashrc .vimrc [15:37:32 root@localhost ~]#useradd test-1 [15:37:43 root@localhost ~]#ls -a /home/test-1/ . .. .bash_logout .bash_profile .bashrc .vimrc [15:37:49 root@localhost ~]# 还有个默认行为文件 [15:43:09 root@localhost ~]#cat /etc/login.defs | grep -Ev \"^#|^$\" MAIL_DIR /var/spool/mail UMASK 022 HOME_MODE 0700 PASS_MAX_DAYS 99999 # 口令最大有效期 PASS_MIN_DAYS 0 # 口令修改无需等待直接改 PASS_MIN_LEN 5 # 口令最短5个 PASS_WARN_AGE 7 UID_MIN 1000 # 默认普通用户UID从1000开始，就是这里设置的 UID_MAX 60000 # 这里的1000和60000都是自动的范围，手动除外 SYS_UID_MIN 201 # 系统UID自动范围 SYS_UID_MAX 999 # 系统UID自动范围 GID_MIN 1000 GID_MAX 60000 SYS_GID_MIN 201 SYS_GID_MAX 999 CREATE_HOME yes USERGROUPS_ENAB yes ENCRYPT_METHOD SHA512 # 默认的哈希算法，/etc/passwd里的$6 [15:43:16 root@localhost ~]# root 不受上述配置的限制 所以默认新建用户的相关文件如下 [15:51:36 root@localhost ~]#ll /etc/default/useradd -d -rw-r--r--. 1 root root 119 Aug 19 03:04 /etc/default/useradd [15:51:40 root@localhost ~]#ll /etc/skel -d drwxr-xr-x. 2 root root 76 Jan 16 15:37 /etc/skel [15:51:44 root@localhost ~]#ll /etc/login.defs -d -rw-r--r--. 1 root root 2512 Aug 19 03:04 /etc/login.defs /etc/default/useradd也可以用useradd -D查看 [15:53:09 root@localhost ~]#useradd -D GROUP=100 HOME=/home INACTIVE=-1 EXPIRE= SHELL=/bin/bash SKEL=/etc/skel CREATE_MAIL_SPOOL=yes [15:54:10 root@localhost ~]#cat /etc/default/useradd # useradd defaults file GROUP=100 HOME=/home INACTIVE=-1 EXPIRE= SHELL=/bin/bash SKEL=/etc/skel CREATE_MAIL_SPOOL=yes 1、直接修改文件 2、通过useradd修改 useradd -D -s SHELL类型 useradd -D -b BASE_DIR/home useradd -D -g GROUP默认useradd -N所带的组 [15:54:10 root@localhost ~]#cat /etc/default/useradd # useradd defaults file GROUP=100 HOME=/home INACTIVE=-1 EXPIRE= SHELL=/bin/bash SKEL=/etc/skel CREATE_MAIL_SPOOL=yes [15:54:22 root@localhost ~]#useradd -D -g 1000 [16:01:36 root@localhost ~]#cat /etc/default/useradd # useradd defaults file GROUP=1000 HOME=/home INACTIVE=-1 EXPIRE= SHELL=/bin/bash SKEL=/etc/skel CREATE_MAIL_SPOOL=yes [16:01:37 root@localhost ~]# 批量操作 newusers # passwd格式文件 批量创建用户 chpasswd # 批量修改用户口令 将/etc/passwd文件里的格式复制出来，放入单个文件，然后到别的机器上newusers xxx即可创建 user1:x:1008:1009::/home/user1:/bin/bash user2:x:1009:1010::/home/user2:/bin/bash user3:x:1010:1011::/home/user3:/bin/bash user4:x:1011:1012::/home/user4:/sbin/nologin [13:58:02 root@localhost ~]#getent passwd -----看下👇创建的具体过程---------- [root@centos7 ~]# cat addusers user1:x:1008:1009::/home/user1:/bin/bash user2:x:1009:1010::/home/user2:/bin/bash user3:x:1010:1011::/home/user3:/bin/bash user4:x:1011:1012::/home/user4:/sbin/nologin [root@centos7 ~]# newusers addusers newusers: line 5: invalid line newusers: line 6: invalid line newusers: error detected, changes ignored [root@centos7 ~]# cat addusers -n 1 user1:x:1008:1009::/home/user1:/bin/bash 2 user2:x:1009:1010::/home/user2:/bin/bash 3 user3:x:1010:1011::/home/user3:/bin/bash 4 user4:x:1011:1012::/home/user4:/sbin/nologin 5 6 [root@centos7 ~]# ---------👆可惜报错鸟------------ 删掉多余的空行后，尝试👇----------- [root@centos7 ~]# cat addusers user1:x:1008:1009::/home/user1:/bin/bash user2:x:1009:1010::/home/user2:/bin/bash user3:x:1010:1011::/home/user3:/bin/bash user4:x:1011:1012::/home/user4:/sbin/nologin [root@centos7 ~]# [root@centos7 ~]# newusers addusers [root@centos7 ~]# getent passwd |grep user* user1:x:1000:1000::/home/user1:/bin/bash user2:x:1009:1010::/home/user2:/bin/bash user3:x:1010:1011::/home/user3:/bin/bash user4:x:1011:1012::/home/user4:/sbin/nologin [root@centos7 ~]# -------------然后再批量改口令方法1👇-------------- [root@centos7 ~]# chpasswd user1:cisco # ctrl d安全退出才能生效 [root@centos7 ~]# getent shadow user1 user1:$6$dR6ZP/lQ5aA$V6xJwgibZELgZh2NKOVDSez8CTzw6h05NX.n/Ft4ZpGtlVNfNEpkpTFRdZqkSQWKKgeZ/BxKgfSm2BRcFaMgo0:19029:0:99999:7::: [root@centos7 ~]# chpasswd user1:huawei ^C # 不能ctrl c强制退出 [root@centos7 ~]# getent shadow user1 user1:$6$dR6ZP/lQ5aA$V6xJwgibZELgZh2NKOVDSez8CTzw6h05NX.n/Ft4ZpGtlVNfNEpkpTFRdZqkSQWKKgeZ/BxKgfSm2BRcFaMgo0:19029:0:99999:7::: [root@centos7 ~]# ------👆注意没截图就是方便后面搜索，但是要小心失真丢东西，这里是ctrl C强制退出，所以没改成功，很多这种交互式的配置都需要ctrl +d 退出。--------- ----非交互式配置方式👇------ [root@centos7 ~]# echo user1:lianxiang |chpasswd [root@centos7 ~]# getent shadow user1 user1:$6$A55IfCFmc$aJPxuWvGRvpTzNocXonzz/gEZTEjV7y3qcHSWEPvxZg1IfA0EUrXMMBpOsw9DXodx4KQ1yCa8SZCTiQtvDYu50:19029:0:99999:7::: [root@centos7 ~]# ---------批量改的方法👇---改口令1---------- [root@centos7 ~]# vi p.set [root@centos7 ~]# cat p.set user1:centos user2:cisco user3:huawei [root@centos7 ~]# cat p.set |chpasswd [root@centos7 ~]# getent shadow user1 user1:$6$PFoqG/41wd3x$PDCFFjFD84xNc2t4je5119lP.ifsTyspYRGnbP4Bx0QpP/9XRd4s9vUFICbEdoDv3pOd7y/7PBLuBsE6EXhwu/:19029:0:99999:7::: [root@centos7 ~]# getent shadow user2 user2:$6$0ilWD/oW7CN$IdC6Gz0.eJKdPBWuGx4KJR00GBrjoxE8KWtCp9lurmP1TaCQGcUra5.VscBTQZ5Um0lKYZO.qb6/fNyYiey0s1:19029:0:99999:7::: [root@centos7 ~]# getent shadow user3 user3:$6$Uv41MY/y9$Q1251b9f9CPX5/sQ1aDhITVsl9pbKEXJspkV4uib/ugaCAlMfg9/Xy4WJBdyq56SJF4k5YuIc0muouxLpi61T0:19029:0:99999:7::: [root@centos7 ~]# 查看id [root@centos7 ~]# id user1 uid=1000(user1) gid=1000(user1) groups=1000(user1) [root@centos7 ~]# id -u user1 1000 [root@centos7 ~]# id -g user1 1000 [root@centos7 ~]# id -G user1 1000 [root@centos7 ~]# id -n user1 id: cannot print only names or real IDs in default format [root@centos7 ~]# id -ng user1 user1 [root@centos7 ~]# id -ngG user1 id: cannot print \"only\" of more than one choice [root@centos7 ~]# id -nG user1 user1 usermod修改用户 [16:04:46 root@localhost ~]#id jack uid=1002(jack) gid=1000(alice) groups=1000(alice),1001(g1),1002(g2) [16:04:48 root@localhost ~]#usermod -g sb001 jack # 修改主组 [16:04:56 root@localhost ~]#id jack uid=1002(jack) gid=1006(sb001) groups=1006(sb001),1001(g1),1002(g2) [16:04:58 root@localhost ~]#usermod -G root jack # -G附加组要注意是覆盖性操作 [16:05:11 root@localhost ~]#id jack uid=1002(jack) gid=1006(sb001) groups=1006(sb001),0(root) [16:05:13 root@localhost ~]# 需要用到-aG,-a只能配合G用，因为其他属性不存在多个值。 [16:05:11 root@localhost ~]#id jack uid=1002(jack) gid=1006(sb001) groups=1006(sb001),0(root) [16:06:01 root@localhost ~]#usermod -aG g1,g2,g3 jack [16:06:12 root@localhost ~]#id jack uid=1002(jack) gid=1006(sb001) groups=1006(sb001),1001(g1),1002(g2),1003(g3),0(root) 空口令登入方法 关联用户锁定，就是不需要输入密码进行登入 修改/etc/shadow里的两个!!，没设置密码，就是两个!! [11:38:54 root@localhost ~]#cat /etc/shadow |grep lisi lisi:!!:19008:::::: [11:38:59 root@localhost ~]#vi /etc/shadow ][11:39:14 root@localhost ~]#cat /etc/shadow |grep lisi lisi::19008:::::: 修改/etc/passwd里的x拿掉，效果一样，无需密码，x就是占位，表示密码放在了/etc/shadow里。 [11:47:43 root@localhost ~]#cat /etc/passwd |grep sb001 sb001:x:1006:1006:sbZhuanYong:/home/sb001:/bin/bash [11:47:44 root@localhost ~]#vi /etc/passwd [11:48:00 root@localhost ~]#cat /etc/passwd |grep sb001 sb001::1006:1006:sbZhuanYong:/home/sb001:/bin/bash 注意这个好像没用了 锁定用户 [root@centos7 ~]# useradd test [root@centos7 ~]# getent passwd test test:x:1003:1003::/home/test:/bin/bash [root@centos7 ~]# getent shadow test test:!!:19029:0:99999:7::: # 新创建的用户是被锁定的 [root@centos7 ~]# getent group test test:x:1003: [root@centos7 ~]# getent gshadow test test:!:: -------↓--------设置密码后的变化------↓--------- [root@centos7 ~]# echo cisco |passwd --stdin test Changing password for user test. passwd: all authentication tokens updated successfully. [root@centos7 ~]# getent passwd test test:x:1003:1003::/home/test:/bin/bash [root@centos7 ~]# getent shadow test test:$6$QexkrOWQ$3e85TAtRmiYEMioZOU8QJ7qaD0xCP2lW4Dposctg7evJMRZy3kseNQXD.C21lKtXtqFnzGEhCnbiFq7yI4c5H.:19029:0:99999:7::: [root@centos7 ~]# getent group test test:x:1003: [root@centos7 ~]# getent gshadow test test:!:: -------👇------加锁后的变化---------- [root@centos7 ~]# usermod -L test [root@centos7 ~]# getent passwd test test:x:1003:1003::/home/test:/bin/bash [root@centos7 ~]# getent shadow test test:!$6$QexkrOWQ$3e85TAtRmiYEMioZOU8QJ7qaD0xCP2lW4Dposctg7evJMRZy3kseNQXD.C21lKtXtqFnzGEhCnbiFq7yI4c5H.:19029:0:99999:7::: # 锁是加在shadow里 [root@centos7 ~]# getent group test test:x:1003: [root@centos7 ~]# getent gshadow test test:!:: #gshadow这里一直都是这样的 [root@centos7 ~]# ------👇----解锁------ [root@centos7 ~]# usermod -U test [root@centos7 ~]# getent shadow test test:$6$QexkrOWQ$3e85TAtRmiYEMioZOU8QJ7qaD0xCP2lW4Dposctg7evJMRZy3kseNQXD.C21lKtXtqFnzGEhCnbiFq7yI4c5H.:19029:0:99999:7::: [root@centos7 ~]# -------👇如果是空口令是不给你解锁的---- [root@centos7 ~]# useradd ceshi [root@centos7 ~]# getent passwd ceshi ceshi:x:1004:1004::/home/ceshi:/bin/bash [root@centos7 ~]# getent shadow ceshi ceshi:!!:19029:0:99999:7::: [root@centos7 ~]# usermod -U ceshi usermod: unlocking the user's password would result in a passwordless account. You should set a password with usermod -p to unlock this user's password. 至于两个！！和一个！没啥区别，一来都是锁定。二来只要没有设置密码都不能-U解锁 不过可以vi进去解锁。 当然这个!可以加在passwd里的--通过vi手动加，usermod -L -U都是针对shadow操作，而且要比加在shadow里优先。 其实针对这个 echo \"cisco\" | passwd --sdtin test 这个非交互是的修改密码，其实我可以这样做 亲测有效稳定。 修改账号有效期 chage比它好 就是shadow文件里单行，倒数第二个字段--账号有效期，倒数第一字段保留字段。 [root@centos7 ~]# getent shadow test test:!$6$QexkrOWQ$3e85TAtRmiYEMioZOU8QJ7qaD0xCP2lW4Dposctg7evJMRZy3kseNQXD.C21lKtXtqFnzGEhCnbiFq7yI4c5H.:19029:0:99999:7::: [root@centos7 ~]# usermod -U test [root@centos7 ~]# usermod -e 2023-12-12 test [root@centos7 ~]# getent shadow test test:$6$QexkrOWQ$3e85TAtRmiYEMioZOU8QJ7qaD0xCP2lW4Dposctg7evJMRZy3kseNQXD.C21lKtXtqFnzGEhCnbiFq7yI4c5H.:19029:0:99999:7::19703: 设置密码宽限期 chage比它好 在最大超时时间到期后，你还能用几天 [root@centos7 ~]# getent shadow test test:$6$QexkrOWQ$3e85TAtRmiYEMioZOU8QJ7qaD0xCP2lW4Dposctg7evJMRZy3kseNQXD.C21lKtXtqFnzGEhCnbiFq7yI4c5H.:19029:0:99999:7::19703: [root@centos7 ~]# usermod -f 3 test [root@centos7 ~]# getent shadow test test:$6$QexkrOWQ$3e85TAtRmiYEMioZOU8QJ7qaD0xCP2lW4Dposctg7evJMRZy3kseNQXD.C21lKtXtqFnzGEhCnbiFq7yI4c5H.:19029:0:99999:7:3:19703: [root@centos7 ~]# 改时间还是用chage 交互式和非交互是都有 [root@centos7 ~]# chage test Changing the aging information for test Enter the new value, or press ENTER for the default Minimum Password Age [0]: Maximum Password Age [99999]: Last Password Change (YYYY-MM-DD) [2022-02-06]: Password Expiration Warning [7]: Password Inactive [3]: Account Expiration Date (YYYY-MM-DD) [2023-12-12]: [root@centos7 ~]# [root@centos7 ~]# chage -h Usage: chage [options] LOGIN Options: -d, --lastday LAST_DAY set date of last password change to LAST_DAY -E, --expiredate EXPIRE_DATE set account expiration date to EXPIRE_DATE -h, --help display this help message and exit -I, --inactive INACTIVE set password inactive after expiration to INACTIVE -l, --list show account aging information -m, --mindays MIN_DAYS set minimum number of days before password change to MIN_DAYS -M, --maxdays MAX_DAYS set maximum number of days before password change to MAX_DAYS -R, --root CHROOT_DIR directory to chroot into -W, --warndays WARN_DAYS set expiration warning days to WARN_DAYS [root@centos7 ~]# ------注意-E选项时间格式有点坑---------👇--人工写成YYYY-MM-DD----- [root@centos7 ~]# chage -E 10 test [root@centos7 ~]# getent shadow test test:$6$QexkrOWQ$3e85TAtRmiYEMioZOU8QJ7qaD0xCP2lW4Dposctg7evJMRZy3kseNQXD.C21lKtXtqFnzGEhCnbiFq7yI4c5H.:19029:0:99999:7:3:10: [root@centos7 ~]# chage -E 2022-12-12 test [root@centos7 ~]# getent shadow test test:$6$QexkrOWQ$3e85TAtRmiYEMioZOU8QJ7qaD0xCP2lW4Dposctg7evJMRZy3kseNQXD.C21lKtXtqFnzGEhCnbiFq7yI4c5H.:19029:0:99999:7:3:19338: [root@centos7 ~]# chage -I 2 test [root@centos7 ~]# getent shadow test test:$6$QexkrOWQ$3e85TAtRmiYEMioZOU8QJ7qaD0xCP2lW4Dposctg7evJMRZy3kseNQXD.C21lKtXtqFnzGEhCnbiFq7yI4c5H.:19029:0:99999:7:2:19338: [root@centos7 ~]# userdel删除用户 [root@centos7 ~]# ll /home/ total 0 drwx------. 2 ceshi ceshi 83 Feb 6 12:08 ceshi drwx------. 2 dalao001 dalao001 62 Feb 5 14:54 dalao001 drwx------. 2 ming ming 83 Jan 26 09:44 ming drwx------. 2 test test 83 Feb 6 12:08 test drwx------. 2 998 996 62 Feb 5 15:20 test001 drwx------. 2 user1 user1 96 Jan 10 14:16 user1 [root@centos7 ~]# [root@centos7 ~]# [root@centos7 ~]# ll /var/spool/mail/ total 0 -rw-rw----. 1 ceshi mail 0 Feb 6 12:06 ceshi -rw-rw----. 1 dalao001 mail 0 Feb 5 14:54 dalao001 -rw-rw----. 1 ming mail 0 Jan 16 09:28 ming -rw-rw----. 1 test mail 0 Feb 6 11:57 test -rw-rw----. 1 user1 mail 0 Jan 10 11:12 user1 [root@centos7 ~]# [root@centos7 ~]# userdel test [root@centos7 ~]# ll /home/test -d drwx------. 2 1003 1003 83 Feb 6 12:08 /home/test [root@centos7 ~]# ll /var/spool/mail/test -d -rw-rw----. 1 1003 mail 0 Feb 6 11:57 /var/spool/mail/test # 除了家目录，邮箱也要注意是否删除 [root@centos7 ~]# ------不要以为重新创建test用户能继续关联之前没有删除的家目录和邮箱---那是不可能的👇--因为此用户非彼用户，正所谓去年今日此门中，人面桃花相映红，人面不知何处去，桃花依旧笑春风一句话就是uid变了，要是uid没变还是可以对接回去的，或者你人工修改新建用户名的uid为之前的id就可以对接上了-- [root@centos7 ~]# useradd test useradd: warning: the home directory already exists. Not copying any file from skel directory into it. Creating mailbox file: File exists [root@centos7 ~]# [root@centos7 ~]# [root@centos7 ~]# ll /var/spool/mail/test -d -rw-rw----. 1 1003 mail 0 Feb 6 11:57 /var/spool/mail/test [root@centos7 ~]# ll /home/test -d drwx------. 2 1003 1003 83 Feb 6 12:08 /home/test [root@centos7 ~]# userdel -r test userdel: /var/spool/mail/test not owned by test, not removing userdel: /home/test not owned by test, not removing [root@centos7 ~]# ll /var/spool/mail/test -d -rw-rw----. 1 1003 mail 0 Feb 6 11:57 /var/spool/mail/test [root@centos7 ~]# ll /home/test test/ test001/ [root@centos7 ~]# ll /home/test -d drwx------. 2 1003 1003 83 Feb 6 12:08 /home/test [root@centos7 ~]# userdel -r test userdel: user 'test' does not exist -----选项 -r ----👇能够删除用户家目录和邮箱------- [root@centos7 ~]# useradd test2 [root@centos7 ~]# ll /home/test2 -d drwx------. 2 test2 test2 62 Feb 6 13:36 /home/test2 [root@centos7 ~]# ll /var/spool/mail/test2 -d -rw-rw----. 1 test2 mail 0 Feb 6 13:36 /var/spool/mail/test2 [root@centos7 ~]# userdel -r test2 [root@centos7 ~]# ll /home/test2 -d ls: cannot access /home/test2: No such file or directory [root@centos7 ~]# ll /var/spool/mail/test2 -d ls: cannot access /var/spool/mail/test2: No such file or directory [root@centos7 ~]# 附加，group如果是组里没有其他人，userdel 也会删除组的。 所以这里userdel，要注意 组、家目录、邮箱 信息是否有变化。user没了，group、家目录、邮箱如果在，那么这些文件的属性里的user id都会变成该用户的uid--数字，而不再是原来的用户名。而且1005也只是个空数字，并没有任何用户与其对应。 PATH内容随用户而变 变量变量，它是变的，root和user1的PATH变量的内容是不一样 [root@centos7 ~]# echo $PATH /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin [user1@centos7 ~]$ echo $PATH /usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/user1/.local/bin:/home/user1/bin [user1@centos7 ~]$ su 切换 su - user1 # 这种切换用户环境一并切换 su # 原地切换，pwd的所在路径都不变 ------------完全切换👇---------------- [root@centos7 data]# pwd /data [root@centos7 data]# su - user1 Last login: Sun Feb 6 16:10:51 CST 2022 on pts/0 [user1@centos7 ~]$ pwd /home/user1 [user1@centos7 ~]$ echo $PATH /usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/user1/.local/bin:/home/user1/bin [user1@centos7 ~]$ --------------原地切换👇-pwd和$path都不变的-------------- [root@centos7 data]# su user1 [user1@centos7 data]$ pwd /data [user1@centos7 data]$ echo $PATH /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin [user1@centos7 data]$ --------换个用户执行命令，本身不切换过去----👇-------------- [user1@centos7 data]$ su root -c \"getent shadow root\" Password: root:$6$Kih8C.5/adh8TNjx$wNC09CUb7KsECwLH1LFfAagv8N47OAEqSMHLlOuU.vB24ZzU/H5p6DLpNV31zLKlJioqNmXkIkQEaAUf0H74Z0::0:99999:7::: [user1@centos7 data]$ su活su - 直接回车就是切root，root参数默认就有 root 切换 普通用户 无需密码 普通用户 切换 root 需要密码 ubuntu默认不让root登入的情况 ubuntu默认root等不了，su 切换要密码，但是没设置过root密码默认就 root的口令情况，你非root用户也看不全 这个时候就的使用sudo命令咯 sudo -i 提示出入的是当前普通用户的口令---👇-- 不是每个账号都能sudo 切换到root的，之所以可以是因为系统安装的时候授予了wang账号可以切换。 所以ubuntu这里的！去掉，root就直接无口令登入了 ----而且上面知识运行了root本地登入👆-----远程root还是无法登入ubuntu-------- -----👇一般只有系统安装时设置的默认第一个账户才能sudo -i 切成root用户------ passwd的有用选项 [root@centos7 data]# type passwd # 外部命令，就是用--help去查看帮助，当然也可以man passwd is hashed (/usr/bin/passwd) [root@centos7 data]# passwd --help Usage: passwd [OPTION...] -k, --keep-tokens keep non-expired authentication tokens -d, --delete delete the password for the named account (root only) -l, --lock lock the password for the named account (root only) -u, --unlock unlock the password for the named account (root only) -e, --expire expire the password for the named account (root only) -f, --force force operation -x, --maximum=DAYS maximum password lifetime (root only) -n, --minimum=DAYS minimum password lifetime (root only) -w, --warning=DAYS number of days warning users receives before password expiration (root only) -i, --inactive=DAYS number of days after password expiration when an account becomes disabled (root only) -S, --status report password status on the named account (root only) --stdin read new tokens from stdin (root only) Help options: -?, --help Show this help message --usage Display brief usage message -d ： 删除密码 -l : 这个和usermode -L一样 -u: 这个和usermode -U一样 -e: 👈这个好，典型应用按理，强制用户首次登入修改密码的。 -n -x -w 这些和chage以及usermod差不多，都可以改，推荐chage或者passwd。 改口令的方法2 echo cisco | passwd --stdin user1 &> /dev/null 这个passwd怎么批量啊？密码和用户都是变量，密码可以放到文件里，cat file |重定向给passwd，问题时用户怎么弄呢？好像没有chpasswd方面呢~注意此处划重点敲黑板👉呢字带尾音~。其他技术问题忽略即可~ [root@centos7 data]# vi change_passwd.sh [root@centos7 data]# [root@centos7 data]# . change_passwd.sh # 这里也是个点，放到后面，就是脚本执行的N种方法 Changing password for user user1. passwd: all authentication tokens updated successfully. Changing password for user user2. passwd: all authentication tokens updated successfully. Changing password for user user3. passwd: all authentication tokens updated successfully. [root@centos7 data]# [root@centos7 data]# cat change_passwd.sh #!/bin/bash echo cisco |passwd --stdin user1 echo huawei |passwd --stdin user2 echo juniper |passwd --stdin user3 [root@centos7 data]# --------👇优化输出----------- [root@centos7 data]# . change_passwd.sh [root@centos7 data]# [root@centos7 data]# cat change_passwd.sh #!/bin/bash echo cisco |passwd --stdin user1 > /dev/null echo huawei |passwd --stdin user2 > /dev/null echo juniper |passwd --stdin user3 > /dev/null [root@centos7 data]# 修改shell类型 [root@centos7 data]# getent passwd user1 user1:x:1000:1000::/home/user1:/bin/bash [root@centos7 data]# chsh -s /sbin/nologin user1 Changing shell for user1. chsh: Warning: \"/sbin/nologin\" is not listed in /etc/shells. Shell changed. [root@centos7 data]# getent passwd user1 user1:x:1000:1000::/home/user1:/sbin/nologin [root@centos7 data]# cat /etc/shells /bin/sh /bin/bash /usr/bin/sh /usr/bin/bash [root@centos7 data]# -------- 等价于usermod -s --------- [root@centos7 data]# getent passwd user2 user2:x:1009:1010::/home/user2:/bin/bash [root@centos7 data]# usermod -s /sbin/nolgin user2 [root@centos7 data]# getent passwd user2 user2:x:1009:1010::/home/user2:/sbin/nolgin [root@centos7 data]# 组操作补充 附加组的操作 [root@centos7 data]# id user1 uid=1000(user1) gid=1000(user1) groups=1000(user1) [root@centos7 data]# usermod -G g11,g12 user1 usermod: group 'g11' does not exist usermod: group 'g12' does not exist [root@centos7 data]# groupadd g11 [root@centos7 data]# groupadd g12 [root@centos7 data]# usermod -G g11,g12 user1 [root@centos7 data]# id user1 uid=1000(user1) gid=1000(user1) groups=1000(user1),1013(g11),1014(g12) [root@centos7 data]# -------------删除附加组👇----------- [root@centos7 data]# usermod -G \"\" user1 [root@centos7 data]# id user1 uid=1000(user1) gid=1000(user1) groups=1000(user1) [root@centos7 data]# 查看组信息的其他方法 [root@centos7 data]# usermod -G g11,g12 user1 [root@centos7 data]# groups user1 user1 : user1 g11 g12 [root@centos7 data]# [root@centos7 data]# gpasswd --help Usage: gpasswd [option] GROUP Options: -a, --add USER add USER to GROUP -d, --delete USER remove USER from GROUP -h, --help display this help message and exit -Q, --root CHROOT_DIR directory to chroot into -r, --delete-password remove the GROUP's password -R, --restrict restrict access to GROUP to its members -M, --members USER,... set the list of members of GROUP -A, --administrators ADMIN,... set the list of administrators for GROUP Except for the -A and -M options, the options cannot be combined. [root@centos7 data]# gpasswd -a user1 root Adding user user1 to group root [root@centos7 data]# id user1 uid=1000(user1) gid=1000(user1) groups=1000(user1),0(root),1013(g11),1014(g12) [root@centos7 data]# 有时候发现直接图片更好看一些，要不还是放弃cli复制了，直接图片吧，补充关键字就好。 给组设置口令 某个普通用户要加入某个组，就用到了组密码 id user1 su - user1 touch file1 ll file1 希望创建的文件主组时g12，可修改user1的主组为g12， newgrp g12 user1 -------👆 上图的newgrp时临时有效的，exit后就退出来临时的主组了，👇见下图------ root一样可以 永久的修改就用usermod -g 一些操作排查踩坑记录 因为user3创建之前就有同名的家目录，所以带来一些问题：这也是su user3为什么显示-bash-4.2$ 的原因 查看附加组 [root@centos7 ~]# id ming uid=1001(ming) gid=1001(ming) groups=1001(ming) [root@centos7 ~]# [root@centos7 ~]# [root@centos7 ~]# groupmems --help Usage: groupmems [options] [action] Options: -g, --group groupname change groupname instead of the user's group (root only) -R, --root CHROOT_DIR directory to chroot into Actions: -a, --add username add username to the members of the group -d, --delete username remove username from the members of the group -h, --help display this help message and exit -p, --purge purge all members from the group -l, --list list the members of the group [root@centos7 ~]# groupmems -l -g ming [root@centos7 ~]# groupadd g1 [root@centos7 ~]# groupadd g2 [root@centos7 ~]# groupadd g3 [root@centos7 ~]# usermod -G ming g1,g2,g3 usermod: user 'g1,g2,g3' does not exist [root@centos7 ~]# usermod -G ming g1 g2 g3 [root@centos7 ~]# usermod -G g1,g2,g3 ming # 注意次序 [root@centos7 ~]# id ming uid=1001(ming) gid=1001(ming) groups=1001(ming),1015(g1),1016(g2),1017(g3) [root@centos7 ~]# groupmes -l -g ming -bash: groupmes: command not found [root@centos7 ~]# groupmems -l -g ming [root@centos7 ~]# groupmems -l -g g1 # 这是以某个组为线索看谁把它作为附加组了 ming [root@centos7 ~]# groupmems -l -g g2 ming [root@centos7 ~]# groupmems -l -g g3 ming [root@centos7 ~]# -----如果本身就是group的附加组，newgrp直接切成主组 无需密码-----👇---- [11:41:27 root@localhost ~]#usermod -G g12 user1 [11:41:43 root@localhost ~]#id user1 uid=1008(user1) gid=1009(user1) groups=1009(user1),1013(g12) [11:41:47 root@localhost ~]#id uid=0(root) gid=0(root) groups=0(root) context=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 [11:41:48 root@localhost ~]#su - user1 Last login: Mon Jan 17 20:48:42 CST 2022 on pts/0 [11:41:55 user1@localhost ~]$id uid=1008(user1) gid=1009(user1) groups=1009(user1),1013(g12) context=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 [11:42:01 user1@localhost ~]$id user1 uid=1008(user1) gid=1009(user1) groups=1009(user1),1013(g12) [11:42:03 user1@localhost ~]$newgrp g12 [11:42:09 user1@localhost ~]$id uid=1008(user1) gid=1013(g12) groups=1013(g12),1009(user1) context=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 [11:42:10 user1@localhost ~]$exit exit [11:42:25 user1@localhost ~]$exit logout [11:42:29 root@localhost ~]#groupmems -l -g g12 user1 [11:42:35 root@localhost ~]# 删除附加组成员 [11:42:29 root@localhost ~]#groupmems -l -g g12 user1 [11:45:06 root@localhost ~]#groupmems -l -g g12 user1 [11:45:08 root@localhost ~]#id user1 uid=1008(user1) gid=1009(user1) groups=1009(user1),1013(g12) [11:45:24 root@localhost ~]#groupmems -d user1 -g g12 [11:45:30 root@localhost ~]#id user1 uid=1008(user1) gid=1009(user1) groups=1009(user1) [11:45:32 root@localhost ~]# 这个只是附加组里的成员 [11:47:07 root@localhost ~]#groupmems -d user1 -g user1 groupmems: user 'user1' is not a member of 'user1' [11:47:12 root@localhost ~]#id user1 uid=1008(user1) gid=1009(user1) groups=1009(user1) 其实usermod就挺好，方法有点多，哈哈 [11:49:06 root@localhost ~]#id user1 uid=1008(user1) gid=1009(user1) groups=1009(user1),1014(g13) [11:49:08 root@localhost ~]#usermod -G g12,g13 user1 [11:49:19 root@localhost ~]#id user1 uid=1008(user1) gid=1009(user1) groups=1009(user1),1013(g12),1014(g13) [11:49:21 root@localhost ~]#usermod -G g12 user1 [11:49:46 root@localhost ~]#id user1 uid=1008(user1) gid=1009(user1) groups=1009(user1),1013(g12) [11:49:48 root@localhost ~]# 清空组中所有成员 工具各有所长 [11:51:22 root@localhost ~]#id user1 uid=1008(user1) gid=1009(user1) groups=1009(user1),1013(g12) [11:51:24 root@localhost ~]#usermod -G g12 user2 [11:51:44 root@localhost ~]#usermod -G g12 user3 [11:51:46 root@localhost ~]#id user1 uid=1008(user1) gid=1009(user1) groups=1009(user1),1013(g12) [11:51:48 root@localhost ~]#id user2 uid=1009(user2) gid=1010(user2) groups=1010(user2),1013(g12) [11:51:48 root@localhost ~]#id user3 uid=1010(user3) gid=1011(user3) groups=1011(user3),1013(g12) [11:51:49 root@localhost ~]# [11:51:49 root@localhost ~]#groupmems -l -g g12 user1 user2 user3 [11:51:57 root@localhost ~]# 情况附加组成员就用groupmems [11:51:49 root@localhost ~]#groupmems -l -g g12 user1 user2 user3 [11:51:57 root@localhost ~]# [11:52:28 root@localhost ~]#groupmems -p -g g12 [11:52:53 root@localhost ~]#groupmems -l -g g12 [11:52:56 root@localhost ~]#id user1 uid=1008(user1) gid=1009(user1) groups=1009(user1) [11:52:59 root@localhost ~]#id user2 uid=1009(user2) gid=1010(user2) groups=1010(user2) [11:53:02 root@localhost ~]#id user3 uid=1010(user3) gid=1011(user3) groups=1011(user3) [11:53:02 root@localhost ~]# 不知道主组成员能不能清 [11:53:55 root@localhost ~]#usermod -g g12 user1 [11:54:03 root@localhost ~]#id user1 uid=1008(user1) gid=1013(g12) groups=1013(g12) [11:54:05 root@localhost ~]#groupmems -l -g g12 [11:54:18 root@localhost ~]#groupmems -p -g g12 [11:54:35 root@localhost ~]#groupmems -l -g g12 [11:54:35 root@localhost ~]# --------👆肯定不能了，主组是不归groupmems管的----------- useradd\\usermod\\userdel基本上这些事都能做， groupmems这个命令有问题啊 [root@centos7 ~]# id user1 uid=1000(user1) gid=1000(user1) groups=1000(user1),1014(g12) [root@centos7 ~]# whatis groupmems groupmems (8) - administer members of a user's primary group [root@centos7 ~]# groupmems -l -g user1 [root@centos7 ~]# groupmems -l -g g12 user1 [root@centos7 ~]# ---------毛的primary group，它就是个附加组管理工具------------👆------------ 练习 创建用户cacti，附加组为bin和root，默认shell为/bin/csh，注释信息为\"i am a cacti\" useradd -s /bin/csh -G bin,root -c \"i am a cacti\" cacti [root@centos7 ~]# useradd -s /bin/csh -G bin,root -c \"i am a cacti\" cacti [root@centos7 ~]# id cacti uid=1007(cacti) gid=1007(cacti) groups=1007(cacti),0(root),1(bin) [root@centos7 ~]# getent passwd cacti cacti:x:1007:1007:i am a cacti:/home/cacti:/bin/csh [root@centos7 ~]# finger cacti Login: cacti Name: i am a cacti Directory: /home/cacti Shell: /bin/csh Never logged in. No mail. No Plan. [root@centos7 ~]# 创建下面的用户、组和组成员关系， 名字为webs的组， 用户nginx，使用webs作为附加组 用户varnish，使用webs作为附加组 用户mysql，不可交互登入西路，且不是webs的成员 nginx,varnish,mysql密码都是cisco groupadd webs useradd -G webs nginx useradd -G webs varnish useradd -s /sbin/nologin mysql cat p.set nginx:cisco varnish:cisco mysql:cisco EOF cat p.set |chpasswd ---------------------------👇检查下，效果杠杠的----------------------- --------👆上面讲了用户和组，👇下面开始整理文件针对这些用户和组的权限------- QoS， diff serv （打标\\分类+后面的管制、限速、队列）也是这个道理，区别对待，上面的用户和组就是区别，下面针对这些人设置对应文件的访问就是对待。 文件权限 chown修改文件所属 [root@centos7 ~]# touch /data/f1 [root@centos7 ~]# su - user1 Last login: Mon Feb 7 12:33:30 CST 2022 on pts/0 [user1@centos7 ~]$ ll /data/f1 -rw-r--r--. 1 root root 0 Feb 7 12:33 /data/f1 [user1@centos7 ~]$ cat /data/f1 [user1@centos7 ~]$ echo 111 > /data/f1 -bash: /data/f1: Permission denied -------👆user1作为other没有f1的写权限----------- -------👇chown就可以修改文件的所有者和所属组，好像也用不到chgrp------- [user1@centos7 ~]$ [user1@centos7 ~]$ exit logout [root@centos7 ~]# chown user1 /data/f1 [root@centos7 ~]# ll /data/f1 -rw-r--r--. 1 user1 root 0 Feb 7 12:33 /data/f1 [root@centos7 ~]# chown :g12 /data/f1 [root@centos7 ~]# ll /data/f1 -rw-r--r--. 1 user1 g12 0 Feb 7 12:33 /data/f1 [root@centos7 ~]# ll /data/f1 -rw-r--r--. 1 user1 g12 0 Feb 7 12:33 /data/f1 [root@centos7 ~]# chown root:g13 /data/f1 chown: invalid group: ‘root:g13’ [root@centos7 ~]# chown root:g1 /data/f1 [root@centos7 ~]# ll /data/f1 -rw-r--r--. 1 root g1 0 Feb 7 12:33 /data/f1 [root@centos7 ~]# chown user1.g12 /data/f1 [root@centos7 ~]# ll /data/f1 -rw-r--r--. 1 user1 g12 0 Feb 7 12:33 /data/f1 --------👇chgrp就是文件属组---------- [root@centos7 ~]# chgrp g2 /data/f1 [root@centos7 ~]# ll /data/f1 -rw-r--r--. 1 user1 g2 0 Feb 7 12:33 /data/f1 [root@centos7 ~]# chmod修改文件权限 模式法： chmod who opt per file who: u,g,o,a opt: +,-,= per: r,w,x 去掉文件的所有者r权限：chmod u-r file [user1@centos7 ~]$ ll total 4 -rw-rw-r--. 1 user1 user1 0 Feb 6 20:23 file1 [user1@centos7 ~]$ chmod u-r file1 [user1@centos7 ~]$ ll total 4 --w-rw-r--. 1 user1 user1 0 Feb 6 20:23 file1 [user1@centos7 ~]$ ---------此时再看👇user1用户对file1的权限的情况----------- [user1@centos7 ~]$ cat file1 cat: file1: Permission denied [user1@centos7 ~]$ echo xx >> file1 [user1@centos7 ~]$ ll total 8 --w-rw-r--. 1 user1 user1 3 Feb 7 13:43 file1 -rwxrwxrwx. 1 root root 839 Jan 10 14:20 fstab [user1@centos7 ~]$ -----------可见👆权限是所属者适用就只看所属者了--------------- ---------------user>group>other-----3个权限只一个有效--------- [root@centos7 ~]# chmod u=-,g=r,o=rwx /data/f1 [root@centos7 ~]# ll /data/f1 ----r--rwx. 1 user1 g2 3 Feb 7 13:48 /data/f1 [root@centos7 ~]# su user1 [user1@centos7 root]$ cat /data/f1 cat: /data/f1: Permission denied [user1@centos7 root]$ echo xx > /data/f1 bash: /data/f1: Permission denied [user1@centos7 root]$ exit exit [root@centos7 ~]# su user2 [user2@centos7 root]$ cat /data/f1 11 [user2@centos7 root]$ echo xx > /data/f1 [user2@centos7 root]$ cat /data/f1 xx [user2@centos7 root]$ --------------user1的文件权限user1自然可以加回去-------👇--- [user1@centos7 root]$ ll /data/f1 ----r--rwx. 1 user1 g2 3 Feb 7 13:52 /data/f1 [user1@centos7 root]$ chmod u=rwx /data/f1 [user1@centos7 root]$ ll /data/f1 -rwxr--rwx. 1 user1 g2 3 Feb 7 13:52 /data/f1 [user1@centos7 root]$ cat /data/f1 xx [user1@centos7 root]$ echo yy >> /data/f1 [user1@centos7 root]$ cat /data/f1 xx yy [user1@centos7 root]$ ----------非文件拥有者自然不能修改该文件的属性👇------------- [root@centos7 ~]# su user2 [user2@centos7 root]$ ll /data/f1 -rwxr--rwx. 1 user1 g2 6 Feb 7 13:53 /data/f1 [user2@centos7 root]$ chmod u=rx /data/f1 chmod: changing permissions of ‘/data/f1’: Operation not permitted [user2@centos7 root]$ chmod g=- /data/f1 chmod: changing permissions of ‘/data/f1’: Operation not permitted [user2@centos7 root]$ [root@centos7 ~]# chmod a=rwx /data/f1 [root@centos7 ~]# ll /data/f1 -rwxrwxrwx. 1 user1 g2 6 Feb 7 13:53 /data/f1 [root@centos7 ~]# chmod a=- /data/f1 [root@centos7 ~]# ll /data/f1 ----------. 1 user1 g2 6 Feb 7 13:53 /data/f1 [root@centos7 ~]# chmod a=r /data/f1 [root@centos7 ~]# ll /data/f1 -r--r--r--. 1 user1 g2 6 Feb 7 13:53 /data/f1 [root@centos7 ~]# chmod a= /data/f1 [root@centos7 ~]# ll /data/f1 ----------. 1 user1 g2 6 Feb 7 13:53 /data/f1 [root@centos7 ~]# ------------谁都不行，root还行👇------root超脱🐟权限除了x执行权限----- [root@centos7 ~]# chown root.root /data/f1 [root@centos7 ~]# ll /data/f1 ----------. 1 root root 9 Feb 7 13:59 /data/f1 [root@centos7 ~]# cat /data/f1 xx yy zz [root@centos7 ~]# echo ee >> /data/f1 [root@centos7 ~]# cat /data/f1 xx yy zz ee [root@centos7 ~]# ---------👇--执行权限root要是没有的，也不行，root也就rw读写不受权限影响----- [root@centos7 ~]# ll /bin/cat -rwxr-xr-x. 1 root root 54080 Aug 20 2019 /bin/cat [root@centos7 ~]# [root@centos7 ~]# chow a-x /bin/cat -bash: chow: command not found [root@centos7 ~]# chmod a-x /bin/cat [root@centos7 ~]# ll /bin/cat -rw-r--r--. 1 root root 54080 Aug 20 2019 /bin/cat [root@centos7 ~]# cat /data/f1 -bash: /usr/bin/cat: Permission denied [root@centos7 ~]# /bin/cat /data/f1 -bash: /bin/cat: Permission denied [root@centos7 ~]# chmod +x /bin/cat # 这里等价于a+x [root@centos7 ~]# cat /data/f1 xx yy zz ee -------👇----root比较牛逼，只要u、g、o里一个角色有执行权限，那他就有权限了--------- [root@centos7 ~]# ll /bin/cat -rwxr-xr-x. 1 root root 54080 Aug 20 2019 /bin/cat [root@centos7 ~]# chmod u-x,g-x /bin/cat [root@centos7 ~]# ll /bin/cat -rw-r--r-x. 1 root root 54080 Aug 20 2019 /bin/cat [root@centos7 ~]# cat /data/f1 xx yy zz ee [root@centos7 ~]# 修改目录下所有文件和子目录的权限，这个R特别的坑和rm也差不多了 [root@centos7 ~]# ll /data/ total 8 -rw-r--r--. 1 root root 151 Feb 6 19:31 change_passwd.sh ----------. 1 root root 12 Feb 7 14:19 f1 -rw-r--r--. 1 root root 0 Feb 7 14:19 f10 -rw-r--r--. 1 root root 0 Feb 7 14:19 f11 -rw-r--r--. 1 root root 0 Feb 7 14:19 f12 -rw-r--r--. 1 root root 0 Feb 7 14:19 f13 -rw-r--r--. 1 root root 0 Feb 7 14:19 f14 -rw-r--r--. 1 root root 0 Feb 7 14:19 f15 -rw-r--r--. 1 root root 0 Feb 7 14:19 f16 -rw-r--r--. 1 root root 0 Feb 7 14:19 f17 -rw-r--r--. 1 root root 0 Feb 7 14:19 f18 -rw-r--r--. 1 root root 0 Feb 7 14:19 f19 -rw-r--r--. 1 root root 0 Feb 7 14:19 f2 -rw-r--r--. 1 root root 0 Feb 7 14:19 f20 -rw-r--r--. 1 root root 0 Feb 7 14:19 f3 -rw-r--r--. 1 root root 0 Feb 7 14:19 f4 -rw-r--r--. 1 root root 0 Feb 7 14:19 f5 -rw-r--r--. 1 root root 0 Feb 7 14:19 f6 -rw-r--r--. 1 root root 0 Feb 7 14:19 f7 -rw-r--r--. 1 root root 0 Feb 7 14:19 f8 -rw-r--r--. 1 root root 0 Feb 7 14:19 f9 [root@centos7 ~]# chmod a+x -R /data/ [root@centos7 ~]# ll /data/ -d drwxr-xr-x. 2 root root 241 Feb 7 14:19 /data/ [root@centos7 ~]# ll /data/ total 8 -rwxr-xr-x. 1 root root 151 Feb 6 19:31 change_passwd.sh ---x--x--x. 1 root root 12 Feb 7 14:19 f1 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f10 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f11 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f12 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f13 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f14 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f15 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f16 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f17 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f18 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f19 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f2 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f20 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f3 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f4 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f5 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f6 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f7 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f8 -rwxr-xr-x. 1 root root 0 Feb 7 14:19 f9 [root@centos7 ~]# [root@centos7 ~]# ll /data/ total 8 -rw-r--r--. 1 root root 151 Feb 6 19:31 change_passwd.sh ----------. 1 root root 12 Feb 7 14:19 f1 -rw-r--r--. 1 root root 0 Feb 7 14:19 f10 -rw-r--r--. 1 root root 0 Feb 7 14:19 f11 -rw-r--r--. 1 root root 0 Feb 7 14:19 f12 -rw-r--r--. 1 root root 0 Feb 7 14:19 f13 -rw-r--r--. 1 root root 0 Feb 7 14:19 f14 -rw-r--r--. 1 root root 0 Feb 7 14:19 f15 -rw-r--r--. 1 root root 0 Feb 7 14:19 f16 -rw-r--r--. 1 root root 0 Feb 7 14:19 f17 -rw-r--r--. 1 root root 0 Feb 7 14:19 f18 -rw-r--r--. 1 root root 0 Feb 7 14:19 f19 -rw-r--r--. 1 root root 0 Feb 7 14:19 f2 -rw-r--r--. 1 root root 0 Feb 7 14:19 f20 -rw-r--r--. 1 root root 0 Feb 7 14:19 f3 -rw-r--r--. 1 root root 0 Feb 7 14:19 f4 -rw-r--r--. 1 root root 0 Feb 7 14:19 f5 -rw-r--r--. 1 root root 0 Feb 7 14:19 f6 -rw-r--r--. 1 root root 0 Feb 7 14:19 f7 -rw-r--r--. 1 root root 0 Feb 7 14:19 f8 -rw-r--r--. 1 root root 0 Feb 7 14:19 f9 [root@centos7 ~]# chown -R user1 /data/ [root@centos7 ~]# ll /data/ total 8 -rw-r--r--. 1 user1 root 151 Feb 6 19:31 change_passwd.sh ----------. 1 user1 root 12 Feb 7 14:19 f1 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f10 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f11 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f12 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f13 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f14 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f15 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f16 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f17 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f18 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f19 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f2 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f20 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f3 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f4 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f5 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f6 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f7 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f8 -rw-r--r--. 1 user1 root 0 Feb 7 14:19 f9 [root@centos7 ~]# [root@centos7 ~]# ll /data/ -d drw-r--r--. 2 user1 root 241 Feb 7 14:19 /data/ -------坑在这里👇----- rm -rf / data #小手一抖，空格全没有 chmod -R a=rwx / data #小手再都，大妈食堂有 ------👆你把/根下所有的文件夹和子文件权限都弄了，更狠的来了👇---- chown -R user1 / data #/根下所有文件夹和文件所有者都变成了user1了 参考别的文件设置同样的用户和组，以及权限 [root@centos7 ~]# ll /etc/fstab -rw-r--r--. 1 root root 595 Jan 5 17:41 /etc/fstab [root@centos7 ~]# ll /data/f1 ----------. 1 user1 root 12 Feb 7 14:19 /data/f1 [root@centos7 ~]# chown --reference /etc/fstab /data/f1 [root@centos7 ~]# ll /data/f1 ----------. 1 root root 12 Feb 7 14:19 /data/f1 [root@centos7 ~]# chmod --reference /etc/fstab /data/f1 [root@centos7 ~]# ll /data/f1 -rw-r--r--. 1 root root 12 Feb 7 14:19 /data/f1 [root@centos7 ~]# Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"6-用户、用户组和权限/3-文件和特殊权限.html":{"url":"6-用户、用户组和权限/3-文件和特殊权限.html","title":"第3节 文件和特殊权限","keywords":"","body":"第3节. 文件和特殊权限 接上文，模式法 chmod who opt per file who: u,g,o,a opt: +,-,= per: r,w,x 数字法 rwxrw-r-- f1 111110100 👉 111 110 100 = 7 6 4 r 4 w 2 x 1 文件夹的权限 w：针对文件夹，就是创建、删除其中的文件。而修改文件涉及的是文件本身的写权限。 ----------👇--------------------------------- [user1@centos7 dir]$ ll ./ -d drwxr-xr-x. 2 root root 16 Feb 8 09:23 ./ # 文件夹dir的权限 [root@centos7 dir]# su user1 [user1@centos7 dir]$ ll total 0 -rw-r--rw-. 1 root root 0 Feb 8 09:23 f1 [user1@centos7 dir]$ touch 11 touch: cannot touch ‘11’: Permission denied [user1@centos7 dir]$ vi f1 [user1@centos7 dir]$ cat f1 111 [user1@centos7 dir]$ rm f1 rm: cannot remove ‘f1’: Permission denied [user1@centos7 dir]$ echo xxx > f1 [user1@centos7 dir]$ cat f1 xxx [user1@centos7 dir]$ r: 读权限针对文件夹就是看不到文件夹下面的内容，但是如果你知道某个文件的名称，是可以直接看该文件内容的。 [root@centos7 data]# chmod o-r dir/ [root@centos7 data]# ll total 0 drwxr-x--x. 2 root root 16 Feb 8 09:46 dir [root@centos7 data]# su user1 [user1@centos7 data]$ cat dir/f1 xx [user1@centos7 data]$ cd dir [user1@centos7 dir]$ ls ls: cannot open directory .: Permission denied [user1@centos7 dir]$ cat f1 xx [user1@centos7 dir]$ ll -d f1 -rw-r--r--. 1 root root 3 Feb 8 09:48 f1 [user1@centos7 dir]$ ll ls: cannot open directory .: Permission denied [user1@centos7 dir]$ x：执行权限针对文件夹就是进入咯，这个执行一旦取消，关系就大了，你连文件夹都进不去，那么文件夹下的文件就看不到 dir/f1 bash: dir/f1: Permission denied [user1@centos7 data]$ ll dir/ ls: cannot open directory dir/: Permission denied [user1@centos7 data]$ 👇-----给上面的dir补一个r读权限---- [root@centos7 data]# chmod o=r dir [root@centos7 data]# ll total 0 drwxr-xr--. 2 root root 16 Feb 8 09:46 dir [root@centos7 data]# ll dir/f1 -rw-r--rw-. 1 root root 3 Feb 8 09:48 dir/f1 [root@centos7 data]# [root@centos7 data]# su user1 [user1@centos7 data]$ ll dir ls: cannot access dir/f1: Permission denied total 0 -????????? ? ? ? ? ? f1 # 👈元数据看不到，文件名字倒是可以的 [user1@centos7 data]$ cd dir bash: cd: dir: Permission denied [user1@centos7 data]$ ll dir/f1 ls: cannot access dir/f1: Permission denied [user1@centos7 data]$ 文件夹来讲： 目录存放的数据块里的内容是各个文件名和其对应的节点信息 文件存放的数据块里的内容是文件的内容 读：可以列出该文件夹下的文件名，拿掉后，如果知道文件夹下的文件名，也能通过/dir/file去直接cat（这取决于文件本身的r权限）。 执行：可以进入目录，可以访问目录里的文件内容(依赖于文件本身的r权限)。 写：决定是否可以在目录里面创建和删除文件。文件本身的权限还得看文件自己的。 注意，w需要x加持~如果文件夹的执行权限取消，及时有写权限，由于进不到该目录下，所以也就没法去写文件的。 说下大X，后面再将st [root@centos7 data]# ll total 0 drwxr-xr--. 2 root root 16 Feb 8 09:46 dir -rw-r--r--. 1 root root 0 Feb 8 11:31 f1 -rw-r--r--. 1 root root 0 Feb 8 11:31 f2 [root@centos7 data]# chmod -R a+x /data [root@centos7 data]# ll /data total 0 drwxr-xr-x. 2 root root 16 Feb 8 09:46 dir -rwxr-xr-x. 1 root root 0 Feb 8 11:31 f1 -rwxr-xr-x. 1 root root 0 Feb 8 11:31 f2 [root@centos7 data]# ll /data -d drwxr-xr-x. 3 root root 37 Feb 8 11:31 /data ------👆通过-R可以使文件夹和其下所有文件的权限都递归改掉----- 但是如果遇到文件你给它一个x执行权限，往往存在安全风险---所以-R 配合大X就可以过滤文件的权限修改 👇 [root@centos7 data]# chmod -R a-x /data/ [root@centos7 data]# ll /data/ total 0 drw-r--r--. 2 root root 16 Feb 8 09:46 dir -rw-r--r--. 1 root root 0 Feb 8 11:31 f1 -rw-r--r--. 1 root root 0 Feb 8 11:31 f2 [root@centos7 data]# chmod -R a+X /data/ [root@centos7 data]# ll /data/ total 0 drwxr-xr-x. 2 root root 16 Feb 8 09:46 dir -rw-r--r--. 1 root root 0 Feb 8 11:31 f1 -rw-r--r--. 1 root root 0 Feb 8 11:31 f2 [root@centos7 data]# 练习： 误删了用户ming的家目录，进行恢复 三条命令 cp -r /etc/skel /home/ming chown -R ming.ming /home/ming chmod 700 /home/ming # 里面的几个隐藏文件都是从/etc/skel下复制过来的，属性不变就好。 ---误删除了用户ming家目录下的文件，但是目录还在，进行恢复👇 [root@centos7 ~]# rm -rf /home/ming/.* rm: refusing to remove ‘.’ or ‘..’ directory: skipping ‘/home/ming/.’ rm: refusing to remove ‘.’ or ‘..’ directory: skipping ‘/home/ming/..’ [root@centos7 ~]# ll -a /home/ming total 0 drwx------. 2 ming ming 6 Feb 8 13:43 . drwxr-xr-x. 16 root root 192 Feb 8 12:01 .. --👇注意，此时通过.*复制/etc/skel/下的所有文件--包含隐藏和非隐藏，会有大问题🐕-- [root@centos7 home]# cp -r /etc/skel/.* /home/ming cp: will not create hard link ‘/home/ming/skel’ to directory ‘/home/ming/.’ cp: overwrite ‘/home/ming/.bash_logout’? ^C [root@centos7 home]# ll /home/ming total 1036 -rw-r--r--. 1 root root 16 Feb 8 13:44 adjtime -rw-r--r--. 1 root root 1529 Feb 8 13:44 aliases -rw-r--r--. 1 root root 12288 Feb 8 13:44 aliases.db drwxr-xr-x. 2 root root 236 Feb 8 13:44 alternatives -rw-------. 1 root root 541 Feb 8 13:44 anacrontab -rw-r--r--. 1 root root 55 Feb 8 13:44 asound.conf drwxr-x---. 3 root root 43 Feb 8 13:44 audisp drwxr-x---. 3 root root 83 Feb 8 13:44 audit drwxr-xr-x. 2 root root 22 Feb 8 13:44 bash_completion.d -rw-r--r--. 1 root root 2853 Feb 8 13:44 bashrc drwxr-xr-x. 2 root root 6 Feb 8 13:44 binfmt.d -rw-r--r--. 1 root root 37 Feb 8 13:44 centos-release -rw-r--r--. 1 root root 51 Feb 8 13:44 centos-release-upstream drwxr-xr-x. 2 root root 6 Feb 8 13:44 chkconfig.d drwxr-xr-x. 2 root root 21 Feb 8 13:44 cron.d drwxr-xr-x. 2 root root 42 Feb 8 13:44 cron.daily -rw-------. 1 root root 0 Feb 8 13:44 cron.deny drwxr-xr-x. 2 root root 22 Feb 8 13:44 cron.hourly drwxr-xr-x. 2 root root 6 Feb 8 13:44 cron.monthly -rw-r--r--. 1 root root 451 Feb 8 13:44 crontab drwxr-xr-x. 2 root root 6 Feb 8 13:44 cron.weekly -rw-------. 1 root root 0 Feb 8 13:44 crypttab -rw-r--r--. 1 root root 1620 Feb 8 13:44 csh.cshrc -rw-r--r--. 1 root root 1103 Feb 8 13:44 csh.login 👆发现复制很N多文件过来了，原因是因为.*通配符它代表.xxx还有..xxx所以复制.*意味着你不仅仅复制了当前目录下的所有文件，也复制了上级目录下的所有文件。 推荐👇👉使用cp -r /etc/skel/. /home/ming这种方式复制所有文件含隐藏文件 drwx------. 2 root root 6 Feb 8 13:52 ming [root@centos7 home]# cp -r /etc/skel/. /home/ming [root@centos7 home]# ll -a ming total 12 drwx------. 2 root root 72 Feb 8 13:53 . drwxr-xr-x. 16 root root 192 Feb 8 13:52 .. -rw-r--r--. 1 root root 18 Feb 8 13:53 .bash_logout -rw-r--r--. 1 root root 193 Feb 8 13:53 .bash_profile -rw-r--r--. 1 root root 231 Feb 8 13:53 .bashrc -rw-r--r--. 1 root root 0 Feb 8 13:53 f1 [root@centos7 home]# ------👇这样也行，就是通过.[^.]*来表示所有隐藏文件，和*来表示所有非隐藏文件---- [root@centos7 home]# cp -r /etc/skel/.[^.]* /home/ming [root@centos7 home]# ll /home/ming -a total 12 drwx------. 2 root root 62 Feb 8 13:55 . drwxr-xr-x. 16 root root 192 Feb 8 13:52 .. -rw-r--r--. 1 root root 18 Feb 8 13:55 .bash_logout -rw-r--r--. 1 root root 193 Feb 8 13:55 .bash_profile -rw-r--r--. 1 root root 231 Feb 8 13:55 .bashrc [root@centos7 home]# cp -r /etc/skel/* /home/ming [root@centos7 home]# ll /home/ming -a total 12 drwx------. 2 root root 72 Feb 8 13:55 . drwxr-xr-x. 16 root root 192 Feb 8 13:52 .. -rw-r--r--. 1 root root 18 Feb 8 13:55 .bash_logout -rw-r--r--. 1 root root 193 Feb 8 13:55 .bash_profile -rw-r--r--. 1 root root 231 Feb 8 13:55 .bashrc -rw-r--r--. 1 root root 0 Feb 8 13:55 f1 [root@centos7 home]# mkdir创建文件夹的时候可以设置权限 [root@centos7 home]# mkdir --help Usage: mkdir [OPTION]... DIRECTORY... Create the DIRECTORY(ies), if they do not already exist. Mandatory arguments to long options are mandatory for short options too. -m, --mode=MODE set file mode (as in chmod), not a=rwx - umask -p, --parents no error if existing, make parent directories as needed -v, --verbose print a message for each created directory -Z set SELinux security context of each created directory to the default type --context[=CTX] like -Z, or if CTX is specified then set the SELinux or SMACK security context to CTX --help display this help and exit --version output version information and exit GNU coreutils online help: For complete documentation, run: info coreutils 'mkdir invocation' [root@centos7 home]# [root@centos7 ~]# mkdir -m 000 /home/sb001 [root@centos7 ~]# ll /home/sb001 -d d---------. 2 root root 6 Feb 8 14:00 /home/sb001 [root@centos7 ~]# 文件的特殊权限 /etc/shaow这个文件普通用户没有权限对其修改，但是可以通过passwd命令对其进行修改的，因为改自身密码本质上就是修改了shadow文件。 [root@centos7 ~]# ll /etc/shadow ----------. 1 root root 1366 Feb 8 14:06 /etc/shadow [root@centos7 ~]# su user1 [user1@centos7 root]$ cat /etc/shadow cat: /etc/shadow: Permission denied [user1@centos7 root]$ echo xx /etc/shadow xx /etc/shadow [user1@centos7 root]$ echo xx >> /etc/shadow bash: /etc/shadow: Permission denied [user1@centos7 root]$ passwd Changing password for user user1. Changing password for user1. (current) UNIX password: passwd: Authentication token manipulation error [user1@centos7 root]$ passwd Changing password for user user1. Changing password for user1. (current) UNIX password: New password: Retype new password: passwd: all authentication tokens updated successfully. [user1@centos7 root] 这是因为passwd命令-也就是这/bin/passwd这个执行文件用户属性位上有s位。 [user1@centos7 root]$ ll /bin/passwd suid当用户使用该程序/命令访问某个文件的时候，原则上是使用这个用户的权限去访问文件。 一旦有了suid，不管谁运行这个程序，通过这个程序访问文件，就是获得这个程序所有者的权限。上图只要你运行passwd，你的身份就转换为root了。suid全称就是set owner user id up to execution在执行时设置所有者用户ID。 第二点，suid一定是作用在二进制的可执行的文件上(对shell脚本无效)，否则没有意义了就。所以大S没有意义-去掉x后就是大S [root@centos7 ~]# ll /usr/bin/vi -rwsr-xr-x. 1 root root 928056 Oct 14 2020 /usr/bin/vi [root@centos7 ~]# su user su: user user does not exist [root@centos7 ~]# su user1 [user1@centos7 root]$ vi /etc/shadow # 此时就可以vi进去修改并保持了 [user1@centos7 root]$ echo xxx >> /etc/shadow # echo不行肯定的啊你suid的是vim啊 bash: /etc/shadow: Permission denied ----------这个，，，尝试将echo变成suid权限，发现还是不行，可能要该重定向文件咯呵呵---- [root@centos7 ~]# which echo /usr/bin/echo [root@centos7 ~]# ll /usr/bin/echo -rwxr-xr-x. 1 root root 33088 Aug 20 2019 /usr/bin/echo [root@centos7 ~]# chmod u+s /usr/bin/echo [root@centos7 ~]# ll /usr/bin/echo -rwsr-xr-x. 1 root root 33088 Aug 20 2019 /usr/bin/echo [root@centos7 ~]# su user1 [user1@centos7 root]$ echo xx >> /etc/shadow bash: /etc/shadow: Permission denied [user1@centos7 root]$ exit exit [root@centos7 ~]# which >> -bash: syntax error near unexpected token `newline' [root@centos7 ~]# 数字法修改suid： 4是单独算的 [root@centos7 ~]# ll /usr/bin/echo -rwsr-xr-x. 1 root root 33088 Aug 20 2019 /usr/bin/echo [root@centos7 ~]# chmod 755 /usr/bin/echo [root@centos7 ~]# ll /usr/bin/echo -rwxr-xr-x. 1 root root 33088 Aug 20 2019 /usr/bin/echo [root@centos7 ~]# chmod 4755 /usr/bin/echo [root@centos7 ~]# ll /usr/bin/echo -rwsr-xr-x. 1 root root 33088 Aug 20 2019 /usr/bin/echo [root@centos7 ~]# sgid 1、如果某个用户运行cat程序也即是使用cat去访问文件，就会继承所属组的权限。或者说就会将用户原本的所属组提升至该程序的所属组。 同样数字法 755前面补一个2，sgid 755前面补一个4，sguid 755前面补一个6，suid+sgid 粘滞位 针对文件夹的属性 非用户本人，无法删除文件夹下的文件 粘滞位对文件不生效 [root@centos7 dir]# su user1 [user1@centos7 dir]$ ll total 0 -rw-r--r--. 1 root root 0 Feb 8 16:19 f1 -rw-rw-r-T. 1 user1 user1 0 Feb 8 16:22 f2 [user1@centos7 dir]$ rm -rf f2 [user1@centos7 dir]$ ll total 0 -rw-r--r--. 1 root root 0 Feb 8 16:19 f1 [user1@centos7 dir]$ 总结 suid： ​ 作用于可执行的二进制的程序，权限4，功能：用户执行此程序时，将继承此程序所有者的权限。 sguid： ​ 作用于可执行的二进制的程序，权限2，功能：用户执行此程序时，将集成此程序所属组的权限。 ​ 作用于目录，权限2，功能，新建的文件，将自动集成该目录的所属组。 sticky： ​ 作用于目录，权限1，功能：只能删除自己的文件，root不受限。 创建一个目录可以让有限的几个用户使用 [16:49:55 root@localhost data]#mkdir -m 770 testdir [16:50:10 root@localhost data]#ll total 1 drwxrwx---. 2 root root 6 Jan 19 16:50 testdir [16:52:38 root@localhost data]#chown .grp001 testdir [16:52:50 root@localhost data]#ll total 1 drwxrwx---. 2 root grp001 6 Jan 19 16:50 testdir [16:53:01 root@localhost data]#usermod -G grp001 user1 [16:54:31 root@localhost data]#usermod -G grp001 user2 [16:55:01 root@localhost data]#groupmems -l -g grp001 user1 user2 [16:55:14 root@localhost data]#su user1 [16:55:19 user1@localhost data]$cd testdir/ [16:55:28 user1@localhost testdir]$touch f1 [16:55:30 user1@localhost testdir]$echo 11 >> f1 [16:55:34 user1@localhost testdir]$exit exit [16:55:36 root@localhost data]#su user2 [16:55:43 user2@localhost data]$cd testdir/ [16:55:54 user2@localhost testdir]$echo xx >> f2 [16:56:06 user2@localhost testdir]$cat f2 xx 貌似centos7.9和7.6这里有个不一样的点👇 就是user1可以修改user2创建的文件，如果时之前的观点，就会再设置文件夹的sguid来使目录下的文件创建的时候自动集成父目录的所属组。 当然最好还是设置一下文件夹的sgid [root@centos7 data]# chmod g+s renyue/ [root@centos7 data]# ll total 0 drwxrws---. 2 root renyue-group 26 Feb 8 17:12 renyue [root@centos7 data]# [root@centos7 data]# su client1 [client1@centos7 data]$ ll total 0 drwxrws---. 2 root renyue-group 26 Feb 8 17:12 renyue [client1@centos7 data]$ cd renyue/ [client1@centos7 renyue]$ touch f3 [client1@centos7 renyue]$ ll total 4 -rw-rw-r--. 1 client1 client1 2 Feb 8 17:12 f1 -rw-rw-r--. 1 client2 client2 0 Feb 8 17:12 f2 -rw-rw-r--. 1 client1 renyue-group 0 Feb 8 17:35 f3 [client1@centos7 renyue]$ cp /etc/fstab /data/dir/ 普通需要什么权限？ cp 命令的执行权限 /etc文件夹的执行 fstab文件的读 /data文件夹的执行 /dir文件夹得执行和写 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"6-用户、用户组和权限/4-umask权限.html":{"url":"6-用户、用户组和权限/4-umask权限.html","title":"第4节 umask权限","keywords":"","body":"第4节. umask权限 chattr i :文件不会被修改、删除、包含所在目录也不能被删除。 [19:40:28 root@localhost data]#chattr +i f1 [19:40:37 root@localhost data]#ll total 0 -rw-r--r--. 1 root root 0 Jan 19 19:40 f1 [19:40:38 root@localhost data]#lsattr f1 ----i--------------- f1 [19:41:22 root@localhost data]#rm -rf f1 rm: cannot remove 'f1': Operation not permitted [19:41:29 root@localhost data]#echo xx > f1 -bash: f1: Operation not permitted [19:41:32 root@localhost data]#mv f1 f2 mv: cannot move 'f1' to 'f2': Operation not permitted [19:41:36 root@localhost data]#cd .. [19:41:38 root@localhost /]#rm -rf /data/ rm: cannot remove '/data/f1': Operation not permitted [19:41:44 root@localhost /]# a:文件仅可以添加，同样所在目录不能被删除 [19:45:29 root@localhost data]#chattr +a f1 [19:45:36 root@localhost data]#lsattr f1 ----ia-------------- f1 [19:45:39 root@localhost data]#echo xx > f1 -bash: f1: Operation not permitted [19:45:45 root@localhost data]#echo xx >> f1 -bash: f1: Operation not permitted [19:45:48 root@localhost data]#chattr -i f1 [19:46:05 root@localhost data]#lsattr f1 -----a-------------- f1 [19:46:09 root@localhost data]#echo xx > f1 -bash: f1: Operation not permitted [19:46:13 root@localhost data]#echo xx >> f1 [19:46:16 root@localhost data]#cat f1 xx [19:46:19 root@localhost data]#rm -rf f1 rm: cannot remove 'f1': Operation not permitted [19:46:22 root@localhost data]#exit logout [19:46:54 root@localhost /]#rm -rf /data/ rm: cannot remove '/data/f1': Operation not permitted ---但是👇vi进去后在最后一行添加这种操作，系统判定不出来你是不是追加所以这种追加时不行的。 umask 1、root用户新建文件和文件夹可发现默认的权限分别时644和755 [19:57:42 root@localhost data]#ll total 0 drwxr-xr-x. 2 root root 6 Jan 19 19:57 dir -rw-r--r--. 1 root root 0 Jan 19 19:57 f1 [19:57:42 root@localhost data]# 2、换普通用户创建文件和文件夹权限就不一样 [putong@centos7 data]$ ll |grep putong drwxrwxr-x. 2 putong putong 6 Feb 8 20:02 dir2 -rw-rw-r--. 1 putong putong 0 Feb 8 20:02 f2 [putong@centos7 data]$ [putong@centos7 data]$ type umask umask is a shell builtin [putong@centos7 data]$ umask 0002 [putong@centos7 data]$ exit exit [root@centos7 data]# umask 0022 [root@centos7 data]# umask+default_value=777目录|666文件 000+default=777，假设文件也用777总和，会导致文件可能就带上了x执行权限，带来一定的风险。 022+default=777|666，文件夹default=755，文件default=644 👆上面的公式不正确 umask，mask时掩码，user的mask就是用户的掩码的意思。 umask ugo 也分user group other umask的功能，将777或者666中对应的权限去掉，得出默认权限。 777 022 ↓转成二进制,0锁死，1放开，就是通配符或者反掩码的算法. 111 111 111 000 010 010 ------------ 111 101 101 = 755 这就是文件夹创建默认权限 666 022 110 110 110 000 010 010 ------------ 110 100 100 = 644 这就是文件创建默认权限 ----👇修改umask值再来看，发现777|666-umask就不准确了---- [root@centos7 data]# umask 123 [root@centos7 data]# touch f1 [root@centos7 data]# mkdir dir [root@centos7 data]# ll total 0 drw-r-xr--. 2 root root 6 Feb 8 20:18 dir -rw-r--r--. 1 root root 0 Feb 8 20:18 f1 [root@centos7 data]# ------- 分析： 777 123 111 111 111 001 010 011 -------------- 110 101 100 => 掩出来的文件夹默认值为：654，这个确实就是777-123=654 如果是文件 666 123 110 110 110 001 010 011 -------------- 110 100 100 => 得到：644，这个就不是666-123=543，使用奇数+1的规律=644，所以速算法就是 543里面带上了执行权限了，肯定不可能的。 👇 如果是文件夹777-umask=default 如果是文件666-umask=default(3个数，如果是奇数就+1，偶数不变) umask退出后丢失，可以写到.bashrc或者/etc/bashrc里，这里也有个点就是几个文件里配置环境变量等，谁优先的原则，涉及文件有/etc/profile bashrc等，这个后面讲。 [root@centos7 ~]# cat /etc/bashrc | tail -3 fi # vim:ts=4:sw=4 umask 123 [root@centos7 ~]# [root@centos7 ~]# umask 0022 [root@centos7 ~]# umask -p umask 0022 [root@centos7 ~]# umask -p >> .bashrc # 将当前umaks值写入配置文件里 [root@centos7 ~]# tail -1 .bashrc umask 0022 [root@centos7 ~]# FACL 解决一些特殊需求，普通权限解决不了，比如 user1不能访问f1，user2能对f1完全控制，user3只能读f1，user4只能写f1 此时ugo三个角色，user、group、other，用户权限超过3个，就需要ACL了。 setfacl -m u:user1:0 f1 setfacl -m u:user1:- f1 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"6-用户、用户组和权限/5-FACL实现权限的灵活控制.html":{"url":"6-用户、用户组和权限/5-FACL实现权限的灵活控制.html","title":"第5节 FACL实现权限的灵活控制","keywords":"","body":"第5节. FACL实现权限的灵活控制 解决一些特殊需求，普通权限解决不了，比如 user1不能访问f1，user2能对f1完全控制，user3只能写f1，user4只能读f1 此时ugo三个角色，user、group、other，用户权限超过3个，就需要ACL了。 setfacl -m u:user1:0 f1 👈表示啥权限都没有 setfacl -m u:user1:- f1 👈表示啥权限都没有，等价于0 👉user1不能访问f1 [10:03:19 root@localhost data]#ll f1 -rw-r--r--+ 1 root root 4 Jan 29 10:03 f1 [10:04:59 root@localhost data]#su user2 -c \"cat f1\"👈切换用户输入cli后直接退出来 123 [10:05:00 root@localhost data]#su user1 -c \"cat f1\" cat: f1: Permission denied 👉user2完全控制f1 [10:20:21 root@localhost data]#su user2 -c 'cat f1' 123 [10:20:39 root@localhost data]#su user2 -c 'echo 123 > f1' bash: f1: Permission denied [10:20:43 root@localhost data]#setfacl -m u:user2:rw f1 [10:20:59 root@localhost data]#su user2 -c 'echo 321 > f1' [10:21:05 root@localhost data]#su user2 -c 'cat f1' 321 [10:21:11 root@localhost data]# 👉user3只能写f1 [10:24:33 root@localhost data]#setfacl -m u:user3:w f1 [10:25:44 root@localhost data]#su user3 -c 'cat f1' cat: f1: Permission denied [10:25:52 root@localhost data]#su user3 -c 'echo aaa >> f1' [10:26:01 root@localhost data]#su user3 -c 'cat f1' cat: f1: Permission denied [10:26:03 root@localhost data]#cat f1 321 aaa [10:26:15 root@localhost data]# 👉user4只能读f1,就归到other整体权限去，无需修改 👉查看facl [10:26:15 root@localhost data]#getfacl f1 # file: f1 # owner: root # group: root user::rw- user:user1:--- user:user2:rw- user:user3:-w- group::r-- mask::rw- other::r-- 针对group设置facl [10:28:34 root@localhost data]#setfacl -m g:g1:rw f1 [10:36:27 root@localhost data]#getfacl f1 # file: f1 # owner: root # group: root user::rw- user:user1:--- user:user2:rw- user:user3:-w- group::r-- group:g1:rw- 👈g1有了rw mask::rw- other::r-- [10:38:33 root@localhost data]#su user5 -c \"echo 123 > f1\" bash: f1: Permission denied [10:38:37 root@localhost data]#usermod -G g1 user5 👈user5加入g1扩展组 [10:39:09 root@localhost data]#id user5 uid=1012(user5) gid=1016(user5) groups=1016(user5),1001(g1) [10:39:11 root@localhost data]# [10:39:15 root@localhost data]#su user5 -c \"echo aaa > f1\" [10:39:28 root@localhost data]#cat f1 aaa 针对user1 同时设置facl的user和group权限，user优先。 [11:03:16 root@localhost data]#setfacl -m u:user1:- f1 [11:03:37 root@localhost data]#su user1 -c 'cat f1' cat: f1: Permission denied [11:03:46 root@localhost data]#su user1 -c 'echo 123 > f1' bash: f1: Permission denied [11:03:49 root@localhost data]#getfacl f1 # file: f1 # owner: root # group: root user::rw- user:user1:--- user:user2:rw- user:user3:-w- group::r-- group:g1:rw- mask::rw- other::r-- [11:03:55 root@localhost data]#id user1 uid=1008(user1) gid=1013(g12) groups=1013(g12),1015(grp001) [11:03:59 root@localhost data]#usermod -G g1 user1 [11:04:08 root@localhost data]#id user1 uid=1008(user1) gid=1013(g12) groups=1013(g12),1001(g1) [11:04:46 root@localhost data]#su user1 -c 'echo 123 > f1' bash: f1: Permission denied [11:05:06 root@localhost data]#su user1 -c 'cat f1' cat: f1: Permission denied 所有文件的权限判定规则：从上往下优先，先中先得 1、先看所有者 2、看针对user的FACL 3、看所属组 4、看针对group的FACL 5、看other 交换机的acl 、linux 路由表 ip roue show (metric小的自动放到上面) ，都是从上到下匹配的， ssg 的policy 也是从上到下匹配，linux的shell脚本、python的主程序都是从上到下，所以此乃天地法则🤮 👇判断所有者优于facl的user [11:12:11 root@localhost data]#getfacl f1 # file: f1 # owner: root # group: root user::rw- user:user1:--- user:user2:rw- user:user3:-w- group::r-- group:g1:rw- mask::rw- other::r-- [11:12:18 root@localhost data]#ll f1 -rw-rw-r--+ 1 root root 7 Jan 29 10:53 f1 [11:12:21 root@localhost data]#chown user1 f1 [11:12:35 root@localhost data]#ll f1 -rw-rw-r--+ 1 user1 root 7 Jan 29 10:53 f1 [11:12:36 root@localhost data]#su user1 -c 'cat f1' aaa bb [11:15:58 root@localhost data]#getfacl f1 # file: f1 # owner: root # group: root user::rw- user:user2:rw- user:user3:-w- group::r-- group:g1:rw- mask::rw- other::r-- 👇判断facl的group 优先于本来的group，这里错啦，group没命令中，自然不起作用啦 [11:16:01 root@localhost data]#su user1 -c 'catf1' bash: catf1: command not found [11:16:10 root@localhost data]#su user1 -c 'echo aa > f1' [11:16:16 root@localhost data]#su user1 -c 'cat f1' aa [11:16:21 root@localhost data]#setfacl -x g:g1 f1 [11:16:48 root@localhost data]#su user1 -c 'cat f1' aa [11:16:54 root@localhost data]#su user1 -c 'echo 11 >> f1' bash: f1: Permission denied [11:16:59 root@localhost data]#getfacl f1 # file: f1 # owner: root # group: root user::rw- user:user2:rw- user:user3:-w- group::r-- mask::rw- other::r-- [11:17:04 root@localhost data]# 删除facl两种方法 -x删一个 -b全删 -R -b dir 递归删除文件夹下所有的acl，据说相当有用 [11:19:58 root@localhost data]#getfacl f1 # file: f1 # owner: root # group: root user::rw- user:user1:--- user:user2:rw- user:user3:-w- group::r-- group:g1:rw- mask::rw- other::r-- [11:28:31 root@localhost data]#setfacl -x u:user1 f1 [11:28:41 root@localhost data]#setfacl -x g:g1 f1 [11:28:46 root@localhost data]#getfacl f1 # file: f1 # owner: root # group: root user::rw- user:user2:rw- user:user3:-w- group::r-- mask::rw- other::r-- [11:28:48 root@localhost data]#setfacl -b f1 [11:28:54 root@localhost data]#getfacl f1 # file: f1 # owner: root # group: root user::rw- group::r-- other::r-- [11:28:57 root@localhost data]# 经典案例 我们复制文件夹的时候总担心权限、所有者、所属组这些信息的丢失，cp -a 可以提供思路 我们修改文件夹的权限比如chmod -R 777 dir/ , 带来的问题是，以后想要回收权限，没有办法了，这个时候facl就提供了很好的思路。 [11:40:55 root@localhost ~]#setfacl -R -m u:user1:r data/ [11:41:02 root@localhost ~]#ll total 12 -rw-r--r--. 1 root root 3 Jan 12 16:53 1 -rw-------. 1 root root 1031 Jan 5 16:52 anaconda-ks.cfg drwxrwxrwx+ 4 root root 61 Jan 29 10:59 data -rw-r--r--. 1 root root 0 Jan 12 16:53 f1 -rw-r--r--. 1 root root 0 Jan 12 16:53 f2 -rw-r--r--. 1 root root 4 Jan 12 17:51 hello.txt [11:41:03 root@localhost ~]#cd data/ [11:41:04 root@localhost data]#ll total 8 drwxr-xr-x+ 2 root root 6 Jan 19 19:57 dir drwxr-xr-x+ 2 user1 g12 6 Jan 19 19:58 dir2 -rw-r--r--+ 1 root root 3 Jan 29 11:16 f1 -rw-r--r--+ 1 user1 g12 0 Jan 19 19:58 f2 -rw-r--r--+ 1 root root 65 Jan 29 10:59 test [11:41:05 root@localhost data]#getfacl f2 # file: f2 # owner: user1 # group: g12 user::rw- user:user1:r-- group::r-- mask::r-- other::r-- [11:41:31 root@localhost ~]#getfacl data # file: data # owner: root # group: root user::rwx user:user1:r-- group::rwx mask::rwx other::rwx [11:41:56 root@localhost ~]#setfacl -R -b data/ [11:42:08 root@localhost ~]# [11:42:09 root@localhost ~]#ll total 12 -rw-r--r--. 1 root root 3 Jan 12 16:53 1 -rw-------. 1 root root 1031 Jan 5 16:52 anaconda-ks.cfg drwxrwxrwx. 4 root root 61 Jan 29 10:59 data -rw-r--r--. 1 root root 0 Jan 12 16:53 f1 -rw-r--r--. 1 root root 0 Jan 12 16:53 f2 -rw-r--r--. 1 root root 4 Jan 12 17:51 hello.txt [11:42:11 root@localhost ~]#ll data/ total 8 drwxr-xr-x. 2 root root 6 Jan 19 19:57 dir drwxr-xr-x. 2 user1 g12 6 Jan 19 19:58 dir2 -rw-r--r--. 1 root root 3 Jan 29 11:16 f1 -rw-r--r--. 1 user1 g12 0 Jan 19 19:58 f2 -rw-r--r--. 1 root root 65 Jan 29 10:59 test [11:42:19 root@localhost ~]# 其他用法参考setfacl -h 比如 setfacl -m d:u:ming:rx dir👈意思是dir文件夹下创建的文件默认就带针对ming的rx权限，d设置的默认权限，删除用setfac -k dir来删 setfacl -X file.acl dir👈意思是file.acl里写好g:sales:rw这些facl的明细，这个比较好的。 setfacl -m u:user1:rwX dir👈X是只是针对文件夹设置，不过我用x一i杨的效果。要么是rocky-linux自带的，要吗是版本高的好处，不管。 getfacl file1 | setfacl --set-file=- file2👈参考chmod里的--reference一个效果，就是将f2的权限设置成f1一样的。 FACL里的mask mask就是设置一个最高权限，谁都不能超过 ll可见group的rwx3位现在用来填充mask的值了。 mask默认设置了facl后位rwx，手动修改后getfacl 可见#effective:rw-这种 mask只影响单个人，所有者和other不受影响 [11:59:54 root@localhost data]#getfacl f1 # file: f1 # owner: root # group: root user::rw- group::r-- other::r-- [11:59:57 root@localhost data]#ll total 8 drwxr-xr-x. 2 root root 6 Jan 19 19:57 dir drwxr-xr-x. 2 user1 g12 6 Jan 19 19:58 dir2 -rw-r--r--. 1 root root 3 Jan 29 11:16 f1 -rw-r--r--. 1 user1 g12 0 Jan 19 19:58 f2 -rw-r--r--. 1 root root 65 Jan 29 10:59 test [12:00:03 root@localhost data]#setfacl -m u:user1:rw f1 [12:00:25 root@localhost data]#ll f1 -rw-rw-r--+ 1 root root 3 Jan 29 11:16 f1 [12:00:27 root@localhost data]#setfacl -m u:user2:rwx f1 [12:00:42 root@localhost data]#ll total 8 drwxr-xr-x. 2 root root 6 Jan 19 19:57 dir drwxr-xr-x. 2 user1 g12 6 Jan 19 19:58 dir2 -rw-rwxr--+ 1 root root 3 Jan 29 11:16 f1 -rw-r--r--. 1 user1 g12 0 Jan 19 19:58 f2 -rw-r--r--. 1 root root 65 Jan 29 10:59 test [12:00:44 root@localhost data]#getfacl f1 # file: f1 # owner: root # group: root user::rw- user:user1:rw- user:user2:rwx group::r-- mask::rwx 👈mask默认值 other::r-- [12:00:57 root@localhost data]#setfacl -m mask::r f1 [12:01:14 root@localhost data]#ll total 8 drwxr-xr-x. 2 root root 6 Jan 19 19:57 dir drwxr-xr-x. 2 user1 g12 6 Jan 19 19:58 dir2 -rw-r--r--+ 1 root root 3 Jan 29 11:16 f1 👈修改mask后group位的3位用来表示mask的3位 -rw-r--r--. 1 user1 g12 0 Jan 19 19:58 f2 -rw-r--r--. 1 root root 65 Jan 29 10:59 test [12:01:15 root@localhost data]#getfacl f1 # file: f1 # owner: root # group: root user::rw- user:user1:rw- #effective:r-- 👈注意mask影响了单个用户的权限上限 user:user2:rwx #effective:r-- group::r-- mask::r-- other::r-- [12:01:20 root@localhost data]# facl的备份 怎么备份和还原 getfacl -R /tmp/dir1 > acl.txt 👈备份到acl.txt setfacl -R -b /tmp/dir1 👈清空下，Centos8 -b一旦用了，组权限清空为---，8的BUG,centos7亲测没问题，放心用，读我这篇的你自己测你的版本啊。 setfacl -R --set-file=acl.txt /tmp/dir1 👈恢复方法1 setfacl --restore acl.txt 👈恢复方法2 getfacl -R /tmp/dir1 👈递归，也就是包含dir1及其下所有文件的facl cp -p 或-a就能备份facl，还有所有者权限等 mv 也支持facl这些的保留 tar不行，tar备份的时候facl就丢了 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-11-30 19:45:46 "},"7-文本三剑客1_grep和正则表达式/7-文本三剑客1_grep和正则表达式.html":{"url":"7-文本三剑客1_grep和正则表达式/7-文本三剑客1_grep和正则表达式.html","title":"第七章 文本三剑客1_grep和正则表达式","keywords":"","body":"第七章 文本三剑客1_grep和正则表达式 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:01 "},"7-文本三剑客1_grep和正则表达式/1-常见文本处理工具.html":{"url":"7-文本三剑客1_grep和正则表达式/1-常见文本处理工具.html","title":"第1节 常见文本处理工具","keywords":"","body":"第1节. 常见文本处理工具 cat查看行结束符/行尾 cat -A查看回车、换行、TAB建 👆cat 空行不算行号 cat 压缩连续空行 倒着看tac和rev nl等价于cat -b 文本截取前后 head默认前10行 tail默认后10行 head一行内取前3个字节，密码生成方法2 前面有openssl还有一种，这里就是3中随机数的生成方法了。好像就一个靠谱，其他缺胳膊少腿的。 tail -f和-F跟踪是不同的，删除文件的效果 文件描述符时连接着inode的，删除文件后重新创建同名，其实inode变了。 文件名就是简单的只看名称了 当然文件描述符本身和inode也不是等价的 只要文件名恢复了，tail -F又继续跟踪了 只是理解一下各个用法，不一定这么用 这就是一个取某个网卡IP地址的固定语法咯，可以做成别名来用。 cut列截取 多个空格的压缩成1个边缘cut基于空格 进一步 [16:14:14 root@localhost ~]#df Filesystem 1K-blocks Used Available Use% Mounted on devtmpfs 897812 0 897812 0% /dev tmpfs 916616 0 916616 0% /dev/shm tmpfs 916616 8868 907748 1% /run tmpfs 916616 0 916616 0% /sys/fs/cgroup /dev/mapper/rl-root 17811456 2153364 15658092 13% / /dev/sda1 1038336 198012 840324 20% /boot tmpfs 183320 0 183320 0% /run/user/0 [16:14:16 root@localhost ~]# [16:14:17 root@localhost ~]#df |cut -c48-51 Use 0 0 1 0 13 20 0 [16:14:18 root@localhost ~]#df |cut -c48-51|tr -dc '[0-9\\n] ' 0 0 1 0 13 20 0 [16:14:50 root@localhost ~]#df |cut -c48-51|tr -dc '[0-9\\n]' 0 0 1 0 13 20 0 [16:14:55 root@localhost ~]# 👆这可以作为观察服务器的登入信息 👇看网站访问信息 linux的词汇量？ 起密码的时候，说明你这是一个单词不让你起，凭的就是这个words里的单词了吧 文件内容纵向合并 文件内容横向合并 两个文件的内容合并到一行 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:01 "},"7-文本三剑客1_grep和正则表达式/2-文本三剑客1_grep和正则.html":{"url":"7-文本三剑客1_grep和正则表达式/2-文本三剑客1_grep和正则.html","title":"第2节 文本三剑客1_grep和正则","keywords":"","body":"第2节. 文本三剑客1_grep和正则 wc统计 显示最长一行的长度（单位字符？5个字符） sort排序 排名部分先后，可以用R 对第3列当作数字进行排序 对IP地址排序， 这个还是要用lambda去排的，比如接口和IP这种g1/0/1,192.16.10.1分段去比较的，这里仅仅是整体比一下，看下效果就好。 sort -u 去掉重复行 uniq删除上下连续的重复行 last -f wtmp就是last一个意思 [17:33:36 root@localhost data]#ll /var/log/*tmp -rw-rw----. 1 root utmp 2688 Jan 17 12:00 /var/log/btmp 👈lastb看的是这个文件，是密码输错了的记录 -rw-rw-r--. 1 root utmp 36480 Jan 29 11:15 /var/log/wtmp 👈last看的就是这个文件，是登入成功的记录 [17:33:41 root@localhost data]# 👆以什么样的用户猜密码的，安全加固的方式 uniqd -d 只显示重复的 uniq 的话如果不前置一个sort排序的话，就只是抓取连续的情况。 找出两个文件的相同行 👆上面的题目有BUG啊，如果a.txt里有两行z，那么就会误判咯。 [17:50:07 root@localhost data]#cat f1 z z a b c [17:50:10 root@localhost data]#cat f2 b c [17:50:11 root@localhost data]#cat f1 f2 | sort |uniq -d b c z [17:50:23 root@localhost data]# 可以这样优化👇，先各自去重后再cat结合再找出重复的就行了。 [17:51:20 root@localhost data]#cat f1 z z a b c [17:51:29 root@localhost data]#cat f2 b c [17:51:49 root@localhost data]#uniq f1 |cat - f2 z a b c b c [17:52:22 root@localhost data]#uniq f1 |cat - f2 | sort | uniq -d 👈这才是正解-d就是重复的 b c [17:52:29 root@localhost data]#uniq f1 |cat - f2 | sort | uniq -u 👈u就是取uniqu不一样的 a z 比较文件 -号代表第一个文件，+代表第二个文件,-号去掉+号加上 👆注意patch -b 选项是为了恢复之前先备份a.txt，因为patch的还原文件时直接将a.txt原文件覆盖掉的。 grep三剑客之一 grep不一定都带颜色，因为root的grep系统默认是别名 grep选项 grep -m匹配N次后停止 grep -i忽略大小写 grep -n命中第几行 grep -c匹配的行数 grep -o 命中多少个单行内多次也算 统计文本出现字符的次数-o出现一次单行列出来，再wc -l计算行数 grep -q 静默输出0找到1没找到0是true保持一惯的linux的真假标准 grep -A或-B或-C还是经常用的，但是cisco的show run | section router ospf显然更优化 此外还有-B -C nmap扫描、关于IP探测要总结一下好几种呢ping呢也是有灰常快速的方法的很赞的，当然ping肯定不可靠的。 👉最好是探测该IP上的几个常用端口，然后才能说这个IP是不是UP。他这个sP就是scan ping，聊胜于无，要用-Pn去扫 这招可以用来梳理IDC或者内网的HOST网段使用情况，选项不靠谱，仅作参考咯。 --- grep -E \"XX|YY|ZZ\"或的关系等价于grep -e xx -e yy -e zz 一样 grep 并且过滤 grep -w单词等价于grep的定界符grep \"\\\" grep -w 或grep \"\\\"的这个单词整体 判断的能力： 👆数字 字母 下划线 是一个单词，- 默认会当作分隔符的 ；同样也算作分隔符了 -w就是查找root单词，而root-er是当做root和er两个单词的。-不会被当做一个整体的。 不支持regex，这是什么需求？👇就是比如. *这玩意不做正则的时候，省的转义了 -F 或者fgrep就挺好，挺好~lizheng~tt tx sf sx grep -f 文件内容去匹配，这个玩意支持regex吗？支持的 用文件过滤文件，文件里也是可以写正则的 说明：以前学习的通配符是匹配文件名的，而grep里的正则是匹配文本内容的。 而且通配符的*和regex的\\，以及通配符的.和regex的.都不太一样。regex的.\\表示所有差点比如换行符？，而且regex的*不能独立存在，然是通配符的*就是自称一体表示所有。 1、regex的 .表示 除了 \\n以外任何一个字符，*表示前面的字符不出现或者出现N次。 2、通配符的.就表示. 而通配符的*表示除了.开头的文件名，其他都可以匹配(大概吧哈哈，有的文章说明什么路径中带/的，我就纳闷了通配符是抓文件名的，你文件名中能带/这玩意？呵呵所以这块理解的差不多得了，够了)，包括文件名中带.的(只要不是.开头的就好) 3、还有regex和通配符的其他区别，比如[a-z]在通配符中表示小写的a-z和大写的A-Y不到Z；regex显然没这么奇葩。 好，下面是工作中遇到的补充👇 -l, --files-with-matches Suppress normal output; instead print the name of each input file from which output would normally have been printed. The scanning will stop on the first match. 就是去重的效果咯，我只要知道在哪个文件里，不需要知道一个文件里出现了几次，所以加上-l。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:01 "},"7-文本三剑客1_grep和正则表达式/3-基本和扩展正则.html":{"url":"7-文本三剑客1_grep和正则表达式/3-基本和扩展正则.html","title":"第3节 基本和扩展正则","keywords":"","body":"第3节 基本和扩展正则 举个例子 [^ming] 不是m、i、n、g的字符 [0-9] [[:lower:]] 任意一个小写字母 . 任意一个非\\n的字符 * 前一个字符出现0次或N次 a\\? a出现了0次或1次，可有可无的表达方式 a\\+ a出现1次及以上 a\\{10\\} a出现了10次 a\\{10,20\\} 10到20次 a\\{,20\\} 20次以下 a\\{10,\\} 10次以上 .* 所有但是不能匹配\\n，所以你用.*抓全文只能抓到换行符就结束了， .*等价于通配符里的* 位置锚定 [16:47:46 root@host1 ~]#grep -v \"^#\" /etc/fstab /dev/mapper/centos_host1-root / xfs defaults 0 0 UUID=e36eac36-1940-4883-8c19-a05f6b4bb4a6 /boot xfs defaults 0 0 /dev/mapper/centos_host1-swap swap swap defaults 0 0 [16:47:55 root@host1 ~]# [16:47:56 root@host1 ~]# [16:47:56 root@host1 ~]#grep ^[^#] /etc/fstab /dev/mapper/centos_host1-root / xfs defaults 0 0 UUID=e36eac36-1940-4883-8c19-a05f6b4bb4a6 /boot xfs defaults 0 0 /dev/mapper/centos_host1-swap swap swap defaults 0 0 [16:48:07 root@host1 ~]# 上图注意下，grep -v \"^#\" 和 grep \"^[^#]\"的区别，明显第二种也过滤空行。因为[^#]里面至少的又一个字符的。 这种[^#]写法是有问题的，不推荐这么写。 搜索shutdown行尾👆 [[:space:]]他不仅仅抓空格，还抓TAB。当然上图其实都是空格，因为做了4空格等1tab的设置，取消后再验证下 还是[[:space:]]能够抓到空格和TAB的。没问题。注意一个细节，cat -A 是能够区分TAB和空格的，但是如果你优化了tab=4空格，那么就自然都是空格了。-A看到的都是空格了就。 搜索空行👆 单词：在系统中，数字字母下划线都算单词的范畴。此外都不算单词。 空行是^$,空白行^[[:space:]]*$ 注意，写的思路： :%s///g :%s/(abc)(123)/1eradmin2/g :%s/(abc)(123)/\\1eradmin\\2/g 👆这个叫后向引用，在后面的sed搜索替代有关 nginx里也有后向引用的 [17:30:32 root@host1 ~]#echo rootrootxxroot |grep -E \"(root){2}\" rootrootxxroot 👆抓两连续的root 练习 4题 cat /etc/passwd |grep -E \"[0-9]{2,3}\" -o | grep -Ev ^0 👈这是错误的，因为4位数也会搜出来的比如65534这个数字也会当作655和34两个匹配结果的，需要词尾锚定 cat /etc/passwd |grep -E \"/\" -o | grep -Ev ^0 注意该方法由于是:xx:所以对于后面的数字是不匹配的。 方法一肯定只能是抓出第一个段数字， 方法二可以匹配所有数字 --- 词尾铆钉的必要性👇 扩展正则 grep -E还是有一些还是需要加\\的。 nginx的后向引用举例 这是nginx里的rewrite替换的正则写法 windows里也有正则 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:01 "},"8-shell脚本编程基础/8-shell脚本编程基础.html":{"url":"8-shell脚本编程基础/8-shell脚本编程基础.html","title":"第八章 shell脚本编程基础","keywords":"","body":"第八章 shell脚本编程基础 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:01 "},"8-shell脚本编程基础/1-shell编程脚本基础.html":{"url":"8-shell脚本编程基础/1-shell编程脚本基础.html","title":"第1节 shell编程脚本基础","keywords":"","body":"第1节. shell编程脚本基础 编程基础 shell和py都是边解释边执行 gcc是个编译软件，可以把高级语言转换成机器代码 gcc就是编译器 在执行的时候有python解释器，会读到内存里翻译成机器码了。但是这个机器码是在内存里的，不是个放在硬盘里的文件。它是边执行边翻译。 编程基本概念 shell脚本基础 创建shell脚本 脚本规范 脚本的基本结构 vim的初始化 脚本执行的方法1:bash xxx 方法2，source xxx和. xxxx 方法3：添加执行权限 👆直接运行脚本，就是外部命令了，是要到PATH变量里找路径的，而当前目录是/root并不在PATH变量里，所以找不到。 添加到PATH变量 👆其实也可以用ln -s 软连接来实现path变量的 但是如果你以后很多脚本都统一放到/data/scipts下的话，还是加/data/scripts为PATH变量好一点 脚本运行方法4：传递给bash命令 evn.sh，只要是sh后缀就行了。 例子，写个脚本创建用户 让其口令立即过期 chage -d 0 test等价于passwd -e tezt都是修改date of last password chage这个值为0，意思就是登入后强制修改密码 语法错误检查方法 两种语法检查方法 删除if那行后 再次执行就OK了 举个例子 之前接触过%s/xx/yy/g，现在又看到了.,$s/XX/yy/g .点表示当前行号,逗号是一直到整个文件最后一行 u撤销后，改成 引号替换一下 变量 变量代表着内存空间 内存中的一个地址块放了magedu，而name就表示地址值。于是就是name中存放了magedu。 变量，值可变化，当然也有不可变 python和shell都不需要事先申明变量 变量起名规范 特殊变量 👆变量的正儿八经的写法，很重要 如果此时Y的值变成了30，问X的值是多少，这个在PYTHON里面叫变量赋值，如果是列表、字典是需要.copy()的 变量取消 上图替换语法存在错误 不用加g，%s/xx/yy/g，的g如果是每行只有一个不需要加g全局 一般脚本结束了变量也就没了。不过还是建议删掉。 把命令放到变量里 第一题答案就有了 cp -a 的a等价于-dR 文件夹不存在cp会直接创建的 第二题答案 nl 和 cat -b一个意思，不过不能列出空行行号 环境变量的查看 env和printenv是等价的 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:01 "},"8-shell脚本编程基础/2-shell编程特殊位置变量.html":{"url":"8-shell脚本编程基础/2-shell编程特殊位置变量.html","title":"第2节 shell编程特殊位置变量","keywords":"","body":"第2节. shell编程特殊位置变量 初识变量生效范围 1、tty再开一个终端就没了 2、退出后就没了 3、再次运行/bin/bash后就没了👇 [23:15:39 root@host1 ~]#NAME=ming [23:15:43 root@host1 ~]#echo $NAME ming [23:16:21 root@host1 ~]#pstree |grep -A 2 bash |-sshd---sshd---bash-+-grep | `-pstree |-systemd-journal [23:16:34 root@host1 ~]#pstree -p |grep -A 2 bash |-sshd(1191)---sshd(2132)---bash(2140)-+-grep(2207) | `-pstree(2206) |-systemd-journal(502) [23:17:10 root@host1 ~]#/bin/bash [23:17:17 root@host1 ~]#pstree -p |grep -A 2 bash |-sshd(1191)---sshd(2132)---bash(2140)---bash(2208)-+-grep(2239) | `-pstree(2238) |-systemd-journal(502) [23:17:29 root@host1 ~]#echo $NAME [23:17:36 root@host1 ~]#echo $BASHPID 2208 [23:17:49 root@host1 ~]#exit exit [23:17:52 root@host1 ~]#echo $BASHPID 2140 [23:17:56 root@host1 ~]#echo $NAME ming [23:17:58 root@host1 ~]# 父进程的NAME变量并没有传给子进程。 每个账号都有个shell类型，比如👇，表示root账号一登入就会自动去运行/bin/bash [23:23:25 root@host1 ~]#getent passwd root root:x:0:0:root:/root:/bin/bash 父进程的NAME变量并没有传给子进程，如果需要传进去，就要使用环境变量。 其上👆这句话也不完全对，换个方式就能将局部变量传进去了，比如小括号 环境变量 查看上级父进程编号 查看环境变量 举例EDITOR=vim 默认编辑器是 vipw是调用的EDITOR编辑器这个变量，而EDITOR默认复制应该就是vi，如下： 现在将EDITOR改成vim，再看，发现还是黑底白字，只有将EDITOR提升为环境变量，才会出彩，也就是vipw调用的是环境变量EDITOR里的值，普通变量没有关系。 unset name普通变量和环境变量都适用 环境变量可以由父进程传给子进程，但是不能从子进程传给父进程，也就是说子进程里修改的环境变量只在子进程里有效，退出子进程后，在父进程中还是原来的值；但是子进程再次赋值可以影响身后的子进程 [23:49:22 root@host1 ~]#export name=ming [23:49:42 root@host1 ~]#echo $name ming [23:49:46 root@host1 ~]#bash [23:49:51 root@host1 ~]#echo $name ming [23:49:55 root@host1 ~]#name=yi [23:50:11 root@host1 ~]#echo $name yi [23:50:13 root@host1 ~]#export name=yi 👈多余动作，name早就是环境变量了，所以无需再次申明 [23:50:24 root@host1 ~]#echo $name yi [23:50:28 root@host1 ~]#exit exit [23:50:29 root@host1 ~]#echo $name ming [23:50:31 root@host1 ~]# shell的嵌套深度 上一次执行的命令 常量就是只读变量 可能父进程和子进程配合使用是有用的， 小括号就是开启子shell，一运行完，子shell就退出了 注意只针对内部命令和变量赋值 证明小括号就是开启了子shell 上图👆此时可以再开一个窗口pstree -p看到确实8542就是7703的子进程 大括号和小括号是不同的 上图说明，小括号开启子进程，大括号不开启子进程。 位置变量 这样的话，就可以将输入的固定位置的参数变量传到脚本里面。 对比下$*和$@ 引号引起来才是一个整体，不能去掉。 练习，rm=rm.sh，rm.sh里写mv f1.txt /tmp/当前日期精确到秒，开局设置里可以用 用mv替代rm 如果要使用原来的rm，则\\rm就行了，不过要自带-i了 其他注意事项 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-12-05 14:02:03 "},"8-shell脚本编程基础/3-算术逻辑运算和条件测试.html":{"url":"8-shell脚本编程基础/3-算术逻辑运算和条件测试.html","title":"第3节 算术逻辑运算和条件测试","keywords":"","body":"第3节. 算术逻辑运算和条件测试 退出状态 [00:16:02 root@host1 ~]#grep aaa /etc/passwd #找到找不到结果自然不同 [03:44:30 root@host1 ~]#echo $? 1 [03:44:35 root@host1 ~]#grep -q root /etc/passwd [03:44:59 root@host1 ~]#echo $? 0 [03:45:02 root@host1 ~]# 错误对照表：https://www.cnblogs.com/x_wukong/p/5148237.html 一个脚本里2条命令，最后一条执行成功了，返回的$0就是0 算术运算 图中的echo $[$RANDOM%50]里面的$可以去掉的，因为$[]里面会认为RANDOM就是变量 方法一：let 方法二：中括号 方法三：2个小括号 方法四：expr 方法五：declare申明强制运算 65取模是0-64 如果是0-65的随机数呢？哈哈，不好弄了吧。 /66啊，不就行了哦，笨哦。 颜色的取值范围是31-37，可以用RANDOM随机数产生，用7取模范围就是0-6，+31就可以了。 ++i和i++ let id+=5 就是 id=id+5 逻辑运算与或非 python里也学过与或非，来了解一下，哈哈哈 and是与，&也是与，两者截然不同，貌似相同又。举例 再来 再看 懂了吧~ 1、and和or是基于运算符两边的整体值来算的；而&又叫做位与是将运算符两边化作0101后再进行位与的哈哈，我在用名称解释名称咯，额。 2、然后and和or里的99 or 100 和99 and 100也挺有意思的。一句话做人呐or就行了，做研究呐可能需要and。 or就是已经是true的情况下就不会再继续比了。反正或的话，结果都是true。 and就是当前如果是真，就一定要看到最后一个元素，万一他是假，就全盘就是假了，所以要那最后一个元素。A(true) and B(true)也就取B了。 3、一句话，or和and是真假运算--基于表达式两边的整体，而&和|是二进制的与或运算--基于表达式两边的数值的二进制单个位来算的。 这里的短路与的真假，不要简单按上图0和1，去理解，0啊他这个图是假的意思。但是linux，true你去echo $?会发现是0，所以0代表的是真。所以这种运算是真假运算，不要用0和1区理解，除非你定死了01和真假的一一对应。 当然也可以不要理解短路与，而直接理解第一个cmd1执行ok了再执行cmd2：cmd1 && cmd2 true和false就是命令，专门产生真假的 还有yes就是专门产生y，不停的 其实不是y，而是yes后面的参数 两个变量值互换 方法二就是上图的A^B=C，C^A=B，C^B=A x=$[x^y]就是得出了中间值C赋值给了x，x此时就是中间值。然后拿中间值x去和y异或得到的就是原来的x，将x赋值给y。此时y里的值就变成了x。再拿中间值x去和现在的y--其实是原来的x异或就得到原来的y将此值赋给x，这样x里的值就变成了原来的y。 短路与 短路或 true是真，echo true本身也是真，同时打印出true，此时两个都是真，结果就是真，后面的就不执行了。 false是假，只要是假都是假，所以就不会执行后面的 echo true。 然后不会执行&&后面的内容，但是&&的结果还是假，所以就会执行||后面的内容，于是打印出false了就。 test比较表达式 这个和if else还不是一样的，因为A && B || C，不是if A成立就执行B，A不成立就执行C这么简单，还多一个A成立执行B，B执行失败，那么||前面的整体就是假，于是还是会执行C的。 除了字符串的比较，还有数字比较 printf是是格式化字符串的。类似python里的format 中括号代替test test $x -gt $y Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:01 "},"8-shell脚本编程基础/4-条件判断.html":{"url":"8-shell脚本编程基础/4-条件判断.html","title":"第4节 条件判断","keywords":"","body":"第4节. 条件判断 判断是否为空 不是的，空格当然不为空，但是[ ]综括号的写法 里面空格再多就是不算的。你引号来表示空格试试 上图是help test出来的，内部命令的帮助用法help xx 0自然也不是空 文件夹存在就不创建的方法 存在就不会创建了。 本身touch就是这样的效果了，不过touch一个存在的文件，虽然内容不会清掉，但是3个时间统统刷新。如下 [03:22:10 root@host1 ~]#stat f1 File: ‘f1’ Size: 9 Blocks: 8 IO Block: 4096 regular file Device: fd00h/64768d Inode: 71287069 Links: 1 Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root) Context: unconfined_u:object_r:admin_home_t:s0 Access: 2022-02-02 18:49:12.966012106 +0800 Modify: 2022-02-02 18:49:11.773012078 +0800 Change: 2022-02-02 18:49:11.777012078 +0800 Birth: - [03:22:14 root@host1 ~]#cat f1 dd [03:22:17 root@host1 ~]#touch f1 [03:22:21 root@host1 ~]#ll f1 -rw-r--r--. 1 root root 9 Feb 6 03:22 f1 [03:22:24 root@host1 ~]#stat f1 File: ‘f1’ Size: 9 Blocks: 8 IO Block: 4096 regular file Device: fd00h/64768d Inode: 71287069 Links: 1 Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root) Context: unconfined_u:object_r:admin_home_t:s0 Access: 2022-02-06 03:22:21.871014487 +0800 Modify: 2022-02-06 03:22:21.871014487 +0800 Change: 2022-02-06 03:22:21.871014487 +0800 Birth: - [03:22:26 root@host1 ~]#cat f1 dd -e -a后面不跟文件，单单一个-e或者-a就不认为是选项了，而是当作字符了，有字符就是非空了👆👇所以使用-e这种一定要后面用双引号引起来。 所以加上 双引号 可以避免严重逻辑错误， 判断是否位数字，可以用正则表达式👇 [03:41:04 root@host1 ~]#[ \"11\" -gt 10 ] && echo true true [03:41:09 root@host1 ~]#[ '11' -gt 10 ] && echo true true [03:41:16 root@host1 ~]#[ 'xx' -gt 10 ] && echo true -bash: [: xx: integer expression expected [03:41:22 root@host1 ~]# 说明linux里的引号，并不会改变里面值的类型，这里11引起来还是数字，不会变成字符串。这话不对， 其实是shell是动态编译语言--就是类型是随时改变的。 双综括号里面支持正则，需要这么写： 纯数字的判断👆 还是需要补上双引号👆，虽然不影响结果，一般在[]里变量都是推荐加上双引号。 判断是否位.sh后缀 判断合法IP 判断是否是一个合法IP的办法：其实还可以进一步到A B C 类地址以及私网地址。 下图第三行才是正解，没有^和$就是包含了。 注意上图命令是转行了 reg嵌入到字符串表达式里shell的写法。 并且的关系-方法1 [ xxx -a yyy] 并且的写法，不过它这里不支持正则了，正则得用短路与，不过不是普遍适用的，可能还需要第二种方式： 并且的关系-方法2 判断的是实际上的权限，不是表面上的文件权限。上图是root执行的命令，所以就是可读可写的。 但是执行权限不同，root也是需要文件的执行权限的。 补充个点，f1.sh要执行，用户要有f1.sh的r读权限，然后再/bin/bash f1.sh就能执行了，如果连f1.sh的读权限都没有，必然无法执行的。 [04:52:19 root@host1 ~]#su user1 [04:52:23 user1@host1 root]$bash /data/f1 bash: /data/f1: Permission denied [04:52:27 user1@host1 root]$ll /data/f1 ----------. 1 root root 23 Feb 6 04:49 /data/f1 [04:52:30 user1@host1 root]$exit exit [04:52:58 root@host1 ~]#chmod 444 /data/f1 [04:53:09 root@host1 ~]#ll /data/f1 -r--r--r--. 1 root root 23 Feb 6 04:49 /data/f1 [04:53:11 root@host1 ~]#su user1 [04:53:15 user1@host1 root]$bash /data/f1 xxx 需求： 写个脚本user10.sh创建用户，考虑用户存在以及user10.sh后没有跟参数的问题。 上图是第一版有问题啊不少 这版是OK了 这是对应的结果 可能$1为空要改一下，改成S# 好理解一下，一个参数都没有不就是$1为空嘛。对不对，所以上面无需修改。 但是还是有问题 添加花括号： 现在应该OK了 可以个屁，（ ）小括号是子shell，exit10是退出的子shell。 优化一下将Changing passowd for user tom和passwd：xxx隐藏。 如果你干了这事：将chmod的执行权限弄没了 利用facl修复权限 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-12-08 14:31:17 "},"8-shell脚本编程基础/5-算术运算和read.html":{"url":"8-shell脚本编程基础/5-算术运算和read.html","title":"第5节 算术运算和read","keywords":"","body":"第5节. 算术运算和read && || 和 || &&先后效果不一样 = 是比字符串 -eq是比整数的，小数不行。 上图的两个等号，一般一个就行了，双综括号里可以用两个等号，然后双综括号里一般用=~正则表达式。 read read varXX unset varXX 这两个后面跟的都是变量名，不需要加$xxx这样。就是变量了。 优化不换行 echo 不换行 再次优化，read的本身就自带提示语句 写个脚本实现鸡兔同笼算法 read一下赋值多个 失败案例 man bash可见 管道符后面是一个子进程，所以要括起来，你用小括号就是子进程后面再接一个子进程了。 花括号就是管道符-子进程后面直接一个整体。 总之作为一个整体就行了。 证明管道符确实开启了子进程 先来一个还阔以但是有点不太推荐的解法，因为短路与或用的太多了 if条件判断 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:01 "},"8-shell脚本编程基础/6-脚本条件分支和安全.html":{"url":"8-shell脚本编程基础/6-脚本条件分支和安全.html","title":"第6节 脚本条件分支和安全","keywords":"","body":"第6节. 脚本条件分支和安全 type xxx一般可见就是build in 这种内部命令或者外部命令或者alias，现在忽然发现type if不一样的显示 [17:19:51 root@host1 ~]#type echo echo is a shell builtin [17:19:59 root@host1 ~]#type help help is a shell builtin [17:20:07 root@host1 ~]#type ls ls is aliased to `ls --color=auto' [17:20:09 root@host1 ~]#type cp cp is aliased to `cp -i' [17:20:10 root@host1 ~]#type date date is /usr/bin/date [17:20:13 root@host1 ~]#type if if is a shell keyword 👈不能独立作为命令，是shell的关键字 [17:20:15 root@host1 ~]# 老王说得好，世界上最远的距离就是，一个在if下，另一个在else里。 if的shell格式 有个问题啊，上面的exit没有意义。下面的都是一样效果，# 怎么没有意义，那会的脑子是没带嘛我！ 有啥意义 你告诉我呢。我告诉你个二五仔，fi下面要是还有东西，你不加exit试试。要做靓仔啊，不要做二五仔啊~ 例子：ping一个主机通就算了，不通看下是否处于维护状态(维护的机器一般规范的话是放到一个文件里记着的)，如果不在维护 则认为机器是down的。 if不适合的情况 此时就需要case 👆上图注意关键字：变量引用。变量引用和变量是两码事，变量引用是要加$的，就是说case 和read 不同，read后面是直接写NAME就表示变量了，而case得写$NAME，引用一下。 注意：PAT1)是通配符，不是正则！ 变量引用和变量是两码事 if开头，fi结尾，case开头esac结尾。 下面是一些补充 上图的小括号是什么鬼？！，上图还差一个小括号没讲，小括号的优先级最高。 各种符号的优先级见👆上图： 小括号的分组优先级最高 1、命令行里先拆成单词， 2、然后看单词里有没有别名，别名要展开 3、然后看花括号，也要展开，{1..10}这种 4、如果有~表示家目录 5、然后再看$()和``表示里面放的命令 6、因为5所以再次将命令行拆成单词 7、展开通配符命令的文件名 8、接着再重定向 9、最后再运行命令 转义 [11:18:16 root@localhost ~]#echo \"ls\" 👈双引号防止扩展，就是转义的意思 ls 上图就是说双引号也可以转义，但是以下几个情况转不了。 [11:23:13 root@localhost ~]#echo \"$PATH\" /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin [11:23:20 root@localhost ~]# [11:23:24 root@localhost ~]#echo \"`ls`\" 1 anaconda-ks.cfg data f1 f2 hello.txt [11:23:50 root@localhost ~]#\"!1020\" \"ls\" 1 anaconda-ks.cfg data f1 f2 hello.txt [11:29:23 root@localhost ~]#echo \"\\\\n\" \\n [11:29:25 root@localhost ~]#echo '\\\\n' \\\\n [11:29:28 root@localhost ~]# 环境配置文件等到底放哪里 “个人配置”只影响家目录的这个用户，“全局” 所有用户生效。 交互登入就是：xshell或者直接终端登入，su - 完全切换是交互式登入。 非交互登入：su 这种不完全切换就是非交互式登入；图新界面里右键打开终端也是非交互登入；脚本登入； 👉非交互方式，看的配置文件就少了两个，所以推荐放到/etc/profile.d/*.sh这样，你脚本上来也是OK的。不过一般脚本上来也不太需要这些环境配置吧，比如vim 空格 退出不清屏 PS1颜色等脚本上来也不需要的啊。 演示1： [11:45:23 root@localhost ~]#vim /etc/profile 👈最后一行添加echo xxxxyyyy [11:46:01 root@localhost ~]# [11:46:02 root@localhost ~]# [11:46:02 root@localhost ~]#su - user1 👈完全切换的交互登入 Last login: Mon Feb 7 11:45:20 CST 2022 on pts/0 xxxxyyyy [11:46:09 user1@localhost ~]$exit logout [11:46:12 root@localhost ~]#su user1 👈不完全切换的非交互登入 [11:46:14 user1@localhost root]$exit exit [11:46:15 root@localhost ~]# 演示2： 👆仔细看上图，分析一下到底是~/.bash_profile优先还是~/.bashrc优先，对吧，脑经多走两步就出来了。.bash_profile是加载了.bashrc的，如果在fi xxx后面重新设置相同的变量，则就是.bash_profiile优先，如果是在if xxx之前设置，肯定是.bashrc优先嘛，所以上面的PPT也不一定的哦，同理FACL的优先级，owner肯定也没有FACL针对owner的优先。这些不要学的太细，树干+枝叶+框架比较合理。 下图👇是su - 完全切换 这是属于交互方式的真正原因，而不是什么终端，他这个终端明显是GUI里右键调出来--属于非交互式，但是又用了su - 所以最终还是交互式的。 profile是配置文件的意思 bashrc是bash和rc，bash是shell类型，rc是run config，run bash运行的时候的对应的配置文件。run command profile和bashrc分工不是很明确 一般认为profile用来定义环境变量和运行命令或脚本 bashrc用来定义别名和函数还有本地变量 profile和bashrc修改后生效的方法 其实就是把profie当作脚本执行一下 1、加执行权限 2、bash xxx 3、cat xxx | bash 这种有点问题 4、source xxx或. xxx sleep观察source和bash的区别 在文件里跑个slepp 100看看当前的bash，source和bash不同👇 而bash bash会开启子进程，一般运行脚本都会开启子进程。否则可能会影响当前变量的值。 source(.)运行脚本不推荐哈，否则👇；配置文件恰恰建议用source(.) 所以一般脚本不用source。而一般配置config文件就是要用source，因为配置文件就是希望改变当前环境的。 退出的时候执行点东西 set命令相关 $_是上条命令最后一个参数 $-又是啥 插入题外话 关闭**VIM后，屏幕唉显示之前的VIM里的内容：** 在.vimrc文件里加上配置语句： 在.vimrc中设置set t_ti= t_te= 方法二 回到原题 [13:56:43 root@localhost ~]#echo ${-#*i} 👈好神奇的表达式，意思就是$-的值 从左到右 看到i，就连i一起截除掉。其实搜索也没搜到，然后一想换个变量用$-试试，一下子就知道答案了。 mBHs [13:56:46 root@localhost ~]# 然后himBHs的s是这个意思 https://unix.stackexchange.com/questions/329682/what-is-an-s-inside 其他补充 解释下unmask为什么root时022，普通账户时002 uid大于199，并且 gid=uid，则umask=002，否则umask=022 同理 脚本安全 当使用一个没有定义的变量的时候，直接报错。 问题来了，如果上面的脚本写成如下错误 变量写错，$DIR为空，直接就灾难性的把根删了。 将上图略微修改一下（rm -rf $DIR/*.txt），然后👇测试结果如下： 如何避免 上图👆问题大了-如果没有set -u的话就是$DIR不存在直接把/根下面都删了，删库的100种方法你又学废了一种，恭喜恭喜。 还有一个 说明脚本也是在子进程里跑的。 脚本错误就不执行了的方法，因为不是语法错误时会继续执行的。 虽然出错了，但是还是继续执行了 处理方法如下 整一个这个还是不错的。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-12-09 19:26:40 "},"9-文本查找和压缩/9-文本查找和压缩.html":{"url":"9-文本查找和压缩/9-文本查找和压缩.html","title":"第九章 文本查找和压缩","keywords":"","body":"第九章 文本查找和压缩 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:01 "},"9-文本查找和压缩/1-文件查找.html":{"url":"9-文本查找和压缩/1-文件查找.html","title":"第1节 文件查找","keywords":"","body":"第1节. 文件查找 章节目录 grep是过滤文本的行 cut是过滤文本的列 这里是磁盘上搜索文件 locate找文件非常快，依赖于mlocate.db 用updatedb创建/var/lib/mlocate/mlocate.db文件。如果工作中磁盘文件很多，就会占用磁盘IO，瞬间飙高，导致业务被波及。所以需要操作窗口。 默认模糊搜索 👇要updatedb(不能随便用，生产小心)更新一下数据库，就能利用locate查找了 locate支持基本正则 👆基本正则写起来还是比较麻烦，上图。 [15:27:53 root@localhost ~]#find / -name passwd |grep -Ei \"^/[a-z]+/passwd$\" /etc/passwd /Etc/passwd /a/passwd /A/passwd /Z/passwd /z/passwd [15:28:17 root@localhost ~]#find / -name passwd |grep -Ei \"^/[A-Z]+/passwd$\" /etc/passwd /Etc/passwd /a/passwd /A/passwd /Z/passwd /z/passwd [15:28:51 root@localhost ~]#find / -name passwd |grep -E \"^/[A-Z]+/passwd$\" /A/passwd /Z/passwd [15:28:57 root@localhost ~]#find / -name passwd |grep -E \"^/[a-z]+/passwd$\" /etc/passwd /a/passwd /z/passwd [15:29:03 root@localhost ~]#find / -name passwd |grep -E \"^/[a-Z]+/passwd$\" /etc/passwd /Etc/passwd /a/passwd /A/passwd /Z/passwd /z/passwd [15:29:09 root@localhost ~]#find / -name passwd |grep -E \"^/[A-z]+/passwd$\" grep: Invalid range end [15:29:17 root@localhost ~]#find / -name passwd |grep -E \"^/[A-z]+/passwd$\" grep: Invalid range end [15:29:22 root@localhost ~]# 👆通过上面的实验发现find后面的[A-Z][a-z][a-Z]这样写都有其特定的意义，但是没有[A-z]的写法。这点和通配符不同 [15:37:01 root@localhost ~]#locate -r \"^/[a-z]+/passwd$\" [15:37:06 root@localhost ~]#locate -r \"^/[A-Z]+/passwd$\" [15:37:10 root@localhost ~]#find / -name passwd |grep -E \"^/[a-z]+/passwd$\" /etc/passwd /a/passwd /z/passwd 👆可见locate -r只支持正则，所以+这种扩展正则表达式 是不支持的。 [15:38:24 root@localhost ~]#locate -r \"^/[A-Z]*/passwd$\" /A/passwd /Z/passwd [15:39:57 root@localhost ~]#locate -r \"^/[a-Z]*/passwd$\" /A/passwd /Etc/passwd /Z/passwd /a/passwd /etc/passwd /z/passwd [15:40:01 root@localhost ~]#locate -r \"^/[[:alnum:]]*/passwd$\" /A/passwd /Etc/passwd /Z/passwd /a/passwd /etc/passwd /z/passwd [15:40:45 root@localhost ~]#find / -name passwd |grep -E \"^/[[:alnum:]]+/passwd$\" /etc/passwd /Etc/passwd /a/passwd /A/passwd /Z/passwd /z/passwd find 实时查找，其实也可以利用xargs变得快些，同样占CPU，locate就是在机器上APP服务维护阶段执行updatedb会占CPU [15:36:15 root@pyConsole /]#time `ls --hide=proc | xargs -i -P 0 find /{} -name \"*i*\"` -bash: /bin: Is a directory real 0m1.101s user 0m1.206s sys 0m0.336s [15:36:17 root@pyConsole /]#time `ls --hide=proc | xargs -i -P 0 find /{} -name \"*i*\"` -bash: /bin: Is a directory real 0m1.391s user 0m1.496s sys 0m0.356s [15:36:22 root@pyConsole /]#time `ls --hide=proc | xargs -i -P 0 find /{} -name \"*i*\"` -bash: /bin: Is a directory real 0m1.123s user 0m1.186s sys 0m0.363s [15:36:24 root@pyConsole /]#time `find / -name \"*i*\"` find: ‘/proc/4065730’: No such file or directory find: ‘/proc/4065733’: No such file or directory -bash: /boot/efi: Is a directory real 0m1.677s user 0m1.380s sys 0m0.396s [15:36:28 root@pyConsole /]#time `find / -name \"*i*\"` -bash: /boot/efi: Is a directory real 0m1.721s user 0m1.400s sys 0m0.399s [15:36:31 root@pyConsole /]#time `find / -name \"*i*\"` -bash: /boot/efi: Is a directory real 0m1.739s user 0m1.407s sys 0m0.404s [15:36:34 root@pyConsole /]# locate和find一样存在一些普通用户没有某些文件夹权限，也会搜不到。 find默认就是递归查找，也就是会进到子目录里继续查找。 [处理动作]比较实用，搜出来删除之类。 find 指定搜索深度 [16:08:08 root@pyConsole /]#find / -name \"*i*\" -maxdepth 1 find: warning: you have specified the -maxdepth option after a non-option argument -name, but options are not positional (-maxdepth affects tests specified before it as well as those specified after it). Please specify options before other arguments. /bin /sbin /lib /lib64 /media /.bash_history /switch 更精准一些的搜索方法 [16:10:06 root@pyConsole /]#find / -name \"passwd\" /etc/pam.d/passwd /etc/passwd /var/lib/sss/mc/passwd /usr/bin/passwd /usr/share/licenses/passwd /usr/share/doc/passwd /usr/share/bash-completion/completions/passwd [16:10:11 root@pyConsole /]# [16:10:13 root@pyConsole /]# [16:10:13 root@pyConsole /]#find / -name \"passwd\" -maxdepth 2 find: warning: you have specified the -maxdepth option after a non-option argument -name, but options are not positional (-maxdepth affects tests specified before it as well as those specified after it). Please specify options before other arguments. /etc/passwd [16:10:18 root@pyConsole /]#find -maxdepth 2 / -name passwd find: paths must precede expression: / Usage: find [-H] [-L] [-P] [-Olevel] [-D help|tree|search|stat|rates|opt|exec] [path...] [expression] [16:10:59 root@pyConsole /]#find / -maxdepth 2 -name passwd /etc/passwd [16:11:11 root@pyConsole /]#find / -maxdepth 2 -mindepth 2 -name passwd /etc/passwd [16:11:22 root@pyConsole /]#find / -name passwd /etc/pam.d/passwd /etc/passwd /var/lib/sss/mc/passwd /usr/bin/passwd /usr/share/licenses/passwd /usr/share/doc/passwd /usr/share/bash-completion/completions/passwd [16:11:29 root@pyConsole /]# [16:11:32 root@pyConsole /]#find / -maxdepth 3 -mindepth 3 -name passwd /etc/pam.d/passwd /usr/bin/passwd [16:11:36 root@pyConsole /]# find -depth选项,这个有什么应用场景？想不出来 默认是先搜索目录本身，再进到每个目录再去搜索。 现在就是先处理文件，再处理文件夹。应用场景呢？ find自带的是通配符不是正则 find -iname 不分大小写 [16:32:18 root@localhost ~]#find / -name etc /run/initramfs/state/etc /etc /usr/share/factory/etc /usr/local/etc [16:32:25 root@localhost ~]#find / -iname etc 👈忽略大小写的方法，这也是个总结点，以后用▲来表示总结线索吧，▲忽略大小写2 /run/initramfs/state/etc /etc /root/ETc /usr/share/zoneinfo/Etc /usr/share/zoneinfo/posix/Etc /usr/share/zoneinfo/right/Etc /usr/share/factory/etc /usr/local/etc /Etc [16:32:32 root@localhost ~]# find -inum 根据inode编号来搜 [16:54:36 root@localhost ~]#find / -inum 70 /sys/kernel/tracing/events/raw_syscalls/sys_exit/filter /sys/kernel/debug/tracing/events/raw_syscalls/sys_exit/filter /sys/fs/cgroup/devices/system.slice/sys-kernel-tracing.mount/tasks /sys/fs/cgroup/memory/system.slice/system-systemd\\x2dhibernate\\x2dresume.slice/tasks /sys/fs/cgroup/pids/system.slice/systemd-journald-dev-log.socket/pids.current /sys/bus/memory/drivers_autoprobe [16:54:39 root@localhost ~]# [16:54:41 root@localhost ~]# [16:54:41 root@localhost ~]#find / -inum 70 -exec ls -il {} + 👈提前用一下exec看下效果呵呵 70 -rw-r--r--. 1 root root 4096 Feb 7 16:54 /sys/bus/memory/drivers_autoprobe 70 -rw-r--r--. 1 root root 0 Feb 7 16:54 /sys/fs/cgroup/devices/system.slice/sys-kernel-tracing.mount/tasks 70 -rw-r--r--. 1 root root 0 Feb 7 16:54 '/sys/fs/cgroup/memory/system.slice/system-systemd\\x2dhibernate\\x2dresume.slice/tasks' 70 -r--r--r--. 1 root root 0 Feb 7 16:54 /sys/fs/cgroup/pids/system.slice/systemd-journald-dev-log.socket/pids.current 70 -rw-r--r--. 1 root root 0 Jan 29 09:57 /sys/kernel/debug/tracing/events/raw_syscalls/sys_exit/filter 70 -rw-r--r--. 1 root root 0 Jan 29 09:57 /sys/kernel/tracing/events/raw_syscalls/sys_exit/filter [16:54:43 root@localhost ~]# 👆节点编号相同也不是同一个文件哈哈。 插入一个find -exec的用法细节 搜索inode节点编号，以及搜索inode相同的文件(硬的) find 的regex要匹配的是全路径，locate不需要 对比实验 17:07:14 root@localhost ~]#ll /usr/share/pixmaps/ total 92 -rw-r--r--. 1 root root 5459 Sep 9 13:25 cockpit.png -rw-r--r--. 1 root root 13071 Jun 28 2021 fedora-gdm-logo.png -rw-r--r--. 1 root root 21820 Jun 28 2021 fedora-logo.png -rw-r--r--. 1 root root 12760 Jun 28 2021 fedora-logo-small.png -rw-r--r--. 1 root root 6620 Jun 28 2021 fedora-logo-sprite.png -rw-r--r--. 1 root root 1442 Jun 28 2021 fedora-logo-sprite.svg -rw-r--r--. 1 root root 14493 Jun 28 2021 system-logo-white.png 👇这是 -name后跟通配符 [17:07:37 root@localhost ~]#find /usr/share/pixmaps -name *png /usr/share/pixmaps/fedora-gdm-logo.png /usr/share/pixmaps/fedora-logo-small.png /usr/share/pixmaps/fedora-logo-sprite.png /usr/share/pixmaps/fedora-logo.png /usr/share/pixmaps/system-logo-white.png /usr/share/pixmaps/cockpit.png 👇这是 -regex后跟正则(扩展正则，因为不用\\[xx\\]这样写，也支持+)，注意这里的正则匹配的是全路径 [17:08:21 root@localhost ~]#find /usr/share/pixmaps -regex \".*\\.png$\" /usr/share/pixmaps/fedora-gdm-logo.png /usr/share/pixmaps/fedora-logo-small.png /usr/share/pixmaps/fedora-logo-sprite.png /usr/share/pixmaps/fedora-logo.png /usr/share/pixmaps/system-logo-white.png /usr/share/pixmaps/cockpit.png [17:08:30 root@localhost ~]#find /usr/share/pixmaps -regex \"\\.png$\" [17:08:33 root@localhost ~]# [17:08:34 root@localhost ~]# 👇这是locate -r 后跟 正则 [17:09:12 root@localhost ~]#locate -r \"/usr/share/pixmaps/.*\\.png$\" /usr/share/pixmaps/cockpit.png /usr/share/pixmaps/fedora-gdm-logo.png /usr/share/pixmaps/fedora-logo-small.png /usr/share/pixmaps/fedora-logo-sprite.png /usr/share/pixmaps/fedora-logo.png /usr/share/pixmaps/system-logo-white.png 👇当然locate无需全路径 find 选项的PPT总结图 还有一个补充，要注意-name 后面要带上双引号的 [18:32:04 root@localhost ~]#find -name \"f*\" ./f2 ./data/f2 ./data/f1 ./f1~ ./fz~ ./f3 ./f1 ./f1.link [18:32:05 root@localhost ~]#find -name f* find: paths must precede expression: f1~ Usage: find [-H] [-L] [-P] [-Olevel] [-D help|tree|search|stat|rates|opt|exec] [path...] [expression] [18:32:11 root@localhost ~]# [18:32:12 root@localhost ~]# [18:32:12 root@localhost ~]# 按属主和属组查找 默认是print，这里换了个动作-ls 所以其实不用上面的-exec \"ls\" {} + 这么麻烦，简单的ls直接加就行了。 这样-nouser就体现出来了👆 根据文件类型查找 搜索所有文件夹 搜索所有块 搜索空文件或空文件夹 组合条件与或非 非空文件和文件夹 并且关系 或者关系 -a与的运算优先级要比-o或运算高，所以-type f -a -ls先进行运算了。 关键点来了，为什么-name \"f*\" -o -type f -a -ls 后面先算，结果就是t.txt了呢 [17:28:06 root@localhost data]#ll total 16 -rw-r--r--+ 1 root root 10 Jan 29 17:49 f1 -rw-r--r--+ 2 root root 4 Jan 29 17:49 f2 -rw-r--r--+ 2 root root 4 Jan 29 17:49 f2.link drwxr-xr-x. 2 root root 6 Feb 8 10:39 fdir -rw-r--r--. 1 root root 65 Jan 29 10:59 t.txt [17:28:08 root@localhost data]# [17:28:10 root@localhost data]#find ./ -name \"f*\" -o -type f -ls 👈不太好解释为什么变成了1行 33577450 4 -rw-r--r-- 1 root root 65 Jan 29 10:59 ./t.txt 👆上面的命令等价于下面两个的结果做了-o，但是-o显然不能用man里的用法来解释这个结果。 [17:28:12 root@localhost data]#find ./ -name \"f*\" ./f1 ./f2 ./fdir ./f2.link [17:28:16 root@localhost data]#find ./ -type f -ls 33577448 4 -rw-r--r-- 1 root root 10 Jan 29 17:49 ./f1 33577447 4 -rw-r--r-- 2 root root 4 Jan 29 17:49 ./f2 33577450 4 -rw-r--r-- 1 root root 65 Jan 29 10:59 ./t.txt 33577447 4 -rw-r--r-- 2 root root 4 Jan 29 17:49 ./f2.link [17:28:21 root@localhost data]# 👇倒是如果大家都是一个格式都是ls -l长格式就可以-o了 [17:32:00 root@localhost data]#find ./ -name \"f*\" -ls 33577448 4 -rw-r--r-- 1 root root 10 Jan 29 17:49 ./f1 33577447 4 -rw-r--r-- 2 root root 4 Jan 29 17:49 ./f2 51325760 0 drwxr-xr-x 2 root root 6 Feb 8 10:39 ./fdir 👈 33577447 4 -rw-r--r-- 2 root root 4 Jan 29 17:49 ./f2.link [17:32:02 root@localhost data]#find ./ -type f -ls 33577448 4 -rw-r--r-- 1 root root 10 Jan 29 17:49 ./f1 33577447 4 -rw-r--r-- 2 root root 4 Jan 29 17:49 ./f2 33577450 4 -rw-r--r-- 1 root root 65 Jan 29 10:59 ./t.txt 👈 33577447 4 -rw-r--r-- 2 root root 4 Jan 29 17:49 ./f2.link [17:32:08 root@localhost data]#find ./ -name \"f*\" -ls -o -type f -ls 33577448 4 -rw-r--r-- 1 root root 10 Jan 29 17:49 ./f1 33577447 4 -rw-r--r-- 2 root root 4 Jan 29 17:49 ./f2 33577450 4 -rw-r--r-- 1 root root 65 Jan 29 10:59 ./t.txt 👈 51325760 0 drwxr-xr-x 2 root root 6 Feb 8 10:39 ./fdir 👈 33577447 4 -rw-r--r-- 2 root root 4 Jan 29 17:49 ./f2.link ------------👇这段是符合-o的本来逻辑的，就是前面true就不算后面了---------- [17:33:24 root@localhost data]#find ./ -name \"f*\" -ls -o -type f 33577448 4 -rw-r--r-- 1 root root 10 Jan 29 17:49 ./f1 33577447 4 -rw-r--r-- 2 root root 4 Jan 29 17:49 ./f2 51325760 0 drwxr-xr-x 2 root root 6 Feb 8 10:39 ./fdir 33577447 4 -rw-r--r-- 2 root root 4 Jan 29 17:49 ./f2.link [17:33:28 root@localhost data]# [17:33:44 root@localhost data]#find ./ -name \"f*\" -ls 33577448 4 -rw-r--r-- 1 root root 10 Jan 29 17:49 ./f1 33577447 4 -rw-r--r-- 2 root root 4 Jan 29 17:49 ./f2 51325760 0 drwxr-xr-x 2 root root 6 Feb 8 10:39 ./fdir 33577447 4 -rw-r--r-- 2 root root 4 Jan 29 17:49 ./f2.link [17:33:59 root@localhost data]# [17:34:01 root@localhost data]#find ./ -type f ./f1 ./f2 ./t.txt ./f2.link ------------👇这段是不符合-o的本来\"表面\"逻辑的，看起来像是短格式在前(左)，长格式在(右),会变成左边的文件名去掩码右边的文件名，掩出来就剩下一个t.txt在用find里的ls(其实就是ls -dils)显示出来----------可能这里的-o就是异或运算了，相同出0就消掉了，不同也就是t.txt不同就出1也就保留了-----但显然上面的例子是逻辑或--▲linux逻辑混乱案例1-- [17:34:22 root@localhost data]#find ./ -name \"f*\" ./f1 ./f2 ./fdir ./f2.link [17:34:34 root@localhost data]#find ./ -type f -ls 33577448 4 -rw-r--r-- 1 root root 10 Jan 29 17:49 ./f1 33577447 4 -rw-r--r-- 2 root root 4 Jan 29 17:49 ./f2 33577450 4 -rw-r--r-- 1 root root 65 Jan 29 10:59 ./t.txt 33577447 4 -rw-r--r-- 2 root root 4 Jan 29 17:49 ./f2.link [17:34:48 root@localhost data]# [17:34:56 root@localhost data]#find ./ -name \"f*\" -o -type f -ls 33577450 4 -rw-r--r-- 1 root root 65 Jan 29 10:59 ./t.txt [17:35:04 root@localhost data]# 总之，这东西要规范了用就是-a是默认存在的 优于 -o，然后要规范使用小阔话来实现正确的逻辑，否则结果很难解释。 德·摩根定律 locate -r xx是正则，find -name xx是通配，locate xx是包含就算，find -regex 是扩展正则，本章上文有总结过了。 如果find 后接 regex就需要是全路径匹配。 [18:04:14 root@localhost ~]#find /etc -name *.conf | head -10 /etc/dnf/dnf.conf /etc/dnf/plugins/kpatch.conf /etc/dnf/plugins/copr.conf /etc/dnf/plugins/debuginfo-install.conf /etc/dnf/protected.d/dnf.conf /etc/dnf/protected.d/setup.conf /etc/dnf/protected.d/systemd.conf /etc/dnf/protected.d/sudo.conf /etc/dnf/protected.d/yum.conf /etc/libreport/events.d/collect_dnf.conf [18:04:18 root@localhost ~]#touch x.conf [18:04:33 root@localhost ~]#find /etc -name *.conf | head -10 [18:04:36 root@localhost ~]#find /etc -name *.conf [18:04:39 root@localhost ~]#👇-name后面一定要加上引号，否则你看家目录里的文件竟然会影响/etc/下面的文件匹配，这个似乎很不合理，但是让我联想到了pycharm的init文件也是，你只要跑一个普通的xx.py文件，就会先跑一个init文件，但是也不至于像linux这种奇奇怪怪的问题。 都说linux稳定，今儿给大家看看逻辑不通的两个案例~▲linux逻辑混乱案例2 [18:04:39 root@localhost ~]#find /etc -name \"*.conf\" | head -10 /etc/dnf/dnf.conf /etc/dnf/plugins/kpatch.conf /etc/dnf/plugins/copr.conf /etc/dnf/plugins/debuginfo-install.conf /etc/dnf/protected.d/dnf.conf /etc/dnf/protected.d/setup.conf /etc/dnf/protected.d/systemd.conf /etc/dnf/protected.d/sudo.conf /etc/dnf/protected.d/yum.conf /etc/libreport/events.d/collect_dnf.conf ▲linux逻辑混乱案例2 [18:13:15 root@localhost ~]#cd /data/ ---进到/data下find -name 不带*看看，果然是当前目录会干掉实际搜索的目录文件，具体往下看👇--- [18:13:25 root@localhost data]# [18:13:25 root@localhost data]# [18:13:25 root@localhost data]# [18:13:25 root@localhost data]#find /etc -name *.conf | head -10 👈现在不带引号可以搜到 /etc/dnf/dnf.conf /etc/dnf/plugins/kpatch.conf /etc/dnf/plugins/copr.conf /etc/dnf/plugins/debuginfo-install.conf /etc/dnf/protected.d/dnf.conf /etc/dnf/protected.d/setup.conf /etc/dnf/protected.d/systemd.conf /etc/dnf/protected.d/sudo.conf /etc/dnf/protected.d/yum.conf /etc/libreport/events.d/collect_dnf.conf [18:13:28 root@localhost data]#ll total 16 -rw-r--r--+ 1 root root 10 Jan 29 17:49 f1 -rw-r--r--+ 2 root root 4 Jan 29 17:49 f2 -rw-r--r--+ 2 root root 4 Jan 29 17:49 f2.link drwxr-xr-x. 2 root root 6 Feb 8 10:39 fdir -rw-r--r--. 1 root root 65 Jan 29 10:59 t.txt [18:13:31 root@localhost data]#touch a.conf 👈只要在find的命令键入的当前目录下创建a.conf [18:13:48 root@localhost data]#find /etc -name *.conf | head -10 👈就搜不到了 [18:13:51 root@localhost data]# [18:13:53 root@localhost data]#touch /etc/b.conf [18:14:02 root@localhost data]#touch /etc/a.conf 👈然后在/etc/下面创建a.conf就搜索到了 [18:14:05 root@localhost data]# [18:14:05 root@localhost data]#find /etc -name *.conf | head -10 /etc/a.conf [18:14:07 root@localhost data]# [18:14:07 root@localhost data]#touch b.conf 👈再在/data下创建b.conf，就报错了哈哈。 [18:16:14 root@localhost data]#find /etc -name *.conf | head -10 find: paths must precede expression: b.conf Usage: find [-H] [-L] [-P] [-Olevel] [-D help|tree|search|stat|rates|opt|exec] [path...] [expression] [18:16:40 root@localhost data]#rm -rf b.conf [18:17:32 root@localhost data]#find /etc -name *.conf | head -10 /etc/a.conf [18:17:34 root@localhost data]# find的裁剪，让我想到了vtp的裁剪 用裁剪prune，它的裁剪语法是组合逻辑的，不是很简洁 题外话 搜arp协议文件 搜文件大小区间(] -size 写10K，实际上是(9k-10k] 👆既然是(9k-10k]之间，那么8192就不在里面了，自然就搜不到了。 搜文件时间区间[) -size 👆这个线索可以拎出来，▲判断某个动作或者事件 带来了哪些影响，①比如yum history是可以回滚yum的动作(包括依赖，这是remove做不到的)；②就是这里的时间，我这一分钟内完成了用户的创建，于是我查看1分钟来产生的新文件-mmin -1就这些，所以八九不离十的 就是useradd 产生的。 权限搜索-perm xxx -perm /222的意思是三个人(所有者、所属组、other)只要有一个角色有写权限就匹配出来，本质是222 和 / 的组合，010 或 010 或 010 ，0是不关心，1是固定住，/是或的关系。 -perm 222的意思是只找出 权限为222的文件或文件夹 -perm -222的意思是010 且 010 且 010，三者都必须有写权限就行。 助记： -少就是且 /多就是或 要知道/以前等价于+ ，就是说+222等价于/222，只不过+不推荐了。 下面👇的理解过程是不是有问题，是的~！ 总结下 当/XXX都不为0的时候好理解：就是xx or xx or xx或者的关系，比如/222就是只要三者一个有写 当/XXX为101 001 010 反正只要有0出现，就意味着0不看，比如/202就是u和o两个中的有一人有写 注意/333表示u,g,o三者一人有写和执行？请看下例👇 ★是拆成二进制然后bit位之间或的关系 ★是整体111111111 9个bit位之间是或的关系，而不是u,g,o之间的关系。 [18:06:26 root@pyConsole test]#find -perm /333 👈表示111111111都是或 . ./f1 ./f2 ./f3 ./f4 ./f5 [18:06:32 root@pyConsole test]#find -perm /303 👈表示011nulnulnul011都是或，不看g，只看u和o . ./f1 ./f2 ./f3 ./f5 [18:06:34 root@pyConsole test]#ll total 0 ---x--x-w- 1 root root 0 Feb 9 17:45 f1 -rw-rw--w- 1 root root 0 Feb 9 17:45 f2 -r--r---wx 1 root root 0 Feb 9 17:48 f3 ------x--- 1 root root 0 Feb 9 17:56 f4 ---x------ 1 root root 0 Feb 9 17:59 f5 [18:06:35 root@pyConsole test]# ----------------------上面这段其实是后写的，下面的是梳理过程中的截图，保留供参考---上面的结论OK的---------- [18:00:21 root@pyConsole test]#ll total 0 ---x--x-w- 1 root root 0 Feb 9 17:45 f1 -rw-rw--w- 1 root root 0 Feb 9 17:45 f2 -r--r---wx 1 root root 0 Feb 9 17:48 f3 ------x--- 1 root root 0 Feb 9 17:56 f4 ---x------ 1 root root 0 Feb 9 17:59 f5 [18:00:22 root@pyConsole test]#find -perm /100 . ./f1 ./f5 [18:00:25 root@pyConsole test]#find -perm -100 . ./f1 ./f5 [18:00:27 root@pyConsole test]#find -perm /101 . ./f1 ./f3 ./f5 [18:00:29 root@pyConsole test]#find -perm /111 . ./f1 ./f3 ./f4 ./f5 [18:00:31 root@pyConsole test]# 分析 find -perm /622 的意思👇 上图错了，/622，不是必须6，而是110里面有一个就行了 哈哈，上图是最最开始的笔记，那会我就发现啦，哈哈，给自己点个赞👍。不过没有这一次梳理的完整。 所以回到一开始的PPT ① xxx就是精确匹配，000就是u,g,r三者权限都是---的文件，精确匹配不存在什么或，不存在0表示不关注的说法；倒是存在bit位的并且哦，哈哈~ ② 然后接下来： 2.1 /表示或，人家说了一位就是bit位，看到没，哈哈 2.2 0表示不关注，这个0说的是/303，里的这个0是十位数的0，哈哈(不对，这个0依然是二进制的0)，好家伙，PPT果然言简意赅，结果大佬就讲错了。 2.3 同样-xxx 人家也说了0表示不关注，然后是bit位之间的且。 2.5 一句话总结：/ 和 - 都是展开bit二进制后，0不关注，然后/就是或，-就是与。 ③ 我牛逼的地方来了哦，以上总结OK了到位了，问题来了，如果我要find 权限是rw?---rw?也就是707,606,607,706的文件捏，哦你要输入 find -perm -606 没办法了吧，哈哈，还不如这样 find 后的处理 👆上面的用法很危险。 重定向的>等于-fls -ok 的交互 但是是交互式的。 -exec的非交互 案例，日志处理 找到大于10M的，移动到tmp/下。 还是不行，因为还有子文件夹，//没关系的，不影响效果。 👆上图存在同名冲突的问题的。那样怎么做呢？遗留问题用⚪这个吧哈哈。 文章标识有▲、⚪、了★预留。⚪是微软输入法yuan第5个。 找到符合文件\\文件夹，然后整体(带路径)搬到某个文件里去 将上面查找出来的符合条件：1天内修改过的 并且 名字不是 . 的--这就去除了当前目录。找出来后，带路径复制到目标文件夹处。 但是上图要注意cp -a --path 才行，-a就是保证属性不变。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-02-02 14:47:36 "},"9-文本查找和压缩/2-文件压缩和解压缩.html":{"url":"9-文本查找和压缩/2-文件压缩和解压缩.html","title":"第2节 文件压缩和解压缩","keywords":"","body":"第2节. 文件压缩和解压缩 参数太多，一个个传进去 touch rm 等命令后面的参数都有上限的。 touch f{1..100000000}应该就会报错， xargs可以解决该问题 没有标准输入，怎么传给他比如rm 上图 ls是没有标准输入的，管道符是传不过去的，所以说它是错误的，不是说：+号过时了用/替代。 参数太长怎么办 利用xargs获取stdin来传给rm -f作为参数 ▲xargs是用来传参数的。 注意默认行为，达到一定长度就换行了 上图不是一个个传给touch的，而是一堆堆，大概是2000+一次传给touch，一个个传如下图 就是说 touch f1 f2 f3 这种一下创建多个文件，xargs 一行传过去也没问题，但是useradd xx yy 的yy生效的，所以需要换行。 创建10个用户 /7000，0不关心，7就是111，针对3个特殊权限有一个有就行 上图因为没有xargs传过去，所以就仅执行了ls -SL，验证下👇 find 后删除 上面是表面上合理，但可能有问题的。 特殊情况案例：单个文件名称位\"fa b.txt\"中间带空格。 观察上面报错，find 传给xargs后xargs默认是空格作为分隔符，所以\"fa b.txt\"就被判定位fa和b.txt两个文件了。 print0 是啥呢？是ASCII码为0，可不是十进制的0哦。 验证下-print0的分隔符为null的效果👇 这是txt的t后买那就是00(print0) -print0就是为了避免文件名带特殊符号。 第一个示例，是原地目录备份提好的，好在如果备份到其他地方存在子，子子文件夹不存在的情况从而报错的。要么复制其他目录就别带文件夹了，统统放在一个层级下就是不带{}的意思，这样又会存在文件同名的问题。详情见上一章节的文末内容。 练习 打包压缩 gz bz2 xz 3个主流 压缩要消耗CPU的，看你需求，你的磁盘空间大，你需要节省CPU消耗，就不压。空间换性能(时间) compress默认压缩后原文件就没了。 👆上图就是compress比较聪明，不给你压缩.jgp文件。同样👇issue根本不给你压缩。 compress是标准输入的信息进行压缩，完了屏幕上打印ctrl+d退出可见，可能存在乱码。 zcat直接预览 gz后缀用的多 也是压完，原文件没了。 gzip -d 一样的也是gunzip解压 压缩比 gzip也是标准输入形式，不过要带上-f 其实有没有标准输入都可以传的，有就用|，没有就用xargs。 当一个命令的标准输出非常大，比如数据库特别大就(压缩一下放硬盘里)，就可以使用gzip配合生成文件。 bz2 压缩比跟高 bz还是比gz的9级，压缩度还要高。 所以 看下两个压缩算法： 上图的-r是不是写错了，应该是-R啊？⚪表示疑问。 👇解是能解，但是不能tab补全 👇这次都不能解了 后缀很关键啊 gzip、bz2 、xz 三种压缩，网上比较多。 zcat看.gz和.Z；bzcat看.bz2；xzcat看xz xz 压缩工具 所以linux内核就是用xz xz 压缩和解压缩速度慢，耗时长。 理论上xz要强，但是数据量不大的时候，还不如bz2。 观察 这里都是有tar 结论：都需要先用tar打个包，再用gz，bz2，xz去压缩（这些工具只能针对一个文件去压缩，不能针对文件夹）。 打完包就是一个文件了，再压就行了。 zip打包和压缩 这个勾选，你感觉不到什么变化，该怎么用还是怎么用。就是读取的时候会自动压缩解压缩。NTFS有这个压缩功能。 zip在windows和linux都是一样的软件 adding：下面的明细etc前头是没有/的，就是担心将来你解压缩导致覆盖了/etc。目的就是让你解压到当前文件夹下。👈压缩的时候把/etc/变成了etc/，把/根拿掉了，防止你加压缩把根下面的etc覆盖掉了，所以给你变成了相对路径。 👆上面的压完后再看：白压了，越压越大了，哈哈，找原因： 因为把内存里的文件带上了吧？搞不清⚪存在问题。 前面sysconfig是压缩后产生的文件，会自动打赏后缀.zip的。 管道符的使用▲ 线索总结 这是解压后重定向到文件中。 原来是436K压缩后为93K 解压的风险，存在撑爆磁盘的可能 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:01 "},"9-文本查找和压缩/3-文件打包和解包.html":{"url":"9-文本查找和压缩/3-文件打包和解包.html","title":"第3节 文件打包和解包","keywords":"","body":"第3节. 文件打包和解包 传统公司还有用磁带保存数据的tap -cpvf 这个只是打包，没有压缩 c就是创建 v详情显示 f指定创建的文件名 p是保留权限，但是保留不住acl (联想到cp -p，不过tar的-p保留不住facl) 之前讲过备份acl的方法，，，恩，cp也能备份facl的--“第5节. FACL实现权限的灵活控制--文末”。 tar -cvf 的-可有可无，bsd unix风格 打包不会压缩什么的 t是预览 x是解包 也可以解压到指定文件夹 r是追加 打包且压缩 传统打包压缩 也可以合并起来 解压和解包 压缩格式是自动识别，J不用加 102M ---解开后大小--->930M 查看C代码一共多少行 到底花了多久呢 如此大的差距啊 sys不是系统空间是内核空间。 一些常见后缀比如tgz .**tar.gz 就等于 .tgz** 排除以及filelist 要打包的文件名统一放到一个文件里，↑ split切割文件 合并的方法 cpio不常用，老文件可能采用该格式 cpio也是个打包的，类似tar 预览可见，这其实就是一个小linux系统-虚拟的小文件系统。 i就是解包，d就是自动创建文件夹，解开后就是一个完整的操作系统 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:01 "},"10-文本三剑客2_sed/10-文本三剑客2_sed.html":{"url":"10-文本三剑客2_sed/10-文本三剑客2_sed.html","title":"第十章 文本三剑客2_sed","keywords":"","body":"第十章 文本三剑客2_sed Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:34:59 "},"10-文本三剑客2_sed/1-文本处理三剑客2_sed.html":{"url":"10-文本三剑客2_sed/1-文本处理三剑客2_sed.html","title":"第1节 文本处理三剑客2_sed","keywords":"","body":"第1节. 文本处理三剑客2_sed sed内置行为 Stream EDitor, 行编辑器 sed是一种流编辑器，它一次处理一行内容。处理时，把当前处理的行存储在临时缓冲区中，称为“模式空间”（ pattern space），接着用sed命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕。然后读入下行，执行下一个循环。如果没有使诸如‘D’ 的特殊命令，那会在两个循环之间清空模式空间，但不会清空保留空间。这样不断重复，直到文件末尾。文件内容并没有改变，除非你使用重定向存储输出。 功能：主要用来自动编辑一个或多个文件,简化对文件的反复操作,编写转换程序等 参考： http://www.gnu.org/software/sed/manual/sed.html sed就是用来解决我多地方dns文件的最佳实践，好好学。 sed命令内置特性，内置循环，内置一行行，和grep也是一样一行一行处理 内存空间在这里就叫模式空间 一行处理完 print，删除，第二行读进来，处理，print，删除，第三行继续 sed 语法 地址+命令， 地址就是哪行， sed '' passwd 👈这个就是内置行为的证明了，就是每行打印一遍 下面是脱裤子放屁的命令，是不是很吊~👇 2P- 只打印第2行 sed是读取标准输入处理的👇，有这玩意--标准输入，就可以利用管道；没有就利用xargs一样传！ 最后一行 tail -n1就行，sed 10 | tail -1或seq 10 | sed -n '$p' 在最后一行添加文本 sed '$ a xxx' /etc/passwd sed '10 a xxx' /etc/passwd 就是在第10行下面插入，$在这个位置就是最后一行的行号 sed '/nginx/s@xxx@zzz@' /etc/passwd 这就是查找nginx关键字的那一行进行替换，不同于上面的 第几行 定位。 下图最后一样是cli，上面的内容是cli的结果 正则匹配 基本上还是grep的等价命令。还没有体现sed的自己的活。 行的范围 显示3-5行 👆上图可以用来过滤出你想要的日志--几点几分到几点几分。 步进行-实现打印奇偶行 sed编辑命令-这个只是print的时候修改下，不修改原文件 d 删除模式空间匹配的行，并立即启用下一轮循环 两个sed👆其实可以合成一个sed来做👇，两次操作合并▲ 但是要注意下这个是不是真的就是两个sed合在一起，看下图👇就知道明显不是。 我觉得正确解释就是，针对处理内容，进行分号前后的两个命令的执行。这也是还原了最基本的逻辑。①👆针对/etc/fstab执行去注释;和去空行的动作②👇针对/etc/passwd执行了打印10行和打印20行的动作。你看有的就是两个sed合并，有的就不是，哈哈。神奇嘛，其实不神奇，就是一个常规操作在不同场景(一个描述在不同语境)里的不同解释。 一个是d删除操作，一个是p选择操作；删除自然两个动作可以用|管道符两个sed作为前后传参，说~哦，我一个文件删除这个再删除那个；而挑选的动作就是我针对这个文件挑选这个，再挑选那个。一个圆圈挖掉两个洞和一个圆圈取出两个洞，都是针对圈圈这个实体，但是挖掉两个洞和先挖一个后的结果作为后挖动作的输入是一致的；而一个圆圈取出两个洞，就不能说我取出的那个洞作为后取得输入参数，这就是逻辑上好玩地方，我希望我自己能把这些看似不好理解，但是实际是一会事得东西啊，有时间又机会琢磨透，世人常说转牛角尖，我很小的时候就想过很小很小10岁，小学吧好像，就说钻出来不就行了，哈哈，其实底层知识逻辑就是哲学了，换了个名字，世人就认了，世人是愚昧的。但是这样的人当前社会很难成功，因为给他的时间不够，他也要玩啊，哈哈哈哈哈~ 问：下面的[\\]是啥东东，答：答NM，是转义，举例 同样对原文件未做修改 如果想要改 sed修改原文件-i，为了安全推荐-i.bak 👆/^Listen/i listen 8080，这里你几个空格都没用，如果你要插入的字符前面带空额，就需要上图的 ​ /^Listen/i\\ listen 8080，转义下 注意c是找到行后，整行替换 sed另存为，之前是修改原文件或是备份，这个直接是另存为 👆注意d;w用;分开来，两次操作合并▲ a是追加文本，r是追加整个文件的内容，注意sed -r和上图的r不是一个东西哦。 其实就是位置+动作，位置就是/正则或者行号之类/ ，都工作就是这里的a也好c也好。 包含root行的行号 查找替换 这里和vim里面很像 sed -e 的用法-等价于上面的两次操作合并▲ 例子，找出IP地址 sed -r 是表示后面使用扩展正则，而sed /基本正则/ ▲正则 这里用到了分组()的概念 这个和py里的format字符串格式化一样。再合并一下整成一个sed命令👇 这个其实就等价于py里的rematch，而不是refind，而refind不用写全。rematch还需要写全。确实要用正则匹配全了，证明： 优化下 牛逼的是👆(())这种写法它能识别好。 例子，取消注释 先定位位置 上图是系统判定为/的用法，至少查找的//是占用了的。不行你猫猫看。 批量取消注释▲，这个vim里也有操作比如ctrl+v ,I, # 两下esc注意是vim不是vi。 例子，sed实现dirname和basename 例子，修改网卡名称为eth0，可能不对 思考这么对不对 sed -rn '/ .*linux/s/$/net.ifnames=0$/' /boot/grub2/grub.cfg 上面的显然不对，而且还多了一个$ 上图infname写错了改成ifname &就表示前面搜索出来的内容。注意下面的p参数拿掉，不然会将目标行复制2遍。 成功案例 [root@centos7 ~]# sed -rn 's/^[[:space:]]+linux16.*/& net.ifnames=0/p' /boot/grub2/grub.cfg linux16 /vmlinuz-3.10.0-1160.el7.x86_64 root=UUID=db575dcc-512a-4240-ab49-f3d41bc3e372 ro crashkernel=auto rhgb quiet LANG=en_US.UTF-8 net.ifnames=0 linux16 /vmlinuz-0-rescue-8173b565dc324c7180303567796b941c root=UUID=db575dcc-512a-4240-ab49-f3d41bc3e372 ro crashkernel=auto rhgb quiet net.ifnames=0 [root@centos7 ~]# [root@centos7 ~]# sed -ri.org 's/^[[:space:]]+linux16.*/& net.ifnames=0/' /boot/grub2/grub.cfg [root@centos7 ~]# ll /boot/grub2/grub* -rw-r--r--. 1 root root 4267 Feb 11 14:47 /boot/grub2/grub.cfg -rw-r--r--. 1 root root 4239 Jan 5 17:45 /boot/grub2/grub.cfg.bak -rw-r--r--. 1 root root 4239 Jan 5 17:45 /boot/grub2/grub.cfg.org -rw-r--r--. 1 root root 1024 Jan 5 17:45 /boot/grub2/grubenv [root@centos7 ~]# cat /boot/grub2/grub.cfg |grep ifname linux16 /vmlinuz-3.10.0-1160.el7.x86_64 root=UUID=db575dcc-512a-4240-ab49-f3d41bc3e372 ro crashkernel=auto rhgb quiet LANG=en_US.UTF-8 net.ifnames=0 linux16 /vmlinuz-0-rescue-8173b565dc324c7180303567796b941c root=UUID=db575dcc-512a-4240-ab49-f3d41bc3e372 ro crashkernel=auto rhgb quiet net.ifnames=0 重启后 [root@centos7 ~]# ip a 1: lo: mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: eth0: mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:b9:89:eb brd ff:ff:ff:ff:ff:ff inet 192.168.25.44/24 brd 192.168.25.255 scope global noprefixroute dynamic eth0 valid_lft 64705sec preferred_lft 64705sec inet6 fe80::4efd:3be2:da5a:12cb/64 scope link noprefixroute valid_lft forever preferred_lft forever [root@centos7 ~]# [root@centos7 ~]# [root@centos7 ~]# 然后再补一个这个：也不知道是不是上面需求擦头必须的： 或者 [root@centos7 ~]# cat /etc/default/grub GRUB_TIMEOUT=5 GRUB_DISTRIBUTOR=\"$(sed 's, release .*$,,g' /etc/system-release)\" GRUB_DEFAULT=saved GRUB_DISABLE_SUBMENU=true GRUB_TERMINAL_OUTPUT=\"console\" GRUB_CMDLINE_LINUX=\"crashkernel=auto rhgb quiet\" GRUB_DISABLE_RECOVERY=\"true\" [root@centos7 ~]# [root@centos7 ~]# [root@centos7 ~]# sed -rn 's/(.*CMD.*)\"$/\\1 net.ifnames=0\"/p' /etc/default/grub GRUB_CMDLINE_LINUX=\"crashkernel=auto rhgb quiet net.ifnames=0\" 这样👇更好，我找到不直接s///，而是先//再s///也就是/zz/s#xx#yy#m，因为/CMD/是找出这一行然后再查找部分字符进行替换，而s///可能就匹配的过多，理由不充分哈哈~还没没找到 [root@centos7 ~]# sed -rn '/CMD/s/\"$/net.ifnames=0\"/p' /etc/default/grub GRUB_CMDLINE_LINUX=\"crashkernel=auto rhgb quietnet.ifnames=0\" [root@centos7 ~]# 👇如果是直接s@@@，会全部行都直接换了 “部分” 字符比如s@CMD@zzz@， [root@centos7 ~]# sed -rn 's/\"$/net.ifnames=0\"/p' /etc/default/grub GRUB_DISTRIBUTOR=\"$(sed 's, release .*$,,g' /etc/system-release)net.ifnames=0\" GRUB_TERMINAL_OUTPUT=\"consolenet.ifnames=0\" GRUB_CMDLINE_LINUX=\"crashkernel=auto rhgb quietnet.ifnames=0\" GRUB_DISABLE_RECOVERY=\"truenet.ifnames=0\" [root@centos7 ~]# sed -rn 's/CMD/net.ifnames=0\"/p' /etc/default/grub GRUB_net.ifnames=0\"LINE_LINUX=\"crashkernel=auto rhgb quiet\" [root@centos7 ~]# [root@centos7 ~]# sed -rn 's/CMD//p' /etc/default/grub GRUB_LINE_LINUX=\"crashkernel=auto rhgb quiet\" [root@centos7 ~]# sed -rn 's/CMD/&/p' /etc/default/grub GRUB_CMDLINE_LINUX=\"crashkernel=auto rhgb quiet\" [root@centos7 ~]# s///是基于行去进行字符替换，//是找到这一行。 不加g，就是只处理每行第一个命中的，g加上就是行内所有都替换。 --------------- sed 中的变量要注意双引号的基本常识 sed自己可以👇这样，在单引号里使用变量 这是sed的自己的用法，比较少见。 存在这种情况 'xx'''$var'''xx\"xxx'，这样可以使用变量了，然后可不可以这样 \"xx$varxx\\\"xx\" 使用转义可以不，可以的吧，可以的 所以要啥自行车~，注意哦，下图三引号不是在sed里用的，是我在echo玩的，别搞混了，本段讨论的是sed里如何使用变量以及转义的双引号，哈哈。 然后上图的另一个点就是和sed一样，也支持单引号里表达变量 sed高级命令-多了一个空间 体现在sed内置的行为就是一个模式空间，高级就高级在多了一个保持空间 hold空间就是临时存一下 sed的强大之处还体现在高级命令及其保持空间。 hold住保持一会，待会取回来用。 模式空间里是可以放好几行的，D是删除一行，后续行就不删了。 sed高级用法的的例子 分析sed -n 'n;p' FILE ​ ①初始 ​ ②打印第2行 ​ ③读入第3行 ​ ④同理 ​ ⑤试试： 看sed '1!G;h;$!d' FILE 不是第一行就G，不是最后一样就删除，中间有G和h追加和覆盖操作，涉及两个模式空间 真要倒着写，tac就行了， 例子sed 'N;D' FILE 补充 linux每行结尾只有换行“\\n”， Windows每行结尾是换行+回车“\\r\\n” Mac OS 为 “\\r”。 用dos2unix file 活unix2dos file命令直接转换，有时候是最小化安装，所以vim里的方法也是要会的。 利用Linux下的vim，去除^M，去之前file看一下 vi xxx 然后 :set ff 用于查看当前文件是dos格式还是unix格式，显示如下： 切换为unix格式，然后保存即可： :set ff=unix #👈转换为unix格式 :wq 如果上图的格式不对，直接./xxx.py是找不到文件的，只能用python xxx变通运行，这里改成unix换行符后，就可以直接./xxx.py运行了。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-07-27 16:33:14 "},"11-软件包管理/11-软件包管理.html":{"url":"11-软件包管理/11-软件包管理.html","title":"第十一章 软件包管理","keywords":"","body":"第十一章 软件包管理 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:34:59 "},"11-软件包管理/1-软件管理基础.html":{"url":"11-软件包管理/1-软件管理基础.html","title":"第1节 软件管理基础","keywords":"","body":"第1节. 软件管理基础 ABI 应用程序二进制接口，API是开发接口 WINE，让linux上跑windows的软件 Cygwin，windows上跑linux的软件 预处理：去掉注释、打上行号、引用的文件(include代码)等放进来，等 编译：语法分析，错误，转成汇编代码 汇编：汇编代码还是文本，汇编之后就是机器码了，还要把库连接起来。这些库有静态和动态之分 静态：把库和二进制结合在一起，合成一个文件； 动态：程序运行的时候再寻找依赖库；不合并。 .so是shareobject 共享对象，好多程序会共用这个库 ldd可以看用的哪些库，不仅仅cat依赖这个库，ls也依赖。共同依赖的库 共用的库 .c源代码C语言写的---用gcc预处理成.i后缀---compilation编译成汇编语言assembly----汇编成二进制.o对象文件----link链接.a静态库----生成最终的一个文件。 动静优缺点 应用案例：注意通常我们都是动态链接的库，所以把一个二进制程序复制过去别的电脑上需要考虑把依赖的库文件也一并找出来复制过去。 JAVA号称一次编译，到处运行的底层思路： 1、存在本质上的两次编译 2、第1次编译，是编译成标准字节码文件 3、然后再各个系统上面预装了JVM java虚拟机，当字节码在这些JVM上运行的时候 就会再次编译一次。 需求产生了，降低使用开源软件的难度，直接给C，编译困难，就出来了debian版本 三大主流linux分支debian、redhat、slackware。 debian就率先考虑的需求，就帮你编译好，打好包，让你使用的时候自动的解包，dpkg debian package管理器，Ubuntu就是debian咯。 RPM GNU自己定义自己~八错八错~ linux-5.1.4 5是大版本号，1是次版本号，4是小版本号；大5-就是版本大变动，次1-就是小变化，小4-就是打个补丁。大概这么个意思。 rpm就是什么，就是开源软件，红帽拿过来打包整合的rpm包。所以包名的意思是 bash-4.3.46-19.el7.x86_64.rpm 包名和人家包自己的版本 19是红帽拿过来编译的次数 el7是红帽企业版7 x86_64CPU架构 神奇的文件夹/misc， 明明里面没东西，强行进入/misc/cd下就生成了cd文件夹，并自动挂载了光盘 后面补一个这个神奇的文件夹是什么来的，6上面可能自带的。7上面要想这么用，就执行systemctl start autofs systemctl enable autofs ;-安装方法要对--应该是server的套餐吧，反正最小化安装是没有这东西的。 在centos6和7上进到这Packages文件夹下，注意5和8都不叫这么名字好像，不管了8也不用了 用sed来弄 问题来了，什么用-n什么时候用p，怎么这里不用-n 和p呢，结果是对的。它这个上图的命令是已经对print的结果进行编辑过了修改过了，所以无需-n p，当然你加上-n 和p应该也是OK的 1、-n就是不打印了呗，全都不打印 2、xxxp就是你处理后的结果也要打印出来，如果此时前头没有-n就是说默认打印+处理后的打印 3、-n xxxp就是只打印处理后的结果 4、-n和xxxp 两个都不带，就是处理后的全文显示。 5、上图为啥-n xxxp和 都不带 效果一样呢，因为匹配了所有都能匹配到的，所以就一样咯。 ================================================================================ rpm包el6\\el7\\x86_64\\noarch\\i686 大软件 一般会拆包，挑着安装就可以比较方便。 这就是拆包分类 rpm安装的依赖只是直接的依赖包，间接依赖包不会显示，所以一眼看不见 --------------------------- lib64库文件 思考是不是cat命令就是用的/bin/cat文件，还是后面调用了C语言的库呢？ 再者so就是share object 很多二进制文件都是依赖一些共同的so库 例子-移动一个库及修复 可惜mv也是依赖这个库 然后图形界面也死掉了 修复要么快照，或者借助光盘 上面的关闭客户机这些本质上还是调系统的命令，下面的重置才是按电源重启。 重启也起不来了 重试救援光盘来解决 1、插入光盘，连着的 2、进度条出来后果断esc 3、选择3 CD-ROM启动 4、选择troubleshooting 5、救援系统 就是类似windows的pe，交换机路由器的RMON，类似这种最小操作系统。 6、进入后界面 因为是从光盘启动，所根不再是/了，而是/mnt/sysimage/ 你的系统被挂载到了/mnt/sysimage。你看到的文件系统是/mnt/sysimage这套 上图system写错了改成sysimage。 而我们要找的文件就在： 思考此时mv能用吗？ 因为用的是光盘里的mv，不是硬盘里的mv。所以是可以用的。 然后exit退出，自动重启就修复好了。 以上就是mv修复，下面是rm修复： 应该就在上面救援模式的/lib64下面有的。 lib64，库现在都是64位的了 学习包管理 一个RPM包里可能包含的东西比较多： 脚本的意义在于，你安装程序前先给你创建好用户，这样你才有所有者，所有组啊。诸如此类的信息。 前两行都有： 第三行的脚本不一定每个RPM包里都有。 RPM包不是安装好了就行了，还需要处理文件的属性信息存放便于后续查找。 数据库简单说就是文件夹，里面存放了安装rpm包的很多信息。如果没有/var/lib/rpm，你都不知道你安装了那些程序。也不知道哪些文件来自哪个包。 /var/lib/rpm的意义 比如安装软件，如果已经安装过了，就不会安装了，这就是到这里查找的。 有些官网提供了编译好的，有些就是提供源码给你自己编译。 操作路径 ppc是powerpc的，不用管 EPEL Fedora是红帽的上游测试版，dnf在Fedora 18版就有了。 然后现在centos-stream要取代centos8变成rehat的上游了。 ------- 配置 > /dev/null就可以实现静默安装。 一般warning看下，问题不大，是光盘里的，但是这里的告警是说验证来源是没有验证的。 signature是来源，其实就是公钥的验证。就是windows里的受信任的证书。 --- 选项放前面，这里习惯不好。 软件脚本安装的思路 之前装过了，这里查询的话只要写名称就行了 没装是这个样子的 我们-e卸载后再试试 ====== 或者查询某个包里包含哪些文件 是不是重新安装一些tree就行了 因为那个var/lib/rpm里有安装过的信息了，所以不会给你安装了，你说rpm -e卸载呢，不推荐，因为说不定之前都做过一些配置优化了。 办法也许可以，但通常不行，因为会全部覆盖的。方法还在下面往下看 replacepkgs和replacesfiles，就是只覆盖有的，没有的就安装。 replacefiles是只覆盖有冲突的文件。一般用在两个包一样但是版本不同，第二个包安装覆盖掉冲突的就是相同的文件就能正常安装第二个包了，同时第一个包的不同版本的软件可以自然可以使用同名的文件。 bash这个包基本就是随着操作系统安装而安装的，所以通过rpm -qi bash也能看到何时安装的系统 查看软件包的信息 上图中的官方站点可以去获取最新的版本 tgz就是tar.gz 如何只修复其中一个文件呢 利用cpio来解开rpm 利用cpio -tv查看文件列表 不过这样cpio解开的rpm再mv过去，有个问题，文件属性可能还需要注意一下。 据说类似于菜市场猪肉上面的蓝章。不过我想起来好像有红的。 默认就不具备完整性校验 先看下包里有没有脚本 -q --scripts 查看已安装的包 -qp --scripts 查未安装的包 将来如果是源码安装，就需要参考这些rpm安装的脚本来自己创建这些用户和组。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-12-28 10:41:06 "},"11-软件包管理/2-rpm管理软件.html":{"url":"11-软件包管理/2-rpm管理软件.html","title":"第2节 rpm管理软件","keywords":"","body":"第2节. rpm管理软件 rpm包升级 感觉，不会单单升某一个包吧，除非比较清楚依赖版本的限制情况。 -U也就是--upgrade，包没有就给你安装的，有就给你升级。 -F也就是--freshen，包没有就不安装，仅仅升级。 类似--replacekgs还有一个force，一个效果。 思考能不能安装两个版本的软件 windows的比如foxmail可以安装在不同的文件夹里，同时使用，无需关注注册表。 rpm包的话，除非名称都改一改，不然是不能共存的，很多都不能共存。 内核倒是可以的 可见kernel安装的文件绝大多数是带版本号的，所以可以并存的。 个别文件是冲突的，替代掉： 包查询 上图PPT有问题啊，cpio 的-i是解包，你都解包了，还和t预览个屁啊。 名字记不住，可以这样： -qa 加过滤的方法grep的regex和直接的通配符 两个不同版本的内核就有了 下面开始安装 强制安装 机器上存在两套内核， 计算机启动后可选择其中一套 如果要卸载就要注意 卸载哪个都可以，即使是当前使用的内核也可以的，因为linux加载到内存里了已经，而内核作为文件存在是可以删的。 重启后就剩一个内核了 查询文件来自哪个包 删除文件依然可以查，因为/var/lib/rpm下面有安装tree的文件信息的 如果卸载了就自然这些信息就没了 记一次VmwareWorkstation的光盘挂载问题和重启解决的经过 重新挂载光盘依然还是8.8G，还是不行。重启VM主机后，变为11G此时光盘挂载正常。后续rpm和cp正常。 查询包里面的文件。 ----------------------- 包里依赖文件叫做能力 上图查询的前提是已经安装完毕 上图是某个能力是由某个包提供的，而下图是哪些包需要这个能力 不安装包仅查询依赖的办法 yum可以查到这些依赖的能力来自于哪些包-不安装也能查询，rpm还做不到这一点。 不对，还有更直接全面的办法。 和依赖相关的能力的四个选项 包查询还有一些选项 ql就是全列出来 qc是列出配置文件 qd是看文档 bash提供了哪些能力，也就是哪些文件。 如果你安装了两个软件，卸载的时候想一起都卸了，可以考虑--allmatches。 rpm命令修复例子 查找rpm命令来自哪个包 所以进入救援模式 这样安装路径是不对的，如下 安装都是在/根下的 所以要以/mnt/sysimage为根安装 至此就修复好了 包校验-就是rpm觉察到包变化了， 对就是觉察到，用词就是这样的恶心。 恢复下上面的tree，怎么把上面的echo 弄进去的一个换行给去掉呢。 ----------------------------------------------- tree刚才被echo了一个换行，所以找到最后一行 删掉就可以恢复rpm -V tree检查 xxd🐖助记词，怎么改二进制 哈哈， 时间没办法，肯定改了，数据内容大小MD5都恢复了 查询所有包有无变化 包校验-来源性 导入这个验证工具--import，其实就是公钥。 导入这个验钞机实际上是放在了这个地方 检查某个rpm包的合法性-也是依赖于公钥的 公钥本地有，光盘也有的 缺少验钞机（公钥），只要安装完系统后，本地光盘上就有 修改一下验证 进rpm包里删除最后一行的回车 如果不转回去，则文件大小会差很多，且都不再是rpm包了 rpm数据库 上图初始化没有啥意义，因为你删掉/var/lib/rpm后系统也会自动给你初始化，但是安装的信息都没了。 yum就是python写的，依赖于rpm的，你把rpm的数据库删了，yum也就挂了。 rpm是单机命令，yum是c/s架构。 yum在client和server都要配置好。c和s通过网络互通，单机就是c、s在一台机器上。 光盘就是一个仓库 EPEL也是一个仓库 仓库的元数据metadata：rpm文件列表和依赖关系就是放到元数据里。还会分组-分门别类。repodata文件夹就是专门放元数据的。 仓库可能会叫做packages文件夹，也可以是别的名称 客户端要配置config文件 yum install httpd就是： 1、查询本地repo文件，看你配置的仓库 2、按照仓库配置的服务器以及对应的路径就是文件夹， 下载元数据到本地，将这些元数据下载到本地的缓冲区中（所谓缓冲区就是磁盘上的某个文件夹）。 去看元数据。是有httpd包的。而且依赖的包也找到。 3、针对httpd和依赖的包，去服务器上下载rpm包。也要放到一个缓冲区里。 4、安装。。。 5、下载完了的rpm包默认自动删除，而元数据不删。下载的东西有两个：元数据和rpm包。元数据下次就不用再下载了。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 16:08:58 "},"11-软件包管理/3-yum工作原理.html":{"url":"11-软件包管理/3-yum工作原理.html","title":"第3节 yum工作原理","keywords":"","body":"第3节. yum工作原理 在已经安装了autofs后，rpm -ql autofs，看下该包里的关键文件 以后看到 表示/usr/lib/systemd/system下面的都是服务。 基于光盘的yum源 autofs开启后就可以实现自动挂载光盘路径了，号称神奇目录：直接访问/misc下面不存在的文件夹就可以自动挂载。 为什么一定要这个目录呢，因为要当yum源必须有一个repodata文件夹。 当yum源的前提：路径下有repodata 只要看到repodata文件夹，那么其所在的文件夹就是yum源的目录。不要看packages那些。 yum repolist的本质 下载到哪里呢？通过yum.conf可见该目录 [root@centos7 ~]# cat /etc/yum.conf [main] cachedir=/var/cache/yum/$basearch/$releasever keepcache=0 ... 省略... [root@centos7 ~]# cd /var/cache/yum/ [root@centos7 yum]# ll total 0 [root@centos7 yum]# l. . .. [root@centos7 yum]# yum repolist 👈本质上就是把元数据的down到本地 Loaded plugins: fastestmirror Determining fastest mirrors * base: mirrors.cn99.com * extras: ftp.sjtu.edu.cn * updates: ftp.sjtu.edu.cn base | 3.6 kB 00:00:00 extras | 2.9 kB 00:00:00 updates | 2.9 kB 00:00:00 (1/4): base/7/x86_64/group_gz | 153 kB 00:00:00 (2/4): extras/7/x86_64/primary_db | 243 kB 00:00:00 (3/4): updates/7/x86_64/primary_db | 13 MB 00:00:00 (4/4): base/7/x86_64/primary_db | 6.1 MB 00:00:00 repo id repo name status base/7/x86_64 CentOS-7 - Base 10,072 extras/7/x86_64 CentOS-7 - Extras 500 updates/7/x86_64 CentOS-7 - Updates 3,411 repolist: 13,983 [root@centos7 yum]# ll total 0 drwxr-xr-x. 3 root root 15 Feb 14 12:06 x86_64 [root@centos7 yum]# [root@centos7 yum]# ll -R x86_64/ x86_64/: total 0 drwxr-xr-x. 5 root root 87 Feb 14 12:06 7 x86_64/7: total 8 drwxr-xr-x. 4 root root 278 Feb 14 12:06 base drwxr-xr-x. 4 root root 183 Feb 14 12:06 extras -rw-r--r--. 1 root root 84 Feb 14 12:06 timedhosts -rw-r--r--. 1 root root 473 Feb 14 12:06 timedhosts.txt drwxr-xr-x. 4 root root 183 Feb 14 12:06 updates x86_64/7/base: total 6376 -rw-r--r--. 1 root root 6351994 Oct 30 2020 6d0c3a488c282fe537794b5946b01e28c7f44db79097bb06826e1c0c88bad5ef-primary.sqlite.bz2 -rw-r--r--. 1 root root 156763 Oct 30 2020 a4e2b46586aa556c3b6f814dad5b16db5a669984d66b68e873586cd7c7253301-c7-x86_64-comps.xml.gz -rw-r--r--. 1 root root 0 Feb 14 12:06 cachecookie drwxr-xr-x. 2 root root 31 Feb 14 12:06 gen -rw-r--r--. 1 root root 546 Feb 14 12:06 mirrorlist.txt drwxr-xr-x. 2 root root 6 Feb 14 12:06 packages -rw-r--r--. 1 root root 3736 Oct 30 2020 repomd.xml x86_64/7/base/gen: total 30876 -rw-r--r--. 1 root root 31614976 Oct 30 2020 primary_db.sqlite x86_64/7/base/packages: total 0 x86_64/7/extras: total 256 -rw-r--r--. 1 root root 0 Feb 14 12:06 cachecookie -rw-r--r--. 1 root root 248733 Sep 3 23:22 db1c88508275ffebdc6cd8686da08745d2552e5b219b2e6f4cbde7b8afd3b1a3-primary.sqlite.bz2 drwxr-xr-x. 2 root root 31 Feb 14 12:06 gen -rw-r--r--. 1 root root 589 Feb 14 12:06 mirrorlist.txt drwxr-xr-x. 2 root root 6 Feb 14 12:06 packages -rw-r--r--. 1 root root 2998 Sep 3 23:22 repomd.xml x86_64/7/extras/gen: total 1296 -rw-r--r--. 1 root root 1326080 Sep 3 23:22 primary_db.sqlite x86_64/7/extras/packages: total 0 x86_64/7/updates: total 13736 -rw-r--r--. 1 root root 14049533 Feb 9 04:02 c96f20635c7f289398519818a077b294f1855722181378b5105f5ef49f0cf57a-primary.sqlite.bz2 -rw-r--r--. 1 root root 0 Feb 14 12:06 cachecookie drwxr-xr-x. 2 root root 31 Feb 14 12:06 gen -rw-r--r--. 1 root root 589 Feb 14 12:06 mirrorlist.txt drwxr-xr-x. 2 root root 6 Feb 14 12:06 packages -rw-r--r--. 1 root root 3011 Feb 9 04:02 repomd.xml x86_64/7/updates/gen: total 75048 -rw-r--r--. 1 root root 76846080 Feb 9 04:02 primary_db.sqlite x86_64/7/updates/packages: total 0 [root@centos7 yum]# yum clean all 👈这下理解到位了，清的哪里，就是这里 Loaded plugins: fastestmirror Cleaning repos: base extras updates Cleaning up list of fastest mirrors [root@centos7 yum]# ls -R x86_64/ x86_64/: 7 x86_64/7: base extras timedhosts updates x86_64/7/base: gen packages x86_64/7/base/gen: x86_64/7/base/packages: x86_64/7/extras: gen packages x86_64/7/extras/gen: x86_64/7/extras/packages: x86_64/7/updates: gen packages x86_64/7/updates/gen: x86_64/7/updates/packages: 也可以用du -sh /var/cache/yum验证可见大小为0 yum clean all，如果你修改yun源后不清理，就是照着就得yum源那会的yum repolist下载下来的元数据缓存去找rpm包的。所以要清一下的。 yum的问题主要就2个，①路径写错了②缓存没清。你别跟我讲rpm数据库删了。③/etc/yum.repos.d/下面只要有一个repo文件不能用就会影响所有的repo源。 下面是将base源和epel源合在一起讲的： 上图👆是epel的alias 快速启用和禁用。主要是考虑安装rpm包的时候，不让他再去找epel，因为base是再本地的，而epel在网上，所以即使你安装base也会去epel找一遍，浪费时间的。不过yum 本地仓库其实是将base和epel都拉下来的，所以实际工作中base和epel都是内网本地的仓库。也无需禁用epel。 👆上图是将base源和epel合在一个.repo文件里的，也可以分开来，将epel单独做一个epel.repo文件。 这两个应该是从上往下，能走哪里走哪个。 下图是key的写法 key启用后的第一次安装rpm包，会问你是否导入key，👇下图， 然后后面再安装其他rpm包就不会问你了。 YUM出问题就两个：①配置文件以及路径问题，②缓存清一下 比如要安装sl这个小火车，就要删除yum仓库，清除缓存，安装yum源，epel源，比如centos8 https://developer.aliyun.com/mirror/centos?spm=a2c6h.13651102.0.0.23961b11BCsMUT yum cleall all yum makcache yum updata https://developer.aliyun.com/mirror/epel 安装会自动给你安装依赖，那么卸载是否会自动卸载依赖包呢 默认不会自动卸载依赖包的，因为可能别的包也会依赖这些依赖包。 yum list可以看到安装历史 实际上yum安装的时候也有自己的log，👇 Centos8就是dnf.log yum history info 11可见当时做的事情，比如command line install mariadb-server。 把这个事件撤销 undo就是卸载掉 这样就卸掉了，然后看下yum事件，卸掉了10个包Altered 如果你又不想卸了，还可以yum事件回去 redo就是重装一遍。 baseurl还有一个mirroslist(这个后面讲) baseurl可以写多个，如下👇图： 写多个baseurl，都生效， 上图是光盘禁用后，走的网络yum安装的。但是这多个baseurl，优先用谁呢？答案还是在上面的PPT里：failovermethod={roundrobin|priority},cost的值越大优先级越低。 然后是yum的baseurl的4种路径： yum仓库的内置变量 自己写脚本，里面的yum源可以使用多行重定向来写，👇▲脚本惯用手法-cat多行重定向写文件内容。 别忘了别名、vim、history格式、PS1、yum源。 yum list就列出了这1w多个包，一共就是1w多行： yum 看到已安装的包是@打头 anaconda是操作系统安装向导的时候安装的程序，所以yum list不仅看到哪些已安装，还知道从哪装的，①比如anaconda②还有base仓库③epel等其他仓库。 这两个包是base仓库创建后，利用yum安装上去的。 比如，下图👇其实查看已经安装的可以yum list installed更快，必进grep要CPU计算的。 也可以用yum search http 上图，说的是搜索的包名，前提你的知道包名， 包名不知道咋办？以httpd为例，先卸载掉👇 整体卸掉包含之前yum install的所有东西，就需要查案yum history info NUMBER，见到httpd就行。 然后undo就行 上图提示的是依赖的文件名，而不是包名 找到依赖的文件来自哪个包 -qf必须已经安装了的文件名；-pqf后面必须跟包名，package；不对，换方法： 这里注意 yum search 和 yum provides 的差异，provides更胜一筹啊看来~ 查找文件由哪个包提供。这种方法一般也就是用在没有yum源的情况下，自己把依赖准备好，放一起，走哪都yum -y install *rpm就行了。 list查所有的、已经装好的，可用的available-就是未安装的。 yum list 默认就是yum list all yum repolist是将仓库的元数据down下来，同时给你list列出来，不过是针对启用的仓库，加上all就是关掉的也会列出来： yum provides 后面可以是某个文件的，也可以是依赖包。相当于既有了-qf的跟文件能力，也有了-qpi的跟包能力。 👆上图就是展示了怎么rpm查询/bin/tree来自于哪个包。 yum的reinstall和rpm --replaces和--force一样咯。显然不一样，yum的reinstall还带依赖的。 红色框框里的常用，其他不怎么用了，使用yum yum info 类似于rpm -qi rpm包也是yum安装的。需要依赖也会自动给你安装的。 尽量还是不要升级包。 还有centos6不会升级到7，而是重装成7 注意update和upgrade的区别就是没区别 https://cloud.tencent.com/developer/article/1375013?from=article.detail.1604418 update If run without any packages, update will update every currently installed package. If one or more packages or package globs are specified, Yum will only update the listed packages. While updating packages, yum will ensure that all dependencies are satisfied. (See Specifying package names for more information) If the packages or globs specified match to pack‐ ages which are not currently installed then update will not install them. update operates on groups, files, provides and filelists just like the \"install\" command. makecahe一般不需要用 因为，第一次使用过yum，就自动makecahe了 这样一下yum的缓存也就有了。 总结： 这是查这个包依赖哪些文件，然后这些文件又是由哪些包提供的--这就需要再次yum deplist xxx了，比如上面的bash Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-12-29 17:12:16 "},"11-软件包管理/4-实现yum源仓库和使用yum管理软件以及dnf.html":{"url":"11-软件包管理/4-实现yum源仓库和使用yum管理软件以及dnf.html","title":"第4节 实现yum源仓库和使用yum管理软件以及dnf","keywords":"","body":"第4节. 实现yum源仓库和使用yum管理软件以及dnf 定下来学某个东西的时候，就要摸清楚来龙去脉，这样比较对得起人这种动物它这个脑部、神经、心跳节奏的规律。否则不舒服的，我在试图理解底层心理学？显然这是不对的，感觉对了就好。 配置内网的YUM源 yum -y install httpd 安装httpd服务，通过光盘镜像安装就行（各种rpm包，和yum仓库-repodata元数据） 通过rpm -ql 查看安装的文件 systemctl start httpd 目录结构 所以就是/var/www/html/centos/7/os/x86_64 把centos7的安装光盘整个目录复制过去，也可以挂在光盘的。 再接一个CENTOS6的 把对应的光盘挂过去-工作中复制过去 临时挂用命令mount就行 centos6的也有了 yum源就OK了。 服务端就配置好了，下面开始配置CLIENT 只要不是repo后缀的就不会干扰repo源。 验证可以不写，写的话也很简单 这就是校验文件，赋值一下路径 搞定，当然上面的6也可以用$releasever替代他 测试下 这里注意下，6713个包的解释：我们就挂了一张盘，但是6K个包是两张盘的总量，可能就是第一张盘里有两张盘的包总量信息。然后一些偏门的包在第二张盘里，你是安装不了的。 以上就是基于HTTP协议的yum源 如果没有光驱-显然基本都没有，就用iso文件去挂 光盘可以挂，ISO文件也可以挂 然后web看到就成功了 但是前置条件别忘了：selinux和防火墙 还有客户端 其他补充 mirrorlist是把多个路径写到一个文件里 现在这个机器可以指两个源，准备添加一个网上的阿里源： 复制远端路径 把上面的txt路径一复制，贴到下面去就行了。 搞定了 不信可以看看centos默认的yum源写法，他也是用的mirrorlist的。 包组的管理用group group分为环境组和普通组，环境组就是安装系统的时候让你选择的包--老王使用的事GNOME Destop，老刘使用的是Server with GUI，俺使用的是Minimal Install。 你选择某一种比如Serer with GUI就会对应地安装很多包。 开发包组里的包 \"Development Tools\"注意引号，否则当作两个包组了。 强制组、可选组 不是随着group包组安装的，是随系统安装的。 不同符号不同状态 groupinstall可以连起来写 工作中一般不用包组group，都是需要什么安装什么，group里的东西可能太多了。 yum 的脚本安装可以加上-q --disablerepo和--enablerepo没有试验成功，不知道咋弄的，不过我倒是可以用sed 来开关。恩，也不常用。这么用的，临时的，所以是要配和install xx一起用的 创建自定义的仓库createrepo-其实就是为一堆rpm包生成元数据。 仓库虽然说要rpm包和元数据以及公钥，但实际上站在机器角度，仓库其实就只要一个repodata文件夹和里面的元数据。 自己研发的rpm包，或者网上找的单个rpm包，没有现成的仓库，或是就算你down的是常规的rpm包，但是仓库没down，也可以自己生成。这个题外话参考别人的博客https://www.jianshu.com/p/3b669bcebfb6 👆这样仓库的元数据就有了。 但是有个问题 httpd要开启443 仓库路径得找repodata的路径。 如图是在server下的，而其他的分别是集群、集群存储、server、虚拟化的repodata 多个repodata就是多个yum源。如果你不需要就配一个yum源就行了。 上图👆两个点①cat 重定向写法ctrl + d安全退出才行②baseurl的路径是repodate的pwd路径。 DNF dnf比yum的优势据说就是速度快 推荐yum install *.rpm因为包可能不全，还需要依赖。 这样就可以用dnf了， dnf的使用和yum一样 仓库配置也是一样yum的配置文件。 比较下dnf的性能 = = 效果不行啊，哈哈 time dnf reinstall httpd -y time yum reinstall httpd -y 这个可以看到dnf快些，可能。 yum其实是python写的程序 yum底层就是依赖于rpm的 小软件编译举例 上图gcc hello.c 回车，会自动生成一个a.out。注意上图不是一个命令哦。 指定一个名称-o 将来要编译的软件必然不是一个c文件咯： 看看这个httpd的源码有多少个c 解开的文件里有284个c文件 gcc 能搞定吗？还有编译先后顺序的。所以就不是gcc这种方式了。 那是项目了，项目管理工具了，不同的语言编译工具不一样。JAVA用maven。C语言里make Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-12-30 16:18:45 "},"11-软件包管理/5-编辑安装httpd2.html":{"url":"11-软件包管理/5-编辑安装httpd2.html","title":"第5节 编辑安装httpd2","keywords":"","body":"第5节. 编辑安装httpd2 理解源码安装 很多较新的版本，光盘里是没有的，这就需要自行到官网下载源码进行安装（官网提供的软件通常就是源码的）。 源码理论上是通过gcc从源代码-->预处理-->编译-->汇编-->链接--最终生成二进制然后执行起来。 但中间过程源码多、不仅仅源代码 还有各种文档 配置文件 说明等，这些文件你放在哪 手动拷贝工作量巨大，所以针对发布的源码 都会有一个官方的 源码编译的项目管理工具 + 配合脚本。 C一般是make这个项目管理器，把软件作为项目统筹管理。利用make里的项目管理功能便捷的部署源码。大概步骤有3： ①创建makefile文件 ​ 这个makefile就定义一些必要信息：各种文件的安装路径（二进制文件放在哪里、配置文件放在哪里、man帮助等分门别类 也可以不分同一个一个总目录放进去 各有各的子目录，这点和yum截然不同了，yum安装时自动给你安排好了，而源码得自己指定安装路径） ​ 为什么要源码编译呢，其中一个原因就是，功能定制，比如源码内置100个功能，如果你是yum或rpm安装，yum的底层也是rpm，官方给你编译完了，官方觉得50个功能是常用的，就给你把这个50个功能编译在了rpm包里，剩下50功能就用不了了。或者生产环境场景单一无需已启用的50个功能这么多，所以就需要定制化。 ----所以就需要把哪些特性功能 放到Makefile里。 ​ 所以makefile尤其2点：安装路径、启用特性。所以configure 后面启用功能的参数就可能很长，cli就会很长了。 ​ Makefile手动写不现实，也是使用工具configure脚本 借助Makefile.in(Makefile模板文件)来生成。 ②利用C语言的项目管理工具make 自动读取Makefile的内容，进行后续工作（编译） ③利用make install 将编译后的文件复制到指定的路径，就是安装动作。 然后configure脚本也是通过autocnf生成的，Makefile.in这个模板也是通过automake生成的。这里不用管，源码下载下来configure脚本和makefile.in模板都是自带的，开发人员做好的。 ./configure要进到当前目录运行的，不然可能人家的代码里写的都是相对路径，会存在问题的。 还有一点./configure的时候会检查依赖，所以会报各种错误，然后工程师就更正错误，补上对应的包，然后再回过来继续./configure。 上述的./configure , make , make install 三大步是通用的，但是每个软件各有特点，所以还需要参考install 和readme里的说明。通常源码解压缩后也会有这两个文件。有时候把install里的东西拿出来复制粘贴就直接执行就行了。 所以源码安装就是上面那回事，easy~，源码安装说的是安装，又不是让你写源码，哈哈，难不成让你跨行理解还是执行吗，no way~。不要有畏难情绪，不要有什么都敢尝试的莽撞。 源码安装tree 上图👆可见tree这个工具-ql就是安装的所有文件了，除了/usr/bin/tree其他都是文档了，不重要。 很多软件都是这个cli格式xx -V yyy --version这种查看自身版本的方式。 右键得到下载链接后使用wget下载 REAME里没啥东西，看看INSTALLL 上图👆说了它这个源码的Makefile是适合各种OS的，但是需要你改一改设置。 CC=gcc，编译器是gcc tree编译后的二进制文件放在/usr/bin下 MAN帮助放在了/usr/man/man1下 默认是linux的。需要什么OS，就取消哪个模块的注释。 源码安装的不要了，只能手工删除 看看install说明，就是常用的make 这和CPU核数有关。多线程 大量的文件才需要-j并行编译。 其实这个时候已经就能用了 当前的tree 1.6和安装后的tree 1.8共存了， 修改PATH变量 你希望tree 1.8执行而不是1.6，所以就要把1.8的path路径放到/usr/bin的前面 这是自己在这些特殊文件下创建的env.sh 上图👆有个sb的操作，就是PATH='/apps/tree/bin:$PATH'，不信你试试，回头vi都用不了，只能/bin/vi编辑。 退出一下shell使之生效 大软件和小软件 大软件是长期站着内存在系统中运行，小软件就是简单的各个选项用的时候就加载一下内存run一下就好了。 而大软件长期运行，就需要把一些设置存到一个配置文件中，下次再用的时候自动就加载配置文件里的一堆配置。 编译安装一个大点的软件httpd 这是光盘自带的2.4.6👆 这是官网下的2.4.25（用这个简单点来感受下编译安装）。2.4.39难度较大。 1、tar 解包 这次发现和tree不一样了，有绿色的configure脚本了 有这个configure脚本，就没有Makefile文件了，因为这玩意就是configure生成的。自然也就有Makefile.in文件了，in就是模板。 参考Makefile.in模板利用configure脚本来生成Makefile文件。 看看readme，也没啥用 看看install ./configure --prefix=PREFIX就是跟了个路径，安装到什么地方。 然后./config需要些指定一些配置：①安装路径指定好，②哪些特性启用哪些不启用。 如上图不写就是默认安装在/usr/local/apache2 然后再看下特性的启用： enable 或 disable 特性 然后开始执行./configure生成Makefile文件 这就制定了安装的总文件夹，和配置文件的存放地点。而且这些文件夹是 不需要事先有的。 需要enable说明默认是未启用的，需要disabled说明默认是启用的。这话对不对哦？⚪疑问 后缀很长建议这么放 我们编译工具之前已经安装了gcc，但是这些特性启用可能还需要依赖 好，下面开始一步步检查和拍错 记住咯，一般提示XXX not found，就是需要XXX.devel这个包，所以需要的就是apr.devel。缺什么就加devel，通常对的。 继续./configure go on 。。。 继续./configure --prefx --xxx 这次依据惯例，使用mode_ssl-devel是没有的 仔细观察上图，提示OpenSSL version is too old 继续 MD，上图我还以为是打了个叉叉，几个月前写的了，现在梳理突然第一眼没看明白，哈哈。是成功两字哦呵呵~。 所以httpd的依赖包列表如下 上面就可以写脚本了~，部署就很快乐~ 字词configure编译完了，就会生成Makefile文件 这个图的步骤在cat install里一样看得到 然后make -j 4 可能是和CPU核数对应的。 我们来复习编译的安装路径 最后一步makeinstall复制文件 主目录/apps/httpd24，配置文件/etc/httpd 这就安装好了，那么就要使用了 每次写路径比较麻烦，所以还是写到PATH变量里去 启动： 这种开机自启动的方法：它又不是sytemctl enable xxx 这种大的软件且是持续运行的就是叫做服务。而不是一次运行的程序。 reboot后测试一下： 以上过程可以写成编译安装的脚本。 下面再装个小软件-黑客帝国的既视感哈哈~ ll 看看 README，看看INSTALL 可以通过./configure --help查看安装路径选项 和 特性启用选项 curses.h，是缺少curses的头 这个头由什么文件提供的呢？ 改为模糊搜索 这个搜到的东西太多了，不仅仅是提供该关键字的包，还有文件，不是一目了然。 或者搜包名这种好一点： 可见是叫ncourses 错误是courses.h安装晚了，应该是configure之前装好的。此时需要make clean一下。也可以把这个目录删了，重新tar xvf解压 重走一遍configure 再make👇： 所以还是删除整个文件夹 脚本写好后，放到网站上，这也是一个常见操作 要想执行往bash里一传就行了 所以将来，你把一键安装脚本放到http网站里面，然后，随便找个机器这么一执行就本地安装成功了。 ★这是个法宝啊 复习下 Ubuntu软件管理 .deb类似.rpm包 dpkg 类似rpm安装 APT类似yum du -sh *查看所有文件和文件夹大小 这就可以看到.deb后缀的包了 dpkg -i xxxxx 安装即可。 -l列出了所有安装的包类似rpm -qa 上图的这个大箭头挺抽象，几个月后也半天(5s)才看明白， 类似于rpm -ql centos如果是minial最小安装，后来又想要GUI，于是可以安装一个包组GNOME。 带空格和不带空格的区别：是grouplist[空格]不是group[空格]list 这个如果你最小安装tab不出来的哦。 16.04以后apt基本整合取代了之前的3个。 但是这个虽然是CN的网站，但是还是不快，所以很多人都替换成阿里的。 类似centos的GNOME的ubuntu里叫ubuntu-destop yum list installed也能看，但是不知道是哪个 友情提示，yum 安装的过程种或者脚本执行的过程中，等等如下图👇 不要敲任何键盘，否则后果比较危险，证明👇 等10s后就发现 复习 补充： tree 编译安装的其他问题处理记录 root@vpn tree-2.0.2]#make gcc -O3 -pedantic -Wall -D_LARGEFILE64_SOURCE -D_FILE_OFFSET_BITS=64 -c -o tree.o tree.c In file included from tree.c:20:0: tree.h:63:1: warning: C++ style comments are not allowed in ISO C90 [enabled by default] // Start using PATH_MAX instead of the magic number 4096 everywhere. ^ tree.h:63:1: warning: (this will be reported only once per input file) [enabled by default] tree.c:47:1: warning: C++ style comments are not allowed in ISO C90 [enabled by default] //off_t (*listdir)(char *, int *, int *, u_long, dev_t) = unix_listdir; ^ tree.c:47:1: warning: (this will be reported only once per input file) [enabled by default] tree.c: In function ‘main’: tree.c:100:3: warning: ISO C90 forbids mixed declarations and code [-Wpedantic] bool needfulltree; ^ tree.c:124:29: warning: ISO C90 forbids compound literals [-Wpedantic] lc = (struct listingcalls){ ^ tree.c:138:3: warning: ISO C90 forbids mixed declarations and code [-Wpedantic] char *stddata_fd = getenv(ENV_STDDATA_FD); ^ tree.c:145:33: warning: ISO C90 forbids compound literals [-Wpedantic] lc = (struct listingcalls){ ^ tree.c:263:30: warning: ISO C90 forbids compound literals [-Wpedantic] lc = (struct listingcalls){ ^ tree.c:271:30: warning: ISO C90 forbids compound literals [-Wpedantic] lc = (struct listingcalls){ ^ tree.c:279:30: warning: ISO C90 forbids compound literals [-Wpedantic] lc = (struct listingcalls){ ^ tree.c: In function ‘usage’: tree.c:659:2: warning: string length ‘3348’ is greater than the length ‘509’ ISO C90 compilers are required to support [-Woverlength-strings] \" -- Options processing terminator.\\n\"); ^ tree.c: In function ‘patignore’: tree.c:668:3: error: ‘for’ loop initial declarations are only allowed in C99 mode for(int i=0; i 上面error说这个只能用c99编译，结果你的MakeFile 注意，在我的一台centos8里是CC=gcc，没问题的，但是在另一台centos7里，报错c99， 网上搜了下，说gcc默认是使用c89，然后我rpm -ql看了一下 果断修改Makefile里的CC=c99就好了，不明觉厉~ 所以不管怎么说，人家要c99就给他c99好了 改成 再次make就好了 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-01-04 16:23:02 "},"12-磁盘存储和文件系统/12-磁盘存储和文件系统.html":{"url":"12-磁盘存储和文件系统/12-磁盘存储和文件系统.html","title":"第十二章 磁盘存储和文件系统","keywords":"","body":"第十二章 磁盘存储和文件系统 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-03-31 16:26:33 "},"12-磁盘存储和文件系统/1-磁盘工作原理详解.html":{"url":"12-磁盘存储和文件系统/1-磁盘工作原理详解.html","title":"第1节 磁盘工作原理详解","keywords":"","body":"第1节. 磁盘工作原理详解 设备类型 一般将数据存到文件里，就是说的存到磁盘上了，不要较真说proc也是文件，你存到proc里就是存到内存里。 通常这里理解：1-存文件-存盘，2-生效-就是在内存里运行 块存储是一块一块（比如512为一块单位），当你读到内存里必须是块为单位512 512 地去取，，cpu就可以1bit1bit的处理了。 数据的访问时随机的，块设备的读取，你打开文件就是随机的一个数据，你也不知道存在哪里位置。怎么可能不知道具体在哪呢，inode是吃干饭的啊。 随机的意思是和顺序相对的，块设备和字符设备，一个是看磁盘空间空闲块，然后这些inode快bitmap是空的，然后就可以用来存放数据了没有像磁带那样的一个顺序读取，而是指针地址读取。写还有一定意义上的随机性，读可没有哦。 磁带就不能跳过，只能顺序的快进。 光盘可以跳过，也实现了随机读写 块有缓存，因为是随机的，所以将数据缓存了， 光驱和硬盘里面都有缓存，提供读取效率。 字符设备，比如键盘，就是一个字符一个字符的输入的，且是按照顺序的。字符设备没有缓存~ 块设备要么硬盘、要么光盘 其他都是字符设备，比较多 下图👇是字符设备 这两个数据表示的是设备的类型，8类型，第5个。类型下的编号。 如果两个数字相同，就判定为同一个设备，并不看名称。 比如，构建一个光盘 11 0 创建一个同样编号，名称不一样的 mknod 创建设备 创建了光盘，然后将这个/dev/sr0同类型同编号的设备/dev/cd就是光盘了，挂载到/mnt，可以看到mnt下光盘内容了就： 不同接口命名不同 https://blog.51cto.com/u_12958700/1933385 并行理论OK，但是电磁干扰没办法目前，所以串行才是优选。 redhat 5 添加IDE硬盘 centos 6上加普通的SCSI硬盘 加了好几个 题外：家里搞个NAS？貌似这这样玩的。 上图IDE口在red5红帽5的显示： 除了IDE接口的都判定为sd---这是老的红帽5的做法👆 centos从 6 开始就不一样了，不管是什么接口的IDE SCSI SAS的MVNE的都是sdxx同一个命名 但是工作中不一定是物理介质，还有阿里云等，云服，虚拟机可能是dev/vd /dev/xvd xvd一般是zen虚拟化技术，vd一般是kvm的。 如果是1就是机械，如果是0就是固态--适用于物理机--虚拟机不能这么判断 sda就是第一块硬盘， sdb就是第二块硬盘 sdaa...sdaz sdza...sdzz就这么排下去。 机械盘才是旋转的，所以是1 当然这种方法只能看物理机上的情况，如果是虚拟机就不行了。 MBR方面：单块硬盘最多4个主分区（可以没有主分区），多块硬盘只要有一块有主分区，其他可以全部都是扩展分区， 扩展分区不能直接使用，需要再次创建逻辑分区才能使用。 主分区不能再继续划分成小的分区了，就是独立使用的。 注意sda4是一个扩展分区，下面的所有sda5 sda6（如果继续分的话），都是属于sda4扩展分区的一部分。 这个1K不是真的是1K，只是显示效果。扩展分区不能存数据，所以这里判定为1K，可以用fdisk来看真实大小 上图的红圈是起始位置，还有后面的结束为止，在 centos7里，起始位置和结束位置是以扇区为单位。从start扇区开始到end扇区结束(扩展分区里面分出的小逻辑分区一定是在这个扇区316672000-419430399内的--也就是sda5在sda4扇区里面的。)，Blocks的值是它的真正大小。而1block是1K。所以上图的扩展分区就是50G大小的容量。 sda5就是4G的大小，还剩下40G+的空间未使用。 51379200单位是block，1个block是1kB。这个其实也是扇区512B/1024自然就是kB了。 然后1个block就是2个扇区，读取是整数倍也就是blocks是吧 ------ 这是centos6的，对比上面的7的发现，6比7多了Heads和cylinders。下面开始介绍硬盘结构，从来了解这些现象。 友情提示，硬盘是密闭的，不是真空的~真空早就压扁了。当然你要说是那个真空我也无话可说。 PS：数据是左上图框选的地方放一点，右上图框选的地方放一点，所以要读出来，磁头就要换道了。比如从内圈读完换到外圈，那估计盘片就转走了，就不是同一个扇面了，要等下一圈了就。 磁头换内外圈，就会影响速度了 硬盘的转速就是体现出来速度了。 磁头正反都得有，因为盘面就是正反的 不灵活，整体旋转的。 盘面数=磁头数 不可能是255个磁头，100多个盘片？物理上没这么多，这个head是逻辑上，早期确实就是这样的，后来保留了这种表达方式。 最外圈是0磁道，往里圈编号。 硬盘属于块设备，组织硬盘空间不是一个磁道来整合的。磁道切成一块块扇区。 早期扇区划分(就是在磁道上划分)是同心圆划分的，内外磁道的扇区数一样。这是早期的划法。 一个扇区的大小512字节固定的，整个硬盘要存放更多的数据，就要划更多的扇区。 上面的扇区划分，内圈磁道太短，存放数据有限，随着磁盘密度增大，内圈逐渐可用度越来越差。里圈以达到了工艺极限单位面积存放数据越来越多，但是外圈仍然富裕。同心圆的划分就不行了。 为了解决内圈拥挤外圈富裕的问题，所以产生了下面的扇区划分方法。 拽个名词ZBR zbr 区位记录 法 磁盘扇区划分 这种外圈和里圈放的扇区数量不一样了。 磁头放在外圈数据读取块，放在里圈读取慢。 数据放外圈处理就快些(怎么放外圈啊？⚪)，将来优化系统性能的思想。这是现有的硬盘基本都用ZBR划分的。 如果早期磁盘内外圈速度一样的。 通过磁道来识别外圈还是里圈，0磁道在最外圈，不过实际操作种你看不到磁道号吧，应该都是扇区号。 其实有N个0磁道，和N个n磁道：👇下图有6个0磁道，6个1磁道，6个. . . 所有的0磁道，1磁道，2磁道。。。都是各自组成了柱面 8bit来表示head 255个磁头heads的上限，0不用； 10bit来对应track磁道，1024个磁道上限； 6bit的扇区，63个扇区sectors上限，0不用。 ​ 63个扇区就是一圈 1cylinder（柱面的大小）= 512（1个扇区512个字节）* 63个扇区*255（磁头数也就是盘面数）=8M不到的样子 上面👆这些等到下一章节里就可以对应到MBR里的具体字段就知道怎么算的怎么由来的了。 其实就是这张图 CHS，cylinder柱面，H head，s sector扇区，这就是硬盘的三维 CHS,24bit的局限性 整个硬盘多大？512*63*1024(柱面的上限)*255≈8G，所以传统的磁盘最大8G。这就是CHS的极限。 LBA的容量大 所以又产生了LBA来表达磁盘大小的方式 LBA，只有扇区，全是扇区了就。所以centos7上就只有扇区，没有head和track以及cylinder了。👇 28位寻址就是👉28bit来表示扇区，一个扇区512，所以128GB=2^28*512B 128GB也不够用了 centos6实际上也是支持LBA的，只是为了兼容老版本，所以才是按CHS的方式显示的。 centos7也能够按CHS的方式显示👇 Units = cylinders of 16065 * 512 = 8225280 bytes 的意思是 一个柱面的大小，说明如下： 上文已讲过一个磁盘的容量怎么计算的，当然是最早期的磁盘。CHS，1024个磁道也就是柱面，255个磁头，63个扇区。一个扇区的大小是512B。所以，一个柱面的大小=63*255*512=16065*512 早期red5分区就是按柱面来分的（不是以扇区、磁头、磁道来划分的），就是最小单位是柱面cylinder。整个柱面为单位来划分。就是必须是1个柱面道100个柱面算一个分区，不能是0.5个柱面来划分，然后一个柱面的大小也是8M左右，所以分区的大小也是这个8M的整数倍。 centos6就打破了以柱面为单位，而是以扇区为单位进行划分了。但是centos6为了兼顾centos5，还是以柱面为单位显示的 如上图，第一个1柱面到131个柱面，但是可以打破单个柱面的。说的是partition1分区1跨了柱面了。也就是打破柱面为最小单元了。131到底属于sda1还是sda1,131都属于，说明131柱面跨分区了。也就是说分区的边界线切在了131柱面里面了。 下图就是centos6支持扇区分区，但是兼容柱面，所以显示最小单元是柱面，但是如果存在131这种切到柱面里面的，就会做个提示出来。Partiton 1 does not end on cylinder boundary 上图👆就很明显，分区1不在柱面的边界，那说明就是柱面中间切了一刀。 centos5不能这么干的，7彻底都是扇区了也就不提示这种信息了。 分区的话，扇面或者柱面必须是连续的--也就是单块硬盘的连续空间来作为某个分区。 windows的所谓的跨区卷，但不是分区，也不能跨硬盘。 100G分一个区在一个连续空间中，后来空间不够了，它前后的空间被别人占用了，就算没有被占用，我们统统认为分区不可扩展，不可缩小。后面有些技术LVM、RAID类解决此类问题。 windows某些软件号称可以扩，但是也就是玩一玩，很危险的操作。生产中统统认为分区不能扩！ Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-01-05 11:31:45 "},"12-磁盘存储和文件系统/2-MBR和GPT分区管理.html":{"url":"12-磁盘存储和文件系统/2-MBR和GPT分区管理.html","title":"第2节 MBR和GPT分区管理","keywords":"","body":"第2节. MBR和GPT分区管理 三步：分区、格式化、挂载 为啥要分区 分区 隔离数据，系统分区，数据分区，系统坏了，数据不受🦅影响， 分区的格式也可以不同。对于修复来说提高了修复的速度，没必要针对总体硬盘修复了。 一个小小重点 日志和DATA要分开来，性能得以优化。不然写日志可能导致东一个扇区西一个扇区，造成了文件的碎片化，将来读取不是太顺畅，性能就不好。这个如果是真的，影响很大的话，确实是个关键点★。 MBR 所以说，分区对读取速度有帮助的，简单来讲就是分门别类提供效率。 △结合上一章，搞清楚几个问题哦，①8G、2T、16B、32位、CHS这些东西分别说的啥，谁的上限，怎么得来的②同样的MBR里有两台表达方式CHS和LBA，这两个自然存在不同的上限的。上面的32位是LBA表达法用了4个B，所以是32个位也就是2^32来表示扇区的，所以MBR的分区上限是这么来的，当然CHS要小咯。然后CHS是3个字节也就是24位来表达扇区的，自然分区就更小了。 主要上次提到2^48*512B是在磁盘空间表示上见到的。而这次是分区空间上限表示的计算方法。计算公式一样，但要注意说的不是同一个东西。本质上是一回事，都是多少位来表示多少个扇区，一个说的是分区，一个说的是硬盘。 你看哦这就是完全错误的理解了，错啦，往下看吧，MBR-如果用LBA它支持的硬盘最大就是2T，如果是CHS，最大硬盘支持的就是8G。不是说的一个分区最大值哦。 [root@vpn ~]#echo 2^28*512/1024/1024/1024 |bc 128 👈128G [root@vpn ~]# [root@vpn ~]#echo 2^32*512/1024/1024/1024 |bc 2048 👈2T [root@vpn ~]# 进一步总结，那么为什么还有大把的人讲MBR单个分区最大支持2T呢，因为如果你将3T的硬盘划分区MBR的哦，划了2T作为第一个主分区，那么剩下的1T空间就用不了了，就灰掉了，说单个分区最大2T的也对，但是不准确，因为单个分区用掉了整个MBR格式的硬盘的2T上限，所以剩下的空间无法划分了。举例 MBR目前依旧是主流的 、 55AA就是标记位。 MBR分区结构 -------------------------- 这0磁道0扇区的512B，不属于任何分区，既然不属于任何分区就没有任何文件系统，没有文件系统自然就没有文件的概念。 最后标记为就是55aa 四个分区，每个16个字节。 活动和非活动，所谓活动分区，就是计算器启动的时候找80标记的分区，从该分区上找操作系统（引导操作系统的相关文件）。如果有两个80，就找不到了。就启动不了了。 这个磁头、柱面(也就是磁道数track)、扇区都有了也就是CHS定位了起始位置就有了，就是该分区从哪里开始。磁头从1开始，扇区也是从1开始的，因为扇区0就是上图拉，MBR和分区起止位啦。所以8bit的磁头不是256而是255，6bit的扇区不是64个而是63个。 在上图👆中指出8bit的磁头head、10bit的track磁道也就是柱面、以及6bit的扇区的具体位置。 第五个字节为0表示空间未使用。都不是0上图，就是分区都使用了，都分区了。 CHS如图才3个字节，也就是3*8=24个bit，也就是2^24*512/1024/1024/1024=8G的空间上限。问这是分区最大值还是所有分区-整块硬盘最大值。就算你不知道直接的答案，使用现有的肯定的知识也能得出来，来，3个字节来表示CHS是吧，假设是表示的单个分区最值，那么3个字节全部设置为1，也就是FF FF FF，好00 00 00-ff ff ff 表示8G一个分区，那么第二分区同样也是00 00 00 - ff ff ff ，第三个 第四个都这样，你觉可能吗，CHS是什么是那张硬盘结构图cylinder磁道也就是柱面，磁头也就是盘面，sector扇区，比如C-H-S值为1111111111-11111111-111111，这个东西是啥就是磁盘上的唯一的个扇形拉扇区对吧，我柱面定了-磁头定了-扇区也定了，东西就一个东西，还能在4个分区里出现4次？！扯淡吧，所以_ ___ __ 三个字节是4个分区整体计算分配的空间，比如分区1 CHS是1-10,分区2 CHS就是11--20，3就是21-30 ，4就是31- 40这样的。就像你写word里的序号是续的，不是重新编号的，当然我用10 20 30 便于理解，其实是下面这些值👇，同理LBA也是一样，所以LBA的2T上限就是整个磁盘的。 8个字节是换LBA玩法了。 所以2T也就是MBR的上限了，“也就是MBR可以表达的一个分区的最大容量”，这句话也是错的，我上面已经解释过了。 EBR表达起始位置和下一个EBR的位置，自然就能知道自己的起止位置了。 EBR不固定，是因为扩展分区不固定，第一个EBR不固定，自然后面的EBR都不固定。 但是MBR是固定的，整个硬盘的第0个扇区就是MBR所在，自然是固定的。 上图👆最左边一列是偏移地址，也不知道是怎么意思？⚪不管他参考基准是什么，反正对不上号和下图：是什么，是你大爷，看东西不会思考，第三次过的我来告诉一年前的你， 以前两行为例： 00000000 00000010 等价于 0000-0010 等价于 0000-001F 也就是2^5=32，也就是32个B字节，你数数前两行是不是32个字节，中间段是不是8*4=32个。 所以下图的红框就是位置，就是上图的位置，只不过下图统一用10 20 30 F0来表示，人家就是行开头了， 比如00000000-00000010，就是0000-0010，就是0000、0001、0002、0003、... 000F、0010就是2^4=16就是一行16给字节咯。 这个在MBR分区结构里也有小字表示的见下下图 上图的Error就是出错信息数据区。 ================ 备份分区表 需求来了，分区表的备份。emm，如果分区没了，上面的数据也没办法读取了。所以分区也有必要备份一下。 如果全公司的硬盘都是一个分区方法，基本也无需备份了。有一个导出分区表就行了。 也可以把这个512字节都拷贝出来 现在只备份这个64B的分区表，因为不是文件 所以cp拷不了，所以用dd把二进制读出来。 看二进制的方法来了：od、xxd、hexdump 举例，删除分区表-不是删除分区 就是把最后的标识位清了，但是skip用的有问题，skip是跳的if的设备，跳of=/dev/sda设备，要使用seek。 fdisk和lsblk的区别来了-一个看的硬盘上的，一个看的是内存中的 一旦重启，内存中的分区表就没了，硬盘里的分区早就没了，重启就起不来了。 当前真正生效的还是内存中的数据（分区表） ps：不管你skip510还是seek510，skipxxxx要得到的是/data/dpt里的55aa，显然dpt只有66B，skip写错了，下面改过来了。 这样就恢复了55aa标记位 举例-破坏分区表-保留了标志位 有些是0，就给你用*省略了，不显示了，详细看的就加参数 因为标志位55aa还在，所以还有个分区标题 虽然fdisk有这些磁盘标题Device Boot Start End Bloks Id System，但是没有东西，因为分区表清零了 系统判定有55aa标识位，觉得有分区，但是又不知道分区的起始结束位置。 此时重启，就起不来了，不重启是可以的，因为当前分区表是用的内存中的，也是说分区表还有的。救援模式来恢复可以吗？刚才的备份数据在/data里，但是分区没了/data个毛啊。 所以要备份一定要scp到远程主机上。当然如果你有可以用两块硬盘，分区破坏了一块，可以从另一块硬盘上手动挂载后获取分区备份（加入你的备份在那块上）。 重启模拟故障处理，重启之前先把分区表备份到远端机器上。 提示没有找到分区了 进入救援模式，硬盘起不来，光盘起。 如果硬盘分区还在，就会看到挂载到mnt/sys里面的，由于我们之前将硬盘的分区删了，所以这里自然也看不到了。 但是好像救援模式没有网络，你的分区备份还在远端主机上呢， 可以拿U盘，其实还可以临时配个IP地址的 这就就完成了救援模式下的scp 同时你要知道，此时是光盘加载的，数据拷贝过来都是放在内存里的，重启就没了。 上图👆注意 ：sdb、sdc、sdd都不管，是刚才加的。 再看下a硬盘 上图是看了全部了，下面只看前512一个扇区的内容 55aa前面的64确实是空的（注意中间*省略了，其实是64B的0）。 写硬盘的话：工作原理，是把内存的数据先放到缓冲区里，过一会再放到硬盘里。 dd 命令你看到提示ok了，但其实还在缓冲区里呢。你立马重启缓冲区内容就清了，此时就造成了数据写失败。所以不能捉急。 手动sync同步一下：多次sync就是担心sync没有立马执行。还是要等等。 此时硬盘已经还原，系统已经能识别了--系统就是装在硬盘里的，能识别自然就说明硬盘分区恢复了。 dpt disk partition table ======================================================== 实际上整个硬盘都不能超过2T，不是说分区不能超过2T。超过MBR就没办法了。为啥，分区表里的的bit位算出来的不是针对单个分区的，为啥说是整个硬盘呢。你再看下原来的图 他那个4字节“分区起始LBA”里填写的是起始和结束位，结束位本身就是2^32*512B=2T的上限，2^32个bit位用来多次表达分区起始位置，所以怎么算整体的表达能力就是2T空间。这个好理解，我们拿两个bit位类比来表示空间，00-01,01-10,10-11,11-00，没了，是不是一共也就会2^4个分段。它是续接的，不是每次都重新编号的。 每块硬盘可以有独立的分区格式，下面一块就是MBR ▲面试题有了：问：windows硬盘分区底色是绿色是啥情况？哈哈哈，气死人不偿命~ 变色，就是自动将第4个分到一个扩展分区里面了，然后自动创建了一个逻辑分区。 删除里面的逻辑卷 、 这就是扩展分区划分逻辑分区 再说会GPT分区 UUID是国际标准，微软发布的GUID属于UUID的具体实现。 UUID后面写的是16进制。128bit，就是32个16进制。 IPv6也是128位，这个UUID也是128位。 题外话： [14:54:45 root@pyConsole ~]#cat /etc/fstab | grep UUID |cut -d \"=\" -f 2 | cut -d \" \" -f1 |cut -d \"$\" -f1 |cat -A 07507cea-e91c-42ff-9cc9-ca3eb61212f0$ [14:54:48 root@pyConsole ~]#cat /etc/fstab | grep UUID |cut -d \"=\" -f 2 | cut -d \" \" -f1 |wc -c 37 wc这个算字符是把最后的$也算上去了哦，我输过了是36个~对输过了，要赢回来的 UUID生成工具uuidgen,▲各种生成工具可以整一波~ Protective MBR完全是保护后续的GPT分区信息的。 👆一组4个分区的定界信息。 Partitioin Header头部和分区表 都 有备份 早期的BIOS启动的蓝色界面操作，现在不是这个颜色了，到后面的支持鼠标操作的启动界面 固件接口， 否则BIOS不支持GPT分区作为引导操作系统的 UEFI启动就得配合GPT分区。 BIOS+MBR与UEFI+GPT 这样的，BIOS启动，UEFI启动，这两个启动，启动的时候要引导操作系统的，①而引导如果安装在GPT，就只能用UEFI启动；②BIOS启动的只能MBR分区方式里的引导。③BIOS可以使用GPT分区，只是用来存放数据而不是OS，这个其实是搞笑的说法，因为BIOS通过MBR分区里的引导操作系统启动后，然后就是通过windows/linux操作系统来识别GPT，从而达到在GPT分区中存放数据的效果。 启动的时候只能靠BIOS和UEFI本身去引导操作系统的。 虽然UEFI也支持MBR，但是没有意义了，UEFI虽然支持MBR启动，但必须要有UEFI引导文件存放在FAT分区下；UEFI是无法使用传统MBR引导来启动系统的。 你要把操作系统装在GPT上，就有要硬件的UEFI支持（就是新的硬件已经不用BIOS咯）才能启动。 常用的BIOS+MBR分区里安装系统+另一块硬盘GPT来支持超过2T的空间。这个可以有，不过直接UEFI+GPT不更香么。这是家庭电脑才需一块磁盘超过2T吧，工作中一般来讲服务器-装软件用不了多大空间，而大数据的话用mysql-mysql本身达到T级别早就分库了--拆成好几份，每个机器上放点。也不需要单硬盘超过2T的场景吧。 开始搞命令：lsbk这些cli lsblk（list block） 在centos 6 和 7上都可以用。 👆就是5的util-linux这个工具集咯应该，里面不带lsblk软件，6\\7 带的。 man fdisk👇 👆man 可见fdisk就是不支持gpt分区的，所以生产中肯定不能用fdisk来分GPT的。 man下gdisk👇 man parted👇 parted工具 分区时即时生效的 操作时要小心，很容易因误操作把你的分区表破坏了就。 partprobe同步的问题，后面再说。 parted使用要小心 fdisk查看分区，了解什么字眼代表什么分区 当前硬盘里啥都没有，所以也不存在什么446B的bootloder，这不废话嘛，它都不是活动分区，哪来的引导。 这条命令就是创建个GPT，就是说这个盘是GPT格式的了。下面可以继续用GPT的命令进行分区了。 这是个假的MBR，呵呵 打印分区表 上图单位M是MB 所以可见分区必须是连续空间。 虽然删干净了，但是还是认为有分区表，因为protection mbr的分区标识位55aa还在 你这个512B看的是protectionMBR字段内容，是不包括GPT分区表信息的 上图也看到了UEFI PART。 下面重点看fdisk和gdisk Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-01-06 11:57:49 "},"12-磁盘存储和文件系统/3-MBR和GPT分区管理工具详解.html":{"url":"12-磁盘存储和文件系统/3-MBR和GPT分区管理工具详解.html","title":"第3节 MBR和GPT分区管理工具详解","keywords":"","body":"第3节. MBR和GPT分区管理工具详解 fdisk和gdisk基本一样， 上图说明虽然分区删了，但是分区的类型还在（protection MBR里的55aa还在，可以通过dd将整个b硬盘的512B清空，这里B盘就啥信息也没有了）。 此时就是没有任何信息的硬盘了，初始接进来的硬盘就是这样显示的了。 这个时候就可以用一些工具对其重新管理（比如分区）。 保存退出，没有做任何设置 扩展分区是5，swap82，主分区是83 默认都是83，将来可能根据实际情况修改ID 只是一个标签，并不是功能性的强制标识。 就是说当前0个主分区，0个扩展分区，4个都是空闲的。 如上图，可以直接划分e扩展分区，从2开始，也不一定非要从1开始。 划分之后一个p就能看到当前划分的结果 上图是以扇区起始位置标记的，再一个就是ID是5，就是扩展分区的标识。 而且上图观察p和l，以前是p和e，其实就是说扩展分区就一个嘛，然后都是在其上划分逻辑分区了。 注意上体逻辑分区是从扩展分区的4096个扇区开始而不是2048个扇区开始的，所以你要知道每个逻辑分区的头部还有一个EBR字段里面都是本段分区的元数据来着。 逻辑分区也是ID85， 上上图的5也是自动的，固定的 扩展分区上的逻辑分区都是从5开始编号的。 上图就说明一个问题，逻辑分区的设备名是不稳定的。 你将来设备名你写到磁盘配置文件里面，你后来分区调了一下，很可能分区名就变了。 所以逻辑分区不适合写到配置文件里。 这就需要找一个不变的东西来应对。后面会讲到。 同时上图带来的问题就是，如下图： 这才2G的最大空间，所以超出了，注意2G是扇区相减后乘以512B可得出。 # 这句话也是错的，上图是1G的空间，算法是对的，结论是错的。 下面修改一下分区ID L是你记不住了就看下ID有哪些可以选择的。 关注上图的82 83 8e fd是软raid 还有一些淘汰的技术 上图是修改分区id之前的sdb3的id为83 下图是修改为82 此时还未存盘退出(w)，此时是否真的分区成功了没？👇 3种看分区的方法 上面4个方法都是没看到b硬盘上有分区的。 然后w存盘退出后，再观察 硬盘里的分区表和内存里的分区表并不是时时同步的，也就是说fdisk 分区的时候，w保存退出后并不是时时同步的。很多时候硬盘上的分区表分好了，但是内存中的没有。 ========================== centos6，以柱面为分区单位的，一个柱面8M 观察上面WARING，告诉你reboot后就同步了、partprobe或kpartx也行。 此时centos6的磁盘确实分区了，但是内存中同步不了。 不跟选项，但是要跟同步的设备哦 上图就是centos6的bug命令，不好使。记住了！！！partporbe在centos5和7上都可以，就是在centos6上不行。 可以kpartx，或者只直接partx 其实centos8是有-h的 报警error不用管，就看结果对不对-sda6出没出来就行了 上面partx -a是添加分区同步，删除分区同步用-d 但是内存里还在 ==================================== centos7也同样出现了waring ------------------------------------------------ 但实际效果应该是没有的，即使partprobe同步了。 虽然对分区再分区，且同步了，但是最终还是看不到的。 ---------------------------------------------------- 需求：将B硬盘分区分的和A一样 思路：复制A的分区表就行了。 操作：不就是A的那个64字节么，扣出来复制到B那边就行了。 所以克隆只能克隆主分区和扩展分区。但是没有办法克隆逻辑分区，因为512B里的64B是MBR，而逻辑分区是EBR是再扩展分区里的。 1、克隆的目标硬盘空间要大于等于原硬盘； 2、无法克隆逻辑分区，只能克隆主分区和扩展分区。 不过怎么看图上EBR也是可以克隆的啊。估计就是EBR比较多分散，MBR固定好操作。EBR还要计算。 再来，B硬盘和A硬盘一样大，此时克隆MBR就很OK了。 EBR的位置不在MBR那边，你克的是512的MBR里的64B，EBR在后面的扩展分区里面的EBR头 这个就是永久保存了，不存在再write，w写的动作了。 ======================================== gdisk 主要用来分GPT格式的区 都是和fdisk一样的 82\\8e这些都在 分区太多了，清一下，fdisk肯定可以清，就是太慢了 这么记笔记太慢了，体会不到学习的乐趣和快感！，，，i need fly，时隔1年，no u need 跬步 上图hexdump -C -n 512 /dev/sdb -v加个v就能看全部的0，上图默认是省略连续的0了。 不过为啥中间有28 c7 86 4a这几个值，而且我的centos 8 的情况也不符合这里所讲的，但是肯定centos8是使用正常的，那是因为我sb了，因为下图看错了，应该是sda而不是sda1。 如果把数据放在硬盘的磁道的外圈，速度读取和写入就快，如果是内圈就慢。所以再看看内外圈。 如果是centos-6的话就很清楚，本身有柱面，数字越小就越在外圈。越往里数字越大。 所以分区划分编号越小数字越快。6和7就是偏内圆了。 如果你希望数据读取快点，就将数据放到前面的分区。能提高个百分之几就不错了。 sda6里面全是0，你把数据放进去也只能0101往外读，因为还它没有文件概念。 创建完文件系统才有文件的概念，目录、属性、分门别类这些东西才会有。 注意力，持续 不同的文件系统除了必备的功能-文件管理功能，有的可能还有一些额外的功能。比如，NTFS除了文件管理，还有加密、 这就是windows的NTFS加密，只要看到 \"安全\"选项 就是NTFS系统 右键-属性-高级-加密就行了。 这是对别人是打不开的，而本人是无需的还是正常操作，没有影响（打开时自动解密，保存的时候自动解密）。 ext\\xf系统的没有这个额外的加密功能。 但是基本的管理文件功能必然都是有的。 对于linux 来说 xfs 、 ext 文件系统： linux支持的文件系统👇 当然也可以 这是目前linux里支持的文件系统类型。 在centos6上都是ext的 ubuntu用的也是ext centos 7用了个xfs，而ubuntu用的是ext4 ext1没有存在感，ext2存在重大bug，容易奔溃无法恢复，所以后来有了ext3 ext3的日志出现的优点：当系统写数据之前是先写日志的，日志一定是先于数据写，写好日志信息以后再把日志信息同步到磁盘里去，好处就是： ①万一日志写完了，还没来得及存盘，系统突然奔溃没关系有日志可以还原。②如果写日志的时候突然奔溃了，没关系，日志大不了不用了，数据又没破坏。 三刷的时候发现其实本质还是，目录和内容的关系，日志和内容都是数据，只不过日志是内容的简述，日志可以很短的时间内完成写同步的操作，内容量大的时候就比较耗时，所以加了日志容错变好些了。 读取文件，内存中修改，写到日志里，再写到磁盘里。 如果③和④中间断电，系统起来后，磁盘同步日志就好了。 如果③没完成，大不了日志丢了，数据还是完整的。大不了没更新嘛。 但是要注意，如果②没写完，写了30%假如断电了，那么日志里是有30%更新的，而系统后面起来后，磁盘同步日志，那么还是有70%数据没写进去的。 ext3的问题，性能问题在大磁盘中得到凸显，大磁盘T级别的比如，健康检查耗时达数小时之久。 为了解决这个 问题就推出了ext4，相对于ext3性能得到了巨大提升。以前小时级别的，现在分钟级别了就。 但是ext4支持的文件大小有局限性。家庭都是T级别了，生产中高达P级别。 于是xfs文件系统更大了，性能更高，但是linux上单一文件不会超出ext4的局限是，所以unbuntu上还是继续使用的ext4。 插入，在生产中拷贝大量数据时要限速，否则后果兜不住！找个空闲的时候，加上限速复制就差不多了。 上图的btrfs xfs：SGI是老牌的UNIX的厂家。早期的大片泰坦尼克号就是用SGI工作站做的。 btrfs是oracle的号称很优秀的文件系统。centos7上有不过是测试阶段，centos8就不在支持了，该文件系统就没有流行起来。 jfs在AIX小机上用的文件系统。 swap 和 iso9660光盘 FAT12是软盘， 这些是windows的文件系统。 exFAT是U盘的文件系统 U盘右键格式化的时候可以看到 refs是新的了看来 除了上面的单机的文件系统，还有网络文件系统 还有 还有就是分了区但是没有创建文件系统的情况，就是RAW。空文件系统、裸的文件系统。oracle，为了高性能，把数据库的data直接放到RAW上，就是0101010没有文件系统直接存盘，利用oracle自家软件直接利用010101去访问磁盘，由于中间没有文件系统这层，所以读取速度更快，缺点就是没有文件系统，如果oracle软件出问题，运维管理是个麻烦。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-01-09 11:10:45 "},"12-磁盘存储和文件系统/4-文件系统管理实战.html":{"url":"12-磁盘存储和文件系统/4-文件系统管理实战.html","title":"第4节 文件系统管理实战","keywords":"","body":"第4节. 文件系统管理实战 文件系统的格式化咯 这是centos6和7上的分区，sdb1和sda6\\7，都还没有创建文件系统，而创建文件系统就是所谓的格式化了。 一般就是ext4或者xfs，其实还是看系统默认支持什么（centos6默认ext4，centos7默认是xfs），就用什么。 管理工具就是mkfs这个工具 注意，文件系统本身是属于操作系统的功能，由内核来完成的。内核支持这些个文件系统，就是说内核提供了（内核级的）关于这些个文件系统的驱动模块。这点可以通过locate确认 locate xfs.ko，文件系统都是ko文件，查看有没有xfs文件系统的内核驱动。 查看ext4文件系统的驱动：xz就是压缩格式 这些都是属于内核级的功能。 那么问题来了ls，cat这些命令，对于用户来讲他访问文件，ls、cat去访问这些文件的时候，其实是通过文件系统来存放到硬盘上的。 那么这些命令是怎么和文件系统交互的呢？要知道底层用的文件系统有很多种，这些命令又是如何对应N个文件系统的呢？是不是意味着针对xfs有个ls.xfs子模块，针对ext4有一个ls.ext4子功能呢？显然不是这么干的！不可能让一个软件开发者考虑这么多种文件系统的。 所以为了让用户更专心的访问磁盘文件而不是考虑文件系统的差异，让开发或使用人员更透明的使用各种文件系统，就提出了VFS概念。 什么是VFS虚拟文件系统呢 题外话，其实从上图可以看出来一点点，就是cache缓存偏向于VFS，buffer偏向于硬件了； 还有一个简单得说法--缓存是读，缓冲是写磁盘得时候。其实这种说法里得缓冲也是说得磁盘，这就和上图不谋而合了，冲 更多是针对硬盘或是针对硬盘驱动得，缓存更多是偏向于VFS文件系统得。至于读还是写，这个我暂时人为是不分得。 对于用户cat ls cp mv等命令不会直接跑到磁盘上去操作磁盘文件。用户空间的程序是没有权限没有能力直接访问硬件的（而文件就是放在磁盘硬件上的）。 所以要用系统调用，让操作系统内核帮其完成访问磁盘上的文件 对于fat、ntfs、xfs、ext4 而VFS就是一个集大成者：把各种各样的文件系统通用功能收集起来，对外让用户来访问，用户就无需关心下面各种文件系统的区别，因为统一都是用VFS这个文件系统来访问。 这样用户开发的软件都是和VFS打交道的（比如ls、cat、mv等都是和VFS打交道的），而这个VFS文件系统再和底层的不同文件系统打交道就不用我们关心了，这是有内核来完成的，是操作系统本身来完成的。 这样就开发一个诸如ls for vfs就行了 如图可见当前不支持NTFS这种windows的文件系统，因为用的少，内核就没有内置添加这个功能，你要用自己编译到内核里。 源码编译见上文http的操作。 正常用不到这么大，用到了性能就不行了，虽然支持这么大。 创建文件系统 mkfs.ext4=可能还不等价于=mke2fs好像是默认格式化ext2的！！ 还可以这么写，mkfs -t xfs 、mkfs -t ext4 mkfs 格式化后怎么知道具体是什么文件类型 mke2fs /dev/sbd1 默认是ext2 上图的 因为本质上ext2和ext3是相同的，就是3多了日志，所以这两个是兼容的。 硬盘分区的空间可以理解成两大块内容，一个是metadata元数据-节点表（存放文件的大小、权限、时间、所有者、还有一个指针指向数据存放的位置），一个是数据。 实际上还要更加复杂，分区划分成多个组group，每个组是由多少个块组成。 而每块多大？ 不同地方的blocks意义不同 文件系统的blocks意思和磁盘分区里的blocks的意思不同 存放文件的时候，必须以block的整数倍来计算。哪怕一个字节的文件，你也要给我4K字节的空间。 分区里的block就是1个block就是1k。 如果磁盘里都是大量的1k，2k的小文件。此时4k块大小，空间就浪费了很多。如果文件都小，那么文件系统的block最小单元就别默认4KB了。 而目前文件系统，块大小支持：1K\\2K\\4K这3个单位。 4K是系统根据硬盘分区自动分的。如果分区偏大，自动给你4K的block，如果硬盘小自动给你1K\\2K的block。比如你分区就100M，默认肯定不会4K的、 也可以手动指定，-b 1k ，就是手工指定block大小了。 在磁盘上组织空间的时候，是把若干个连续的块blocks组织成一个group 这样把磁盘划分完。分出来后，每一组group里面在有自己的节点表。 superBlock：①分组的描述 从第几个块到第几块是一个分组，算是一个分组的起始位描述。②自身的元数据，比如块大小比如4K，这是文件系统的属性也要放在超级块里。 还可以手动去查超级快superblock： 这个就是最早提到的元数据 磁盘上每个文件都有元数据。这一条记录就是存放的一个文件的元数据信息。也是节点表的一条记录。 这一条占的空间就叫节点的大小。 256B，就是这一行占256个字节。 当然256B不是固定的，可以再添加属性，比如ACL这种扩展属性，这样一行的空间就变大了。 与此对应的就是节点表inodetable空间占用大了，后面真正存放数据的空间就少了。 DateBlocks数据块，一块4KB；然后inode table里的一行也就是一个节点信息占256B大小的空间。 每个文件分配一个节点号，这里66384个节点号，就代表了该分区一共可以放66384个文件。 所以上图可以反推出磁盘空间大小：所以4096单位是B字节，一般block size就是4KB的大小。 话说回来，虽然块很多，但不代表所有的空间都能真正用起来。 如果你也分100G的空间，那么5G是保留下来的。这个5%是默认的行为。 5G是干嘛用的呢？是给root用的，留给0 ID的人用，防止非root用户把磁盘空间占满导致root没有空间了，改个文件，加个字节都加不进去。保证了运维人员的可维护空间。 5%的预留不一定合理，如果10T的空间，500G的预留就很夸张了。可以调节百分比，支持0.1%。 superBlock超级块还记录了分组情况，只是上面的tune2fs -l /dev/sda1命令还看不出来。 换个命令可以 0 - 8 共9个groups 如果superBlocks坏了，文件系统就完了（因为分组分到哪都不知道了，属性也没了！）。 所以superBlocks需要备份，实际上也有备份 superBlocks备份了好几个地方：32768\\98304\\163840\\229376这四个地方都有备份。 所以利用超级块是可以修复出故障的文件系统的。 比如掉电、软件故障造成文件系统的元数据破坏，实际上是可以修复的，因为有备份的。 貌似是奇数有超级块的备份，偶数没有。但是这不是统一的规律，去看看别的。 dumpe2fs /dev/sda3 |less 分页看下 到group9，后面就没了。就是备份那么多就够了，不需要太多。 ------------------------------- 块位图blockBitmap 就是blocks，一个group里有32768个blocks，总共也有很多个块。 将来使用的时候 存放文件的时候 就需要挑出空闲块出来给到文件存放用。 所谓位图就是1bit1bit的图，0表示对应的block为空，1表示对应的block已使用。将来文件用的时候，就找出位图为0的block给它用就行了 这就是整个ext2为例的文件结构，其他相同的，差不多。 xfs的结构不太一样 meta-data 元数据区 data 数据区 naming 是啥？ log 日志区 realtime 实时区 isize=512是节点inode size，和上面ext4不一样（ext4是256B），这里大小是512B。 sectsz 扇区512B bsize块大小也是4KB log 也有日志功能，日志也有块大小 数据的realtime实时空间，每创建文件的时候，先把数据放到实时空间，等写完了，再放到真正空间中。 xfs查看的方法 xfs_info: /dev/sda is not a mounted XFS filesystem 👈需要挂载后才能查看 [root@centos7 ~]# xfs_info /dev/sda1 meta-data=/dev/sda1 isize=512 agcount=4, agsize=65536 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=0 spinodes=0 data = bsize=4096 blocks=262144, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal bsize=4096 blocks=2560, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 [root@centos7 ~]# -j 等价于-O has_journal等价于直接-t ext3。-O ^has_journal 是删除日志功能 -i，inode和磁盘空间有对应关系，多大空间对应一个inode。一个文件是要消耗一个inode的，而一个文件有要消耗至少一个块，一个块如果是4K，也就是说以一个文件要消耗至少4K空间，同时消耗一个inode，而inode又被你对应成了1K，也就是说，此时一个文件要消耗可能4个inode才能对应上，而inode本身又是占空间的，inode之前说了一行一个inode信息消耗256B，所以就造成了空间的浪费，积少成多也是可观的浪费了。 -N 指定分区中创建多少个inode，同样也是摆脱不了-i的默认值的，也就是说你指定的一个值，系统并不会精确到你指定的-N的，而是考虑到-i的大小的。 -I 一个inode占用多少磁盘空间，默认256B -O FEATURE ：ext文件系统了除了2，3和4都是由日志功能的， tune2fs只能看ext系列的superBlock信息，xfs的看不了 一般直接创建ext4就好了，不要创建ext2然后-O FEAUTRE没事找事，除非是已经有一个ext2了，然后再追加一下。注意mke2fs是创建的命令，对于已经格式化成为ext2的硬盘分区，需要使用tune2fs命令来追加。 例子：创建ext2 块大小1024B、预留0.1%、inode大小128B、卷标/mnt/sda6 👆上图bolck size是1024B字节，一共是1048576个块，所以这个sda6大小只有1MB。 这个ext2是没有日志的，所以查看下 👇此时sda6的ext2后面就追加了ext3字段。其实ext3就是比ext2多了一个日志功能，此时就是ext3了。 关于acl的功能来源-挂载选项 centos6系统(7除外)后面分的区--不是安装操作系统时分的区，是没有这个Defeault mount options选项的。 某人看到这 就要怼了，“你的沟通有问题，不是没有这个选项，是这个选项的值为none”，所以跟这些人讲话，要小心些，唉~不要碰枪口，除非你比他牛，他就不怼你了，他会反过来将就你，这其实是有问题，客观来讲有一说一，但怼人是不对的(你Y的沟通才有问题，逮着机会怼人你牛逼~操)，这些人的态度两极分化的厉害所以不喜欢他们。不过反过来，你自己要是凶一点(不是让你怼人哦，就是态度明确硬朗、正)，工作上可能会轻松点这倒是事实，一些喜欢借力、甩锅的人就不太愿意和你怼，因为你凶啊，哈哈~。 没有的，可以通过-o acl添加该功能 再查看就有了，此时就可以用FACL了 会加也要会删 补充说明，这里既然是挂载选项，那么就有这个mount -o acl，不过就是centos 6需要这里的两种方式来处理（上面的一种tune2fs，还有这里的mount -o），现在都是7不需要的。 一个分区可以用三个名字来表示它 UUID具有固定唯一性，其他不具备唯一性。 早期都是些卷标，从centos6开始推荐开始写UUID了。 根据UUID查分区名、根据卷标查分区 blkid -U 等价命令 给ext系统加卷标 xfs系统的卷标使用xfs_admin，不过需要先卸载 不带-h就是超级快和group分组全看 dumpe2fs -h /dev/sda7 等价与tune2fs -l /dev/sda7 xfs_info必须要挂载才能看，上文应该有说过了。 # 这个具体看了，centos8和rhel8不同， fsck 可以修复ext和xfs。 [20:41:23 root@localhost ~]#fsck. 👈两下tab补全 fsck.cramfs fsck.ext3 fsck.fat fsck.msdos fsck.xfs fsck.ext2 fsck.ext4 fsck.minix fsck.vfat [20:41:23 root@localhost ~]# 提示可以看到支持修复的文件系统类型，但实际上直接fsck不带后缀更好，因为万一敲错了，反而坏事，不加会自动判断对应的什么系统。 修复xfs文件系统举例 超级块一般多大，在一个分区上都是些描述信息，应该很小，但是具体多少不清楚。 上图的三个选项一个都不用，-f 是修复文件、-d是修复根。 直接xfs_repair /dev/sda3，一定不要挂载的时候修复。 修复后就可以挂载了 但是数据确实丢掉了，看来dd前10M破坏比较严重的，修复估计也就是修复超级块吧，因为有备份，可能也能修复些其他的，具体还需要研究下。 例子2，修复ext文件系统 bad magic number， 超级块没了已经 取消挂载 修复 输入 -y就行了，自动帮你输入yes 修复后挂载，看下空间大小 如果破坏的不是太严重，可以修复一些数据回来的，备份的都是元数据、分区信息、超级块之类的，用户数据是不会备份的。 这是二次破坏！👇 使用一个磁盘空间的3步骤： 以上就讲解了 1、分区；2、创建文件系统、3下面就要讲挂载了。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-01-09 17:07:19 "},"12-磁盘存储和文件系统/5-文件系统挂载.html":{"url":"12-磁盘存储和文件系统/5-文件系统挂载.html","title":"第5节 文件系统挂载","keywords":"","body":"第5节. 文件系统挂载 挂载的理解 一些相关信息梳理 sda是硬盘，123是分区号。 1、硬盘格式化也就是创建了文件系统xfs\\ext4之类的之后，就需要挂载了，这里的挂载应该是带着各自独立的文件系统和VFS打交道了吧，反正硬盘空间还需要挂载到文件系统上， 2、/dev/sda1挂载到了/根上后，根下的所有当前存在的文件会在/dev/sda1里看到么？我们知道安装系统的时候根是挂载到剩余分区 https://www.linuxidc.com/Linux/2019-04/158216.htm 10.4.2.95的前2个盘位各装2块固态硬盘做RAID1，最小化安装CentOS7.9，分区biosboot 2M , /boot 500M,剩余分区/ 。 一旦把sda2设备挂载到data后，后续在data里创建的文件都会出现在sda2中。 1、一开始是sda2挂载到data里，并创建了一个/dir/f2.txt文件 2、然后再将dir挂载到sda3里，这个时候进到dir文件夹实际上就是看到的是sda3分区， 之前的f2.txt文件还在sda2分区里，所以现在挂载到sda3下了，所以就看不到f2.txt文件了。 如果再将sda2挂载到/home目录下后，就又可以通过/home看到f2.txt文件了（看到个屁，看不到的哦，想想就不对，做了实验也一样看不到的），而且还看到dir文件夹，一旦进入该文件夹，就等于进入了sda3分区。所以从/home也是可以一路顺下来到dir里的。同样\"/根下面的放的都是一级目录\" 说的就是这个道理，因为很多一级目录都是自己另立门户的。 一种理论上的循环挂载 sda2挂载到/home文件夹，sda3挂载到home下的wang文件夹，sda1挂载到wang下的dir 这样，进入到/home就看到sda2里的wang，进入wang，就看到sda3上的dir，然后dir再挂载到sda1，于是进入dir就看到了sda1上的/home，如此就完成了理论上的循环，linux不允许，windows时可以实现这个效果的。 就是D盘挂D:\\test文件夹，然后循环点击效果看看 右键更改挂载点 继续点，层级还会增加 数一下多个层 复制到linux里然后grep一下 31个层级就是循环挂载后的 套娃上限。 挂载操作 umount 直接跟设备就行了 这种挂载重启后就丢了 挂载选项-只读挂载 此时就👇 重新挂载成rw读写，没必要unmount 在mount，可以用命令mount -o remount,rw ，它不是真的取消挂载。效果上是重新挂载，但并不是取消挂载的。 来了，一般分区可以取消挂载unmount再mount挂载，而/根不能unmount。 根/ 不支持unmount，但是可以remount。 因为/根要是取消了，/proc这些内存中的东西不也都是在/根下面嘛，如果根取消，那么内存的东西也就没有FS支持，也就看不到了，也许当前操作界面都没了。 此时重点来了，如果/根要修改挂载属性，就得用remount命令，所以remount可不是真正意义上的先unmount在mount。 和挂载密切相关的文件mtab 该文件就是显示的当前挂载情况 这个文件貌似/etc/下面的，而/etc/下面一般是配置文件，一般莱昂配置文件固定不动得，但是该文件确实实时和当前的挂载信息保持一致的，通过ll /etc/mount可见其实是proc内存文件里的软连接👇--这话不对，centos7上是软连接，而centos6上就是普通文件 mtab是实时挂载信息文件，而fstab是实现自动挂载autofs的配置文件？没错吧，错了，fstab何autofs服务并无关系。fstab是独立的系统加载的挂载文件，autofs是个独立的自动挂载的软件需要安装的,autofs和/misc这个神奇文件夹有关系。 挂载推荐使用UUID设备名来挂载 起个卷标 此时可以通过卷标来挂载 上图注意-L /mnt/sdb1是起的个卷标名 故意和文件夹/mnt/sdb1同名的。 使用UUID挂载 写到配置文件需要使用UUID，即时性的cli还是不会写UUID，而是写名字就行了。 伪文件系统 上图其实是共享内存等内存信息。 这些不用管，都是自动挂载。 一个设备能否挂载到不同的文件夹(挂载点) 可以，将已经挂载的sda7，再次同时挂载到dir1和dir2文件夹下，此时dir1下创建的文件，dir2同样可见。 但是一个挂载点也就是文件夹，只能同时挂载一个设备, 存在分区被顶掉和被顶掉的回来的这个一个逻辑。 注意上面几张图是连起来的，中间没有任何其他操作，所以此时/dev/sda7不仅仅挂到了/mnt/dir1上，还同时挂载/mnt/dir2上呢。 被隐藏的文件 ①本来/mnt/dir1/sda7/sda7.txt是存放在/dev/sda7分区的，②现在将/mnt/dir1/sda7文件夹挂载设备/dev/sda1。此时/mnt/dir1/sda7文件夹下面显示的就是/dev/sda1分区的内容，所以原来的sda7.txt不可见。理解思路，相当于只要你进到/mnt/dir1/sda7想看sda7.txt文件时不可能的，因为一进来就到了另一个分区了。 该文件就永远无法访问，除非取消挂载一次，恢复到前一次的挂载。所以当前该文件就变成了无法访问，但是又占着磁盘空间，于是就成了垃圾文件了。呵呵不一定，也许人家就是要这样的私密文件呢，哈哈 \\* 人世间这个空间，就是多层空间的最后一个挂载，前几层的空间被覆盖隐藏了；得道了就umount了，就恢复到上一层空间了。轮回就不断mount覆盖， 方法论：挂载点也就是文件夹，一定要是个干净的空文件夹▲ 这里有个问题，你不图形化，后面不能一下子记住，还是会忘记。 要找一个生活中的场景：有了，房子有多扇门，多个门能进入同一个房子，但是一扇门不能进入2间房子。房子就是设备\\分区-用来存放东西，门就是挂载点文件夹-只是个入口。 助记来了：一个文件夹只能挂一个硬件设备；一个硬件设备可以挂多个文件夹；好比一个房间可以有多扇门，一个门他不能属于多个房间，对吧，别抬杠~ 然后，同一个设备分区，挂载多个文件夹，第一个挂的那个文件夹在df中显示出来的。 如果别的设备也挂到已经被挂载的文件夹，则前一条挂载信息还在，就是被覆盖了，只要后一条mount信息umount掉就能恢复前一条挂载信息了，mount可见的。 其他挂载选项 一般不用写挂载的文件系统类型，mount会自动判断分区设备的文件系统类型，会自动补上-t vsftype选项的 这个时候写不如不写，就和上一节的fsck修复文件系统会自动发现是什么格式的。▲ 上一节竟然将重要索引字段写在了图片里，不利于搜索，以后图片上面尽量别写字。 默认就是可读可写的，所以一般也不用加这些选项。 加上-n选项就不会自动更新了 实际上确实挂上了，但是mnt里没有，所以df 也看不到 这个可以理解成隐藏挂载 mount、df都看不到 有个地方全都看得到，就是内存里，但是centos7下没有这个-n功能，因为7里面的/etc/mnt就是/proc/mounts内容，所以你-n在centos7下没有意义。哈哈 -a 和fstab有关，后面再说 一般是设备往文件夹上挂载，还支持 文件夹 往文件夹上挂， mount -B /boot /mnt/boot 要求文件夹得是个块设备 解决了硬连接不支持文件夹的问题。莫名其妙的，用软连接不行吗。 也支持 文件 往文件夹上挂 要求文件必须符合一定的文件系统要求 前面都是针对分区做格式化 也就是做成ext4\\xfs之类的，现在找一个大文件来弄 1、生成一个文件/data/disk 2、针对该文件创建文件系统 直接查看确实有的 这个disk文件上面就有了文件系统，既然有文件系统，就可以和分区一样挂载到文件夹里 挂上后的显示效果不太符合预期 PS：在系统中，本身挂载时不允许 一个非设备(分区自然算设备的)往文件夹上挂的。现在时文件往文件夹上挂，就分配了一个loop0环回设备，用loop0设备和文件关联，然后再用loop0设备往文件夹上挂载，这样就间接实现了文件往文件夹上挂载的结果。这一点在centos6上需要手动加选项来实现loop设备的分配 然后再看下centos6上面的情况 centos6直接显示的就是/data/disk2文件，而不是loop设备。7是不需要手动指定，显示的是loop设备。 可以通过losetup -a查看分配的到底是loop几？ loop的个数，centos6最多支持8个文件挂载，7没有这个限制 centos7是自动生成的。/dev/loop0就是自动生成的 如果centos6的loop设备消耗光了，也有办法，mknod自己创建就行 7 100是设备编号类型 b是块设备 上面是命令手动添加，可以修改内核实现开机即得 重启就会得到100loop设备，centos7用不着这样 进一步 实现人工指定loop几，而不是自动分配， 题外话，我不知道为啥老师要讲这么久loop，有毛用啊？ 上面重启过了，所以之前mount的应该丢了，就不需要unmount了 上图报错，排查下,loop写错了是66不是6 拷点文件过来 然后unmount后复制到其他机器，去挂载查看文件 然后到192.168.37.7上去 告诉你了，上面有ext4的文件系统 相当于U盘了，不过要这么麻烦么，直接复制不香吗？哦，具有一定的隐藏效果，别人打不开这个/data/disk2，也不知道怎么看，你一挂载就可以看了。 mount 选项复习 通过tun2efs -l /dev/sdb1看下当前分区有没有支持默认acl的挂载功能 挂载后，复制文件过去 可见centos6默认是不支持facl的 两种方法上一节也讲过，①就是修改文件系统的挂载属性，②就是这里的mount -o带上acl 取消acl的也是用mount -o remount,noacl /mnt/sdb1 这个和fstab有关，稍后再说 这是，设备(分区)里面的执行文件能否执行。 这个厉害的，挂U盘的时候，▲如果U盘里放一个带有suid的vim二进制执行文件，然后拷进去，这样就很危险了，相当于继承了管理员权限了。 此时考虑安全，所以挂载U盘都是就要mount -o nosuid 其他： 同步，就是立即写磁盘，内存改了磁盘也改了。异步就是放到缓冲区里等会再写到磁盘里。 异步 速度快，因为对于程序来讲 放到缓冲区里就算存储就结束了。这时候如果掉电就GG了 同步 更可靠些，速度慢点。 mount 后面的选项啥也不跟就等于： 以上都是临时性挂载，稍后介绍持久性挂载。 findmnt看着还可以 fdisk gdisk parted partx partprobe e2fsck e2label blkid dumpe2fs mkfs.xxx mkfs mke2fs mknod tune2fs xfs_info xfs_repair losetup findmnt uuidgen Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-01-10 11:43:06 "},"12-磁盘存储和文件系统/6-持久挂载实战故障排错和swap空间管理.html":{"url":"12-磁盘存储和文件系统/6-持久挂载实战故障排错和swap空间管理.html","title":"第6节 持久挂载实战故障排错和swap空间管理","keywords":"","body":"第6节. 持久挂载实战故障排错和swap空间管理 如果是别的终端，或者是别的app使用了该分区，就同样无法unmount wall 广播通知功能，也只能通知到登入用户，那些不登入的应用是无法收到wall通知的。 wall没啥用 通过fuser -km /mnt/sda7杀掉所有占用该文件夹的进程 1、通过fuser -v 判断文件夹是否被占用，这虽然是说unmount的前提，但实际上判断文件夹是否被使用 本身就是一个独立的动作，不要和unmount强相关。 2、通过lsof判断文件夹是否被占用 如何判断一个文件夹是一个普通文件夹还是一个挂载了设备的文件夹呢 df 可以看，但是centos6上看的不全--因为挂载的时候可以隐藏的。 通过findmnt /mnt/sda7来查看给文件夹是否为挂载点 而findmnt 的$?的结果也是0表示true--挂载，1表示false--未挂载， 这是脚本方面使用的特点 永久挂载 永久挂载不是自动挂载，autofs才是自动挂载的工具--才是神奇的文件夹/misc 下图可见/etc/fstab是安装操作系统的时候生成的，因为anaconda就是安装系统项目的程序名-应该是应答文件吧。 查看fstab来自于哪个包，再看下该包里有一些其他什么文件 可见setup包都是必装的基础文件 man 5 章可见具体帮助信息 UUID=字段是设备名，还可以用LABEL=\"XXX\"或/dev/xxx来替换，不过一般还是UUID，因为字段稳定不变。 第二列是挂载点，也就是文件夹 第三列是文件系统 要注意必须和设备分区自身的文件系统匹配 第四列 defaults是挂载选项，前面讲过 mount -o ro,acl,nodev,等等，不写也是有很多默认值的，上一章有讲。 最后两列 0 0，在centos7上意义不大，在centos6上有用 倒数第二列是备份频率，需要专门的备份工具配合的 备份工具是专门备份整个分区的，类似于dump，然后这里会记录下来 这种备份工具用的少，更多的还是tar打包文件夹 没必要对整个分区进行备份。 1就是dump了一次，0就是没有备份分区，因为没啥用，所以centos7上都是0了 最后一列 是文件系统的检测顺序，开机的时候会用fsck.工具来检查，因为centos7上都是xfs，所以也不用了。 举例centos6上 先blkid看下设备分区，将/dev/sdb1挂载到/mnt/sdb1文件夹 然后编辑/etc/fstab文件 写/dev/sdb1设备名不推荐这里实验无所谓了 acl,noexec写出来的就是人工设置的，没写的就是按defaults里面默认的一些选项，有冲突的还是按前面写出来的设定。这里算是mount -o和tun2fs -o 一共3个挂载选项修改点了▲ mount -o remount,rw,acl这样就可以修改了应该。 要是fstab文件生效，就需要mount -a重读此文件 然后验证下noexec挂载选项的效果 删掉noexec就vim /etc/fstab里面删掉noexec就行了 上图去掉noexec后，mount -a 想去掉noexec选项，是不好使的👇 mount -a什么时候好使，不得好死~哈哈，人求得好死是吧，mount -a是原来没挂过，然后mount -a就会是选项acl,noexec生效，但是原来挂过，再修改选项就不会生效。 unmount 再mount -a就好了，更好一点得就是使用remount ，也会自动读取/etc/fstab里得配置的 此时就可以执行了 演示一下fstab 设备名不存在的情况 上图👆注意上图的 最后一行0 3，是要做文件系统检查的 上图可见，fsck 做文件系统检查了就出问题了因为没有这个UUID。 ctrol + d还是重启，没用 输入root口令进去 发现只挂载了个根/ vim 进去 搞定开机OK 但是存盘发现写不进去 发现目前就是只读状态，不仅仅是/etc/fstab写不进去，整个根/都写不进去 mount看下 👆确实写的是rw可读可写--但是有warring告警，但是实际结果就是只读的。 重新挂载一下根/ 此时，再去vim /etc/fstab修改最后一列为0，wr就可以保存了 此时就可以正常启动了，不用reboot，直接切换到5模式(图形界面)就行了。 进入系统后，修改正确的UUID就行。这里顺便测试一下LABEL卷标的效果， 然后mount -a就行了 所以/etc/fstab最后两列还是写成0 0 吧，别做检查了就，能不能挂上去再说，先把系统启动起来。▲ 对于centos7不存在这类问题 拿sda6做实验，重新格式化为xfs，为啥要重新格式花，ext2不行吗？不懂 此时就得到了一个xfs格式的sda6 然后取出UUID字段，保持格式上同就行了 修改后保存 确保挂载点存在 如果存在会提示不能创建的，就像这样 [11:20:23 root@localhost ~]#mkdir /root mkdir: cannot create directory ‘/root’: File exists 可见挂载成功， 故意写错fstab里sda6的UUID，重启看能否重启成功？ 上图说要等1min 30s，还是起不来的，又到了和centos6一样的界面 同样通过root口令进去 因为：👇 mount看下就是rw可读可写的，也没有告警提示。所以就可以rw的。 然后直接启动就行了 SWAP df里看不到swap，但是lsblk里可以看到 一般linux服务器上用也不会休眠 如何新建SWAP分区， SWAP是分区，分区时无法扩容的，所以只能新增一个SWAP分区，两个加起来用 SWAP模拟内存，硬盘应该放在磁盘的外圈，所以下图的磁盘，SWAP分区应该放在哪？ 新的SWAP是创建到sda8还是创建到sdb上？答：创建到新硬盘sdb上好，因为新硬盘还没有分区，新分区时从外圈开始划的。 通过fdisk -l 看下swap的编号是82 开始分区 w后没有告警，所以连同步都不用做了。 可见👆多了个新的硬盘分区 分区以前都是mkfs.xxx但是tab补出来可以看到不支持swap类型的 得用mkswap来创建swap分区 创建之前通过blkid /dev/sdb1看下现在是：没有文件系统的--虽然显示了个dos。 mkswap /dev/sdb1，可见👇一些告警：说没有删除一些引导扇区标记，就是保留了硬盘之前的信息，不用管。 此时就可以看到文件系统为swap了 之前分区的时候使用的时默认从sdb硬盘的2048字节开始分的， 这就是swap之前的信息，前面几行到55aa是MBR分区表，后买面是加的SWAP分区的信息。然后SWAP是空的，所以很多都是00。 这块遗忘了就搜一下大概情况如下 然后就是挂载--且是持续挂载： 两个swap，挂载点是swap，文件系统也是swap mount -a 对于swap是不起作用的 此时内存文件中看swap只有sda5没有sdb1呢 使用swapon -a 读取/etc/fstab里的记录是swap生效 等价命令swap -s 和 cat /proc/swap 然后两个设备sda5和sdb1都能放swap的数据，但是sdb1是外圈磁盘，所以速度更快些，所以希望调整一下优先级。 测试一下看下当前哪块分区优先 消耗内存的方法▲ dd往null里写数据，一个bs就是2G，而此时内存空闲只有1G不到，所以肯定会用到swap，此时看谁优先。 此时就很慢，理论上这个命令dd if=/dev/zero of=/dev/null 都是在内存里处理的，都是内存往内存里扔数据，应该很快的，但是现在很慢，是因为内存空间不够，用到了swap也就是硬盘，所以就慢了。 👆而且可见优先级是-2优于-3的，大的优先咯。上下图片都可见用了448M了。 之前修改fstab 然后mount -a是不会对修改某个选项生效的--要么是一行都没有的新挂载的情况才会mount -a生效，此时swapon -a同样不会生效 swap的生效方法如下： swapoff xxx禁用 然后再启用就行 再来测试swap的优先级 可见swap里的sdb1优先得到使用。 一些不规范的操作，举例-由于开始分区没有规划swap，没地方放swap了，只能拿文件来补一个。 看下当前根/的空间利用率比较低，所以将来做swap的文件就放在/下 格式化 blkid看不到没关系，加上文件名/swapfile去查看下，再直接用blkid此时就能看到了 同样写UUID到/etc/fstab实现持续挂载，这里要注意了针对文件作为swap的不能用UUID，这里先用UUID演示看下问题出在哪里。 swapon -a 读fstab进行 挂载，此时swap就多了一个/swapfile 文件实现的swap了。 644就谁都能看这个数据，内存数据建议600 重启后发现： 文件作为swap的丢了，要写设备名也就是文件 重启后再看 swap除了建议放到机械盘的外圈，更加推荐使用固态盘。 有人说现在用不到swap，蓝鲸的平台base和扩展，你看看内存要多大，swap好歹能图个安心对吧，举例别不服--数据检索：针对56台agent查询了1个月的CPU使用率，然后就OOM了。 检索量太大了导致的，正常情况下，没有这个需求，所以如果swap上来，也能解决这种非常规性业务。 下图是蓝鲸base里的pass平台点，有点奇怪没有swap 不管了，暂时不管它了。 之前的 \"文件夹挂载到文件夹\" 如何写到fstab里 注意，文件夹没有文件系统一说，都是硬盘分区是什么文件格式，所以这里写none就是没有文件系统，然后defaults那里就写bind。 然后 mount -a 再，mount查看 可见已经挂上了 fstab如果持久挂光盘 光盘可以直接写设备名也没问题，写UUID也行。 /etc/fstab里写这一行：光盘的文件格式就是iso9660 fstab挂文件，类似用文件做swap (把衣服挂到钩子上，叫做挂衣服，把文件挂到文件夹上，所以叫做挂文件) 将下图稍作变动就可以实现文件往文件夹上挂载了 /dirName/fileName /mnt/dirName ext4 defeaults 0 0 这样就可以了 fstab还可以挂载网络资源：nfs，samb。后面讲 图形界面会自动挂载光盘 如果是开机进入的是字符命令行界面，就不会自动挂载。 普通用户没有权限挂载 神奇文件夹不管你是普通用户还是root，只要一访问呢/misc文件夹，就能实现自动挂载。 这个神奇文件夹，过一段时间不访问，就会给你取消挂载，一访问再次挂载，其实这个是autofs软件实现的，在《linux就该这么学》中有详细讲，其实很简单，哈哈。 删除swap其实上面已经有了，这里再写一下方面看 1、fstab里删掉 2、swapoff /dev/sdb1 如果是文件swapoff /swapfile 名字无所谓，就是意思一下；swapon -s看下确认下 3、删分区，fdisk--->p ----> d ----> 1 意思意思不要照抄；删文件rm -rf /swapfile 4、partprobe同步下 删掉后，再创建/dev/sdb1的时候blkid里会看到之前的swap类型，无所谓，按部就班就是①分区②格式化，格式化就是mks.xfs /dev/sdb1就可以覆盖掉blkid里的原先数据了，然后再③挂载mount或者swap的话就是swapon -a Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-01-10 17:52:22 "},"12-磁盘存储和文件系统/7-外围设备使用.html":{"url":"12-磁盘存储和文件系统/7-外围设备使用.html","title":"第7节 外围设备使用","keywords":"","body":"第7节. 外围设备使用 案例：home本来是在/下的，现在home越来越大，要迁移到一个新的分区 首先找一个新的硬盘分区 👆这种有提示的，要同步分区表 否则分区sdb2出不来 centos7的同步就一个方法， 然后创建文件系统，并确认 现在就是要将home文件夹挂载/dev/sdb2，要考虑/home下的当前文件，直接挂过去home当前的文件就看不到了--因为现在是挂的/目录关联的设备。这点第5章讲过了。 要把当前的数据迁移过来 数据迁移 要把/home下的文件复制到新的分区，需要中转一下 先用一个临时文件挂一下 确认下文件是否都复制过来了 题外话，复习下： 原/home下的文件可以删除了，否则等你挂载后，这些文件没有入口进去找不着就删不掉了，还得取消挂载从/进入home去删。 使用持久挂载 刚才其实还有一个临时挂载，把/dev/sdb2挂到了/mnt/home下，上图是后挂的覆盖了，mnt可见👇 这里有个问题，原来/home文件夹里的东西被隐藏了，要删掉的，否则一直占着空间。如果前面没有舍得删，这里需要unmount回去删掉的 有个问题，在cp -a /home的时候，文件夹可能有人在用，别人可能在往里写数据。 一般需要把系统处于维护状态--init 1 --单用户模式 进去看下可见是从5 切到 1的 可能有点问题，就是终端那边命令输入有问题， 重启直接进入单用户模式 按任意键 上图输入a， 然后进入下图输入1，进入单用户 单用户模式，就是不联网的，网络都是down的👇 这是建议的维护状态下进行操作；只要别人不能访问就行，比如防火墙deny也可以。 移动设备的使用-光盘-U盘 eject后，光盘就弹出了 弹光驱这件事，有意思在 早期服务器主机都是带光驱，机房里面找机器，可以弹出光驱就能一下子找到了。呵呵~~~现在呢，谈个屁，谈恋爱吧。 eject -t 是弹进去，台式机可以，笔记本不行，VMware Workstation VM虚机更不行了。 把光盘制作成iso文件 这个可以用来挂载iso文件，没光驱，就可以这么玩，挂载iso，一样做yum源。 联系前面的章节： windows里制作ISO是用工具比如这玩意 linxu就一条命令的事： 上图时间较长，你想windows一样要读进度条的，不过你可以ctrl c结束也能看到下面内容，不过数据就不全了。 还一种方法，是把文件夹打包成iso文件 打包成iso 并不会压缩，原来也是这么大差不多 挂载看下 注意这种挂载是read-only，光盘嘛iso就是只读的，不过windows的UltraISO好像可以往里写东西，没用过。 centos6上的一个问题 光盘是3243个包，yum上看到是6713个包，剩下的还有3000+的包在第二张光盘上呢，centos6是两张盘来着。 可以考虑把centos6的两张盘和成一张盘 弄一个大文件夹，然后把两张光盘解压进去攒成一个大文件夹就行，不过这样可能没有引导文件，还需要工具，不过只是做yum源应该没关系吧，安装可能不行。 有个官方脚本\"mkdvdiso.sh\"可以把两个centos6的ISO合成一个iso同时具有启动功能 看下U盘 U盘的系统查到linux上，如果是FAT32可以识别，如果是NTFS就不行了。 wmware workstation 插上U盘后会提示 如果选择主机，那么linux这些虚机识别不聊了，所以选择虚机连接 我们选择主机先看下👇，待会再连到虚机上 把U盘从\"主机连接\" 转到 \"虚机连接\" 👇注意tail -f /var/log/messages监控着： 点击后同时观察后面的messages日志 开始弹出信息：usb xxx 设备名也出来了[sde]。 下面就是和硬盘一样的用法，创建文件夹，挂载 因为是2个分区，所以创建2个文件夹 将来挂载 发现sde1是ntfs的，挂不上去，sde2是vfat的可以 因为linux默认不支持ntfs，所以挂不上去 通过locate xxx查找内核文件可以证明确实不支持，👇没有ntfs文件系统的驱动 👆这是看有无驱动的文件，至于是否加载到内存中了没，还要通过lsmod查看 虽然有vfat.ko文件表示系统支持fat格式，但是并没有加载到内存中👇 因为已经mount在用了，所以系统就给你加载内存里面 fat文件系统虽然在linux里支持挂载，但是有问题的，umask貌似没有起作用 完全改不了 改所有者、所属组也不允许 说明fat文件系统的功能太少，连基本的权限rwx和所有者、所属组都不支持。 还有一个fat文件系统不区分大小写👇 这里就可以说这么一句话:linux区分大小写这种说法不准确，显然上图的linux系统存在不区分大小写的情况，所以讲 区分大小写 它是文件系统的事情，linux一般xfs或者ext这两个区分大小写，如果非要用linux也支持的fat文件系统(fat本身不支持权限umask和所有者\\组)--此时就表现出不区分大小写了。 👇下图人家df定义了别名，所以\\df来使用原来的命令，注意原来的df就是以block块为单位的，1个block就是1KB字节。 -h 是human人类可读性好的选项 -h是以2^xx 也就是1024算的 -H 是10^ 也就是1000算的 -T 显示文件系统 -i inode节点使用情况 -P 是格式化好看些的意思 centos7是优化过了，看看centos6就知道了 这个错位，cut就不能取了啊，要注意。加个-P 就解决了 厉害厉害，上图--skip-alias 细节啊， 所以说7就不需要-P了，因为7上的df的rpm包版本更高，6的版本低还需要-P 查看文件夹大小 du 不带选项，就是/boot目录下，每个子目录的占用空间，单位是KB；最后一行/boot是汇总信息。 这个du看到的和df看到的不太一致 du 算的空间是目录数据本身站的空间，而元数据是不算在内的，还有日志、实时运行区？一些额外的东西。 dd count=0就是数据为0咯，但是会产生元数据的，所以多少会有点空间占用的👇 不过多了点元数据 上图最后一行的命令解释：seek是跳过10个bs，也就是10G开始写数据，结果写0个bs。所以前面0-10G的数据为空。也就是有头有尾，中间没东西。 跳过的也占空间的👆 毛的元数据，说好的一点点呢，啥也不占啊， 应该还是有一点点，文件元数据确实有的啊。但是没看到也是奇了怪了，不管了，反正文件ll都看到肯定元数据占用跑不了的。superblock也在分区上的啊。可能du就看不到元数据的空间占用情况。 回到这种10G大小确一点空间不占的问题上来，图①，下面要引用对比 这种文件称之为 稀疏文件--有头有尾，中间时空的。与之相反的是稠密文件。 这个文件将来学虚拟化有用的，提前接触下这个东西。 显示上都是0，要要注意前面空的虽然也用0表示，但实际上没有数据，然后 后面的1G确实写了数据--0。元数据里加了标记，从哪到哪加了标记没用 是空的 硬盘上没有数据的；后面1G真正的写了0的是有数据的。 ▲所以恶心的事情来了，上图是有1G数据的，和上面的\"图①\"是不同的，图①里的是一个数据都没有的。貌似没法区分咯，，，⚪？ du 可以指定深度 除了/boot本身，再深入2级👇 文件大小空间ls -l f看的不对了就，du可以看的准确点。 du看的是真正的占用空间，而ll看的不是，有点像是真实或者预定规划的空间。 ibs和obs是读和写的块大小各自定义，不像bs统一的。 👆表达了，文件系统的最小存储单位是4K，所以即使你文件只有3个字节Byte，占用空间也是4KB。然后注意以下bs=1说的也是块，不过这个块大小上图设定的是1Byte，加上count=3就是3Bytes。▲块这个词真的是到处乱用。对，我理解不好的，都是词名称起的不好，希望内向的同学多一点这样的观点。 空文件不会分配空间👇 空文件不分配空间，现在不需要空间，只需要元数据就行。而元数据的空间占用 看来并不是通过du查看的。▲ 一个换行也会占用一个文件系统的最小存储单元4K👇 所以，如果都是小文件，就会浪费磁盘空间了，这个小就是相对于文件系统的存储单元来讲的。所以文件系统创建的时候 可以指定块大小的：mks -b。 准备两个文件 请问最终效果是啥，结果是： 默认行为就是，从f1.txt取数据写到f2.txt的时候，默认f2.txt多出来的就截断了。 可以修改这个默认行为，使之不截断，这里使用了我讨厌的之乎者也的之，因为书写简洁。 👆这样就f2.txt多出来的就不截断了。不管截不截断，它都是覆盖的写法，不存在插入哈，插入那是insert键盘的效果哈哈~这里是往固定位写数据肯定会覆盖的。 还有转换大小写可还行，可还行--网络用语，在永生里小郡主说出来就很可爱。 还可以目标存在就覆盖，不存在就不创建 👇这个469MB/s是先放到缓冲区里的速度，它这个是先把2G的数据写到缓冲区，再写到硬盘里。 然后有个参数就是直接写硬盘的，就是命令结束前，先写到磁盘上，然后出统计结果比如时间啊、速度啊。 👆这就是真实写入磁盘的速度了，▲这个也是基本思维咯，写数据往往写的都是内存。能给你一个写到磁盘的统计--这里是统计，或给你一个写到立即写到磁盘的开关nginx还是mysql里有这东西的，也是阔以的，否则我就不知道怎么保证立刻写入磁盘--其实应该不必担心，一般都是非常快同步的，少数比如分区划分需要同步到磁盘。 就是从if=xxx中读取100个字节，但是xxx中只有90个字节，所以剩下的10个字节用NUL补齐。懂了没榆木脑袋SYM。非要顺一遍才能理解。 复习下： dd工具其实就是相当于windows里的ghost工具 有个问题，文件备份一般tar一下对吧，那这里的dd又是否合适呢，显然dd覆盖面会广，占用空间会多。然后网上有一些cp dd tar cpio dump来备份的比较说明。 网上的一些信息：就是说类似dump去做增量级别的备份 https://blog.csdn.net/ether_lai/article/details/12656219 把内存里的数据进行备份，内存修改软件--改游戏角色属性的好像有这个东西。 制作iso镜像，除了这里的dd，通常cp一条命令就行了--上一章有讲。 销毁磁盘用dd，还能找回吗？⚪多写几次unrandom随机数进去，即使硬盘支持几次数据找回应该也没办法了。 练习 RAID 避免单点故障，单块磁盘损坏。 原来随着技术演变或者说应用场景的演变、需求的演变，原来的东西的名字也是会改的。 现在主板上都自带raid卡的--内接式。 游戏笔记本做软RAID提升性能？ Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-07-20 11:29:58 "},"12-磁盘存储和文件系统/8-raid工作原理.html":{"url":"12-磁盘存储和文件系统/8-raid工作原理.html","title":"第8节 raid工作原理","keywords":"","body":"第8节. raid工作原理 RAID0的空间大小计算： 取成员最小值*磁盘块数； raid是物理上实现的，所以对于OS来讲，分区还是像以前一样，挂在300G上的连续空间的单块硬盘上。 ①以上就说明了总容量大了 ②下面是数据切片后成条带方式存储在成员磁盘上的。而切片的单元叫做chrunk。它这个3块磁盘同时读写就提高了IO速度。 ③RAID0，单单一个RAID0一般工作中不用，家里可能用的。 图中100M的数据切成多个512K，这是举例假设，不一定是512K。 RAID1 1、RAID的硬盘冗余，是针对硬盘损坏的冗余备份，如果上图RAID1你删掉文件，就删掉了，disk1作为备盘，你操作disk0上的数据，删掉其上的f1文件，disk1上作为备份也会删掉的。而raid1，如果坏了一块盘，会导致磁盘IO飙高的吧？还是你拔出坏的，插入新的才会IO堵塞⚪。不查比较合理吧，否则会同步数据IO就高了，它又不像raid5坏一块就开始算故障盘的数据。同样raid5坏一块读写效率下降，新盘顶上来IO肯定要东西向恢复数据，所以IO也是会高的，留给业务的IO就少了。 2、RAID1叫镜像，RAID0叫条带。 RAID4 raid2 3 4 都是消失的技术，不过4具有典型代表，所以了解一下 ①上图是在说raid4，100M数据存放的规律，条带+校验位(异或校验得到的) ②如果条带中某个数据块的磁盘损坏了，是可以算回来的👇 ③raid4的至少3块硬盘(n≥3)；空间利用率是(n-1)/n。牺牲一块硬盘的空间来实现一定的容错性，容错也只能坏1块。 ④raid4淘汰的原因，是校验盘的压力比较大，损坏几率较高。谁当校验盘谁老坏，这个位置不养盘啊，哈哈就想有的工作不养人一样，教师这个行当是养人的，有利于身心健康的保持。 为了解决raid4的缺陷产生了raid5 raid5 ①和raid4类似，但是校验位是分散在每块盘上的，还是条带+校验 一行。分散带来的好处是--原来raid4的时候数据较多就会频繁访问校验盘，校验盘压力大。 ②如果坏了一块硬盘，再插上新的，就会发现此时由于要算新磁盘上的数据，性能下降的非常明显。此时属于降级设备不是正常的raid5了，如果业务反满磁盘IO本来就高的情况下，坏了一块 导致降级，此时就惨了因为👇会计算故障盘数据的，会导致本来脆弱的磁盘即使是好的还能再坏1块~哈哈。 为什么RAID5系统的磁盘组降级情况下，读写效率会下降：因为磁盘每时每刻都在进行数据的写入，当有一块硬盘发生故障RAID会一直在根据剩余每块成员盘的校验码和数据来计算出故障盘内的数据，这样才能使整体数据不会丢失，也导致硬盘在读写的情况下多了一项计算，所以整体上硬盘的读写效率就会下降。 https://forum.huawei.com/enterprise/zh/thread-351133-1-1.html https://cloud.tencent.com/developer/article/1828247 ③spare disk应该说的是热备盘吧 raid6 ①比raid5多了1个校验 ②利用率(n-2)/n;n≥4 ③以前压缩文件bz zip，是用cpu的损耗--假如你是crontab这种持续性的压缩打包任务，来换磁盘的空间节约。现在就是用磁盘空间来换数据的安全。反正都是要换，要么你用身体换钱，要么要钱换身体，唉，唉~我竟然不知觉的情况下开车了。我说的是工作久坐等一些不好的情况。 raid-10 not十而是壹零 解释为什么raid01不好，首先jd上的产品就告诉你raid01不好了👇都不支持，没市场： 原因： raid-10，坏1块盘 后，再坏一个块盘导致整体不可用的几率小于raid-01，下图说明👇 disk0坏了，剩下的3块中disk1坏了就整体不可用了，其他disk2坏或者disk3坏都不会影响整体，整体不可用几率是1/3。 disk0坏了，剩下的3块中disk2或disk3坏了就整体不可用了(因为是raid0坏一块就右边整体不可用了)，整体不可用几率是2/3。 ▲所以raid-01的容错性较raid-10的差。 0这种东西就是提高IO速度的，与冗余无关，5、6就是冗余+速度、1纯冗余 速度一点点。 jbod就是写完一块，写第二块就是整合一下多个块当1块用。比raid0节约些。 raid7 了解下软RAID 想用百度吧，没啥意义应该。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-07-20 14:22:10 "},"12-磁盘存储和文件系统/9-LVM管理详解.html":{"url":"12-磁盘存储和文件系统/9-LVM管理详解.html","title":"第9节 LVM管理详解","keywords":"","body":"第9节. LVM管理详解 1、创建管理 分区一旦划分好，就没法扩了。而LVM就能扩和缩 操作的时候LVM的底层可能就是以部署raid为主，当然也可以是多块硬盘和分区。 10块组成raid10，OS看到的就是sda一块盘，以前就直接sda上分区，一旦分区就固定了，分区不够用也不能扩(不能扩的原因是，要删除分区后再重新划分和格式化，这样原来的数据就没了，所以才说不能扩，把数据移走，不就行了，不就可以扩了，蛋疼，一般来讲说的是软件应用在使用着这个分区，所以生产环境你没法，而LVM可以支持在线就是热扩，哎~，我发明词汇热扩，反正天下名词各种飘，我也来冒一个，增加读者的难度，对吧 呵呵 悲哀)，所以就再sda上做LVM来管理，如何管，假设一组raid10得到sda，还有一组sdb、再来一个sdc1分区，这些raid也好、硬盘也好、分区也好，都是linux Block Devices。这些块设备大小不限，无所谓。 把这些块设备第一步通过pvcreate变成Physical Volumes物理卷，所以物理卷就是打上标签--意思就是这些块设备不作为独立硬盘用，将来要做逻辑卷的。 有几个块设备(硬盘或分区)就生成几个物理卷，就是打标签吗，原来设备叫啥名，生成后还叫啥名。 然后通过vgcreate将物理卷们 组成一个大的集合 也就是卷组。此时卷组就是一个大的硬盘咯。 然后通过lvcreate将卷组 分成一个个 逻辑卷出来。 逻辑卷不关心上面的数据存放在哪块物理设备上， 逻辑卷的地位就是分区了，该创建文件系统就创建文件系统，该挂载就挂载。 如果LVM1 500G ，LVM2 200G，下面的卷组是1T，将来LVM1满了不够用了，还可以在线扩展到800G。所谓在线就是用户无感--使用不受影响，无需取消挂载，直接在线挂载的状态下，一条命令就挂上去了。 如果lvm1 800G也满了，怎么办，可以再底层块设备上再加入新的硬盘。这一套还是在线扩展吗？⚪ 所以linux默认安装的时候默认就是逻辑卷。 逻辑卷的概念了解后，还有一个PE，叫物理盘区physical Extent。在创建卷组的时候要指定PE，假设PE是16M，卷组就会显示有多少个PE，创建LVM逻辑卷的时候可以从这么多个PE中取出多少个PE来作为逻辑卷。扩展的时候也可以增加多少个PE。PE就是分配的最小单元了。 到现在已经是LVM2代了，LVM2。 在IBM AIX系统unix小型机，就只用LVM，不用分区。 LVM要建立在raid之上，硬盘坏了有冗余。①担心LVM多了一层逻辑层，硬盘坏了导致整个卷组出问题②多一层逻辑层，不是直接面对硬盘，性能是否不好。据说2点担心都是多余的。反正很多企业在用，也有企业不用。 学完再来这里补充发表自己的观点，和网上搜一下。 下面开操作 第一步 准备好块设备 要注意修改分区的ID为8e 存盘退出 同步下 第一步，物理卷的生成-pvcreate x y z\\pvs\\pvdisplay pvs查看下，当前pv是空的 把上面的一个分区、一个硬盘变成物理卷 👆因为sdb1之前做个swap，所以有标记位，所以先dd清空前10M就能覆盖到了。也可以直接敲y就wipe一样也擦掉了。 然后再pvcreate /dev/sdb1 /dev/sdd也可以合起来些。 这样pvs和pvdisplay就能看到了 pvs就是summary概况，其中lvm2就是逻辑卷2代；VG列是空 表示卷组没组建呢还。 pvdisplay同样可见VG是空；PE Size也是0 这个只有创建VG的时候指定才会出现。 第二步 vgcreate创建卷组 vg开头的也是一大堆命令 同样有vgs和vgdisplay，然后pvdisplay肯定也能看VG和PE也就是vgcreate后的信息。 使用帮助看下 -s 指定PE的大小 pe--physical extent size 上图忘记加单位了，不过有默认值的pvdisplay可见。 vg整合好后 ①pvs看 PE的默认值也看到了是4MB，上图PE size是4MB，total PE 1023就是1023个的意思。总容量也就是4G咯。同样/dev/sdd也就是4MB*2559=10G ②然后通过vgs 和vgdisplay看看 👆vgs可见，vg0这个卷组里有2个PV--物理卷，LV还未划分，大小是两个PV的总和14g的样子。 全部PE个数3582个，Alloc PE / Size 0 / 0就是没有分配出去呢--因为逻辑卷lvm还没有分配呢。 由于逻辑卷lvm还没有创建，所以还看不到vg0这个设备 第三步 lvcreate创建lvm lvcreate --help可见用法：从哪个VG--卷组里 通过-L取 多大size ；通过-l 取多少个PE，这是个数 上图有striped和raid1|mirror，这就是raid了，完全可以用lvm再做一层raid，实际上底层物理设备做raid后，上层lvm不会再做raid了。 👆起个名字mysql，-L 直接写大小，-l数个数还要算--不用，从vg0里面划分lvm。 lvs 和 lvdisplay 上图说明： 这个就是完整的设备名，这其实是软连接👇 实际上叫dm-0，还有一个和它一样指向的软连接 所以待会可能看到的是上图这个名字/dev/mapper/vg0-mysql 看下现在的dm设备有几个：如果再创建一个lvm，这里就会多一个dm-1了 上图的Current LE 2048是说的LE的个数。 上图的8G到底用的哪个物理卷，通过pvdisplay可以看到的 可见/dev/sdb1全部空闲就是没有用，所以这个8G都用的/dev/sdd的空间4MB*2048也就是8G。做raid也是不关心具体到底存在那块盘上的，都是当作整体在用的。 2048个PE，在LVM叫LE，就是PE在LVM逻辑卷里的名称。 一旦LVM划分了，blkid就能看到了 现在由于还没有在LVM上创建文件系统呢，sdb1和sdd的UUID肯定是各归各的。[ 所以还看不到一个sdb1和sdd合成一个的情况，其实合成一个情况是blkid是看不清楚那几个合成一个了 ，这个说法不对的，是sdb1和sdd里PV化和VG后再取出PE们来合成的，不是简单的sdb1和sdd直接合成的，之前我想当然的是不好显示的 ] 。只能再下面的格式化看到多出来一个mysql的逻辑卷。而sdb1和sdd是逻辑卷的成员而已，具体是哪个lvm的成员还需要具体去看的。 第四步 mkfs.xfs格式化 这个时候就看到，增加了一个新的记录，mysql这个逻辑卷就有文件系统了。 lsblk是你fdisk后 再 partprobe就可以看到的块设备出来了就 而blkid不一定看到，因为lsblk看到这个块设备后，还需要进一步格式化才能看到的。所以blkid是看带文件系统的块信息的。 第五步 挂载 挂载的时候，要写设备名，可以写这里的/dev/mapper/vg0-mysql可以写当初创建的lvm起的名称/dev/vg0/mysql，这两个都是可以的，因为都是软连接。 上面是临时挂载，永久挂要写fstab 刚才挂过了，所以就行了，reboot也不怕了，正常就是mount -a就行了。 看看性能 上图是不是有点夸张了，逻辑卷能提速这么快的？逻辑卷反正不会比物理分区慢就行了。 上图就是conv=fdatasync就是结果显示的是已经同步到硬盘里的了。上上图的是写到内存里了就显示结果了。 所以lvm + raid，是很好用的。慢也不慢，底层用raid冗余物理设备。 2、管理详解 下面看下逻辑卷的空间扩展 假设这个8G用满了，下面对其进行扩展 这里少了一步看mysql这个lvm到底来自于哪个卷组，其实这里就可以发现人家用vg0-mysql作为自动生成的软连接 来作为设备名 本身就是要告诉你mysql来自于vg0。 逻辑卷扩展 要先看 卷组里有没有空闲空间 可见卷组里还有6G空闲 lvextend -l 小写的l在扩展全部剩下空间就特别好用，可以写-l 1534就是剩下全部的Free PE个数，也可以用上图的+100%free来直接搞定剩下空间的100%。 不需要指定vg卷组，因为mysql这个lvm系统知道从哪个卷组来的，所以无需指定，直接命令就写/dev/vg0/mysql就行。 回车后可见已经扩展到13.99GB共3582个PE。 此时再看vgdisplay可见已经没有剩余了 vg用光了，vg整合的pv自然也就用光了 但是此时确发现df -h 里看到的逻辑卷的空间还没有刷新 注意，这不是没有刷新哦，这是因为 你虽然把lvm扩展了6G，但是这个6G的空间还没有文件系统(还未进行格式化)，不是简单的格式化，而是格式化后并进去，其实确实是一个命令就同步了，也算是笼统的刷新了。 df看到的是文件系统的大小。 现在就是要将扩展的6g空间的文件系统同步到既有的8g空间里去，不是简单的mkfs.xfs哦。 👆可见data blocks 变大了。此时df -T再看文件系统的大小就扩上去了👇 总结下扩展其实就两条命令（在vg卷组有空闲空间的时候） 而用户是无感的，扩展的的时候也没有取消挂载，一直都是挂着的。 再来看看我的centos8的默认就是使用的逻辑卷的 vg没有空闲空间的扩容步骤 此时要扩vg0-mysql，但是vg0已经没空间了怎么办。就再加一块新硬盘。 ①pvcreate 只有分区才要加标签8e，硬盘无需改 pvcreate后再blkid就看到了，就和mkfs.xfs 格式化后就看到了一样，blkid是看带文件系统的块信息的 此时pvs就能看到多了个20g的pv ②vgextend扩展卷组 上图可见现在vg0有两个成员Cur PV 2，再加一个。 vgextend vg0 /dev/sdc 此时卷组就又有空闲空间了，扩展就一样了。还是两条命令的事，可见扩展lvm确实无需取消挂载。 同一个卷组里创建新的逻辑卷 再后面学习中可以把mysql的日志放到专门的逻辑卷或分区中，这里就专门创建一个binlog的lvm ①lvs,lvcreate -n binlog -L 10G vg0 lvdisplay就可以看到有两个lv了 ②mkfs.ext4 /dev/vg0/binlog 格式化逻辑卷为ext4 ③挂载 此处省略了持续挂载fstab的编写，上文有的。 针对binglog逻辑卷扩容，-l +1000个pe 一个pe4MB 此时逻辑卷确实扩展了 由于增加的部分没有格式化，也没有加入进当前的binlog文一个整体，所以 刚才xfs文件系统用的是xfs_growfs /mnt/mysql，现在ext4得用resize2fs /dev/vg0/binlog，前者跟的是挂载点(文件夹)；后者跟的是设备名。注意下 此时就成功了 由于文件系统的不同，最后同步的命令不同，后面跟的部分也不同，所以自动化脚本就有点麻烦，所以有更好的扩展方法来了 不管是xfs还是ext4都一条命令扩 lvextend -r -l +500 /dev/vg0/binlog 翻看前文可知刚才mysql这个lvm是14G，现在扩了500个PE，一个PE是4MB，也就是扩了2G，达到了16G。 上mysql是xfs，下面继续binlog是ext4的也用这一条搞定 一样成功了 此时就发现上面的同步命令白学了？不是 xfs_growfs 挂载点 --- 这个是扩展用的 resize2fs 设备 --- 这个扩展和缩减 都行 lvextend -r -l +500 /dev/vg0/binlog 这个就是扩展lvm的时候自动同步了。 所以resize2fs后面缩减还要用得到。算不上白学~ 其实通过man lvextend可见 其实-r 就是resizefs，哈哈~ 缩减有风险的，如果一不小心写错了--写成缩减到50G，而此时数据就是100G，那么就会造成数据丢失50G~。 以防工作中用，还是要学一下 缩减 缩减上图ext4的这个lvm空间 扩展是在线扩展，缩减必须离线缩减，意味着取消挂载，用户访问受影响了。 ①unmount /mnt/binlog 回想扩展的时候不管是2条命令还是1条命令，底层逻辑都是先扩展lvm，再同步扩展文件系统 现在缩减的时候就是先缩减文件系统，再缩减逻辑卷大小。 缩减前的lvm大小如下15.86G： resize2fs /dev/vg0/binlog 10G # 缩减到10G 注意这个命令①同步的命令(同步的命令其实就是将lvm扩展后的空间，再扩展到文件系统里去，这个场景其实就是不写多少个G就是全部扩展进去，其实你的需求就是lvm扩展后，再同步到文件系统里，自然是全部了)②缩减的命令，在后面跟上空间即可表达缩减到XXG。 缩减的时候会提示你先检查一遍系统完整性，再让你缩减。 ②e2fsck检查下完整性之类的、③resize缩减文件系统 此时由于是resizefs 缩减的是文件系统，所以lvm还没有缩，通过lvs可见大小没变；然后开始缩减lvm:lvreduce -L 10G /dev/vg0/binlog ④缩减lvm -L 10G，不带+加号的就是直接缩减到10G。man lvextend可见👇 ⑤mount，缩完后重新挂载 注意缩减只能缩减ext的，不能缩减xfs的。 上图命令补齐也可见一斑，只有grow，没有reduce resize这些补齐命令出现。 所以▲xfs哪里比ext好了。 逻辑卷的迁移 迁移操作举例 拿这个b硬盘做实验，看下sdb1有没有用，就是看下有无挂载咯 当时老师做实验的，sdb1报错，肯定是fstab里写东西了， 删掉 dd 干掉分区清一下 发现上图dd掉512B后，分区sdb1还在，那是因为没有同步 partx -d --nr 1 /dev/sdb # 不能用-a，-a是增加，-d是删除 注意提示sdb忙 再次df 发现之前fstab里已经删掉了持续挂载哪一行，现在还是有类似的报错--废话你删掉的是mout的配置文件，又没有取消挂载，现在的df报错就是之前mount过--通过mount可见--然后挂载点估计是删掉了被，现在df报错了。通过mount看发现了问题所在， 视频中老师的排错思路看下 看到说明没有取消挂载 哈哈，还是在，我猜是不是dd 512导致的，还没有取消挂载就dd导致的？ 通过fuser -v /mnt/sdb1也没有人用啊，这会umount没报错，lsblk也看到没有挂载了。 取消挂在后，再同步一下，此时分区sdb1就没了 那上面过程总结，①挂载没有unmount②unmout需要时间③好像是/mnt/sdb1先挂，/mnt后挂，这一类也有问题。 下面开始针对sdb创建lvm，然后演示lvm的迁移 先创建一个和将来要过去 名字 存在冲突的vg0和mysql逻辑卷 下图👇创建物理卷、创建卷组并指定PE、创建逻辑卷指名和指大小和所属卷组。 挂载 复制点文件过去 好了 LVM就有了 下面进行迁移 先取消挂载 考虑到迁过去的卷组也叫vg0，lvm也叫mysql，只要vg0改了就行了，因为整体名称vg1-mysql过去就和vg0-mysql 不 冲突了 改名 禁用卷组 卷组禁用后，所有的逻辑卷也就禁用了： 导出vg1 拆硬盘、插硬盘、识别硬盘 正常服务器就直接拔，这里实验用的是Vmware工作站，先关机 是sdb硬盘要迁移 这就是硬盘啦，把这个文件复制到centos7的虚拟机上去 移动硬盘嘛，就是剪切过去 再centos7上加硬盘之前看下 当前硬盘排号已经到d了 完成 不会自动识别，echo - - - 一下 出来是出来了，但是这边的系统还不能识别其上的LVM lsblk看不到没关系，使用vgdisplay可以看到 上图👆可见此时vg1卷组是出于exported导出状态 导入卷组 使用vgimport vg1导入 此时状态OK 通过lvdisplay可见2个卷组 注意上图的not available 启用逻辑卷vg1 启用后再看 就正常了，lvm有了，就可以挂载了 挂载 此时数据就都过来了 以上讲解了lvm的创建、扩展、缩减、迁移 下面来个例子 假设sdd这块硬盘 指示灯开始黄灯 表示快坏了，还没红，但是要坏了。 此时需要把这个块硬盘剔除下来，问题是其上有逻辑卷，不能直接拔。 问，怎么拆走这个块要坏的硬盘 表示sdd这个物理卷已经被别的逻辑卷给占用了已经。 要想拆走这个sdd，必须先把其上的2559个PE的数据搬到同一个卷组vg0下的其他逻辑卷上，必须是同一个卷组。 但是 vg0 发现只有2059个PE空闲 1、只能加个PV了，为啥一定要同一个卷组呢？因为所谓搬家使用的是pvmove命令，估计这个命令需要同一个卷组。 2、当然你也可以缩一下，然后再搬家。 这里还没有加PV，vg0的所剩空间并不够，只是演示一下： 这是把sdd上被占用的PE搬家到同一个vg0下的其他空闲PE上去，前提是空闲PE数大于占用PE数。 有个问题啊，搬家是搬到其他空闲PE是吧，其他空闲PE是否分散在不同的几个LVM上呢，这样文件又该怎么索引找到呢，难道原来一目录下的分散到好几个目录下了？显然不可能这么玩啊。 实际上数据没多少，但是搬家搬的是空间，硬盘拆走，硬盘其上得lvm当初承诺出去的空间是16G和9.8G，现在sdd一拆，承诺出去的2559个PE差不多10G的承诺空间就没了。 当然你也可以缩一下，然后再搬家。 缩的问题也来了 不知道这2559个PE到底是哪个LVM占用的。 通过lsblk查看 可知是vg0-mysql逻辑卷占用了sdd的全部PE，而且vg-mysql还占用了sdc的PE 只要把vg0-mysql的容量变小，就可以搬家了 此时vg0-mysql lvm才用了很少： 再进一步发现，最终还是缩不了 只能加硬盘了 把sde剩下的18G空间加到vg0里面 不需要太多，👇只需要500个PE，也就是2G的大小。 然后...👇 发现整个sde都在vg1里了，没办法给都vg0了。 重新弄个分区来做吧 以上分析就是关键思路 注意此时blkid还没有呢，需要pvcreate后才有 pvcreate后blkid就看到了 加PV就是贴标签 加到vg0卷组里 至此vg0的容量就扩上去，剩下3338个PE，sdd的2559个PE就可以搬家了 此时sdd的PE们就搬家到同一个卷组vg0下的其他PV上去了，至于是哪些PV不关心，反正有地方，有文件夹入口访问就行了。 注意搬的是空间，不是数据，空间过去了数据自然也过去。 刚才的sdb3的5个G空间用完了，当然还有其他的PV也会分担一部分sdd的空间 sdd上的空间就搬走了 此时sdd上既然没有数据了，就可以考虑移除了 当前vg0里4个PV，计划删除sdd这个已近搬完空间的PV 变成3个了 此时/sdd就不属于任何卷组了。， 然后再删除sdd的PV--物理卷 标签 sdd就没有了 此时sdd就是一个完全和逻辑卷没有关系的硬盘了 就可以拔了~ 上面的分析较多，查看较多，真正的命令就3条--当然前提是空间够 注意，从头到位都是在线操作，没有取消挂载。 扩展、缩减、迁移、拆除 都讲了 LVM的删除 某个vg的所有lvm都不要了 ①取消挂载 如果是fstab里有写，也要删除 ②删lvm 删之前要确定上面的数据不要了 此时vg1里的空间就没人(lvm)用了 vg1没人用了也可删了 ③删vg 此时sde这个pv就不属于任何vg了，也可以删这个PV了 删PV之前blkid可见标签👇 ④删PV 此时sde再PVS中不可见，就成了一个纯粹硬盘了 也可以拔走了。 3、快照管理 逻辑卷还有个功能是分区做不到的--快照 VMware里的快照也是一样的道理 卷组里创建多个lvm，/dev/vg0/mysql是vg0里的一个逻辑卷。500G的数据备份时间很长了，但是快照就秒做。你需求不是备份数据，只是能够回到某个时间节点的数据，所以只需要针对变动的数据做备份就行了。 假设待会有100G的数据要产生修改，要是直接备份着500G很花时间，所以在同一个卷组VG0下再创建一个逻辑卷--快照逻辑卷--mysql_snapshot，本身也是个逻辑卷，只不过是个特殊的逻辑卷。因为假设是将来要改100G的数据，所以创建快照逻辑卷的时候就指定创建的空间为100G。所以快照逻辑卷的大小不用和源逻辑卷的大小一样，这个腾讯云上好像也有建议值，一半吧好像。 快照的原理，区别于普通 的备份，是针对变动的文件做的备份，文件要修改前先备份到快照逻辑卷里，所以性能会有所下降，但是还原快，空间占用小。 1、快照的创建的瞬间，其实只是分配了XXXG的空间，并没有备份任何数据， 2、只有后面数据发生变化的时候才会备份，所以性能是有所下降的。 同样改F2为F2'，也会将F2复制过去 3、只要没改过的数据都是在原来的逻辑卷里，只要改过的都会在快照里存在一份，假设F3改了好多次，问第一次的改动的版本在哪，中间的N多版本在哪，最后一次的版本在哪；要回答这个问题，只要抓住快照的本质，就是拍照片的那个时间点，所以第一次改动的版本在快照里，中间都没了，最后一次版本还是在原来的lvm里咯。从这个角度来讲，F2一旦改动过一次，后面的就不会再推送到快照逻辑卷了，也就是说性能就又回升了，所以说只要所有可能发送变动的数据都变过一次后，快照的性能就回升了。 从使用实际角度来讲，不可能所有文件都变过一次，总有第一次变动的时候，所以快照使用完就干净删除，防止性能损失 4、快照的前提是 ，快照卷和需要镜像的卷 必须在同一个卷组中。 5、快照的空间一般是原lvm的 多少呢，反正大于原来卷是没有意义的。 如何实现快照 举个例子 mysql这个lvm目前是16GB不到， 创建快照逻辑卷 要考虑卷组里有没有剩余空间 弄三个小文件做实验 f1删掉 快照里找回；f2修改 快照里找回；f3不动 快照里没有。 -n mysql_snapshot 起个名字 -s 指定为快照snaphost而不是普通逻辑卷 -L 1G 做实验不讲究了就给了1G，因为原lvm的大小虽然是16GB，但是测试的文件才3个小文件，够了。 -p r 就是属性是readonly只读的，这里不写也行，就是后面快照逻辑卷挂载的时候加只读属性mount -o ro 也行。这样逻辑卷就不能被别人篡改了，正常的快照备份业务显然OK的。 /dev/vg0/mysql就是给谁做快照。 此时👆就看到了 多了一个LV snapshot status属性：mysql_snapshot是active destiantion for mysql是mysql这个lvm的快照。 而且看到LV Write Access是 只读的。 同样的去看原lvm就是做了快照的那个lvm也多了1个属性 然后删除f1，修改f2；创建f4 然后去挂载一下快照看下 快照逻辑卷发现不能挂载，blkid可见👇 快照卷和原逻辑卷的UUID一样，XFS文件系统的一个特点就是同样的UUID的设备不能同时挂载的。 提示不能挂载只读的快照，刚才创建快照逻辑卷的时候-p r了。 即使这里写个rw也没用 因为快照是只读的 没有办法挂载的时候改成rw 只能重新创建一个rw的快照，去挂载了，也许有办法修改 把原来的删了吧 原来的也没挂载，所以直接lvremove删了 这次的快照2创建后，同样需要修改数据，数据没变，所以此时快照里没有数据。 👆同样的问题，UUID一样，又加上是xfs系统，挂载需要忽略UUID冲突。 👆此时lvdisplay就看到这个快照就是rw可读可写的。 发现数据没改过，快照文件夹里就已经有了，好奇怪 属性也一样👇 1、文件没有改，快照里就是没有的， 2、虽然我们从快照挂载的文件夹里看到原来的数据，但这些数据实际上还不在快照里。也就是类似于链接之类的机制。 3、这样做的就是让用户有一个心理安慰，让你看到数据在的，其实不在。 下面对文件做一些变动 f2删了、f3改了、f4没动、f5新建 此时看看快照文件夹里的东西，就是当时创建快照时候的数据。 如何恢复快照的文件 接着上图，可以把快照挂载的文件夹里的数据复制回去，其实有专门的命令。 先取消挂载，所以挂载快照卷其实是没必要的操作，只是为了实验看看，所以创建快照卷的时候确实可以-p r设置为只读的。 1、取消挂载快照卷---这是因为之前的挂载操作，是实验环节的演示，正常生成中不需要。 2、取消挂载原逻辑卷的的挂载，这是确确实实需要的操作。 因为要合并快照和原lvm，所以需要取消挂载 等会就好了 然后再挂回去，数据就恢复了 还原后，逻辑卷的快照卷就没了，使命完成，就是说lvconvert --merge xxx后这个xxx快照卷就没了。快照是一次性的？vmware至少不是。云上好像也不是的吧。 以上就是针对xfs系统的快照制作和还原 上图遗漏一个点，lvcreate 去掉-p r后，挂载就需要加上ro，保证快照的安全性。 针对ext做快照 针对binglog这个逻辑卷来做快照 创建3个文件作为镜像还原的对比 创建快照卷，因为不是xfs，所以额可以-p r设置为只读快照。 UUID依然是一样的，不过这回是ext4的 👆ext4不需要-o nouuid--也就是说UUID一样也能挂，然后也不需要lvm是rw的read-only的也能挂 快照里的数据会有的，虽然这是假象--或者叫优化用户体验的效果--类似链接。 原来lvm的数据👇： 删除f1，修改f2，创建f4 还原 之前先取消挂载 还原-合并就是用snopshort覆盖原lvm 此时lvdisplay就看不到这个快照了 挂回去 此时就回来了 完整的过程如下 上图有点小问题，①快照不用删，恢复后自动就没了，除非你还没恢复呢直接删②-p r是xfs的时候去掉，再结合mount -ro -o nouuid③ext4 可以用-p r。具体上文都有说过了。 练习 注意/boot分区不能挂到逻辑卷里。/boot是启动的时候就要挂载使用的，这样系统才能启得起来。而启动的时候系统还不知道啥叫lvm呢。lvm也是要内核驱动模块支持的，刚启动的系统还没有加载lvm的驱动呢。 排版格式化 df - P选项、关键字：太长、对齐、一排。 通过lvdisplay可以看到LogVol00是给根，还有个给到了swap 同样centos8的lvm看看 删除所有的lvm 1、unmount 2、先删快照(如果有)，再删逻辑卷 一条命令好像可以两个逻辑卷都删了 lv就没了 3、删卷组 3、删除PV物理卷 到此就删干净了。 分区用不着删、硬盘不用了拆。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-07-21 18:39:44 "},"13-网络协议和管理/13-网络协议和管理.html":{"url":"13-网络协议和管理/13-网络协议和管理.html","title":"第十三章 网络协议和管理","keywords":"","body":"第十三章 网络协议和管理 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:34:59 "},"13-网络协议和管理/1-网络基础.html":{"url":"13-网络协议和管理/1-网络基础.html","title":"第1节 网络基础","keywords":"","body":"第1节. 网络基础 系网工，略 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:34:59 "},"13-网络协议和管理/2-网络架构.html":{"url":"13-网络协议和管理/2-网络架构.html","title":"第2节 网络架构","keywords":"","body":"第2节. 网络架构 网工，略 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:34:59 "},"13-网络协议和管理/3-TCP&IP.html":{"url":"13-网络协议和管理/3-TCP&IP.html","title":"第3节 TCP&IP","keywords":"","body":"第3节. TCP&IP 网工，略 略不了，这里面东西有点深，不过一般用不到，先放几个图，后面再说 还有滑动窗口、慢启动、重传机制等 accept()是app及时提取全连接队列的函数吧，如果处理不及时，也会造成全连接队列拥塞。 这块应该叫linux的网络内核参数文件以及调优，需要整理的，可参考小林codding这位的。 还有之前的一个tw内核参数，针对NAT后买的时间序列问题的，也会导致丢包的情况。 还有nginx的限制并发等。 服务器禁ping除了云上的安全组、服务器本身的iptables、还有内核参数 0表示不忽略，就是可以ping通，echo_ignore就是忽略icmp的echo 此时ping就卡住不动了，就是不通了嘛 再改回0就通了，可见中间丢了几十个包 ttl判断系统 之前是64，现在是128了。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:34:59 "},"13-网络协议和管理/4-IP地址规划.html":{"url":"13-网络协议和管理/4-IP地址规划.html","title":"第4节 IP地址规划","keywords":"","body":"第4节. IP地址规划 网工，略 皮一下~ ipv4的link-local地址是：_ https://datatracker.ietf.org/doc/html/rfc3927 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:34:59 "},"13-网络协议和管理/5-linux的网络和路由配置管理.html":{"url":"13-网络协议和管理/5-linux的网络和路由配置管理.html","title":"第5节 linux的网络和路由配置管理","keywords":"","body":"第5节. linux的网络和路由配置管理 修改网卡名-方法1-网卡驱动模块 研究下为什么是eth1，怎么改，这是centos6的： 可见eth0已经被某个mac占用，所以现在看到的就是eth1了。 删除并修改 修改后，重启网络服务是不行的 要修改eth1这个名称，需要卸载网卡驱动，并重新加载驱动。 mii-tool 查看 查看网卡驱动 👇找到了驱动模块 lsmod 是找到加载的所有驱动模块 卸载模块用rmmod或者modprobe -r 网卡模块卸了也就是网卡驱动卸了。 此时网卡就自然看不见了 然后再重新加载模块(驱动)： 此时就改为eth0了 方法2-ip子命令 ip 子命令，在centos6上tab不出来，centos7可以 centos6要额外安装软件包才能支持tab键补全 网卡配置 1、setup 进去选-选-选 等价于system-config-network-tui # 这两种方法就是算了，而且在centos7里setup里也没有网络配置选项了。 2、重点看命令和配置文件 ifconfig过时了，擦 主要是因为net-tools这个工具包过时了，所以包里的很多比如ifconfig、netstat都过时了。 推荐你用iproute这个包 ifconfig直接回车看的是激活状态的网卡 禁用和激活 ifconfig eth1 down 禁用eth1网卡 ifconfig 就看不到eht1，ifconfig -a 可以看到eth1但是IP没了，ip a就看的更清除了 ifconfig eth1 up启用 禁用网卡还可以ifdown eth1 不过这种down和刚才的ifconfig eth1 down又不同了 这个ifdown 后，ifconfig确实可以看到的，但是没有地址。 这个ifdown属于网络层的down，IP没了但是数据链路层是通着的。 对比ifconfig属于数据链路层的down。 所以ip a看就会发现是UP的，所以ip a看的就是L2链路层咯。 1、ifdown\\ifup是L3层的up\\down， 这个ifdown后ip a看还是UP的 2、ifconfig down\\ifconfig up是L2层的up\\down，这个ifconfig down后ip a看就是DOWN的 3、ip a看的是L2的up\\down 4、还一种是物理层的down，就是拔网线了 5、ip link set eth0 down 也是可以的，一样是控制L2的up和down，见下图👇 6、几个关键词：LOWER-UP和UP的区别、NO-CARRIER DOWN和DOWN的区别 https://stackoverflow.com/questions/36715664/using-ip-what-does-lower-up-mean ifup 要起来还需要依赖一些网络配置文件，所以ip a还是看不到地址 没关系，在centos6上用service NetworkManager restart就可以了。 把网线的演示 这就类似拔网线了 1、ifconfig看就没有地址了 2、ip a看就是down 此时上图👆就能判断是网线拔了，而不是其他的，因为有关键词NO-CARRIER。 对比ifconfig eth1 down的描述信息 配地址-临时 清地址-临时 增加地址-临时 就是huawei里的sub地址咯，或者是思科的second ip。还一种是子接口，子接口在linux里是一种别名 ifconfig eth1:123 1.1.1.1/24 ifconfig eth1:321 2.2.2.2/24 ifconfig可见 这里不涉及子接口的vlan id封装解封装，直接就能和外界同样的IP进行通信，所以我感觉更像是second ip而不是子接口。 删除linux的子接口 ifconfig eth1:123 down 这个down掉就是删除子接口了，这里就称之为linux的子接口咯，虽然它没有vlan的概念。 混杂模式 抓包的时候就用的混杂模式 混杂--不管这个数据是否给我的，我都收。 https://cloud.tencent.com/developer/article/1439013 VMwareWorkstation的话有时候需要手动修改centos的接口为混杂，原视频中我没有找到当时老师的操作，不过理解后也能自己设计一个场景，所以这里就仅仅提示下。 https://blog.51cto.com/nizhuan/724081貌似桥接模式就是混杂模式了。 mii-tool 工具 上图说明 capabilities 是支持的能力比如FD就是full duplex；HD就是hafl duplex 第一行就是协商后的当前工作模式是千兆全双工 ethtool 工具 网线8根线，如果断了一根运气好，还能用就是100M，👆这里就可以检查到。但是要注意如果是vmxnet3的网卡，ethtool看到的就是10G速率，虽然实际上是1G的。所以这里的速率显示显然不是实际值。 ehtool可以修改网卡工作模式，一般不改 CMD的grep 例子，查看多少人连到我的VNC上 第三列就是client IP地址 常见服务端口 cat /etc/services 一般客户端电脑不会使用1W6+(65535-49152)个端口，但是如果你这台linux或啥系统的电脑是作为代理上网，比如SNAT，那么1W6+也不是没有可能，因为1台内网的PC大概10连接，1000台PC对吧，再加上手机，还是有可能让你的这台NAT服务器的端口超出1w6+这个默认值的。 如果要当代理，这个端口就要调大👆 实际情况是60999-32768=28231个随机端口。 TCP的序列号问题整理 数据包的序列号，并非0，0是相对编号，应该是初始ISN，好久不碰了有点忘了都，而是下面的97fa6e02 再CISCO的安全方向里ASA的里面有一个SN、ISN的利用。然后linux的tw内核参数 还有一个问题，一般出现在网吧、公司这种NAT环境 https://blog.csdn.net/enweitech/article/details/79261439 文章讲的太细，简单的故障处理就是 “之前的偶尔打不开是因为开启了一个tcp相关的内核参数, 办公网都是nat出去的, 数据包时间戳的抖动会导致服务器把请求给丢弃, 迁移之后的 oa单点登录, 虚宝网等我都把该参数关闭了, oa.sm.xxx 这个不在迁移的机器中, 刚刚修改过了, 后续在观察一下” -- 这个是案例，呵呵。 https://ppabc.cn/1363.html 这个篇针对性强，说的是时间戳。 tcpdump的举例-整理稍后 上图👆是drop后的一个抓包结果，可以看到很多的[S]，这就是SYN包，是重传机制导致的。 其实更多的时候，我一般就是抓个端口然后|grep 哈哈，是不是没想到，哈哈 |前导码+开始符|DA|SA|TYPLE/LENGTH|DATA|FCS| 一共72B的最小值。 ping 默认就是64也即是没有算开头的8B。 附上之前的一个分片解析图 TCP超时重传 TCP的拥塞控制 四个机制 慢启动、拥塞避免、快速重传、快速恢复 https://allen-kevin.github.io/2017/12/21/TCP%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E4%B9%8BCUBIC/ 并发ping-首推方法 seq 1 255 |xargs -i -P 0 bash -c 'ping -w 2 192.168.25.{} &> /dev/null && echo 192.168.25.{} icmp allowed' 还有awk的并发ping，想不起来了，没影响了。 这个也快 ls --hide=proc | xargs -i -P 0 find /{} -name \"sshd\" awk的举例 tcpdump -i eth0 -tnn dst port 443 -c 100 |awk -F \".\" '{print $1\".\"$2\".\"$3\".\"$4}'|sort|uniq -c|sort -rn|head -n20 我之前说过awk和xargs一样快，ping的处理上我怎么不记得有做过呢，肯定是有过的，现在想来是写个for循环awk调用系统命令，但有这么复杂吗，当然其实不复杂，我是说之前的awk实现批量ping 是怎么弄的？ 还有好多工具类的使用iperf 、curl、F12等等，这些就算了，不放到这里了。 广播的情况 👆ping 255广播只有一个37.2响应，因为linux默认是不响应广播ping的，需要开启 1就是忽略，就是不回应，改为0 centos7上一样，centos8也一样 从默认的TTL上可以判断37.2的ttl是128，是台windows机器；37.7和37.6是linux机器。 注意上面这个实验，要在同一个网段做哦，原因很简单，就是跨网段，的192.168.1.100去 ping -b 192.168.10.255，这个广播是不会有任何回应的，因为3层转发广播不转发的，这就是CCNA里的基本概念--广播域--二层广播帧所能到达的范围就是广播域，显然二层广播帧的广播地址全FFFF-FFFF-FFFF显然要比192.168.10.255这种L3广播地址映射到二层的广播MAC地址还要厉害，连这种真广播都跨不了三层，你凭什么能ping通呢，至于为什么垮不了，因为数据要从二层拆包，到三层，再重新封包，这个过程就算3层路由器设备处理广播----其实真可以处理的，CISCO SECURITY 里有个攻击就是用广播做的好像，需要路由器转发广播的。 loopback 略，注意下图 人为将linux的lo环回口改成6.6.6.6/24 ，这样这个段都处于loop，并不是说必须是127。 这里也可以写IP地址，不一定写lo 网卡配置文件 name将来就表现为GUI图形界面里的eth0 改的玩下， BOOTPROTO=none也行都是静态手动配置，BOOTPROTO=dhcp就是动态 1、注意一旦写了dhcp，后买手动配置的IP地址，DNS就会被覆盖了； 2、文件其实就是脚本用的，前面其实就是变量，变量是区分大小写的，然后=左右不能带空格； 这块书上讲的更全，所谓全其实也就是下发明细和下发默认的一些优先级问题。 还能精简成如下3行，再补一个GW和DNS1 改完配置文件后，一般不会立即生效，有时候会立即生效，那是因为NetworkManager服务，不过这个服务不是时刻都能立即发现你修改了文件然后使之生效的。而且这个服务一般也不用都是关掉的。最小化安装好像也是没有的。说反了，一般是我们只用network，但是rocky-linux和centos7最小化安装后好像rocky-linux是没有network服务只有NetworkManager，然后centos7的network是fail的NetworkManager是active的。好奇怪~没事，停用禁用NetworkManager后就可以启用network服务了。 看来rocky-linux不喜欢这个。centos8一样， linux开启路由功能 注意临时修改是用的echo，vim是不能编辑内存里的文件的 vim是改磁盘文件的，不能改内存的数据。 mtr的使用 mtr可以选择icmp tcp udp的，这点要知道，然后我的处理，是通过crontab去弄，大概如下 基本上如果curl的效果不行，就自动触发mtr得到报告，不过with os.popen这种阻塞的方式，在网络质量不好的清苦下，会造成cpu负载高的，因为太多的阻塞等着运行了。网络好就不存在了，30s不到就mtr完了，或者都不会触发mtr。 frr可以弄一下 frr替代quagga了好像 vyos、led、openwrt、strongswan、openswan、routeros、 vyos的ipsec vpn--police的，存在支持上限的问题，未尝试解决、未升级测试是否得以改善，其他功能OK，由于没有大并发，性能未得到测试。 openwrt里的strongswan在旁路模式下，也不知道是我的TP-LINK物理网卡问题还是旁路的问题，反正隧道存在丢包，游戏时存在断线重连的情况，效果不好，未尝试继续改进。 softher vpn这个不多说，emm，真心不错，一键搞定IPSEC、openvpn、pptp、l2tp。其实远程办公，还是要考虑授权、限速的问题，如此衍生出的IP静态分配，等就不是简单使用softehter来实现，从这个角度还不如自己使用开源来弄，顶多写一个脚本来做统一的多协议账号开通。其中openvpn就是要使用radius和mysql或者ldap之类去做，这个不用这么麻烦，直接配置文件里指向一个脚本验证 一个存放用户名密码的文件就行，具体见我的印象笔记的相关模块。 其他还有什么clash、向日葵、vⅡray是吧，哈哈。emm有时间都要整理出来。这些东西可不是仅仅那个作用，可以用来做远程办公，而且客户端软件效果好，openvpn嘛还不必clash的节点测试效果，切换方便，如果公司4个出口，统一到clash就很不错，需要考虑的时clash他后面要自己搞成静态IP，然后用户授权啦--最好是账号密码而不是profile配置文件这种不太好管理的。东西用来做远程办公确实可以研究下的。让技术更好的服务正规需求是我们要考虑的。 不过这里建议大家先从提高收入左手，而不是大量研究这块，恩业务需求的满足，完成就好，完美不好。70个完成远远大于40个完美。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:34:59 "},"13-网络协议和管理/6-网络配置和故障拍错.html":{"url":"13-网络协议和管理/6-网络配置和故障拍错.html","title":"第6节 网络配置和故障拍错","keywords":"","body":"第6节. 网络配置和故障拍错 netstat 那啥ss可能会更好些，netstat也学一下吧，好像mac里用的也是netstat这个命令 套接字socke分2种 1、ip+port，tcp或者udp都是这种； 2、unix domain socket，这种就表现为socket文件。 s开头就是socket文件 这类的socket文件也能实现和tcp/ip 这种Ip+port的类似的通讯效果，可以实现多个进程之间的网络通讯，问题来了：是本地还是远端呢？ 1、两个程序如果处于不同的主机也即是远端通讯，可以使用tcp/udp的socket--ip地址加端口号；这种通讯存在一个封装解封装问题。 2、如果处于本地--同一台机器，就没必要封装解封装的过程了；可以考虑采用这种unix的socket，两个程序想通讯，就把数据扔给socket文件，通过它中转就行了。 netstat说明 -n 不解析地址为域名，端口为服务，这个是常用的 -t和-u就是tcp和udp咯 -l是看监听的，不是看ESTABLISH的。👈 这就是看打开了(监听了)哪些tcp/udp的端口。 1、注意上图，TCP是有状态的，所以显示LISTEN；而UDP是无状态的 所以没有显示什么LISTEN字样。 2、如果发现有些端口不是我们需要的，可以找到该端口对应的应用程序，然后卸载掉。怎么找呢，就是加个-p或者👇 如果知道端口对应的APP lsof 可见6000这个端口是x11这个图形界面软件在用。 netstat -p或者ss -p，当然要辅以其他选项 切到init3就是纯字符界面，就没有x11了， netstat -e 是extend，会显示节点编号inode netstat -ntua ，a就是监听和连接的都会显示 常用组合 这个还挺不错，我是说netstat -nr，它可以看到MSS和window，MSS肯定就是4层传输单元了MTU\\MSS一类的嘛，window就有点不能理解，TCP的滑动窗口也不至于写到路由表里吧，而且窗口还是动态的。网上搜一把没找到，转头进入man netstat 然后\" + -r\"看到👇 然后进入route的man帮助 你看他这个route只有一个8.gz的man，所以不需要man 8 route，哈哈我是不是太无聊了 瞬间找到了，还真是窗口，不过是AX.25的，所以那啥，MSS再看看搞不好也不是动态测试的，而是设置的 默认就不显示咯，MTU1500嘛MSS就是|DA|SA|TYPE/LENGHT|DATA|FSC DATA： |IP|TCP|DATA| MSS=1500-20-20=1460，一般就这么算吧，不过遇到ASA拨号的时候，L2的DATA就是|da|sa|type|pppoeHead|pppHead|ipHead|tcpHead|mss，此时的MTU=1500-6-2=1492这个是对IP层的整个报文限制了，所以MTU是L2对L3的一个限制，你在ASA上要敲的MTU就是1492，然后MSS就是1492-20-20=1452。注意哦MTU是二层对IP层(L3)的一个限制，限制的是整个IP报文长度，限制产生的效果就是IP层会自己去分片，怎么分的上一篇已经讲过了ping -l 1502的分片计算有讲。而MSS的源头也是MTU，但是MSS是TCP里的DATA的上限，这一点不可类比于IP的整体长度限制。恩其他还有PMTU discovery地理发现贫道~恩没有广告~所以在有电视那会还是基本爱调在这个台，哎~俱往矣，属温馨伐木累还看还看还看还看555...哈哈哈我能把人气成这样也是我占着理拿着需，唉得饶人处且饶人啊，别人也是关心你。 我就直接引用别人的博客了https://zhuanlan.zhihu.com/p/139537936 https://blog.csdn.net/lepton126/article/details/70810316 netsta -i 查看接口统计信息，访问量大不大 动态观察的方法 wathc -n1 就是1s刷新一次 netstat -i这个命令的结果 ping嘛就是1sping一个，但是-s 65507后同样也是1s ping一个，但是这一个要切片成N个咯，所以实际上1s发出的包就是N倍，所以此时再去看对端的watch -n1 netstat -i就会发现RX-OK增长的很快。 还可以更快，就flood的ping 这回RX-OK的增长就更快快快了 大包分片+ -f，够了哦~ 这是WIFI，ping -s 打到了32Mbps 去看看有线 哈哈，瞬间打到250Mbps，1G的带宽也就是950Mbps吧，人家要叫了，哈哈。 这种ping -f打出来没有iperf的大，iperf同样的源目1G可打满950M的。 一些个性的命令写法 敲入：watch -n1 netstat -Ieth0 ip命令 ip命令很强，用来替代ifconfig的 ip 后面加 选项，再加 操作对象；操作对象有 link | addr | 等等👆 在centos6或centos7的最小化安装都不能tab补齐，可以通过安装插件bash-completion来实现，centos7没这个问题。 yum完后exit重新登入一下，此时就可以tab两下补齐了 ip命令主要控制的是link数据链路层、addr网络层、route路由 ip link 查看MAC地址、网卡是否启用 MAC地址在网卡的rom芯片里的，真正要改需要借助设备烧入。 所谓修改就是修改配置文件了，关键词MACADDR 发现没变~ 为啥呢？ 注意上上图的提示消息 由于IP地址用着呢，所以MAC地址也不给你变，restart可能不等价down + up哦，down一下IP地址就不是already in use了，试试看，并不是！ 小改动一下MAC，试试 这会就改过来了 真正的原因可能是11打头的,HCIA里有讲，11:22:33:44:55:66正中组播地址。 尝试改一下 验证下 所以没点NA的知识，还真改不了MAC地址。 ip addr查看网络层 这里也能看MTU，支持广播、组播 ip addr 添加地址 这个不是子接口嘛？ 这种方式加的second IP，ifconfig看不到，ifconfig人家加的是子接口形式的 所以子接口+vlan就是我们网工所熟悉的路由器的子接口 然后second IP或者叫sub ip就是第二IP，就好比linux里的ip addr add 添加的地址咯。暂时这里理解先。 使用ifconfig给网卡加子接口，也叫什么别名， man ifconfig可见👇 人家叫别名，叫second address，不叫子接口，哈哈，但是我觉得加上vlan就是子接口了，ip a才是正儿八经的second address。 用ifconfig看下 然后 ip a也能看到， 结论：ifconfig看的没有ip a全，怪不得推荐Ip a呢。ifconfig 创建的网卡别名 ，ip a可看，ip a创建的second address ifconfig看不到。 注意上图1.1.1.1/24 scope global eth1 2.2.2.2/24 brd 2.2.2.255 scope golbal eth1:2这种别名。 然后ip a a也就是ip addr add也能添加ifconfig的别名 上图3.3.3.3加成了ip a 的second 接口没有加成ifconfig 的别名，修正👇 ip a有两种second address，①一种式非子接口②一种是子接口--也就是别名--这种ifconfig可查 注意广播地址ip a配置的，默认是0.0.0.0，哈哈这TM就不是个广播地址啊。 去查一下ip a里的两个second ip的说法 原来这个就是ip a为了兼容以前的ifconfig而设计的。 写到这，发现这一篇其实也可以直接就扔几个命令这就行了，哈哈，算了写完吧，好歹后面看起来舒服些。 清除所有地址 理解下scope 这里其实好理解link-local 对吧，就是Ipv4 和Ipv6 link-local，一个意思。TTL=1嘿嘿。v4和v6的区别就是v6的link-local在下一跳中起作用的，但是v4的link-local实际上没有应用场景--要说有就是网线直连169.x.x.x就通了，哈哈。 hosts是loopback口用的，主机地址，一般/32，也能对外发布路由互通，但是这里更多指的是127.0.0.0/24的回环检测地址，就是真正的本机可用了。所以上图的host更多的指的是127这种地址。 下面看看授课老师大佬的讲解，这就厉害咯 1、global是内核级的 这个就让我想到ASA 和 router的区别(在ping背向网卡地址的时候)，上图的ping在路由器上行，但是在防火墙上就不行，哈哈，可能就是用的link地址特性。 言归正传，上图这种能通，是因为IP1和IP2表面上是配置在网卡上，其实是工作在内核级别的。scope global就是这个意思。 2、link，如果IP2改为scope link，上图左边进来的ping IP2 就不通了。 3、host，网络访问过来的都是不通的，只能自己访问了就。 我们曾今做的loopback为1.1.1.1/32，一般思科的环回口对吧 其实linux一旦你改了地址，他就是global咯，所以主机地址这个称呼 主机地址这个称呼 1、在linux里指的是本地能通，网络不可能通的127.0.0.0/24 2、在华为、华三、思科里面指的是1.1.1.1/32,2.2.2.2/32这种32位主机地址，但在linux看来他们其实都是工作在内核的global地址。 实验看看 诺，scope不是你想改就能改的。所以实验中止~继续整理markdown。 用ip命令修改网卡名称 在centos6上是修改的文件，然后卸载重装了网卡驱动，上文第5节已讲 在centos7上就没有这个文件了，怎么改呢 先禁用网卡 这样就改好了。 ip route 添加ip route add 删除ip route del 加默认路由ip route 0.0.0.0/0 via a.b.c.d或者👇 两个默认，哪个优先 这里还是要注意下metric，不是我们网络工程师常规的默认cost值咯。 手动修改metric---通过man ip route 或者 ip route add help可得 想实现ECMP等价负载均衡，结果发现linux默认不让 SS命令 ss和netstat一样，但是效率高，在服务器访问量大的时候SS显示结果的速度更快，还带一些统计信息，过滤条件比netstat更加丰富。 tcp有11个有限状态机，ss可以显示指定的tcp状态，或者端口号 orhpaned孤儿连接， 还有什么孤儿进程， ss -nta \\ ss =atn 此处顺序无要求 ss -nt 表示正处于连接状态的 查询并发连接数最多的主机 然后sed的做法👇 sed的分组用法，其实就是python里的格式化字符串。 修改主机名 centos6的修改方法 /etc/sysconfig/network + hostname 改成 然后hostname 配置下，再退出下 还有一个地方也要改，就是/etc/hosts文件里👇 本地的DNS解析用的，hostname一样要写到这里。 dns优先级 默认是hosts文件优先级比dns查询 要高，可以修改 方法如👇 /etc/nsswitch.conf files指的就是/etc/hosts文件，它在dns查询之前，调一下个就dns查询优先了 此时ping xxx.com就不是hosts里写的，而是dns请求的了。 domain name 此时ping www是不会自动给你补上后缀的 需要自动补充 .xxxx.com 的 可以在这里添加domain：👇 改为默认路由送出接口的网卡配置文件后，重启网络服务 上图OK的，也可以下图这样 USERCTL是普通用户是否可以启用禁用网卡 这里的HWADDR是真实的MAC地址，真实的MAC地址啥，这里就填啥， 上文改的是MACADDR 两种方法索引 ifcfg-xxx是哪块网卡就看配置文件里的DEVICE或者HWADDR 1、DEVICE=eth1 2、HWADDR=XXXXX 这里写真实的eth1的MAC就行了，两种写一种就行了。上图DEVICE=ethX可以删的 至于反向，这个后面单独讲DNS的时候就知道了，要有反向的mapping的 路由表的静态文件 IFACE是实际的接口名 一般就用10.0.0.0/8 via 172.16.0.1 这种 这里的网卡配置的知识，还是书上整理的比较到位 前面的网卡别名也就是子接口 这些也存不住的，需要单独写一个网卡配置文件 上图提示1.1.1.1已经用在了eth1上了，好奇怪，改成1.1.1.199再次重启，提示归提示，但是已经生效了 问题-一块网卡上的多个地址获取方式不同行不？ 一块网卡的子接口是DHCP的，物理口是手动配置的，或者还有子接口之间是不同的方法，或者反过来。这样行不行？ windows里好像不行； linux里可以做到-物理口是dhcp、接口别名是手动配置，反之不行。 实验 1、修改eth1主接口位DHCP 一但改成DHCP，下面的IPADDR\\PERFIX\\GATEWAY\\DNS1和2都失效 2、发现可以做到物理接口dhcp、子接口手动的效果。 3、反过来，物理网卡使用static，子接口也就是别名使用dhcp是不行的。 👆物理网卡，别名网卡(子接口)👇 重启后发现不行，物理接口静态OK的，子接口依然是下面的手动配置的IP--它根本不认BOOTPROTO关键字，要是DHCP起作用了，就不会拿到1.1.1.199这个IP。 上面虽然拿centos6举例，但是很多都是通用，一些主机名的改法还有NetworkManager的禁用是6独有的。其他无所谓6 7的 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"13-网络协议和管理/7-多网卡集成的企业级应用.html":{"url":"13-网络协议和管理/7-多网卡集成的企业级应用.html","title":"第7节 多网卡集成的企业级应用","keywords":"","body":"第7节. 多网卡集成的企业级应用 数据传输一条龙，从网口进来，到内存、到硬盘，中间还有CPU的运算。 所以看看哪里是瓶颈，iperf就是内存到内存的测试方法，SFTP就是到硬盘的测试手段。 多网卡绑定的模式 👆Mode1其实通过上述，就知道SW那头如果发现只有一个外部端口能看到MAC地址，就说明是Mode1了。 0 2 3 4 都需要SW那头配置portchannel，4还需要动态的协议。 Bonding配置 1、miimon，比如mode1下，就是slave监控master的周期间隔100ms； 2、新建ifcfg-bond0； 3、修改两个网卡配置文件。 实验 VM虚机都改到一个网络里 做bond之前禁用NetworkManager服务，并开机禁用。 删除多余的文件，保证bond成员口的配置干净 创建ifcfg-bond0 这个设备当前是没有的ip a看不到，待会配置完毕后，重启服务器后就有了 配置物理接口加入bond0里 编辑eth0网卡 MASTER=bond0 以及SLAVE=yes，这样，这个网卡就属于bond0了，地址就是bond0说了算，下面的地址就无效了。 再修改eth1网卡配置 然后重启网络服务就OK了 注意，bond0起来后，运来的两个物理成员口的IP就失效了，之前ssh就断开了，只能通过本地终端登入上去看看了。 检查下 eth0和eth1已经不对外了，而且MAC地址是成员口和bond口公用的。 因为做的是bond0，所以有一个主的，通过查看proc确认谁是A谁是S 可见当前是active-backup模式也就是mode1，eth0是主 将eth0断开(前面一个就是eth0)，测试下连通性 发现丢了一个包 两根线都down的样子 cat /proc/net/bonding/bond0 ，下面centos7一样的命令 主备切换，不会抢占。 改成mode3 broadcast看下 37.100就是bond0的IP了，这个DUP就说明broadcast是成员都工作的。 在这个模式下，断开一个接口，发现不通了(在虚拟机环境下)，因为要结合SW配置。 centos7的配置方法 centos7最大区别就是网卡名称不一样，7通常都是ensxxx，一般是cents7是根据网卡插槽定义的，为了稳定，不过一般网卡也不会增加删除，所以更多还是认为改成eth0 eth1 这种方式。 cents7改网卡名称 阔以的，虽然下面的和rocky-linux不同，但是rocky-linx测试一样的操作，就是生成的文件里的ifnames=0的位置不同罢了。 修改/etc/default/grub ubuntu里也是ens33， 切换成root身份： 上面改完还不够，需要利用工具覆盖一个文件 ubuntu需要grub-mkconfig -o /boot/grub/grub.cfg;reboot centos7需要grub2-mkconfig -o /boot/grub2/grub.cfg;reboot reboot即可 不推荐修改，需要借助grub-mkconfig来生成这个/boot/grub2/grub.cfg文件。 grub2-mkconfig -o /boot/grub2/grub.cfg 默认就会读取/etc/default/grub文件来生成最终文件。然后reboot生效。 总之centos7上网卡名称是自动生成的 wlxxx就是wifi网卡， 其实centos7的网卡命名的前因后果是这样的 https://developer.aliyun.com/article/609587 rocky-linux修改大同小异 https://blog.51cto.com/feko/2751292 centos7修改主机名 nmcli nmcli 及时NetworkManger cli的意思，配合NetworkManager服务用的 通过tab键可见有哪些子命令，主要用到的是connection 和 device device是数据链路层 如果网线断掉一根，就会看到如下图情况： 看接口详情 以及 使用connection查看网络层 这里的NAME和DEVICE可以不同，如下 然后systemctl restart NetworkManager可得： nmcli的使用场景和习惯，命令行嘛首先是，灵活 nmcli connection add con-name eth1-test ifname eth0 type ethernet ipv4.method manual ipv4.addresses 1.1.1.1/24 目前针对eth1有两套配置，生效了一套 通过上图过程截图可知，nmcli connection add con-name eth1-test ifname eth0 type ethernet ipv4.method manual ipv4.addresses 1.1.1.1/24 会生成ifcfg-eth1-test网卡配置文件；但是如果是人工创建一份新的网卡文件nmcli默认是不会识别生效的，需要nmcli connection reload一下 网卡的UUDI必须唯一，简单处理方法就是删掉改行就行。 此时eth1-test2就加载了，要是生效同样nmcli connection up eth1-test2 nmcli删除连接 删除在用的连接(也就是网卡配置)，会自动切换到另一个。 nmcli connection delete eth1-test2后/etc/sysconfig/network-scrips/下的ifcfg-eth1-test2网卡配置文件就没了。 手动删除网卡配置文件，nmcli不会自动切，还需要reload 所以总结来了 1、nmcli就是命令行来直接配置网卡配置文件的，nmcli删除创建的连接，就是网卡的配置文件。 2、如果不是使用nmcli创建\\删除connection(其实就是配置文件)，而是手动创建\\删除的ifcfg-xxx配置文件，就需要nmcli connection reload加载一下 nmcli强大在显示信息 nmcli修改接口位DHCP 这样配置文件里的DHCP就修改好了 通过nmcli connection show eth1-test可见 这里的auto就是dhcp 然后在启用该配置 这个看DHCPOPTION还是不错的，什么43、150都能见着了。 不过也不是就这一种方法看DHCP的信息，还有 虽然上图是手动韩国的25.44，但是之前的dhcp获取的信息还在。 有个东西比较呵呵①新的旧的命令技术你都会②老工程师新工程师在你面前就没有优势可言③这个时候人际关系就比较和谐了 nmcli 增加IP地址 这个nmcli connection modify eth1-test +ipv4.addresses 3.3.3.3/24其实就是修改了配置文件 再加一个地址 这加的second ip，ip a可以看ifconfig 看不了，这个在上一节重点讲过了。 其他补充 注意哦加载(reload)是指配置文件的重新同步下：比如人工修改创建的，同步到nmcli这里 这是不需要reload的哦。 nmcli实现bonding 实验 1、将两个网卡都接到一个SW上，WMworkstation就是接入一个网络里 清除之前的网卡配置 开始配置 type很多啊，好友adsl、wifi、vxlan nmcli connection add con-name mybond0 type bond ifname bond0 mode active-backup ipv4.method manul ipv4.address 192.168.37.100/24 但是已经发现远端可以ping通这个额bond0的IP地址了 其实原因是scope global属性导致的，只要这个设备上的接口带global属性，那么就可以背向/朝向都能ping通的。 工作在内核级别，只要流量能发到这个设备上，比如ping 192.168.37.100的ICMP到了这个设备上，那么就可以响应的。 这个ping通不代表bonding绑定成功，而是虚拟的一个网卡通了，还需要进一步绑上物理成员接口的。 上图type 后两个tab里没有bond-slave自动补齐，我的可能版本较高有的 此时就出来了，但是没有起作用，也先不捉急启用 脸厚，你没看错脸厚我们就激活一下 由于现在只加了一个eth1，所以 然后再把另一个接口加进来， 这个，如图就断了，因为ssh的这个机器的这个网卡，现在加进了bond0里了，所以自然就断了。这也是实操bond0的时候要知道的，没事，保证bond0起来就能ssh那个地址就行了。 去终端看下，已ok 同样看下 /proc/net/bonding/bond0 然后测试一下断开的效果，eth1是后面一块网卡 发现丢了1个包哦icmp_seq=309这个。 此时eth1就down，eth0就active了 删掉mybond0这个连接，两个成员的连接就下来了。 网络组 centos7比centos6多了一个网络组 新技术 network teaming和bonding一样，性能据说更好，底层技术实现不同。 创建网络组接口 创建port接口 示例 具体命令和bonding一样，效果一样，就是关键字改了，技术更优。 所以centos7建议用team而不是bond，6嘛只能bond了吧。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"13-网络协议和管理/8-网桥实现和ubuntu网络配置.html":{"url":"13-网络协议和管理/8-网桥实现和ubuntu网络配置.html","title":"第8节 网桥实现和ubuntu网络配置","keywords":"","body":"第8节. 网桥实现和ubuntu网络配置 linux实现sw 网桥 vmnet8和vmnet0按理说是VMwareWorkstation的两个网段是不通的，但是通过VM虚机的网桥实现二层互通。 实验环境如上，下面开始配置 配置好两头的IP地址就行，请不要配置网关 我们在做二层实验 配置中间的机器为网桥 方法1：传统命令配置，采用工具集，缺点不能存盘 确认已经安装了bridge-utils工具集，最小化安装时没有的 其中有一个/usr/sbin/brctl工具 将原有的IP地址等三层信息干掉，以内要实现的是二层SW的二层口 btctl show查看当前信息为空 brctl addr br0创建桥接设备br0这个sw brctl addif br0 eth0 eth1将接口加入网桥设备 此时就其实实验就搞定了， 还可以启用STP 查看sw上的mac地址 还没有学到两头的MAC地址，自然还不通，找下故障原因，其实故障原因上图👆可以看到一个br0是DOWN的，肯定不行了啊。所以只需要ip link set br0 up就行了，哈哈大佬竟然没看出来~ 两头都ping这，然后中间的sw上tcpdum抓包结果没有，看来问题不是在中间设备，这话说的，中间设备的br0没起来，就好比a----sw-----b的sw两个网口是down的，你说是不是中间设备问题，问题就是br0没有UP，ip link set br0 up即可。重要的事说两遍~ 方法2：centos7的专门工具nmcli，可以存盘 上次方法1 的配置 然后开始使用nmcli方法进行配置 创建br0接口 nmcli connection add con-name mybr0 type bridge ifname br0 加入成员口 nmcli connection add con-name mybr0-eth0 ifname eth0 type bridge-slave master br0 nmcli connection add con-name mybr0-eth1 ifname eth1 type bridge-slave master br0 其实就是新建了配置文件 加入两张网卡并启用网桥br0 nmcli connection up mybr0-eth0 nmcli connection up mybr0-eth1 ip link br0 set up 你看上图的mybr0是黄色对吧，其实在终端里是红色，也就是说是down的，是有问题。不管是什么颜色，都要up起来的。 此时br0拿到了个地址，就是DHCP的了，这个地址就是管理IP咯，类比于二层交换机的SVI口，类比于透明墙的L3地址。 其实我在做实验的，发现一样需要ip link set br0 up 的，即使用nmcli 来做br0，一样默认也是DOWN的。 以上就可以了，均测试OK Ubuntu网络配置 网卡名的修改和centos 7一样： 网卡配置 切到root 查看IP地址 nmcli 还看不到，ip a是有接口的 目前处于down状态 尝试启用接口，并未拿到地址， 查看网卡配置文件 cat /etc/netplan/01-netcfg.yaml yaml文件和python一样，缩进必须严格统一，否则报错。 查看网卡配置文件，发现写的是ens33而不是eth0，之前改过名字了，所以配置文件里的名字也要改 改成eth0，注意缩进两个空格 重启服务，netplan apply类似于systemctl restart netowrk。 此时就能DHCP动态获取地址了 https://ubuntu.com/server/docs/network-configuration 按图配置好后，重启服务netplan apply，后cat /etc/resolv.conf里是没有DNS信息的，但是实际上是在的 使用systemd-resolve --status进行查看具体配置的DNS信息 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"14-进程、系统性能和计划任务/14-进程、系统性能和计划任务.html":{"url":"14-进程、系统性能和计划任务/14-进程、系统性能和计划任务.html","title":"第十四章 进程、系统性能和计划任务","keywords":"","body":"第十四章 进程、系统性能和计划任务 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"14-进程、系统性能和计划任务/1-进程管理和内存分配.html":{"url":"14-进程、系统性能和计划任务/1-进程管理和内存分配.html","title":"第1节 进程管理和内存分配","keywords":"","body":"第1节. 进程管理和内存分配 进程概念 进程，正在进行的程序，正在内存中运行的程序；若没有运行，只是安装的系统中的一个软件而已。 ls如果不运行，只是一个文件；当输入ls回车的时候，就会把这个文件读入到内存中，通过CPU读取ls程序里的一条条指令进行执行，最终命令执行完毕，结果输出，程序退出，程序在内存中占用的空间就释放，这个进程也就结束了，所以进程的启动、运行、终止，就是进程的生命周期。 此外有些程序是随着计算机开启后就自动运行的，这种进程一般叫做守护进程，表现为随着计算机启动而运行，随着计算机关闭而终止执行。也可以人为通过工具干涉自动的行为。 进程，不管是普通的进程还是守护进程，本质上都是消耗系统资源的一个单元。 此外还有线程、协程。 每个进程都会分配相应的资源： ①分配独立的内存空间 ②操作系统分配唯一的编号PID进程ID ③其他属性，比如哪个用户运行的此进程 task struct ，进程运行的时候，系统会给他分配一个task struct任务结构表，这个表里存放了进程的PID、谁运行的、占用了哪些内存空间等其他信息。 task list，任务列表，就是多个相关联的task struct互相调用吧 第一进程，centos6上市initd，centos7上是systemd了 systemd不在PATH路径中，是在👇这个路径下 centos7上的init其实没了，只是systemd的软连接 而centos6就是真实的init 第一进程开启之后，然后子进程一般都是fork()函数创建，clone()很少用；创建子进程后，一般采用CoW写时复制机制。 所谓CoW写时复制机制就是 1、父进程已经分配了一定的资源，当创建子进程的时候不会立即给这个子进程分配内存空间，也就是说👇两个父子进程都采用的相同的内存空间 。 2、当子进程涉及到数据修改的时候，就会立即复制父进程的内存空间，然后将子进程指向这块新的内存空间 这就是CoW(copy on write)，只有数据发生变化的时候才会产生复制的行为。 这样就比较节约内存空间。 在cp命令的说明中有提到CoW 进程、线程、协程 进程时独立占用资源的单位，进程A占用的资源和进程B占用的资源时不相干的。 进程相当于项目小组； 线程相当于完成项目的人，所以进程里至少得有一个人--线程。项目复杂了就需要多个人来完成工作，进程里就有多个线程了。 一个进程的任务切成多个小任务，每个任务由单个线程来完成。 线程从哪里可以看到，pstree -p可见 花括号就是线程，其实花不花括号无所谓，一个线程也是线程，如下： 这种就没有多个线程，因为进程下面就一个线程，所以没有花括号。 进程、线程的资源分配都是由操作系统来完成的。 协程和开发语言相关，有的就没有协程的概念，python里有。 协程相当于线程里独立执行的一个语句块；协程的之间的调度由程序员来控制的。 ▲进程和线程的控制由操作系统来完成的；协程的控制是由程序员来完成的。 进程运行必然要分配内存空间，而内存空间的分配是以页page为单位进行分配的。 之前学习文件系统的时候，磁盘上保存文件的最小单位也是4K，那里也有一个最小单元。4K是默认值，额可以修改，一般不改。 内存中给进程分配内存大小，也有一个最小单元，也就是page=4K。这个页最小单元不能改。 ▲磁盘给文件分配磁盘空间是4k4k的给；内存给进程分配内存空间也是4k4k的给。 进程在运行的时候以为自己拥有所有计算机的内存空间，它并不知道还有别的程序在运行。 MMU是CPU里的一个固件单元，就是CPU的一部分咯，复制计算虚拟内存和物理内的映射关系，而这个关系要存下来方便快速取用的，TLB就是这个存下来的映射表。 在一个进程看来，使用的是系统所有的内存就是那么多；而实际上只是物理内存里的一部分，这一部分可能是连续的 可能是离散。所以虚拟内存空间自然也是线性的连续的空间了。虚拟内存空间也叫线性内存空间。 1、用户空间3个G、内核空间1个G 2、用户空间就是给应用程序用的，每个进程都使用的是虚拟地址空间 3、每个进程的虚拟空间又可分为： ​ ①代码段：比如ls二进制程序代码，放在这里； ​ ②数据段：比如程序运行需要的变量，放这个空间； ​ ③BSS:Block Started by Symbol segment: 也是存放变量，不过是一些没有初始化过的变量，比如申明了int或者flat的变量，但是没有赋值。 这个变量n就放在BSS里 这个n就放在数据段里 很好记，有值了就是有数据了，就放在数据段里了。 4、堆：存放系统中需要使用到的一部分内存空间，该空间可动态调整，算是公用的空间；需要时分配，不需要是释放。比如某些进程比如排序类的就比较占用内存，就需要分配一些堆的空间，大概这个意思咯。 5、栈：函数里用到的变量，和堆head不同在于--看下面这段吧，讲的看起还不错 程序的运行场所是内存，栈和堆是进程的虚拟内存中的两部分区域。 当程序被执行时，程序代码，你所创建的变量、常量等都会被压入栈空间里，栈是程序代码的执行区域。栈的内存地址是连续的且被一一记录，所以说当你创建了一个变量(比如int var = 1)，我们就可以通过var这个变量来访问变量的内容。在这里，var就存放在栈中，它的地址已经默认被编译器计算好了，调用过程也不需要你涉及到有关地址的操作。更直观的感受是数组，数组里的元素在栈里面是连续排放的，相邻两个元素的地址相差1。 而堆是不同于栈的另一部分区域，系统会给每个程序分配一部分栈空间让他们能够运行起来，问题就是栈空间必然存在不够用的问题，而堆不属于程序，堆是独立的，是公用的。只要你new，就可以得到相应一部分的堆空间。 有栈，为什么用堆？ 栈里面的东西有生命周期，说俗点就是变量作用域，你在函数内部创建一个变量，函数调用结束这个变量就没了。而堆里面的东西独立于你的程序，new之后，除非你delete掉，否则一直存在。 有什么要注意？ 堆里面申请的东西，是随机分配的，不像栈里面的地址都已经计算好了。所以申请了堆空间之后一定要创建一个指针保存你所申请到的堆空间的地址。不然就找不到你申请的空间了。 堆空间的东西申请好，在用完之后一定要delete掉，以防止堆溢出。 ———————————————— 原文链接：https://blog.csdn.net/u012460314/article/details/52355668 1、创建：fork()函数创建一个程序，先进入了就绪态(ready)； 2、就绪态ready：就是进程需要的资源都准备好了比如内存空间、文件、变量、代码等，准备好了CPU就可以来执行这个程序了。 3、执行态：如果进程执行时间较长，多个进程之间就存在 进程调度 ，而每个进程会分配时间片，时间片用完就回到就绪态，等待下一个时间片的分配。因为时间片特别短，所以即使是单核CPU给人的感觉也是多个程序同时跑的。 ​ 时间片用完，没有执行完，进程就得停止(注意这里不是阻塞哦 不要理解错了，然后这里的停止不是普通意义上的停止就是不断地保存现场和继续执行地过程)，就需要保存现场--将执行的状态保存下来，待会下一次时间片分配了继续执行。这存在一个状态切换的过程，就会带来一点资源的损耗，比如CPU的寄存器的值的存储和清空以及再次读入。 4、阻塞态：进程执行中如果涉及磁盘IO，磁盘IO的耗时远远大于CPU的，所以这个进程就停在这--阻塞态，等磁盘IO的结果出来 再继续执行。 ​ 注意阻塞态完了后 也就是得到结果了 I/O完成了，程序是进入就绪态，才能得到时间片继续运行，所以说阻塞态的进程停在那，实际上也就是现场保存在那，等I/O的结果在继续要时间分片。所以阻塞态必然是进程停止的--这个停止不是kill也不是systemctl stop xxx，而是“不再续杯时间片”的保存现场，I/0有了结果才会去进入就绪态去要时间片去继续执行程序。 5、终止：此时程序执行完毕，所有占用的资源得以释放，比如内存、占用的文件等。 LRU介绍 Least Recently Used 近期最少使用算法，释放内存 在系统中很重要的一个内存使用算法 https://zhuanlan.zhihu.com/p/34989978 不管是大佬讲的还是博客写的，其实主要的理解思路就是：读取数据时从硬盘--写入内存---从内存读取到屏幕打印或者其他输出， 然后PPT也好，博客也罢的图片，都是站在从内存读取数据的角度出发去谈这个事情的，比如读取4 内存中有就调到最优，读取1 内存中没有就压栈的方式，垫底的淘汰掉。 上图的物理块 说的就是内存块的意思。 LRU这个近期最少使用就释放掉的短发，经常用于缓存的处理， 数据从硬盘里读入到内存，再从内存中读取到所需之处，为了提高效率 就会在内存中开辟一处空间用来存放数据，LRU算法就应用于这个内存空间，从而就得到了常用数据就放在了这块空间。而这个空间就叫缓存cache。 面试官-问：常说的经常用的数据放到缓存中，是怎么就做到的，怎么就把经常用的放进了？ 你-答：LRU及变种，回答完毕。 面试官-心里想：被他装到了。 其实这会我学到这，我想搜索LRU及其变种还有之前看到的LFU的具体解释的，但停了一下，判断了一下，不是懒的去查，而是继续往下看，后面看需要再 在这个点上继续深入就好，进一步思考，很多时候大脑需要的是停一下也就是冷静的思考能力，不是被某一个情绪左右，这其实就是真正的自由 学到这，思考一个问题，既然内存都是虚拟内存\\线性内存，也就是每个进程认为是独享的内存-是独立的，那么进程之间要互相通信，也就是内存要互相能访问才能互相通信对吧，所以就需要进一步在内存空间上做文章。 在进程内部的多个线程之间通信还是比较容易的，因为它们都是公用一块内存空间的。而进程和进程是互相独立的内存空间。 进程之间通信分两种 1、两个进程在同一台主机上 ①pipe管道： 比如没有名字的--匿名管道，如：|，题外话这个\"|\"念啥你们知道么，哈哈~ 比如有名字的管道--表现为一些文件，如p打头的 具体就是，进程A把数据传给管道，进程B从数据读取管道。这样两个进程之间就可以交互信息了，思考--这里面是否存在半双工问题啊？是的，是半双工的。 如果希望同一时刻，两头都可以发送数据--全双工，就要用到socket了。 ②socket套接字： socket套接字也分两种 a、unix套接字文件s打头的文件，这是一个全双工的管道 b、ip+port socket，这个写到下面的两个进程不在一台主机上片段里 ③signal 信号 通过一些命令可以给进程发信号，而进程收到这个信号以后，会按信号的定义去操作。 比如，sleep 100的时候 这个ctrl c 就是向这个sleep发送了信号导致其退出。 至于信号有哪些种类，有什么作用，第4节再说。 ④shm: share memory 共享内存，进程和进程之间共享内存 堆是不是就是共享内存呢？ ⑤semaphore：信号量，一种计数器 比如有10个资源，100个进程使用，当然一个资源同时只能被1个进程使用； 如果此时10个资源全都被占用，此时这个semaphore计数就为0； 如果有个资源释放出来了，此时semaphore技术就为1； 以此类推，通过这种方式，进程之间也能通过信号量这种计数器知道资源的使用情况，从而合理分配资源，从而实现了资源的使用上的进程之间的沟通。 2、两个进程不在一台主机上 更多情况下，两个进程并不在同一个主机， ①其中就有socket里的ip+port这种方式。 提到ip+port，就会想到\"面向连接\"和\"无连接\"这两个叫法，一个是tcp一个是udp，而连接就是双方的信息在彼此的内存中进行动态的持续的维护；无连接--就是仅仅初始化 但是不维护咯。比如TCP的滑动窗口，重传这些都是连接这个概念里的内容，UDP显然没有维护这个概念。 https://www.ietf.org/rfc/rfc793.txt里搜索connections关键词可到标准定义 国外的文字表达再翻译国外，往往需要咀嚼一下，比如面向对象编程，面向过程编程，面向连接的TCP，这里的面向XXX，可以体会一下 而面向连接，这连接在了、初始化了，面向它，就意味着要表达它维护它；UDP才不会面向连接，自然不会维护它。了解，这就是最底层的思维，丝滑了把，舒服了吧，无用了吧，费时间了吧，有点点意思了吧。 IP是确定主机，port是确定进程服务，这种sockt是比较底层的方式，一般开发不这么用，比较多地是使用RPC和MQ来实现不同主机进程之间的通信。当然PRC和MQ的底层还是socket(ip+port)。 ②RPC: remote procedure call远程过程调用 情形如下，A上的程序执行一段；然后把数据发给B，调用B上的程序继续执行，得到结果 回传给A；A拿这个结果继续执行。这就是远程过程调用。 ③MQ： 消息队列 左边每个进程A B C 想互相通信，可以通过右边的MQ消息队列来中专，你写我读，就可以了。 进程优先级 注意，在实际系统上优先级不是0-139，而非实时进程的优先级100-139转成了nice值-20到19同样也是比小的。 优先级分为 实时优先级和非实时优先级； 是这样表达的，进程分为两种 紧迫性高的和不高的，高的就是实时处理的，就叫实时进程，不高的就是普通进程。针对实时进程需要优先调度也就是优先级高0-99，这种优先级也叫实时优先级。 1、realtime实时进程的调度方式： ①优先级高的会抢占优先级低进程的资源，0-99比小，0最高； ②如果两个进程优先级一样就遵循FIFO或RR。 ​ FIFO：谁先来，就先处理谁；RR：轮询 每个同优先级的进程互相轮着来。 2、非实时进程也就是普通进程的调度方式 应该也是一样的队列机制肯定也有FIFO\\RR的。 优先级也是按时间片的规则来的，也是存在时间用完就要暂停的情况的。 原则优先级的比较也是存在一个排序的，而排序就要用到什么冒泡、插入等排序的方法，这样就导致花费CPU花费时间的 效率较低，所以实际会存在1-139个队列，将对应的进程划分到不同的队列里去，从而直接达到了排序效果。 当P1进程时间片消耗完后就把P1放到过期队列里，P2时间片用完也移入过期队列；当运行队列1的进程都没了之后，该队列空了 从运行编程过期，此时将过期队列2变为运行队列。 显然这里的队列机制，和我们网工学的QoS的队列类似的，但是这里大佬讲的太浅了，有机会所谓机会就是需要用到的时候，可以再搜一下相关资料。 centos中优先级情况，主要是显示和修改方式 system的优先级 和 命令查看的结果 并不一致，下图是大佬总结的 chrt命令用来修改realtime的，全称就是change realtime， 注意一下👇centos chrt写99就代表0优先级，0就对应上面的99优先级，其实就是centos 优化了一下变成越大越优╮(╯▽╰)╭ 问题来了：上图中，值是越大越优，还是越小越优。回答：越左越优，屌不屌~。 system优先级是0-139区间，但是对应到命令后往往不是这种大小，这个要注意的。 centos的命令 1、chrt命令：是修改realtime； 2、nice命令：就是修改nice值得； 3、top命令里的PR列：看法又不一样了； 4、所以有这里有个小市场--就是写个脚本统一下，哈哈。 TOP里的PR，别看错了，不是NI。 上面讲的PPT如下“： Big O是啥哦？ 进程数量不同，最终的比较的效率存在高低的，存在一个时间复杂度，和软件开发的效率有关，大佬如是说。 工作效率是 当数据量达到一定规模，很多以前正常的工作的，后面就开始出现莫名奇妙的问题了，这就是时间复杂发生了变化，计算不过来，自然各种问题就出来了。这确实挺吓人的哦，你想从故障找规律好像是不可能的了，因为没规律可言了就是处理不过来了。 抢占式多任务和协作式多任务 抢占式多任务：是按照时间片分配资源，进程的时间片消耗完，CPU理解被内核拿回来，然后继续分配，不会被某一个进程卡死了就一直占着资源。 协作式多任务：早期的dos，就是没有时间片的概念，就是一个进程执行，就等他执行完，才释放资源。这样会导致某个进程出问题，连整个操作系统都僵在那了。所以以前老版本的windows动不动就蓝屏死机。 前台进程和守护进程 前台进程依赖于tty线程，所以有2中处理方法 注意console就是本地终端登入的不存在这个情况哦，你怎么关，无非是关闭控制台嘛，关了再进去ping还在的 1、nohup xxxxx & 记得exit安全退出终端，否则不生效 2、screen稳当就是显然没有nohup一条命令帅气 守护进程不是用户登入上来运行的，所以不存在tty关闭就终止的情况。 进程状态除了上面已经讲过的，还有 睡眠态： 可中断--睡觉，叫一下就醒来了； 不可终端--冬眠，回暖才会醒过来，就等着你的IO结果，放到内存里了拿到结果了，它才会继续工作否则只能在这等着。 停止态：冻僵了？消耗资源不，既然暂停于内存 还是消耗点点资源的吧？不过不会消耗CPU，因为不会有时间片分配给它。 僵尸态：异常状态，正常就会释放资源，但是僵死，还是占用内存资源的。因为已经死了，kill也杀不掉了，也激活不了，只能重启计算机处理这种异常状态。 举例mingetty就是 登入界面 的提供程序 上图一直不登入，这个程序虽然还在运行，CPU是否消耗-否，内存是否消耗-是。 ready是什么都准备好了，就等CPU的时间片了。上图是还差输入ID的，显然还没有准备好所有条件，还不是ready就绪态，还不给它分配时间片也就是CPU的使用权。 所以大部分的进程都是睡眠态。可以唤醒，键盘输入回车后，就发送一个 让他进入就绪态。这里应该有个点，就是睡眠态如何进入ready态。一旦进入就绪就等待CPU的时间片进入运行态。 进程分类 1、CPU密集型：CPU消耗大，内存硬盘消耗小，比如数据计算、编译安装等 2、IO密集型：磁盘靠大文件，CPU就发个指令就完了，但是大量数据需要从磁盘考入内存，然后内存到网卡发送出去，这就涉及IO。 早期的时候CPU是参与IO的，说明如下： 1、CPU发送cp f1 f2复制指令后 2、这个过程中，所有的数据全部要经过CPU，当然这是在说以前 3、现在内部架构发生了大变化 CPU只需发送一个指令给DMA，然后DMA就去完成磁盘和内存的数据交互。 这里后面重新画图吧。 DMA有了，CPU就不忙了 到底是CPU忙、IO忙还是网络忙，通过命令去排查。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"14-进程、系统性能和计划任务/2-进程管理工具.html":{"url":"14-进程、系统性能和计划任务/2-进程管理工具.html","title":"第2节 进程管理工具","keywords":"","body":"第2节. 进程管理工具 进程启动后，相关信息会自动放到/proc里 上图的1，就是systemd这个系统启动后的第一个进程。进去后一堆信息(比如内存、挂载等信息)通常不直接查看分析，而是通过命令去看。 ps 默认只显示当前这个tty线程的进程 再开第二个终端跑一个sleep 再开第三个终端跑一个ping 但是在第一个tty里，ps只能看到自己的进程 ps 特殊在，它是一个老牌Unix命令，支持3种风格的option选项 man 帮助种也是如此写道 - h unix风格 -- help GUN风格 h BSD风格 tar xvf 和 tar -xvf 都行 ps a查看各个终端窗口下的进程 a看不到守护进程，和终端没有关系的进程是看不到的。 ps x 查看并非所有进程，包含守护进程这种和终端无关的，也包含终端下运行的进程 ？就是和终端无关的；终端下的也会给你显示出来的。 ps ax会多一些 ps u显示进程所有者的信息 顺便看下列标题 ping 一直在运行，但是不消耗CPU，time这一列0:00就是说占用CPU的时间片少。 ps aux 看所有进程的信息，包含守护、终端进程、带进程所有者 ▲插播-1 iptables如何实现代理 这种方法有时候不生效，所以后来我还是用的softether去搭建的 这种方法不用动路由表，其实就好比windows的代理，就好比clash的“非tun虚拟网卡模式”，现在看下来这种方案更为灵活： iptables -t nat -I SHADOWSOCKS 1 # 添加用 iptables -t nat -D SHADOWSOCKS 1 # 删除用 iptables -t nat -D SS -p udp -d 0.0.0.0/0 -j REDIRECT --to-ports 1080 # 删除具体 iptables -t nat -A SHADOWSOCKS -d 167.xxx.xx.xxx -j RETURN # vpn的建立隧道地质得走本地网络出去 iptables -t nat -A SHADOWSOCKS -d 10.0.0.0/8,172.16.0.0/12,192.168.0.0/16 -j RETURN # 私网 iptables -t nat -A SHADOWSOCKS -d 127.0.0.0/8,169.254.0.0/16 -j RETURN # 本地回环和linklocal iptables -t nat -A SHADOWSOCKS -d a.b.c.d/n -j RETURN # 公司出口IP iptables -t nat -A SHADOWSOCKS -d a.b.c.d/n -j RETURN # IDC公网IP iptables -t nat -A SHADOWSOCKS -d a.b.c.d/n -j RETURN # 云上公网IP iptables -t nat -A SHADOWSOCKS -d a.b.c.d/n -j RETURN # 本地APP访问或者调用的外部IP，这些都是走本地网络，不走代理的。 iptables -t nat -A SHADOWSOCKS -d a.b.c.d/n -j RETURN # 你要是闲的蛋疼，还可以加上所有国内IP地址段，你不怕CPU不忙对吧。 iptables -t nat -A SHADOWSOCKS -p tcp -d 0.0.0.0/0 -j REDIRECT --to-ports 1080 # 剩下统统走代理，注意UDP其实也需要代理，不过要排除UDP 53，同样TCP53也要排除的，这样一些新的QUIC协议就能应用了。 还差一个排除注意点，单个APP的她可能也会本地调用外界的公网IP(这个是不走代理的)，所以也需要排除。 ▲插播-2：业内趋势QUIC体验 H3介绍：https://blog.51cto.com/u_14888059/3790697 https://network.51cto.com/article/625999.html https://new.qq.com/omn/20210504/20210504A01Z1T00.html 谷歌开启H3：https://zhuanlan.zhihu.com/p/108198664 插件下载：https://chrome.google.com/webstore/detail/http2-and-spdy-indicator/mpbpobfflnpcgagjijhmgnchggcjblin 插件显示对比：绿色是H3，蓝色是部分H3没有H1，灰色是有H1。 企业微信有用QUIC也就是H3，CDN里也支持，谷歌youtube都支持--速度快很多 插播结束，继续linux的ps命令 ps aux看的较全，注意用户通常是root，也有非root，就是以系统账号运行的 切换用户看下 再来看下普通用户运行passwd的情况 发现竟然是root运行的，其实这就是SUID的原因，前文已讲 所以ps aux看到的用户严格来讲是有效用户，是wang运行passwd后实际生效的运行的该命令的那个用户。 再看下ps aux的CPU占用百分比，基本都是0，搞一个不是0的。 单核是100%，两核就是200% 内存情况： RSS是常驻内存，进程申请内存的时候，说是这么多，但并不是马上使用，所以RSS就是目前使用到的内存空间，而VSZ就是申请操作系统承诺给到的内存空间。 VSZ和RSS的单位都是以KB为单位的 tty ？就是和tty无关，不是终端上来的 STAT 状态就是进程的状态，运行态、就绪态等，其中 运行态表现为R，基本上看不到 因为你敲这个ps aux的时候肯定是运行态的嘛，同理 敲的就是这个命令，肯定会给你一个grep 的进程的，啊，ps aux里是没有sssss的，但是你既然grep sssss了就是要运行grep程序的，所以当下就有grep的进程了。 sleep 100 跑起来后也不是R运行态 pts/0就不是当前的pst/0窗口 当前是pts/1终端， 好奇这个“TTY是?号非当前终端”的sleep 60哪来的啊？ 这个sleep不是bash命令，估计是系统默认的，之前没关注过，我这个是centos8的，我去其他centos7上去瞧瞧还真有，rocklinux没有 最小化安装的centos7没有sleep这个东西 然后回到这个STAT 的R这些状态 大部分处于S休眠状态且是可中断的， 还有不可中断的休眠 T：stopped是停止态 Z：是僵死态 +：表示前台执行 l:多线程 会话表现形式有qq的一个窗口，浏览器的一个页面，而这些都是涉及到进程的，具体解释如下： https://blog.51cto.com/u_15015138/2555390 这个命令很棒，不过要区分一些ps f 和 ps -f ps auxf 可见看见树形结构的，同级的进程，父子进程等信息👇 ▲插播-3 hostname你真的不会改，具体如下： https://blog.csdn.net/zhaogang1993/article/details/82769439 ps继续，START是什么时候开始的，TIME就是总的CPU时间(是按时间片分配的) 排序功能以及部分显示功能 ps o过滤 加上ax选项进一步显示所有终端的信息 按CPU排序，先搞一个消耗CPU的进程 ps aux k %cpu 可见排序是升序的--根据CPU的占比 降序怎么排，tac咯 cat和tac以及rev对不对~ 上图是关闭图形界面的程序gnome，降低一些内存的消耗。 降序还可以这样 上图的--sort可以换成k的 再到centos6上看下具体的命令 -e等价于ax，在行数上，但是列上👇少一1列： 配合-F显示多一些 PID是进程id，PPID是父进程ID。 C列，表示CPU的百分比，不过是取整的。 STIME是开始时间 TIME是CPU的分配到时间片换算的累计使用CPU的时间 这个占用CPU的时间就比较多了。 老实讲有效和真正，并不能很好的区分两个选项的意思 -u就是程序最终谁来运行的，最终 执行 的 用户 -U就是程序开始时谁来发起运行的，开始 发起 的 用户 ps aux就看所有咯，然后单看wang用户的就用ps -u wang u， -u wang是最终以wang用户来运行的程序 -U wang就是wang敲的命令，通常是SUID这种passwd带SUID所以wang敲命令，但是是以root运行的程序。 所以常见组合有 ps aux ps -ef 其他就看上面的具体需求用哪个了 这是查命令的，敲的命令，如果时脚本呢？ 直接ps -C f1.sh就行，还挺不错的 我的测试 再开一个终端，发现 并没有，赋予x执行权限再看，其实很简单，你是bash f1.sh跑的，自然要看bash进程，而不是f1.sh，你给了执行权限，直接f1.sh跑的就能看到了👇 注意. f1.sh这样也是看不到的 必须是f1.sh作为命令一样敲入的，而不是通过source bash 或者.来运行。具体再看看下面 bash xxx是通过bash执行的f1.sh，然后f1.sh里面又执行了ping ./f1.sh是通过文件本身什么的shell申明的类型直接执行的，ps -C f1.sh所以查得到 将bash改成sh测试把 看到没，./f1.sh就是直接执行f1.sh文件的，只不过是依据文件里定义好的shell类型去执行的，所以ps -C f1.sh就认 而换成source和. 的话又不一样了 也好理解，这两个家伙是直接在当前bash下以当前bash执行f1.sh的，不会再开启子shell进程。所以这两个家伙source和.你用ps -C bash是看不到的，因为这两种方式运行的程序他直接在当前bash跑的，所以层级比上面少一层，ps -C bash不会增加。就是这么个道理，老哥我研究得到位了把。可惜咱环境不care这些东西，呵呵。也不对，基本功也确实要有的。 再来，如果f1.sh里面就是光秃秃的一行ping 127.0.0.1 对比定义文件的shell后，就知道了，👆上图是文件里没有定义shell于是自动给你用当前的bash，下面是文件里定义了shell的👇，所以其实是跟着文件的shell走的， ps -C bash和ps -C f1.sh分别查看上下两种情况，上图会多一个bash，下图是bash不多，多一个f1.sh，因为下图的shell是集成在f1.sh里的，是通过f1.sh开启的shell。 然后ps -C f1.sh上图👆肯定看不到，因为开了一个子bash；下图👇可以看到是因为是直接运行的f1.sh文件自然看得到，虽然文件里申明了shell的。 所以说一万到一千， 1、文件无执行权限 bash就是开启bash子进程 source或.就是直接当前bash跑的 2、文件有执行权限：①申明了shell；②未申明shell ./xxx.sh执行有申明，就是直接跑的是文件当命令执行的，利用里面的shell,跑的是文件本身； ./xxx.sh执行无申明，就是开启当前shell类型的子进程通常就是bash来执行文件的，跑的是bash； 查看nice优先级 -是用的系统优先级 -20这种就是nice，只是对应system priority的后面一部分[上一节里有讲] 这个不管是centos8还是centos7都是这个样子的，nice是-20~19没毛病 但是pri这个它实际上是翻转过来的system优先级，上图-20对应的就是39。 看到这我TM已经不知道优先级比小还是比大了，NND，搞这么乱的，不能统一下的吗！ 通过renice调整ni值，既然是nice就只能是-20是到19之间了 -n是指定新的优先级 所以▲总结一波，ni是-20最优--比小，pri是139最优--比大。 但是官方自己都疏忽了 altime就是实时进程的优先级--实时优先级。 大部分进程都是nice优先级，实时优先级的少。 直接以某个优先级运行程序，有个无聊的点，下图ping的是127.2，系统会自动识别为172.0.0.2 ps axo pid,ni,pri,cmd 可见ping以优先级10开始运行的，如果是负10，就是nice --10 ping 127.0.0.2 上面的-10和--10都不太好，正规写法是 查看进程跑在哪颗CPU上 通过ps axo pid,cmd,psr查看 上图可见敲的dd命令当前是绑定在cpu 3上的，也就是第4颗CPU。 但并不是固定在CPU3上跑的。 再来看一个ping 多用ps axo pid,cmd,psr看几次，就可以看到不是固定在CPU4上跑的 如上图，ping 172.0.0.1，进程的CPU切换了，就会导致 缓存失效 CPU里 也 有缓存，有L1、L2、L3 CPU以两颗举例，各有各的L1、L2，但是L3是共用的 理论上L1缓存最快，L2次之，L3最慢 它可以把内存中的数据放入缓存中，下次取就直接从缓存中取了，速度就快了很多。 问题来了，如果一个程序跑在CPU1上，那么L1和L2也肯定用起来了，如果该程序跑到CPU2上了，此时之前的L1和L2缓存就无法利用了，所以CPU一切换，就导致效率大大下降， 解决方法，将进程就绑在某个CPU上。 同时也会带来CPU的利用率可能不均衡，就是你绑的那个CPU负载就比较高，这个可以将nginx的多个进程分别绑到不同的CPU上，然后这个机器就跑nginx。这样就比较好了 nginx的配置文件中，是可以把nginx的进程和CPU做绑定的。 怎么绑，taskset可以 这是一个外部命令 用这台机器，就两个CPU，来做实验 dd下 通过ps axo cmd,pid,psr可见当前是跑在CPU0上的 由于现在没有进程和它竞争，所以CPU不会飘，再来一个ping -f 去抢CPU 然后可见dd命令的cpu飘走了 然后视频中老师的xshell崩了，就用终端去演示了 现在是两个dd，然后不断地通过ps axo pid,cmd,psr去看CPU切换， 发现两个没切，于是再加一个dd if=/dev/zero of=/dev/null 然后继续用ps axo pid,cmd,psr去观察 结果半天没看到CPU切换的情况，不过上面有两次已经切换了，就是没有出现频繁换的现象。 通过taskset -p xxx可见当前进程ID可以跑在哪个CPU上，注意下图，跑在CPU0上，但是看到的事mask 3 mask 3就是11，就是说当前是2个CPU，11就是打开开关，两个CPU上都可以跑。 如果是下图，就是当前是4个CPU，这个1332进程可以跑在4个CPU上。 下面开始绑定 ping 127.0.0.1这个进程，绑到CPU1上去 绑定的命令为taskset -cp 1 xxx，注意这里的1就是1号cpu，如果你想绑到0号cpu，就写0，如果你想绑两个，就写0,1，这就没意义了，缓存又不能固定了，所以绑就是绑一个cpu号的。 此时进程29654就变成1了，并固定在1了 taskset -cp 0,1 xxx就是0号cpu和1号cpu都可以用，最终taskset -p 查看就表现为11也就是3了。 再看个CPU多的情况 0-7号CPU ff就是对于7969这个进程来说，8个cpu全部可以用。 现在希望该进程就跑在0号CPU和4号CPU上 0,4对应的affinity mask就是0001 0001 上图其实就是一张图拆开来讲，原图如下 绑到0号和4号CPU了，原来的3就跑到0或者4了👇 现在有个问题来了，上面的taskset -cp x xxx都是绑的进程ID，进程ID这个是会变的，所以还需要优化 用pidof去获取进程的ID，前提是这个命令dd就对应一个进程编号。 如果是bash，就会看到好几个进程ID： 所以进程绑CPU的命令为taskset -cp NO. `pid xxx` 这是taskset优化的手段，当然有些软件比如nginx本身就可以绑CPU，无需手动执行taskset命令。 以上就讲了ps的一些常见组合 示例 pgrep=grep for process 感觉pgrep就可以了，上图的那个ps -C httpd,sshd -o pid=没啥用。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"14-进程、系统性能和计划任务/3-进程管理和性能相关工具.html":{"url":"14-进程、系统性能和计划任务/3-进程管理和性能相关工具.html","title":"第3节 进程管理和性能相关工具","keywords":"","body":"第3节. 进程管理和性能相关工具 查看某个终端tty下的进程 区分u和U，这个ps命令，上一篇里也有。 pgrep还支持正则 加上-l或者-a显示进程 pidof 虽然是软链接，但是功能不一样，也就是说，可以创建多个软链接指向同一个文件，但是每个软链接的功能不一样。 uptime dd if=/dev/zero of=/dev/null来消耗CPU然后uptime观察看下 load average这个数值也是进程数量的意思。 一个内核，一搬load average不大于3，所以24是可接受范围以内。 超过24就认为每个内核有3个以上的进程在排队，系统就非常慢了。 uptime一个是命令，一个是proc/uptime文件 单位都是秒，一个系统启动时长，一个是空闲进程总时长(按总CPU数计算的)。 平均下来每个CPU的空闲时间就是/8，7717秒空闲，8604s开机时间，所以大部分时候是闲着的。 w 命令和uptime也是重叠的 top的一行也是uptime 所有进程个数是223个， 3个运行的，220睡眠的，0个停止，0个僵尸态。 cpus的分配情况，us用户空间占用了2.1%，sy内核空间占用了10% 其实us用户空间占用高才是好的，因为这代表着应用程序占用内核率高，而应用程序代表着生产力。 各种软件都是工作在用户空间的 从这个CPU的两个值就可以看出来，你的系统忙不忙，合不合理。 ni是进程的优先级调整 id是空闲，100就是cpu100%空闲，没事干。 wa是wait等待时间，有些进程需要等待资源的访问，准备好了才能运行。 hi是硬终端 si是软中断 st是被盗取的时间片 中断，就是打断了CPU的正常工作。中断什么时候发生呢？ 看下用户空间-内核-硬件的模型图， 内核kernel和硬件的沟通就是通过 中断，比如键盘按一个键，内核就会捕获这个操作，用中断方式响应用户的请求。 当你每次在键盘上按下一个按键后，CPU 会被中断以使得 PC 读取用户键盘的输入。这就是硬中断，还有软中断，比如程序的异常 st：steal，被盗取 早期的计算机操作系统，不支持不理解虚拟机里运行的进程， windows任务管理器打开，看到当前进程，这些进程只是windwos里的进程，然后VMwareWorkStation里跑的进程占用的时间片，就被称为ST-被盗取的时间。 后面会讲KVM，类似于windows的VMwareWorkStation。 内存，总的、空闲、用了多少、被buff/cache占用了多少 然后top下面的主体部分 3s默认的刷新间隔，可改按s建后改。 默认是按CPU利用率高到低，显示的，测试，跑个dd ，top里就看到第一个了。 PID、用户名、优先级PR--这个PR是TOP的PR，它在linux优先级里的情况如下 NI就是nice优先级 VIRT是系统承若的内存、RES是实际使用的物理内存、SHR是共享内存 TIME+是总的CPU分配时长 OOM：out of memory内存泄漏 一般某个进程的内存不断在涨，就认为可能发生了OOM了。 -H显示这个进程下面打开的线程 使用pstree -p 找个多线程的进程PID 花括号就是多线程 这就打开了某个进程里的线程。 top -H -p `pidof xxx` # 这个pid会不会pidof xxx取出来多个啊？就会出错 free看内存 centos6和7不一样 6的buffer和cache是分开的，7是合二为一的 buffer是写，改一个文件后，要写数据， 要先放入buffer缓冲区的，然后buffer里按一定的队列次序写入磁盘。可能就是改一个字符不会给你存盘 就是放在buffer里，等你改了很多字符后才会统一从buffer里给你写入磁盘。这样能提供效率。 cache是读，数据的读取，放入缓存里，下次读取直接从缓存里读取就行了。 默认是KB单位 cp一样会增大cached 看下内存使用情况的计算 used - buffers - cached = 真正使用的内存空间 free + buffers + cached = 真正可用的内存空间 但其实你用echo 3 > /proc/sys/vm/drop_caches释放也不可能将buffers和cached全部释放掉的，所以也没有上面说的那么富裕。 下面是centos7的内存计算方式 total = used + free + buff/cache available 是系统自动给你算的，它不是简单的free + 部分buff/cache，你看上图的available就小于free，这看起来就不科学，因为空闲的竟然不是全部可用的。之所以出现free 注意-g的使用 不会四舍五入 1s刷一次，有助于动态观察 图形界面是很占用内存的 上面的gnome-shell,gnome-software,X,gnome-terminal都是属于图形界面的应用。 通过init 3关闭图形界面后，free大大地增加 所以工作中一般不开图形 vmstat 解释上图 procs列：r b,1 0,这些地意思，r是运行或者可运行的进程数，b是可中断睡眠态的进程数存在阻塞了，这是被阻塞的队列的长度。1 0，1个，0个，这些是动态变化的，不是固定的。 -----memory---- swpd：被交换的内存空间 free：空闲的内存空间 buff和cache：上图buff空间小，cache空间多，说明数据上目前没有什么写操作。 ----swap----- si：进，数据进swap，就是说把内存中暂时不用的数据放到swap里，对于swap来讲是进，对于内存来讲是出。 ​ 可惜我们通常字面意思的理解就错了，这里的swap和后面的---io---都是以内存为参照物的in和out so：出 测试下si so值，构建一个大内存的使用情况，超出内存，然后才会使用swap 此时内存不够用了，就会将内存中不用的数据往swap里写，so就会增长 如图，内存不够用，一开始就是so暴涨，到后面就有进有出了就。 -----io----- io理论上也是磁盘的io，其对应的bi和bo理论上都是说的磁盘的in和out，但这里就不是，这就是统一指的内存的in和out。 如图从硬盘上读数据，表现在vmstat的bi暴涨：因为读数据时先读入内存 如果从内存中读数据，/dev/zero是个内存数据，写到硬盘上，此时---io---里就是bo暴涨 这个命令一会就能把硬盘打满。测试的时候要小心。 ----system------ 进程切换过多会影响效率的 ----cpu---- 这里的us sy id wa st和top里的一个意思 iostat iostat 1s刷新一次 开始读磁盘 读操作瞬间暴涨 对于系统来讲CPU、内存、硬盘、网卡，这是比较关注的4个，和性能密切相关 iftop 需要epel源安装 iftop 可以指定监听的网卡的 iftop -n -i eth1 -n就是不做域名解析 q退出 pmap，显示进程占用的内存空间 每个进程使用的资源都是在/proc下看的很清楚的 比方说，这里开启一个dd命令 这个dd命令的pid呢看下是多少 那么在/proc/11425下去看看 其中就有内存的使用情况 也就是maps文件，打开看看 显示的内容不是特别容易看懂，所以不太使用这种直接看maps文件的方式，而是使用pmap命令去看 这样就可以看到 dd就是程序本身的内存占用 stack就是栈，和堆很相似，都是每个进程占用的内存空间，这个内容讲解在本章 第1节中有讲，了解下就够了。 栈：先进后出， 一般函数，变量赋值，都是用栈 而堆heap，一般都是放大的数据的，面向对象开发的，一些创建的对象都是放在堆里的，堆是在内存中分散的数据块， 还有一些anon也就是anonymous匿名的内存空间，就是没有名字的。 每个应用程序会调用二级制的库，这个库也要占用内存空间，不过这个库是共享库，也会被别的程序调用的，所以这部分内存空间应该是共享的， 将来就可以用这个pmap命令来了解某个应用程序占用的具体的内存空间，比如某个JAVA程序运行的时候内存比较大，还存在不断增长的情况，你就看看，发现 唉~里面的某个模块在不断的消耗内存，这就是OOM的可能了，你就告诉他你的程序某个模块存在OOM内存泄漏的情况。 pmap工作中经常用到据说，回头我就问问应用运维 系统调用 strace可以跟踪 某个进程运行的时候 调用的 \"系统调用\", 就是看看进程占用了哪部分 系统调用 比如说cat这个命令，运行的时候（命令也是程序啊，敲回车就开始运行了） 通过程序运行中调用的 系统调用，就可以发现一些异常，这其实很底层了，这需要经验积累，需要对开发了解。俺没有哦，我就是写下来了解个方向。 上面可能还要cat一些具体的文件 可以看到open的这个系统调用，而且还是RDONLY猜也知道就是readonly了。 这个其实就是 with os.popen('cat ', 'r') as p: z = p.read() strace是看的系统调用， 还有一个ltrace， 看函数库的调用，不是strace看的系统调用 函数库一般就是C语言自己的库， 还有一个ptrace 不太清楚了，哈哈视频中老师就提了这个名字而已， https://bbs.pediy.com/thread-265812.htm https://www.cnblogs.com/tangr206/articles/3094358.html 看不懂，不过知道了strace也是基于ptrace来实现的。 glance可以实现跨网络的监控 然后去到远程的机器上，同样要安装glances 然后client端输入 glances -c a.b.c.d 就可以看到server端的性能 信息丰富、支持跨服务器查看 配合iptables安全策略，可以指定固定来源查看本机信息 dstat 可以替代vmstat,iostat usr用户空间 sys内核空间 idl空闲 wai等待 hiq 硬中断 siq软中断 读写 网卡 swap的分页 int csw 进程的内容切换 这里的int和csw应该就是vmstat的in和cs iotop iostat显示是某个硬盘块设备的I/O使用情况，但是不能精确到进程；此时就可以使用iotop 和TOP很相似，显示的是某个进程的磁盘读写情况 将来发现磁盘很繁忙，进一步想知道哪个进程导致的， 结果肯定是看不到的/dev/zero 是内存里的，/dev/null也是在内存里，所以读写都是在内存里，iftop自然看不到，换一个命令 nload查看网络实施吞吐量 输入nload后回车可见： 当前上图所示没有流量，开始制造流量 上图可见流量开始有了，但是图形显示不是太易读，因为curr 71.63MB/S是这么个图，curr是122MB/S也是这么个图 流量不直观啊有点 lsof 查看某个文件夹是否被挂载或使用 查看某个文件被哪些进程打开 查看某个进程打开了哪些文件 工作中存在 不小心删除 正在使用的文件 制造一个打开的文件效果 注意，这里我们之前讲过使用 > /data/m.txt这种重定向的方式来删除，这个就无法恢复了，因为这个瞬间就将空间释放掉了。 发现正在使用的文件也可以删，当然正在使用的删除就属于误删除了，现在要修复 lsof直接回车，就会显示系统中所有的正在被打开的文件 注意PID 11863，同时此时进程没有停哦 去内存中proc里看 可见4这个文件描述符是删除状态，没关系，可以直接看 照样能看，因为是加载到内存里的 恢复一下就行了 这就找回来了使用中被误删除的文件 尤其日志，经常用这种方法处理。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"14-进程、系统性能和计划任务/4-进程信号和前后台管理.html":{"url":"14-进程、系统性能和计划任务/4-进程信号和前后台管理.html","title":"第4节 进程信号和前后台管理","keywords":"","body":"第4节. 进程信号和前后台管理 在本章 第1节中提到了信号 可以实现 进程之间的通信 信号有很多种，trap -l或kill -l可见信号的种类 每个信号都带有特定的含义，这种废话以后不要说， 如何向一个进程发送指定的信号呢，可以使用kill命令发送信号 1、信号的名称如上图，你可以写全名，也可以省略掉SIG这种所有信号都有的前缀，比如SIGINT可以写成INT还可以用前面的数字编号 1 SIGUP 无需重启服务，重新读取配置文件 这个一些服务里有命令的，估计十有八九就是用的这个UP信号实现的。 有个什么reload的命令来着，记不得了 准备将首页信息放到这个地方 这就需要修改配置文件： centos6这样就行了，7可能还要加一段代码 配置文件改完，一般就是重启服务，但是现在可以这样 查看httpd的进程ps aux： 其中root那个是父进程，可以通过ps auxf 就能识别 所以PID就是2778 kill -SIGUP或kill -UP或者kill -1 都行 2 SIGINT 相当于ctrl c 一些需要ctrl c的情况 然后那边的ping就终止了 3 SIGQUIT 相当于ctrl \\ 相当于quit退出 所以用信号测试一下，下面bc挂起来 然后就quit退出了： 上面就看到INT和QUIT可以关闭进程，但有些进程不一定能关闭 vim 一个文件 进去后 踢不掉的， 再发3信号，发现可以的 kill -3 后vim里的内容就 没了？不一定，你在他kill 之前w!保存了就可以。 如果是vim下按i进入了编辑状态且有修改内容，那么kill了就会产生.xx.swap文件 15 SIGTERM 终止进程，kill的默认信号 kill `pidof xxx` 等价于 kill -15 `pidof xxx` 同样15信号也可以杀vim进程，也不是所有进程都能被其关闭的。 比如bash的进程，kill -15就杀不掉 不会报错，但是实际上杀不掉的，还在： 可以换一个强力kill就是-9 9 SIGKILL 强制杀死正在运行的进程 进程就是正在运行的程序，正在运行的进程本身就是废话 这个2827是bash，所以xshell的登入的一个窗口 直接就没了。 这个是窗口多开后进行的操作，杀的是别的窗口，自己的窗口查看方式： ps aux 可见 直接就把自己的bash就干掉了，不过上图是有个1s的重连才会自动连接上的。 -9是否能杀掉所有进程 比如说systemd是否可以被-9强杀 kill 1肯定不行，等价于kill -15 1, 这是15的默认值，kill -9 1也一样杀不掉 虽然杀不了，但是存在问题的。 pgrep -l mingetty 杀了，又再生了， 这种进程就叫再生进程--respawn ，杀不死没事，看下父进程 pstree -p看下mingetty的父进程是init 这种重生进程，其实可以杀，通过kill 1 一下父进程--父进程虽然不会被杀(kill -9 1也杀不掉)，但是你继续看 此时就杀掉了，所以init和systemd不是说杀不掉就可以杀的，还是会有影响的。 mingetty其实就是登入的终端，ctrl_alt_f3对应的就是tty3已经被杀掉了，所以下面的界面就卡住了，输入回车都没有反应了。 换一个ctrl_al_f4可以的就是tty4 有后台的进程才有再生功能，mingetty能再生，是因为有init做后台。 批量杀进程 killall httpd # 使用进程名称来杀 所以到这里就学习了 1、按PID杀，kill 2、按进程名称杀，killall 下面学习3、按模式也就是正则杀，pkill。 pkill的模式和选项和pgrep是通用的，它俩的帮助都是在一块的。 然后就杀掉了 t就是看控制终端的tty的 杀掉pts/1行运行的所有进程 其实图中要用-9,pkill -9 -t pst/1就可以删掉所有能杀掉的了。否则bash杀不掉。 然后去到运行ping的窗口上看到，就看到被杀掉了。 这两个只有pgrep有，pkill没有。 进程的前后台 这个就是占用了终端资源的前台命令 放后台的方法 这就已经放后台运行了的，但是输出还是在前台输出的。 前台执行是占用终端资源的，后台不占。 此时跑是在后台跑了，但是输出还是在前台，所以ctrl c结束不掉了就，ctrl c只能结束在前台跑的进程 怎么关呢，①再开一个窗口，kill掉ping就行了，②将后台运行的进程再次调到前台来就好了。 手速要快 fg 命令就是front groud 既然在前台了，ctrl c就可以了结束了 fg可以把后台的进程也可以是没在执行中的后台程序调到前台来。 再次研究这个现象 ping 127.1挂着，当前ping的状态是可中断的休眠 然后按ctrl z，此时就放入后台，但是不在是运行状态了 T就是后台，处于停滞状态，冷冻？ 如何恢复:1、恢复到后台运行bg；2、恢复到前台运行fg 开始操作，当前通过jobs可见是后台stopped 使用它bg命令back groud，此时就恢复到前台运行了 所以此时ctrl c不起作用，ls看看的 下面是通过fg直接恢复到前台的。 再来一个问题 已经是后台如何让他stopped 如何将已经后台的进程--正在跑着的，变成继续后台但是是休眠态 由于此时已经是后台了，ctrl z发不到后台了。 发19 SIGSTOP，后台休眠信号。 killall -19 ping 确实停止了，达到了ctrl z的效果。 还可以让他继续运行，除了bg或者fg，还可以发送18 SIGCONT信号，由于现在是后台stopped，所以18发过去就是后台运行 但是没有办法说 发个信号让他从 后台stopped变成前台运行哦。 kill的0信号 0信号是不属于信号列表的，通过kill -l可见没有0信号的 killall和kill是共用信号数字的 这说明ping当前是工作的 如果ping没有运行，就是这个结果 案例：如果http服务没有启动，就重新启动 这个可以放到crontab里1分钟跑一次，确保一些进程莫名奇妙挂了，这个情况也是存在的。 假如某个APP挂了，等个1分钟也就自动好了，就是这里的crontab，不过前提是systemctl start httpd要能起的来哦，如果配置文件有问题自然就起不来了。 关于screen和nohup ping & 两种后台执行，直接搜全文，都有的。 这个默认行为不好，因为文件会越来越大 需要丢到/dev/null里。 窗口一关，bash就没了，ping也就没了，其实不是 父进程bash8292没了，但是ping这个8401子进程还在，父进程没了，重新找了个父进程systemd。 其实视频里漏掉了exit安全退出，否则有时候不会后台运行的。当然这里的实验没有问题，但是我以前必须①nohup cmd > /dev/null $ ②exit才行的。 作业操作 kill %xx # 注意是是作业编号，不是进程编号 并发 这么些是按顺序，而且由于linux默认就是永久ping的，所以结果只会有127.1 注意ping -c 3这钟不好，我们一般都是ping -w 1，其实就是我啦，因为-c 1 万一不通，就会等好久才会给你一个结果说不可达，-w 1就是1s没有结果就认为不可达了，这个就够了，就是合适的。 并发-方法1 bash all.sh瞬间出来下图 改成-c 3 多ping几次看看 方法2、3就是子进程后台、线程后台 注意上图看着以为是脚本，其实可以是命令 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"14-进程、系统性能和计划任务/5-计划任务实现.html":{"url":"14-进程、系统性能和计划任务/5-计划任务实现.html","title":"第5节 计划任务实现","keywords":"","body":"第5节. 计划任务实现 一次性任务用的少：at这个包提供了at和batch两个命令 at用的多一点，batch基本不用。其实at也不怎么用 atq和atrm是at的扩展用法 atd.service必须是启动状态，这是前提 centos6上的atd服务： at一般用法就是跟一个时间执行cmd at -t的格式1和at 后不带-t的格式2 at回车会等STDIN，at -l查看计划任务，ctrl d 安全退出 1就是第一个任务 at -c 1可以查看具体任务细节，上面都是各种变量，最下面才是任务明细 等到时间了，任务执行完毕，就没了 at了3个命令，第一个创建文件执行了，但是后面两个ls和hostname怎么理解呢，在哪里体现呢 计划任务是在未来的时间执行的，ls和hostname是在当前终端tty上运行的。 而你不能确定你将来就在这个tty上，说不定别人正好撞到这个tty上了，就看到了ls和hostname执行的结果了。就是你执行的命令，别人看到了，这就不合理了。 所以基于以上道理，计划任务的STDOUT标准输出不会在屏幕上打印的。虽然没有输出到屏幕，但是以邮件的形式发给你了。 由于刚才是以root用户执行的，所以邮件就发到了root： 所以方法论来了，计划任务的脚本，一般不推荐有输出，而是所有输出都扔到日志或在/dev/null里，这话我就不认同哈哈，因为我的py脚本很多还是保留了print的，这些屏幕上看得到的，当然crontab去执行的化，自然屏幕看不到了。 不对，视频老师的意思的，crontab里的脚本不要有标准输出，否则会给你发送大量邮件，emmm，这话也不对，有时候正要考这些邮件当作日志来分析是否运行了。 不过，确实很多文章上的crontab都是由 /xxx/xxx/ /xxx/xxx > /dev/null的，看来不要发邮件才是比较好的一个做法。 ctrl c是强行终止 然后reboot重启，这些计划任务还在吗？ 重启后发现at -l还在 说明重启也不会影响at的任务，说明肯定是找一个地方存起来了。肯定不是内存里放了，肯定是放到磁盘上了。 磁盘上哪里呢？👇 a00003xxxx和a00004就是at -l看到的3和4编号。 这个cat /va/spool/at/a00003xxx文件看到的正是at -c 3看到的 这个路径的权限只有root 换个普通账号创建计划任务也是可以的 然后wang账号的计划任务也是放在/var/spool/at路径下的 对于wang账号来讲，/var/spool/at路径是没有权限的，但是确实将任务写进去了，说明at由SUID权限👇 删除atrm或者at -d一个意思 atrm -4说白就是把/var/spool/at的对应的文件删了 同理，可以直接删文件， noon：中午12点 midnigth：午夜12点，0点 teatime：下午茶时间，4点 tomorrow now + xxx：现在往后多久时间 -f 创建一个文件 -f 其实也就是利用重定向的效果：at 18:00 -m 告知计划任务有无执行 把原来邮件删掉 1分钟后执行 就是个空邮件告诉你执行了 白名单优于黑名单，如果wang既在白名单也在黑名单，白名单里有就不看黑名单了。 如果user2黑白里都没有，我分析就可以执行。 周期性任务用的多：crontab 对应的软件包比较多 cronie是主要工具包 上图的 crontd是主程序，运行后会自动周期运行计划任务。 上图的 /usr/bin/crontab # 是创建用户自己的计划任务的工具，区别于全局的/etc/crontab文件 centos6下的情况： crontabs是创建计划任务的工具 用户自定义的计划任务 通过crontab创建，后存放在/var/spool/cron下 这个/var/spool文件夹也是一个常用文件夹 除了刚才的at和马上正在学习的cron还有mail邮件也都在这里。 cronie-anacron补充性的包，用的不多 使用场景举例： 在家用电脑中安装了一个linux，这种PC台式机不像服务器一样24小时开机的，可能定期就会自动重启的。而加入计划任务是半夜执行的，而此时你关机了，就会导致计划任务没有执行，此时就有cronie-anacron来执行。 ​ 当你开机后的一段时间，会自动检查时间已过了没有执行的任务，找个时间给你执行了。 通过查看/etc/crontab可知，里面的存在各种环境变量的 而直接crontab -e去编辑用户自定义的任务，有时候就需要手动补上变量，比如我这种 这都是报错，后来解决的方法👆， 然后/etc/crontab还有个地方说明下 这个文件只有root才能读写，所以普通用户无法编辑，所以上面的user-name是root指定，意思就是这个计划任务是以某个普通用户来执行的。 写个磁盘空间告警 以前不太理解为什么sed 要先找到再查找替换，为什么不直接查找替换，现在案例就来了 先找到/dev/sda开头的(相当于做了一步过滤)，再针对这些开头进行替换。它不是说真的要替换，如果真的要替换直接s#a#b#就好了，它是要过滤显示出结果，所以需要查找到再替换显示。 这就找到最大值了。 将脚本写到crontab里 第一个*号的意思： 1,10,30 表示每小时的第1、10、30分钟 * 表示每分钟 */10 表示每10分钟 待会用wang普通账号去执行crontab，就是user-name写成wang，所以要看下脚本是否有权限 这样脚本wang用户就可以执行了。 然后就是 每分钟，1-5工作日，wang 去执行脚本，0或者7表示周日 然后跟踪下cron的日志 解释下面的任务 就是 30分 2点 1，10，20号 每月 周六或周日 问题来了，这个1号10号20号万一不是周末了，他们之间是并取还是或的关系呢？ 通过man 5 crontab可以找到逻辑关系，搜下note either就是也，plus就是加上，这些就说明了是 或的关系。 所以每个月的1、10、20号会执行，然后每周的周6和周日也会执行。 问题来了，如果我就要并且呢，计划任务没有这功能，就需要在脚本里去判断 然后脚本里去判断是否为周末，如果是就执行。这就是且的关系的落地。 用这个命令获得今日是周几；👇man date 通常计划任务不会放到这个/etc/crontab里，一般就是crontab -e那个用户就是哪个创建的。 crontab -e创建的时候，就系统就自然就知道是哪个用户创建的，所以格式上就有个默认的user-name不用写了，直接 * cmd 该文件已经有执行，所以就是CMD搞定 不通用户创建的crontab -e其实就是/var/spool/cron下的不同文件 crontab -l看自己的，看别人的加上 -u 删除某某用户的所有计划任务 文件下的脚本都执行 每分钟，执行/data/scripts下的所有脚本，然后验证确实执行了： 这个次序就是按ls的次序执行的 验证上面的次序判定 可见/usr/bin/run-parts /data/scripts 确实是按脚本存放路径的ls次序执行的。 系统本身就有的周期性任务 mlocate就是locate的依赖的默认数据库，而这个数据库是每天刷新一次的。就是靠这里。 为什么放到/etc/cron.daily下的这些脚本(这些logrotate、man-db.cron、mlocate都是独立的脚本)，为啥这些就会daily每日执行呢，其实还需要有个cron去执行他们的。 上图就是cron.hourly文件夹下的脚本都会执行的原因，因为有/etc/cron.d/0hourly去执行的。而daily文件夹下就不会执行，因为/etc/cront.d下没有对应的周期命令。 但其实上面的可能是执行的，因为还有 日志可以观察，也可以帮助还原误删除的计划任务 /var/log/cron 下次开机执行的方法，应该是等价于rc.local的。 crontab -e 便捷 重启后可见，确实执行了 因为wall看不到广播效果，因为没法提前进到那个终端去等到广播信息 换一个方式 多任务时间一致，可以用分号隔开，呵呵，要考虑前一条执行花费时间哦，第二条执行有延迟的。 anacontab 1表示1天执行一次，开机5分钟后自动运行 cron.daily 每天就是1 每周就是7 每月就是@monthly， 5 25 45就是开机后的5、25、45分钟后执行后面的脚本。 45分钟随机延迟 服务器上这个anacron用的少 管理临时文件 centos6上的一些文件 makewhatis就是手动做了makewhatis.cron mlocate.cron相关的信息，手动就是updatedb。 tmpwatch是清除垃圾文件 10天清理一次/tmp 30天清理一次/var/tmp windows没有定时清理的功能 到了centos7就是一个服务专门来做这事了 原来centos6这个路径下，在7上就没有哪个tmpwatch文件了： 不希望wang执行计划任务 再写一个/etc/cront.allow 白的黑的都有wang，其实就只看白的了 crontab -e就进去了👇 这个deny只是说不能编辑，原来如果有权限的时候编辑的计划任务还是会正常工作的。 crontab精确到s的方法 sleep可以精确到0.1s好像 但是你用sleep控制周期，就不是crontab里的每分钟--其实是到整点就执行了。sleep是真的等1s执行，那么如果之前的脚本本身执行就要花4s，那么用with os.popen阻塞的方式，其实就是5s钟才能一个周期了。而且存在队列不断加大的风险。 usleep是微妙级别的睡眠 利用crontab定期同步时间 这个是取之我们的extmail里的一个案例： 这是视频里老师的写法： 上图有错误，所以wq退出会报错 y重新edit为： 据说&> /dev/null是一个好习惯，否则一堆垃圾邮件。 习题 说是*/7不行，因为60/7除不尽，需要用sleep 420 来做，但你想想就是我说的，脚本执行如果要化10s，没关系，那也是脚本执行后sleep了7分钟才继续执行啊。所以两次周期就是严格的7分钟过了。 sleep也是有单位的 crontab里不要用%，这个踩过坑，当然%如果在py脚本里是没有问题的， 有人想在crontab里写date +%F，这种就不行，换个思路，将date +%F写到脚本里，然后crontab里调用脚本就可以了。 还有就是上文提到过变量问题，或者叫二进制的执行文件要写绝对路径--但是有的遗漏的就是通过邮件看到日志提示 之前的坑记录如下，emmm原来慢慢吞吞都1年半下来了。太慢啦，不过这事写脚本，不算linux系统学习，也还说的过去。 这个还是python脚本里调用了mtr命令，然后crontab报错找不到PATH变量 而且，我都在py里的mtr也是写了绝对路劲的，但是就是不认，哈哈，最后还是加了一行path变量才好的。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"15-shell脚本编程进阶/15-shell脚本编程进阶.html":{"url":"15-shell脚本编程进阶/15-shell脚本编程进阶.html","title":"第十五章 shell脚本编程进阶","keywords":"","body":"第十五章 shell脚本编程进阶 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"15-shell脚本编程进阶/1-循环01.html":{"url":"15-shell脚本编程进阶/1-循环01.html","title":"第1节 循环01","keywords":"","body":"第1节. 循环01 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"15-shell脚本编程进阶/2-循环02.html":{"url":"15-shell脚本编程进阶/2-循环02.html","title":"第2节 循环02","keywords":"","body":"第2节. 循环02 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"15-shell脚本编程进阶/3-函数详解01.html":{"url":"15-shell脚本编程进阶/3-函数详解01.html","title":"第3节 函数详解01","keywords":"","body":"第3节. 函数详解01 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"15-shell脚本编程进阶/4-函数详解02.html":{"url":"15-shell脚本编程进阶/4-函数详解02.html","title":"第4节 函数详解02","keywords":"","body":"第4节. 函数详解02 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"15-shell脚本编程进阶/5-信号处理和函数组详解.html":{"url":"15-shell脚本编程进阶/5-信号处理和函数组详解.html","title":"第5节 信号处理和函数组详解","keywords":"","body":"第5节. 信号处理和函数组详解 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"15-shell脚本编程进阶/6-高级变量和expect.html":{"url":"15-shell脚本编程进阶/6-高级变量和expect.html","title":"第6节 高级变量和expect","keywords":"","body":"第6节. 高级变量和expect Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"16-系统启动和内核管理/16-系统启动和内核管理.html":{"url":"16-系统启动和内核管理/16-系统启动和内核管理.html","title":"第十六章 系统启动和内核管理","keywords":"","body":"第十六章 系统启动和内核管理 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"16-系统启动和内核管理/1-系统启动流程和故障排错.html":{"url":"16-系统启动和内核管理/1-系统启动流程和故障排错.html","title":"第1节 系统启动流程和故障排错","keywords":"","body":"第1节. 系统启动流程和故障排错 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"16-系统启动和内核管理/2-启动流程和服务管理.html":{"url":"16-系统启动和内核管理/2-启动流程和服务管理.html","title":"第2节 启动流程和服务管理","keywords":"","body":"第2节. 启动流程和服务管理 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"16-系统启动和内核管理/3-启动流程详解.html":{"url":"16-系统启动和内核管理/3-启动流程详解.html","title":"第3节 启动流程详解","keywords":"","body":"第3节. 启动流程详解 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"16-系统启动和内核管理/4-linux启动流程grub管理和故障排错.html":{"url":"16-系统启动和内核管理/4-linux启动流程grub管理和故障排错.html","title":"第4节 linux启动流程grub管理和故障排错","keywords":"","body":"第4节. linux启动流程grub管理和故障排错 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"16-系统启动和内核管理/5-自制linux和源码编译内核.html":{"url":"16-系统启动和内核管理/5-自制linux和源码编译内核.html","title":"第5节 自制linux和源码编译内核","keywords":"","body":"第5节. 自制linux和源码编译内核 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"16-系统启动和内核管理/6-systemd特性.html":{"url":"16-系统启动和内核管理/6-systemd特性.html","title":"第6节 systemd特性","keywords":"","body":"第6节. systemd特性 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"16-系统启动和内核管理/7-systemd和grub2管理.html":{"url":"16-系统启动和内核管理/7-systemd和grub2管理.html","title":"第7节 systemd和grub2管理","keywords":"","body":"第7节. systemd和grub2管理 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"17-Security-Enhanced/17-Security-Enhanced.html":{"url":"17-Security-Enhanced/17-Security-Enhanced.html","title":"第十七章 Security-Enhanced","keywords":"","body":"第十七章 Security-Enhanced Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"17-Security-Enhanced/1-SELinux实现安全加固.html":{"url":"17-Security-Enhanced/1-SELinux实现安全加固.html","title":"第1节 SELinux实现安全加固","keywords":"","body":"第1节. SELinux实现安全加固 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"18-文本处理三剑客3_awk/18-文本处理三剑客3_awk.html":{"url":"18-文本处理三剑客3_awk/18-文本处理三剑客3_awk.html","title":"第十八章 文本处理三剑客3_awk","keywords":"","body":"第十八章 文本处理三剑客3_awk Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"18-文本处理三剑客3_awk/1-文本三剑客3_awk详解01.html":{"url":"18-文本处理三剑客3_awk/1-文本三剑客3_awk详解01.html","title":"第1节 文本三剑客3_awk详解01","keywords":"","body":"第1节. 文本三剑客3_awk详解01 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"19-加密和安全/19-加密和安全.html":{"url":"19-加密和安全/19-加密和安全.html","title":"第十九章 加密和安全","keywords":"","body":"第十九章 加密和安全 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"19-加密和安全/1-安全和各种攻击方法.html":{"url":"19-加密和安全/1-安全和各种攻击方法.html","title":"第1节 安全和各种攻击方法","keywords":"","body":"第1节. 安全和各种攻击方法 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"19-加密和安全/2-安全加密算法体系详解.html":{"url":"19-加密和安全/2-安全加密算法体系详解.html","title":"第2节 安全加密算法体系详解","keywords":"","body":"第2节. 安全加密算法体系详解 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"19-加密和安全/3-PKI和证书安全体系详解.html":{"url":"19-加密和安全/3-PKI和证书安全体系详解.html","title":"第3节 PKI和证书安全体系详解","keywords":"","body":"第3节. PKI和证书安全体系详解 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"19-加密和安全/4-互联网安全通讯协议HTTPS详解.html":{"url":"19-加密和安全/4-互联网安全通讯协议HTTPS详解.html","title":"第4节 互联网安全通讯协议HTTPS详解","keywords":"","body":"第4节. 互联网安全通讯协议HTTPS详解 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"19-加密和安全/5-建立私有CA和颁发证书.html":{"url":"19-加密和安全/5-建立私有CA和颁发证书.html","title":"第5节 建立私有CA和颁发证书","keywords":"","body":"第5节. 建立私有CA和颁发证书 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"19-加密和安全/6-证书管理和SSH服务工作原理详解.html":{"url":"19-加密和安全/6-证书管理和SSH服务工作原理详解.html","title":"第6节 证书管理和SSH服务工作原理详解","keywords":"","body":"第6节. 证书管理和SSH服务工作原理详解 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"19-加密和安全/7-SSH服务配置和基于KEY验证.html":{"url":"19-加密和安全/7-SSH服务配置和基于KEY验证.html","title":"第7节 SSH服务配置和基于KEY验证","keywords":"","body":"第7节. SSH服务配置和基于KEY验证 默认的ssh登入方式 关于SSH第一次链接的安全性，即解决方案： 你可以见Server端的公钥用HASH算一下，将值公布在网站上，CLIENT去链接的时候对比一下一样再yes。SSH后续连接就是安全的了。（*其实谷歌AWS等都不是这种方式了，都是用的公钥文件，下文讲) yes的作用就是，就是把对方的公钥放到的.ssh里。 -b 比较牛哈，ping知道怎么带源，ssh也要知道哈。 关于Xclock所代表的X协议 xclock代表的client端 xServer就是服务端 两者是通过x协议沟通， 图形的显示是通过server上的显卡实现。 xClient和xServer不在同一台电脑的场景，比如我A ssh B 登入后，输入xclock这个谁是server谁是client呢 A是server，B是client，因为登入到B上进行xclock，而要显示时钟图形界面是在A这个server上的。 A和B的X协议是通过ssh协议封装传递的。 注意：如果server端不是xshell，而是scrt软件，就不行了，因为scrt没有给你安装X协议server。xshell是xmanager一套软件安装的，是默认安装了x协议的。 windows没有xServer，xshell安装的时候默认安装了xServer，secureCRT没有xServer要额外安装软件的要注意的。 xshell不是单装的 xshell而是安装的xManager，所以带了xServer软件 改MAC地址的一个案例 当你改完网卡配置文件后还是改不过来的时候可以试试下面的方法： modprobe -r e1000，-r是remove掉网卡驱动，通过ip a发现没有卸掉网卡 ethtool -i eth0 ， 年后看下是哪种模块，请认真学习噗冬伐 modprobe -r pcnet32，找到驱动了，进行删除 modprobe pcnet32 重新安装驱动，mac得以刷新 一跳一跳地ssh上去 server会看到是192.168.37.101连上来的。 下面讲基于KEY的ssh 这里的key就是RSA里的密钥对，其实上面默认的ssh其实也是有公钥的，只不过之前的是单向公钥加密码；现在是双向公钥，并且弃用了密码。 安全性方面注意： 私钥拷走就有大问题 1、私钥拷走 2、修改私钥文件的属性 公钥交换，这个说法就很奇怪，听起来加上看上图，都觉得没错，但是实际上，res=ID^xxx这套东西通常是DH算法，而DH算法，就是在交换密钥，SSH加密可能试用非对称密码来加密传输的数据， 1、加密通道的形成，肯定不是公钥的传递，这个图片只是理论上的非对称做法，实际应该略微修改成对称密钥的传递。 2、所以从实际应用出发，上图的client PBULIC-KEY是不存在的。 3、所以下图的SSH加密通信应该改成对称密码加密而不是非对称。 在上面加密隧道形成后，于是开始认证，包括认证成功后的数据传递 同样上图得改，改成用户名+密码 然后通过对称密码加密发送过去，而不是Public key。 图中倒数第二步的 13579传输可不是明文传过去的，是基于对方公钥加密后传递的，其实这图是第二个阶段了，第一阶段是公钥的交互，交互后以后所有的通信都是使用公钥进行传输的了。 上图这个key的认证倒是对的，另附一图佐证 然后参看资料 https://juejin.cn/post/6844903685047189512 http://www.h3c.com/cn/d_200805/606213_30003_0.htm 密钥认证的实验 ssh-keygen -t rsa 默认就是rsa 注意密钥对存放路径，上图中有，然后上图是切到wang用户去生成密钥的。 生成了公钥和私钥文件 接下来要去弄server端的authorized_keys文件 该文件自动生成 ssh-copy-id -i /home/wang/.ssh/id_rsa.pub root@192.168.37.6 注意即使你敲错了id_rsa，也不会传私钥过去的，会自动给你传公钥的。 确实是写的私钥，实际系统给你传的也是公钥。ssh真贴心 现在直接登了就 scp走的就是ssh协议，所以复制也不要输密码了 直接不用输密码了 也挺安全 但是这台电脑的安全一定要保护好，这台机器的账号要是泄露了就危险了。 以上总结 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 16:08:58 "},"19-加密和安全/8-SSH基于key的expect自动化脚本.html":{"url":"19-加密和安全/8-SSH基于key的expect自动化脚本.html","title":"第8节 SSH基于key的expect自动化脚本","keywords":"","body":"第8节. SSH基于key的expect自动化脚本 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"19-加密和安全/9-SSH端口转发功能详解.html":{"url":"19-加密和安全/9-SSH端口转发功能详解.html","title":"第9节 SSH端口转发功能详解","keywords":"","body":"第9节. SSH端口转发功能详解 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"19-加密和安全/10-SSH安全实践配置.html":{"url":"19-加密和安全/10-SSH安全实践配置.html","title":"第10节 SSH安全实践配置","keywords":"","body":"第10节. SSH安全实践配置 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"19-加密和安全/11-dropbear编译安装和文件完整性检查.html":{"url":"19-加密和安全/11-dropbear编译安装和文件完整性检查.html","title":"第11节 dropbear编译安装和文件完整性检查","keywords":"","body":"第11节. dropbear编译安装和文件完整性检查 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"19-加密和安全/12-sudo实现管理授权详解.html":{"url":"19-加密和安全/12-sudo实现管理授权详解.html","title":"第12节 sudo实现管理授权详解","keywords":"","body":"第12节. sudo实现管理授权详解 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"19-加密和安全/13-TCPWRAPPER和PAM安全模块.html":{"url":"19-加密和安全/13-TCPWRAPPER和PAM安全模块.html","title":"第13节 TCPWRAPPER和PAM安全模块","keywords":"","body":"第13节. TCPWRAPPER和PAM安全模块 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"19-加密和安全/14-PAM模块使用.html":{"url":"19-加密和安全/14-PAM模块使用.html","title":"第14节 PAM模块使用","keywords":"","body":"第14节. PAM模块使用 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"20-网络时间服务和Chrony/20-网络时间服务和Chrony.html":{"url":"20-网络时间服务和Chrony/20-网络时间服务和Chrony.html","title":"第二十章 网络时间服务和Chrony","keywords":"","body":"第二十章 加密和安全 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"20-网络时间服务和Chrony/1-时间计时和同步.html":{"url":"20-网络时间服务和Chrony/1-时间计时和同步.html","title":"第1节 时间计时和同步","keywords":"","body":"第1节. 时间计时和同步 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"20-网络时间服务和Chrony/2-时间同步服务.html":{"url":"20-网络时间服务和Chrony/2-时间同步服务.html","title":"第2节 时间同步服务","keywords":"","body":"第2节. 时间同步服务 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"21-运维自动化系统部署/21-运维自动化系统部署.html":{"url":"21-运维自动化系统部署/21-运维自动化系统部署.html","title":"第二十一章 运维自动化系统部署","keywords":"","body":"第二十一章 运维自动化系统部署 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"21-运维自动化系统部署/1-系统自动化安装.html":{"url":"21-运维自动化系统部署/1-系统自动化安装.html","title":"第1节 系统自动化安装","keywords":"","body":"第1节. 系统自动化安装 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"21-运维自动化系统部署/2-DHCPD服务实现.html":{"url":"21-运维自动化系统部署/2-DHCPD服务实现.html","title":"第2节 DHCPD服务实现","keywords":"","body":"第2节. DHCDP服务实现 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"21-运维自动化系统部署/3-实现基于PXE安装centos7系统.html":{"url":"21-运维自动化系统部署/3-实现基于PXE安装centos7系统.html","title":"第3节 实现基于PXE安装centos7系统","keywords":"","body":"第3节. 实现基于PXE安装centos7系统 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"21-运维自动化系统部署/4-实现基于cobbler的自动安装.html":{"url":"21-运维自动化系统部署/4-实现基于cobbler的自动安装.html","title":"第4节 实现基于cobbler的自动安装","keywords":"","body":"第4节. 实现基于cobbler的自动安装 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"21-运维自动化系统部署/5-实现基于cobblerweb的管理.html":{"url":"21-运维自动化系统部署/5-实现基于cobblerweb的管理.html","title":"第5节 实现基于cobblerweb的管理","keywords":"","body":"第5节. 实现基于cobblerweb的管理 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"22-DNS服务和BIND/22-DNS服务和BIND.html":{"url":"22-DNS服务和BIND/22-DNS服务和BIND.html","title":"第二十二章 DNS服务和BIND","keywords":"","body":"第二十二章 DNS服务和BIND Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"22-DNS服务和BIND/1-DNS服务简介.html":{"url":"22-DNS服务和BIND/1-DNS服务简介.html","title":"第1节 DNS服务简介","keywords":"","body":"第1节. DNS服务简介 bind9是这次主学的，dnsmasq也是不错的，其他微软的，路由器上的都行，但是考虑一下这个案例： 公司的员工从飞塔出去，飞塔基于sourceIP做ecmp从ct和cu出去，此时存在一个问题，内部dns从ct出去，此时从cu出去的用户dns拿到的却是电信的，虽然在当前BGP IP较多的情况下，但是随着用户量变多，鸟也变多了，所以娘好儿子才能好，不对，所以良好的方案就很重要了，你不能凑合着用对吧， 你说为什么不用出口设备做DNS分流+ISP路由清单，①没清单②DNS分流要截获的吧，这个iKUAI肯定可以做，没研究。但是作为DNS的学习来讲，显然必学的，所以我的方案来了。 你说为什么不用出口的pbr，或者核心的pbr，pbr是固定一拨人走一个出口，现在利用dns分为2个奇偶，随着用户奇偶，就能自动将dns分流，而且随着飞塔的ECMP随机性，奇偶一定是分别从2个出口走的，但是至于走哪个口是随机且相对固定的，一段时间奇数时走ct，一段时间奇数又是走cu，与之相对的偶数就走另外的线路。ECMP就是随机且相对稳定的负载分担。 1、当前用户在fortigate上是sourceip的ECMP，所以奇数和偶数IP分别随机又相对稳定的分流到两个ISP上的 2、DNS内部有两台10.2和10.3，但是都是从第三条电信EIP出去的。 3、此时加入一段时间偶数IP是从ct出去，奇数IP从cu出去，而dns从EIP出去，此时奇数IP的dns请求就需要调整。 方案如下 1、将10.2的路由保留继续从EIP出去，10.3的路由从第四条线路联通固定IP出去；如果你没有这么多线路，你就用ct和cu啦。具体就是将10.2和10.3都改为从飞塔出去，然后飞塔就会根奇偶ECMP出去。 此时10.2就成为了偶数IP员工的一员，10.3就成为奇数IP的一员了。 2、需要将偶数IP的dns request 转到10.2(因为dns也是偶数，所以它也是这一部分员工走的一样的线路，这就保证DNS也是从员工出去的线路问的，拿到的自然就是当前使用ISP的解析地址咯)，将奇数IP的dns请求转到10.3 3、由于10.2和10.3是用的dnsmasq做的，本来我是想大家都用10.2，然后10.2上做view将奇数IP的请求转到10.3上去，由10.3去代理查询，但是dnsmqs不支持view，所以就需要学习bind9再两个dnsmaq前面套一层，不能说dnsmasq就是轻量级的，套一层bind9只做view转发，想想就美滋滋~ 但是我就不硬上，反正也不急，慢慢撸一遍DNS~emm，之前就看过一遍忘记咯。 开始 ================================================================================ 一、 bind9和dhcp都是isc开发的， https://www.isc.org/download/ 此外还有一个unbound，不过看版本就是知道太新了，不一定有bind9稳定。 https://nlnetlabs.nl/projects/unbound/about/ bind是伯克利大学开发开源的 主流的CPU芯片： x86: intel amd 兆芯(购买了早期的citrix) 移动手机端绝大多都是ARM：苹果A12，高通-晓龙855，华为-麒麟985，联发科-各种山寨？ 华为被制裁由将来可能就不用ARM了， MIPS: 龙芯-生态圈小-用的少，早期比ARM强，ARM在移动设备爆发的时候起来了。 RISC-V罗马数字5代的意思：开源的芯片级的linux架构，华为被ARM制裁 所以加入到这个CPU开源芯片研发团队了。而这个RISC又是伯克利大学人做的。 FQDN Full Qualified Domain Name oneyearice.github.io, oneyearice就是主机名(或者是别名)，github.io就是域名，这是分层的结构，一级域名，二级域名等 DNS是一个分布式的系统，结合hosts的零散和NIS的集中 两家之长~ www.sina.com.cn. 最后其实是有一个.点的。只是在浏览器输入的时候省略了不写了，windows里dns服务里好像之前见到过。 FQDNIP之间互相是可以互相转换的，通常是域名转IP咯。 NIS是把所有的域名解析放到一个地方，而DNS是在每级域处都建立数据。 shanghai.sina.com 就是这么顺下来的 不过还有一个www.sina.com 就是不是递归的dns数据库而是直接二级域的本地数据库里的一个www主机名 同样shanghai.sina.com除了本地的www.shanghai.sina.com,也许还有下级域 然后用户是如何找到www.shanghai.sina.comde 或mail.iwgame.com或者ftp.iwgame.com等IP地址的,两种查询方式，一般都是递归 名词解释： 所谓权威DNS服务，就是比如你要访问的www.shanghai.sina.com这个域名的权威就是在哪里对外发布的那台，哪里就是权威，对应的上图就是最底层的三级域名服务器。 如果223.5.5.5有缓存就直接给你了 FRU算法 缓存长时间不用就慢慢 删掉了就 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-02-15 09:02:10 "},"22-DNS服务和BIND/2-DNS只缓存服务器实现.html":{"url":"22-DNS服务和BIND/2-DNS只缓存服务器实现.html","title":"第2节 DNS只缓存服务器实现","keywords":"","body":"第2节. DNS只缓存服务器实现 下面开始部署DNS服务器 主从 whois 1、购买域名 2、云上解析即可，此时云上就是你的权威DNS 3、搭建企业内部的dns服务器 使用BIND，其实是一系列的软件。包括bind、bind-utils、bind-chroot bind-utils应该是客户端工具，比如nslookup、dig、hosts等 bind是服务端提供服务的包 bind-chroot是bind的一个功能,使bind可以在一个chroot的模式下运行.也就是说,bind运行时的/(根)目录,并不是系统真正的/(根)目录,只是系统中的一个子目录而已.这样做的目的是为了提高安全性.因为在chroot的模式下,bind可以访问的范围仅限于这个子目录的范围里,无法进一步提升,进入到系统的其他目录中。bind的默认启动方式就是chroot方式 yum -y install bind rpm -qi bind rpm -ql bind 其中/etc/named.conf是主配置文件 /usr/lib/systemd/system/named.service是服务启动的文件 /usr/sbin/named是主程序 /usr/sbin/rndc也是要用到的啥啥啥 梦飒飒 /var/named是数据库文件夹用来存放域名解析的信息 /var/named/named.ca不是证书那套体系里的ca哦，而是传说中的13个根。 /var/log/named.log是日志 怎么一下起来这么多53，v4的8个（tcp4个udp4个），v6的8个， 那么问题来了，为什么会是4个udp53呢？ fd好像是socke进程的句柄，可能涉及并发 fd一般就是/dev/fd 文件描述符，这里可能是一个意思？ 然后只要启动了bind服务，就默认具备了dns的递归查询功能，因为人家有13个根，所以能够往上游查询，只是效率将不准了，哈哈，也就是说 本地/etc/resolv.conf里写127.0.0.1，然后启动named，本地就能ping通www.xx.com域名了。 此时named默认空配置，服务起来后，自己可以解析；但是代理dns，也就是还不能做内网dns 上图已经关闭了默认的firewalld和selinux 除了nslookup还有host dig都有类似提示 都是超时，因为udp 53都不通啊，👇 当然tcp53一样也不通 但是ping ok 防火墙和selinux不止早就关了吗，还有啥？ 仔细看前面的ss -tlnup 的截图，上面显示是监听地址为127.0.0.1也就是只侦听在本地环回口，而不是外接的网卡上，所以自然不能提供服务啦 改一下，就是改配置文件 这样端口就通了，也可以改成localhost--代表当前机器的所有IP，效果是一样一样的，都是监听本地所有ip上 localhost是本地所有IP≠any=0.0.0.0/0 本地两个ip一个192.的一个127的，所以就监听在这两个上面了 当然tcp，client是不需要的 此时nslookup还是不行 直接拒绝你了，看来还有地方要改 继续看配置文件，找到关键词 allow-query，改成0.0.0.0/0或者any就行 注意nslookup 不涉及本地缓存哦，上图就说了，named是默认就有缓存功能的。进一步验证，就是讲dns 服务的机器设置成两个网卡，一个网卡沟通内部，一个网卡沟通外网互联网，①第一次client内部dns请求后②关闭server的外网接口，再次请求就会发现依然OK。 dig 用的不多，看看效果 这是不能解析的截图 这个不要深究了，及时ping提示网络不可达其实dns已经由IP了。 正所谓凡是不可毕其尽，谁知道系统怎么提示的，又不是天地法则，都是人为编程。 补上网关 补一个不存的网关，欺骗系统一下，它认为远程的主机是可达的，是有机会访问的 这个时候IP就显示出来了，所以网络不通立马跳出来这个消息，就是网关配有配置，有配置就是尝试通信的。 当然一般dns不是同网段， 如果是同网段+dns在一个子网，解析没问题，网关没配置，一样秒报错 网络不可达。 本来不想细究，但是人家视频里正好演示了，我就顺便截个图咯，本来就没啥意义，只有在处理特殊故障的时候才可能用到这种所谓的底层基本功。 缓存存在域dns server的验证实验截图，人家的 哈哈 dns server下图的路由和网卡：👇 关于接口 down的linux 怎么判断是接口不带电了，还是协议down了呢？要知道VMwareworkstaion的VM虚机的网卡断开后，接口DOWN没错，但是ip route show还能看见默认路由的。这就没有数通的产品路由生效要有下一跳可达的前置条件。 ifconfig看不出到底是命令down还是没插网线的down，交换机上物理口就有administra down和普通的down-no conn 其实除了 上面的管理员down和没插线的down 还有协议down，普通以太网口这种情况不多，顶多就是交换机的err-disable down，抓哟是ppp 串行线的口的协议down，tunnel口的协议down，这些吧。 ethtool eth1 看看 mii-tool比较适合干这活 ifconfig eth1 down 等价于网卡禁用 VM里断开网络来凝结 等价于把网线 好~，现在dns server的网关就没了，无法进一步向根询问dns解析了 结果发现client解析之前解析过的，理应在server上有缓存的，竟然不成功！ 发现自动补了后缀，这是杂肥四 先不着急删除/etc/resolve.conf里的自动不清的后缀domain 先去还原dns server外网试试看，恢复dns server的外网后，client ping 域名 OK👇 然后再次禁用dns server的外网网卡 client依然可以ping通 刚才不通，可能就是server的缓存时间比较短。其实不是是本机有缓存。还需要清除本机缓存--好像没必要， https://jaminzhang.github.io/dns/flush-dns-cache-in-Linux/ 因为centos上好像本地没有dns请求的缓存记录。 dns server服务端清除dns缓存可以的，这样①重启服务②rndc flush； 后client无法解析 linux 就没有本机的dns 客户端缓存的，除非你是dns server做中继或者做解析的。 上面讲的dns本地是没有解析的，都是问别人得到的，这种就是 dns 只缓存服务器； 纯二道贩子 ------------------------------------题外话----------start------------------------- 之前我给开发搭建的NPM缓存服务器就是一样的，NPM代理那里有时间复习下，关键点就是①verdaccio这个软件好像是②npm的代理 client通过它下载的软件网页上是没有记录的，代理服务器自己install的才能上网页，所以就写了个脚本讲代理下载的json文件等 复制到上网页的路径里去就搞定啦~ 点开都有帮助 使用案例 1年都没坏，机器上还有一个yum源，也是一周一更，香香的。 ------------------------------------题外话----------end------------------------- 下面搭建右下角的本地dns解析条目 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-02-15 17:12:56 "},"22-DNS服务和BIND/3-DNS主服务器实现.html":{"url":"22-DNS服务和BIND/3-DNS主服务器实现.html","title":"第3节 DNS主服务器实现","keywords":"","body":"第3节. DNS主服务器实现 dnsmasq就是比较简单的hosts复用就行 bind的它分域，针对一个一级域名进行其下域名解析记录的编写。 前2节内容说白了，就是两行的事 下面继续了解其他配置，针对xxx.com某个域进行dns服务， 第一步，打开主配置文件 配置文件类似C预言风格，都是;分号结尾的 其中有options语句块，用{}花括号括起来的。定义了dns的选项 下面还有logging日志的语句块。 要建立的DNS域信息，区域zone就是针对某个域建立dns解析用的。 zone : oneyearice.asia dbfile1 # zone就是一级域名对应的数据库文件 xkyearsice.asiadbfile2 # 这是第二个区域 上图的file就是数据库的文件名 而且是根，根的tye就是hint，主dns就是写master。这里的file只写了名称，路径没有写。路径在option里定义的👇 还有dns是主还是从 图中的.就是根咯，因为这里填的是域名，而根的域名就是个.点，所以file指向的是named.ca文件，该文件里放的及时13个根域。 根据option里的directory 指定的路径，和zone里自己定义的file 名称，创建数据库文件 既然以named用户运行，那么数据库就要有访问权限 格式 name就是域名 TTL是域名的缓存时间，单位是秒 IN就是固定格式，internet记录，这里固定格式，其实dns还可以做别的工作， rr_type常规就是A记录，AAAA ipv6地址记录， value就是IP地址，当然如果是PTR的类型，前面的name就是IP地址，这里的value值就是域名了。 这些就是rrtype类型：除此之外还有PTR--ip解析成域名的记录，也就是A记录的反向动作。 其中rr_type灰常重要的一种是SOA类型 数据库中可以有很多条记录，SOA必须是第一条记录 SOA就是对该域的初始定义，比如当前域由哪个主dns服务器对外提供服务;写清 主从 主从数据库同步的方式，管理员邮箱 故障通知， 可以使用freenom获得免费域名，然后NS到CF，在使用CF的免费CDN就挺好的。 开始编写，参考模板 接着修改下 下面的NS、A、AAAA分别一行行的，是3条解析记录 上图的SOA记录解释 1、name就是@这个，写全就是oneyearice.asia. 注意最后一个点，不写就当作前缀会自动给你补上zone定义的一级域名oneyearice.asia 也就说写成oneyearice.asia等价于oneyearice.asia.oneyearice.aisa。结尾加上.就不会自动再补了。 然后，@就是zone里指过来的一级域名就可以用@代替。 2、TTL，可以用第一行定义的$TTL 1D，就不用再写了；也可以不用它的，采用自定义比如@ 864000 这样就是10天的缓存 3、IN照抄 4、类型rr_type就是SOA啦 5、value，soa的值不是一个IP地址，而是一个定义的集合，包括 ​ ①当前这个域的主DNS服务器 理论上面的master.oneyearice.asia.可以简写为master，不是说自动补齐嘛，为啥写这么长呢。 通过这里再次明确根就是.咯， 下面的 0 ：serial 表示当前区域数据文件的版本号，数字越大，表示当前内容越新。当我们修改了记录后，就需要手动的递增该版本号。 这个版本的作用就是：主从同步的判断依据，同步考的就是主上的版本号变大了（自己和自己比较，MMP，这同步的思路牛逼了）。只看版本号，不看内容 不看哈希，就看数字。数字还是人写的。牛逼~，看来还得辅以脚本自动判断哈希值 递增主的版本号。 1D：refresh 是从服务器 1 天 去主服务器上拉一次数据库信息。这么理解的，关于主从的同步 分为 推 和 拉 推就是主发现自己的版本号变了，而且是变大了，就会推； 拉就是从没法知道主什么时候变，于是周期性的去拉，周期就是这里的1D设置的。 1H：retry，就是从没拉成功，不用等1D后的周期，只需要1H就会再次尝试去拉。那么问题来，你确定1H不涉及主推的不成功的重试时间？ 1W：如果从服务器长达1W一周没能同主服务器同步，这话不准确啊，是没拉成功还是没被主push成功呢，我初步感觉应该是看日期，不管是主push还是从get，数据库文件的mtime如果小于当前时间 超过1W，就算失联了，对吧。这个就合理了，就算它的逻辑不是我想的这样，我TM写个脚本给你改掉。 3H：minimum是针对client请求的缓存时间，比如client请一个域名，我第一次本地没有的就会去上游dns问，然后缓存3小时内，client再次请求，就会直接把缓存里的记录交给client。如果是本地有的记录呢，是不是也会缓存，应该也不会查本地数据库。错了！ ​ 这3H和上面的TTL是两码事，minimum和TTL都是针对client的请求的记录缓存，minimun是针对本地不存的记录需要去上游问的，不管问到还是没问到的缓存；而TTL是针对本地有记录的用户请求的缓存。 ​ 都不对，两个缓存的理解如下： 所以dnsmasq估计也有这两种缓存，也就是说 修改hosts，说不定不用重启dnasmq，只要等他缓存到期了就行了。 更正 https://www.zytrax.com/books/dns/apd/rfc2308.txt上讲了 Negative caching was an optional part of the DNS specification and deals with the caching of the non-existence of an RRset [RFC2181] or domain name. https://www.zytrax.com/books/dns/ch8/soa.html中讲了 \"the negative caching time - the time a NAME ERROR = NXDOMAIN result may be cached by any resolver.\" 然后人家也说了，older documentation也就是bind4and8不是这么玩的，那会儿表示TTL的默认值。那会还没有explicit TTL呢 nx = nxdomain ttl Signed 32 bit value in seconds. RFC 2308 (implemented by BIND 9) redefined this value to be the negative caching time - the time a NAME ERROR = NXDOMAIN result may be cached by any resolver. The maximum value allowed by RFC 2308 for this parameter is 3 hours (10800 seconds). Note: This value was historically (in BIND 4 and 8) used to hold the default TTL value for any RR from the zone that did not specify an explicit TTL. RFC 2308 (and BIND 9) uses the $TTL directive as the zone default TTL. You may find older documentation or zone file configurations which reflect the old usage. BIND Time format. https://www.zytrax.com/books/dns/apd/rfc2308.txt上讲了 Negative caching was an optional part of the DNS specification and deals with the caching of the non-existence of an RRset [RFC2181] or domain name. 所以关于两个缓存需要重新认识一下 吃饭， 回来了，去的路上我在想，雨果我来开发，我怎么弄，我就会将 请求到的做一个缓存，没请求到的另外做一个缓存，就行拉， 找证据，肯定要去官网了，首先进入到这里：https://www.isc.org/bind/ 页面找了一圈没有看到document关键字，点这里看看 继续点 点 搜 结果在1.4里，哈哈 所以我开发的思路也是对了，就是不存的解析一个缓存。并不是 通过dns server代理查询上游的本地没有的记录的缓存时间。没这个说法！ 然后上图的 For details of what all these fileds mean,please see the authoritatvie server document.去看看明细解释。 SOA Records There is only one SOA that is guaranteed to exist on the internet and that is the one for the root zone (called .). As of 2018, it looks like this: . 86400 IN SOA a.root-servers.net. nstld.verisign-grs.com. 2018032802 1800 900 604800 86400 This says: the authoritative server for the root zone is called a.root-servers.net. This name is however only used for diagnostics. Secondly, nstld@verisign-grs.com is the email address of the zone maintainer. Note that the @ is replaced by a dot. Specifically, if the email address had been nstld.maintainer@verisign-grs.com, this would have been stored as nstld\\.maintainer.verisign-grs.com，This name would then still be 3 labels long, but the first one has a dot in it. The following field, 2018032802, is a serial number. Quite often, but by all means not always, this is a date in proper order (YYYYMMDD), followed by two digits indicating updates over the day. This serial number is used for replication purposes, as are the following 3 numbers. Zones are hosted on 'masters`. Meanwhile, 'slave' servers poll the master for updates, and pull down a new zone if they see new contents, as noted by an increase in serial number. The numbers 1800 and 900 describe how often a zone should be checked for updates (twice an hour), and that if an update check fails it should be repeated after 900 seconds. Finally, 604800 says that if a master server was unreachable for over a week, the zone should be deleted from the slave. This is not a popular feature. The final number, 86400, denotes that if a response says a name or RRSET does not exist, it will continue to not exist for the next day, and that this knowledge may be cached. 所以 1、邮箱的格式要注意 识别不了的时候 \\.的写法 2、时间默认单位是s秒 3、Finally, 604800 says that if a master server was unreachable for over a week, the zone should be deleted from the slave. This is not a popular feature.这句话是说①这是在从服务器上起作用的配置，从服务器判断master不可达持续一定时间后，就将zone删除，是从服务器上删除zone，也就是从自行惭愧了，知道自己差了很久，补提供该方面的服务了②这个功能不受欢迎，很简单啊，master虽然从服务器不可达了，其实大概率就是master挂了，从服务器又不提供服务，那网络里dns一个都没了，喜欢才怪。 4、最后的minimum时间早期是没有定义TTL的时候就用来做默认的TTL，有了$TTL就在BIND9版本里作为新的功能了--NAME ERROR = NXDOMAIN 就是上游dns的response 说不存在，则本地缓存 这个判断 的持续时间。在此时间段里用户请求该域名就直接用缓存回给用户。 5、TTL的作用看来就不是仅仅本地RR，理应包括response 的来的RR。我再去确认， TTL in the DNS context defines the duration in seconds that the record may be cached by any resolver. https://powerdns.org/hello-dns/basic.md.html这里点击 所以没找到 针对本地RR这种说法，所我有理由认为就是所有得有结果得解析记录，后面敲实验的时候验证下就好赖，有啥难的，不查了。 还是这篇就不错https://www.zytrax.com/books/dns/ch8/soa.html 点进去就知道缓存RR超时时间的前生今世了https://www.zytrax.com/books/dns/apa/ttl.html 其中Note: RFC 1912 cautions that 0 = no caching may not be widely supported, however most modern DNS software does support the feature. ，我学这个bind本意就是用来做DNS的请求的负载均衡将奇数偶数分担到10.2和10.3，所以肯定是可以设置为0的，因为10.2 和10.3上就有缓存。不过bind有缓存好像也不影响结果。 然后In BIND 8 the SOA record (minimum parameter) was used to define the zone default TTL value. In BIND 9 the SOA 'minimum' parameter is used as the negative (NXDOMAIN) caching time (defined in RFC 2308).这就是前生今世拉 设置的频率也是一个学问RFC 1912 recommends that the $TTL value be set to 1 day or longer and that certain RRs which rarely change, such as the MX records for the domain, use an explicit TTL value to set even longer values such as 2 to 3 weeks. The value of any TTL is a balance between how frequently you think the DNS records will change vs load on the DNS server. 操作细节In most cases this will not be a problem since IP address changes are normally planned in advance, in which case in advance of the change process the TTL could be reduced to 3h to 12h and then restored to a higher value when the change has stabilized. 然后DNS最长缓存时间是68年The TTL field is defined to be an unsigned 32 bit value with a valid range from 0 to 2147483647 (clarified in RFC 2181) - which is a long time! - somewhere on the other side of 68 years. 看来首位置为0了。 想看再看吧https://www.zytrax.com/books/dns/info/ttl.html 关于www，往往不是A记录，而是CNAME(别名)做CDN这是比较常见的，当然你也可以直接A记录，个人网站其实也有CF的免费CDN也是用CNAME咯。所以除非你不懂，否则还真是用别名，不用A记录。 还是dig看着最舒服，它能够标注出来CNAME，不过host和nlsookup其实也是明确的，要注意它的排版格式就能识别谁CNAME到谁了。 配置CNAME多个看看： 上图的3H更正为：代理查询 没查到 这么一个没查到的结果 缓存的时间。 编辑bind配置文件 不过一般不推荐在这个主配置文件里这么直接加，可以指一个目录，然后统一放在那里，这是常规宇宙法则，其实就是上图倒数第二行的文件，就是统一放区域rr记录文件的。 这里才是专门放区域文件的地方，所以修改一下 至此，该有的配置就配置完了， 1、语法检查：named-checkconf named-checkzone 检查配置文件的命令，也只能检测配置文件，它不能检查数据库文件也就是rr记录文件 检测区域数据的命令： OK就是成功拉，loaded serial 0就是版本号0的意思。 这是报错👇 所以不管最大多少，人家推荐的是 年月日nn nn是当天修订的次数。 验证一下，果然4294967295 是最大值，就是32位，4个Byte的空间。其实你要有这个思路，就是 凡是计算机里的最大值都是几个BYTE空间得出来的。比如IP报文里的 首部长度也是4个B。要知道2^32已经很大了。 2、重新加载配置文件：rndc reload 此时解析就OK 注意区别， 我的测试有点小问题，不递归去问上游dns了，也就是默认的13个根了 开启海外网络，本地dig就成功了，毛仔细看下图 ask的是192.168.10.2. 还是不行，dns server的firewalld和selinux都关掉还是不行，明天再看吧 奇怪了 不过firewalld确实也造成了故障 就是不递归了，下班下班，回去睡觉 好了，好像还是selinux没有disabled之前是permissive，反正今天过来一开始还是老样子，防火墙，selinux，重启linux，就没有啥其他动作了。无非时各种dig，顺带把windows的dig和tcping工具给完善和一下 奇怪的一点时，我怎么查dig都看不到AUTHORITY权威DNS服务器了 以上就完成了主dns的简单搭建 dig的用法 此外还有 从服务器、反向解析、智能DNS、CDN、DNS委托 下一节继续 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-02-20 10:08:36 "},"22-DNS服务和BIND/4-实现反向区域和主从复制服务.html":{"url":"22-DNS服务和BIND/4-实现反向区域和主从复制服务.html","title":"第4节 实现反向区域和主从复制服务","keywords":"","body":"第4节. 实现反向区域和主从复制服务 PRT是独立了存放的数据 发邮件的时候可能需要PTR反向解析 1、当你发送邮件到达对方邮件服务器的时候， 2、对方邮件服务器就会将发送方的IP地址方向解析成域名，如果该域名和发件人的邮箱后缀不一致，则认为是垃圾邮件。 3、就是防止对方冒充一些合法域名发送邮件咯。这个不一定通过IP，通过邮件的源码好像也能判断。 TXT记录的用在： 1、SPF反垃圾邮件记录 2、HTTPS验证记录 示例：_dnsauth TXT 2022122200000051qgs71beoh5h6wht4n1h0lr021x 厂家提供的字符串 搭建反向DNS 主dns里定义了专门用来存放区域信息的路径： include \"/etc/named.rfc1912.zones\"; 解决wwww.oneyearice.aisa的问题 * （泛域名解析）可以CNAME过去，泛域名解析是垫底的策略，类似路由表，也是最长匹配。与zone数据文件里的记录 顺序无关。 泛域名不能覆盖@功能，就是说*.xx.com 不能覆盖xx.com的解析。 @ 阿里云上可以CNAME，bind配置里不能CNAME，奇怪 rndc flush清缓存 rr的批量简化写法： $GENERATE 1-254 HOST$ IN A 1.2.3.$ 代表了: HOST1.@解析到1.2.3.1 HOST2.@解析到1.2.3.2 ... ... HOST254.@解析到1.2.3.254 开始做反向解析 开始创建 如果是192.168.10.0段的PRT就是协亨 zone \"10.168.192.in-addr.arpa\" { ​ type master; ​ file \"192.168.10.zone\" # 这里知识文件名称，无需倒着写。 }; 创建完后，检查、加载 看下面这张图 简写，的自动补全，存在冲突，也就是说SOA里的master主域写的ns1.oneyearice.asia.其实还依赖于正向解析咯。邮件当然得使用正向解析，否则admin.10.in-addr.arpa.也不是邮箱地址。 看来确实无关功能，解析拿不到的时候倒是可以看到SOA记录，这里其实理解错误，下文有讲。 -x的简化 看看老师的写法 他的图里有ns1记录的，可以看到其实也不涉及SOA里的 所谓的 主域名 ，ns记录的补齐也是补的ptr域。 从DNS服务器 直接克隆一台出来，改一下IP地址 1、zone区域配置得类型得改一下 这个zone的数据文件，其实不需要手动创建 重启服务就可以自动同步了。注意，上图的/var/named/下的oneyearice.asia.zone和10.zone都是克隆过来的，不要管他，要看zone配置的指向路径里的文件--也就是/var/named/slaves下面当前为空， 上图有错误一大堆👆 上图的file名字最好也加上.slave后缀，看起来舒服些。 然后这是一些报错，备忘放在这里了： 使用named-check查看，要改成masters才行： 配置都OK了，但是重启服务，没有同步自动生成zone文件，systemctl status 发现是主拒绝53，基本就是服务没启动了，上文都关掉了firewalld和selinux了。 开启主的named服务后，重启从的named，zone数据自动同步创建了。 不过同步过来都变成了data文件，cat也看不了 好像就是centos7开始这样的，看不了了，以前是纯文本。 这样的好处就是从不能编辑修改，从就是得从主上面拿东西。 到这里，从服务器的解析也就正常了 三个PRT好了👆，然后正向的再看看 考察下主从同步机制 版本号是和自己的上一次比较的。 推和拉都要版本号发生递增，所谓递增就是主自己看自己和上一次相比增加了，否则无法同步，不管推还是拉。 保存，rndc reload 重新加载，主也 不会push过去，从get拉也没到3小时呢。 所以当前还是无法立马同步，从那边是配置了masters的，所以等3H，也就能同步，但是想要主推过去，就得让主知道谁是从服务，当前它还不知道谁是从呢。 利用ns记录来告诉master谁是从 所以学到这SOA记录里的主域名就很有意义咯，就不是上文说的没有功能咯。 这样就OK啦，从就同步了 然后nslookup看看 可以了，从拉的时间也没那么及时，我测试在2分钟左右能拉好 安全性问题 上文中可见，从服务器的配置，只要指明master就可以实现数据的同步了，只要主的版本号递增，就能get也好，push也罢，都能拿到数据了。主上面没有做验证措施。 其实也还好，就算有人自己搭一个从服务器，拉取数据下来，他看不清除，因为file是data数据库文件。 此外还有一个安全性问题，就是能够拉取对应域的所有信息： dig -t axfr oneyearice.asia @192.168.126.129 对比公网人家的dns，肯定做了安全措施了 此时axfr就抓不到了，因为129上做了白名单👇 进一步防止到\"从服务器\"上抓取。 好了，主从就OK了， client端就可以配置2个dns服务器了 windows和linux的两个dns服务器的优先级 需要研究下 总之最基础的来讲，就是主dns挂了down机了，从dns就生效了。 两个都down了，windows有缓存，linux无client端缓存。 主从切换OK，这个其实是依赖于client系统的一个自行判断。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-02-20 21:00:30 "},"22-DNS服务和BIND/5-实现DNS子域委派和转发.html":{"url":"22-DNS服务和BIND/5-实现DNS子域委派和转发.html","title":"第5节 实现DNS子域委派和转发","keywords":"","body":"第5节. 实现DNS子域委派和转发 oneyearice算作父域，bejing、shanghai是子域， 1、如果父域和子域在一个机器上 shanghai.oneyearice.asia和oneyearice.asia放在同一台电脑上 根据前面章节学的内容，也就是一条A记录的事 www.shanghai A 192.168.100.100 这样虽然有www.shanghai.oneyearice.aisa的解析看着有一个shanghai的子域，但是其实只是条A记录。 如果shanghai这个子域里的记录比较多，是可以独立出来成为单独的配置文件的。 比如 ftp.shanghai. db.shanghai. mysql.shanghai. mail.shanghai. 管理上父域和子域属于集团不同部门或者子公司的权限下发，就需要独立开来。 独立出来就很简单，cp -a 一份出来 改改就行 修改一下zone域配置文件。然后这里有个快捷键挺好玩的，👇记一下可以。 虽然说是父子域，但是从配置角度上来讲，就是两个独立的zone。 这样父子域 还在同一个设备，从管理角度上还没有完全分开。除非你用facl去管理权限？ 最好分开来合乎管理，下面就是学习 父子不在一起的场景。 2、如果父域和子域在不同机器上 其实就是子域委派，感觉就是NS写一下就好了，之前freenom里就这么写的。 上图有问题写错文件了，应该写道oneyearice.asia.zone这个父域文件里的NS记录，然后这个shanghai.oneyearice.aisa.zone的子域文件就可以删除了。 修改一下： 1、删除zone 配置文件 2、删掉对应的zone file记录文件 3、修改添加一条父域里，关于子域shanghai的NS记录，指向对应的服务器，这里就简单点，直接利用从了。之前从服务器，已经同步了主之前还有的shanghai.oneyearice.asia.zone子域记录文件了(文中未体现，其实就是在从那边配置了一个zone type slave并指明master，然后重启从的服务就拿到了。)，所以此时就可以解析了 必须重启192.168.126.129这个主域上的named才能看到现象，因为有缓存的。 还原 不行还是， 重启服务试试 还是不行，会卡在这里 过一会就 找到原因了 可以了👆 补充： 每次修改主DNS的zone记录的时候，一定要记得递增版本号。 NS在很多地方都有看到，这是阿里的关于子域的NS 腾讯上看看 还挺多，功能 不过我记得有oneyearice.asia这种一级域名的NS修改的，现在没找到。。。 还是说必须是www.oneyearice.asia这种，这种倒是直接就能写。 如果是新开一台干净的机器来做子域， 直接上图了，就这么着吧： 然后人家的报错 然后他就改了下图两项为no 然后就神奇的好了。反正我没改也成功，不过我的子域委派的那台其实是从啦，和他在这点上不一样。 我要新建一台试试了，NND 去到父域上修改ns记录👇 上图说明缓存没清除。 systemctl restart named就行，或者用rndc flush 这不好了嘛，也没有修改那两项啊，父域和子域dns服务器上都没有修改啊。 注意缓存一直在，比如你现在修改子域的A记录为，加一条 然后子域DNS上reload 此时client dig结果不会变的 因为你问的还是父域，父域回你还是TTL时间内的缓存给你的，所以要flush一下 好啦。 dig -t NS查看NS 腾讯还不显示，直接自己查 qq的ns 根的 上图ns1是master，其他都是slave；同样可见版本号就很大了，也不是以年月日NO来编写的。 阿里还不错，按官方推荐来编写的版本号 以上就完成了子域创建和委派， 然后研究下53端口的tcp和udp的情况 先上结论，client查询一般就是udp 53，子域委派也就是域间也是只有UDP53；主从复制的时候是TCP53和UDP53都有。 当前client 去问 子域的www.shanghai.oneyearice.asia的解析情况，这样涉及父域和子域的情况，用iptables进行查看 1、打开firewalld 2、放行udp 53 3、OK 说明client和dns server只需要UDP 53， 4、进一步研究父域和子域之间的53 去子域开启firewalld 清父域的缓存 报错 5、打开子域的tcp 53 测试 依然不行， 查看firewall的抓包记录看是否命中TCP 53 https://developer.aliyun.com/article/1100649 https://www.onitroad.com/jc/linux/sec/firewall/firewalld-log.html 明确可见udp 53被拒了，但是tcp 53 没看到，所以 6、子域firewall改放行UDP 53 tcp干掉。 测试，竟然就可以了 只需要UDP53，啊哈哈 记得client 上一次解析成功了，要去父域上flush缓存的 这个firewall不像iptables可以看到命中报文，有点不爽，估计是有其他方法我没找到。 然后考察主从复制的53是哪种L4协议 去从服务器上 将日志挂在那，然后去主上编辑一下，记得修改版本号 1、只是修改了master的版本号 2、然后看到从服务器有拒绝日志 说明UDP53存在 3、继续修改master的记录+调大版本号 依然只有UDP 53 未见TCP53 放行防火墙的UDP53，同时用户解析也需要UDP的 client去dig下 发现named没开 开了，也要同步一下 从服务器上还是没有同步 看看日志 这里就看到日志，但是不清楚是 要主的TCP53还是从的TCP53 1、放行从的TCP 53看看，虽然我觉得是from 129嘛应该是主的TCP，但是，就像小学老师说的，我这个人明知的情况下就爱绕路 然后我就去主上放行了tcp 53 ，啊哈哈哈哈~ 等等，看看之前没同步的，能否再retry 坐等10分钟，不管是从服务来啦，还是10M重试，都差不多了，15分钟吧 要是不成功，这个版本号就太讨厌了。 可以了，看来它还是知道这个同步没成功，会拉也好，会重试也好，这个点需要继续验证的，否则业务处理故障会模糊的。 结论：主从：①从服务器需要访问主的tcp53和udp53；②主服务器需要访问从的udp53。 进一步测试 看来从服务器需要访问主的tcp和udp 53，都要访问的 从上的日志倒没有具体的UDP 和TCP的 字眼 放开主的tcp 上图没有提示了--在从服务器上，说明从服务器的消息是TCP的，正所谓TCP才会有一些完善的报错回显，可靠啊，而UDP正应了那句话，丢了就丢了。 坐等同步，因为此时从服务器上的版本号肯定是低的，因为之前没同步过去啊。 1M？还是10M，哈哈，有懵逼了，应该是1M没成功啊，刚才firewall调整的1M的拉肯定失败，不过1M不是周期的嘛，1M也应该重新拉了啊， 反正之前失败1M周期到了没有拉--从没有拉 然后等10M再看吧， 我就不加版本号。 👇有了大概过了也不到10分钟 最新的两个A记录都过来了 所以验证完毕 主要放开的 从要放开的 UDP要放开的原因，是同步之前需要有查询的动作，而查询就是和client去查询一样了，就是依靠UDP53。 确定了不一样之后，再利用TCP53去同步传递文件。--据说是这样，应该是正确的。 验证 动作1、在master上只修改版本号后rndc reload，也不用加rr，然后看提前挂载那边的tcpdump就能看见 ①先是udp，②后是tcp，前四行就是主获取从的全部记录，从获取主的全部记录，类似dig -t axfr 其实在message里有同步日志的：AXFR-style IXFR started AXFR就是ALL完全RR，IXFR就是增量 卧槽，还是明文的，我的乖乖，不小心被我发现一个漏洞。 总之 主从两头开抓包，效果杠杠的，记得带上v，vv就算了 tcpdump -v -nn -i eth0 host masterIP and slaveIP |grep -E '.53' 一下是一次完成记录 第二次的交互如下，明显比第一次要多，但是不要怀疑，第一次的解析确实同步了--虽然没有看到rr明细的传递，但是我再次测试dig 是确实过去了，而且，两次为一组，第一次抓包条目少，第二次多很多，不细究了。 然后是从上面 关于同步的进一步研究 动作1、仅修改zone 数据文件的RR --->修改zone 数据文件的RR， 但是不改版本号， 也不rndc reload ， 也不重启服务 坐等5Mins 时间还是在变，但是解析就是没过来 当然master上由于没有rncd reload所以也无法正确解析 动作2、master上rndc reload 完整的条件就变成了 ============= --->修改zone 数据文件的RR， 但是不改版本号， ---> rndc reload ， 也不重启服务 ============== master 自然更新了 10分钟过去了，还是没有更新，虽然文件的时间在变 动作3、master上修改版本号 完整的条件就变成了 ============= --->修改zone 数据文件， --->修改改版本号， 不做rndc reload ， 也不重启服务 ============== 从依然没有更新 重启从服务的named也没用 动作4、master上rndc reload 完整的条件就变成了 ============= --->修改zone 数据文件的RR， --->修改版本号， --->rndc reload ， 也不重启服务 ============== 秒同步 结论：不管是推还是拉，都需要2个动作： ①版本号增加↑②reload(重启服务自然也行咯)，至于你改不改RR，哈哈，无所谓反正2个必须要有。不改你也看不出来哈哈。 rndc工具介绍 上图可见query loggin is OFF 意味着查询日志没有开启 rndc querylog即可开启 这是临时开启，测试用 下面开始讲转发，也就是我要学bind的直接目的，不知道能否满足我啊，我可是要奇偶分开转发的哦，不行只能去研究nginx了，都一样，巴不得不行，正好跳到ningx，否则就慢慢腾腾的学了又，哈哈哈 转发听起来有点像NS哦，有点像子域委派，都是请求的转发出去，接着往下看，去看大腿 1、首先不要像也知道，子域委派--指的是 域相关的 请求 转移 2、而转发，必然是针对的请求，去做转移，而不再受限于 本域下的子域去NS，而是针对请求全面的细化的 转移。 1、本地的直接dns服务器，不能访问互联网，所以需要转发 类似案例如下 如果上海、成都的分公司机器的dns请求都从专线 去 问北京的DNS server，就很费专线带宽啦。 此时分公司的dns server可以搭建起来，只要请求过后就有缓存了，可以大大节省带宽 1、此处我用了大大，因为我在推销这种架构 2、不要听信我说的，以为缓存过期后，一样会请求出去，这个时候就有一个矛盾，缓存多久比价好， 3、1D还是1H，假设1H的$TTL，那么1小时候就会产生一波DNS 请求高潮，怎么地~语文老师教的好，所以1D的TTL是比较合适的， 以下👇4 、5 两点理解错误，主从，什么是主从，是针对本地的rr进行同步的，现在讨论的架构哪来的主从模式！ 都是针对互联网上的域名请求，北京本地没有记录，三地都是缓存，都是只缓存服务器啊，同步个啥哦！ 4、其实针对这个架构，我倒是希望北京是master，分公司部署从，这样分公司的请求压根不会到master上去，直接去本地的从就行了，DNS的流量也就是区域间的同步流量啦， 5、此时考虑的问题就变成了同步流量是否很大的问题，而同步 push势必频繁的，改一个就会推一个，pull也是希望能及时处理的，所以此时我想的这个架构就不合适哦，还是希望分公司为转发+缓存的模式 建立主从的概念，前提是你个有本地记录的服务器--区域数据库-区域数据都在互联网上呢，而现在讨论的必然是互联网上的请求，你只是个只缓存服务器。加上北京的说我确实有本地解析，那么4、5的分析就可以i上啦。结论也是 主从可能也不能这么玩。 6、抽象出来一个解决思路--宇宙法则之--专线+缓存才是王道，就是说如何节省专线带宽，主说：缓存。其实SDWAN的2个核心①选路②去重③缓存。 7、其实回过头来，看分公司的dns 缓存，我是这么想的，缓存为1万年，如果rr变了，就重新问一下这个记录，去覆盖老的缓存。这就是老话讲的好--爱你一万年。那怎么才能爱你就1年呢，就是分公司的dns请求AXFR的时候啊，不要请求具体内容，就是请求①整体rr的哈希②每条rr的哈希③哈希要短一点④cisco安全里讲过要给技巧就是将一些值也就是哈希放到报文结构里好像是tcp的seqnumber？ 8、分公司的用户访问xx.yy.zz，此时三地的DNS上就都有缓存了 然后我又继续往下看，发现这个转发不是我之前搜到的bind的view，view看这里就挺香的 https://blog.51cto.com/360admin/677254 然后man named.conf可见view有通配符字眼，一开始我搜regex没有心都凉了 可能是支持通配符的，下午研究研究 貌似他不支持通配符啊，下午敲一敲。 思路如上，正则我要改成这样，这样比对起来也会快很多。 算了，咱继续把转发学玩吧~ 由于都是中间间隔，的所以难免回不到之前的状态，也记不住，总之遇到问题就去查好了~ 用这台130进行转发，所以删除GW后，重启named，等价于缓存没了应该把，不放行再rndc flush 此时解析不成功 看见他是问根去了，所以看看zone的配置，是否有本地的区域数据 他是slave，那也不影响啊 哦，我知道了slave有一个自行惭愧的机制， 由于看不到data格式的内容，我要看soa信息，看下自行惭愧的时间是多少 dig 去看就好了 只能去主上面看了 查下这个 主的namde开机就没enable 还是报错是根的可达性 确实不通，不通你就不给client dns响应？不应该啊，本地有区域数据库的啊 这两个选项开了，dig 发现要等几秒钟才会有结果，然后就是SERVERFAIL。 这两个选项关掉，dig就发现秒出结果，但是是REFUSE，如下图， 感觉还是根的问题，奇怪了 哦，原来是我打错字了，asia不是aisa，唉，要注意睡眠了 其实都是好的 继续做转发实验 关闭192.168.126.130的网关， 哈哈 重启恢复继续 此时130变成 无法访问互联网了，当然可能涉及海外的根需要通的哦，呵呵 删默认之前OK的 此时130 需要转发请求给129去处理，发现最好还是关掉sec选项 让130转发到129 就好啦，与其好，sec也没关 然后 这样两台针对www.bing.com的只缓存dns就都没有缓存了，也无法访问互联网了 此时 然后将only改成first 敲了两次OK了 所以sec应该最好关掉。 配置就这一点点 ZONE特定区域转发 1、此情况 也就是说，130 only 到 129，129没有GW，缓存清空，自然解析不出来了 2、129打开GW 好了 3、将bing.com在zone里去转发 所以zone 指定了域名的转发，抢先了 比option里的先，127.0.0.1不变，本地GW打开 127.0.0.1不行？改成 好了 但是 说来也奇怪，nslookup 127.0.0.1也不行--当 zone里转发写成127.0.0.1的时候，转发不写127或者自己IP就没问题 问为什么写成 非自己就可以了？写自己就不行 1、自己问自己，不让这种写法，我初步判断，自己问自己，你就用first 不要用only 2、写非自己的IP，可以的原因，是比如192.168.126.131不可达，于是用了option里的转发配置到192.168.126.129了，此时你把129的named关掉就没啦。然后再把129的named开启，又可以了。 继续关掉129的named，让他ng，该130的first 不行，必须去改option全局里的转发方式为first才行。 所以我不清楚zone和option里的forward first 是怎么一个逻辑。 我如果设计的话 1、zone里的优先：forwarders的IP比全局里的优先 2、如果zone里的转发ip 失败，是不是就直接用本地出去问呢，不是还有全局的转发，要去问全局的。 3、然后全局里的转发IP失败，再回来看zone里的是不是又first 所以此时改一下测试 然后129 关闭129的named，然后130的flush 解析NG 然后开启130的GW 就好了 看来zone里的only没生效，我估计zone里的forward first|only 不生效！ BIND9的VIEW也是转发 直接上需求，将奇数IP的dns请求转发到10.3，偶数的转发给10.2 开搞，搞不了，BIND view里的acl不支持正则，思路换到智能DNS里吧。看看那篇有什么新的东西，至少常见的基于ISP的归属地的，各种智能DNS不都在商用吗，我不信一个奇偶数还不能做出来了， 当然这里的VIEW也能做，就是把acl add_ips和acl eve_ips里写满所有的私网网段的奇数，和偶数。当然eve_ips可以! add_ips 直接取反。 acl odd_ips { # 匹配奇数IP地址 !acl even_ips; }; 1、配置主备好 vim /etc/named.conf ------------------------------ acl odd_ips { stdlib.regex(\"/(\\d{1,3}\\.){3}\\d{0,2}[13579]/\"); # 可惜这种chatGPT的一厢情愿，然而BIND并不支持 }; acl even_ips { stdlib.regex(\"/(\\d{1,3}\\.){3}\\d{0,2}[02468]/\"); }; view \"odd_ips\" { match-clients { odd_ips; }; match-destinations { any; }; recursion yes; forwarders { 192.168.126.129; } }; view \"even_ips\" { match-clients { even_ips; }; forwarders { 192.168.126.130; } }; 毛啊~更不不支持regex，唯一找到的信息是bind的一条漏洞 https://www.tenable.com/plugins/nessus/65736 这里支持这种，这是zone数据库里支持的写法 就是不支持regex https://serverfault.com/questions/133707/is-it-possible-to-have-regular-expression-cname-record-in-dns Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-02-24 13:16:44 "},"22-DNS服务和BIND/6-CDN和GSLB工作原理及智能DNS实现.html":{"url":"22-DNS服务和BIND/6-CDN和GSLB工作原理及智能DNS实现.html","title":"第6节 CDN和GSLB工作原理及智能DNS实现","keywords":"","body":"第6节. CDN和GSLB工作原理及智能DNS实现 1、CDN 开局一张图，后面接着编..........................................................................................................................................写 请把CMD里的dig CNAME的信息画到上面的逻辑交互图上去，你就会发现，早期的图里有一个错误 而现在的文档，语文老师估计水平也不行 1、站在用户角度来讲(其实我不喜欢这里我的用词)，应该改成用户请求域名的IP地址，从浏览器打开www.bing.com，F12可见，或者ping www.bing.com 可见就是一个IP啊，只不过dig nlsookup给你看到了交互的信息。 那么为什么cmd里可以看到 LOCAL DNS处理的CNAME呢，用户只有1 6 7 8 理论上用户不知道中间的CNAME啊， 那么肯定是7的内容里带上了2 3 4 5 记录，但是不全，因为你看不到DNS调度系统的IP地址， 难不成是这个NS？ 这个ns应该不是dns调度系统的IP。而作为LOCALDNS一定是知道调度系统的IP的，但是cmd里看不到，说明CMD的信息是报文里携带得到的。 正儿八经CMD里的信息，终端使用的其实就一个第一个问的域名得到的IP地址。 这话也不对，LOCAL DNS他应该不是指的企业内部的，而是ISP的或者是223，114这些公共的LOCAL DNS也就是网卡上能配上去的。这点不纠结，算他没毛病。然后LOCAL DNS请求的看来不是13个根，而是直接抵达权威DNS，这点就和我之前理解的少了很多，我理解是迭代那套，想想也对，LOCAL DNS不可能每次都去国外13个根绕一圈，所以LOCAL DNS肯定直接问的权威--也就是你自己发布的解析--在哪里配置的就是哪里。 所以： 1、CNAME一条记录里就有了两个信息，①LOCAL DNS 询问对象--阿里的DNS调度系统；②LOCAL DNS询问内容--CNAME的域名。 2、而常规的DNS迭代查询，LOCAL DNS询问对象都是固定的，比如先问根，根说你去找.com，.com说你去找bing.com，这一套的①询问对象迭代出来的②询问内容就是域名啦，这两个信息是分开来的。 ​ 就是CNAME里询问，你看不到权威DNS说LOCAL DNS你去DNS调度系统，没有这个独立的动作，它是直接给你一个CNAME，比如cn-bing-com.cn.a-0001.a-msedge.net. 这个就明确的说明了是谁谁谁的调度系统，已经要问这个调度系统的域名(CNAME本身就是一个域名) 废话--就是常规的套路--拿到cn-bing-com.cn.a-0001.a-msedge.net.后，就会找.a-0001.a-msedge.net. 而这个域里自然有智能调度出来的cn-bing-com.cn.a-0001.a-msedge.net. 的IP地址。 3、实际操作LOCALDNS猜测可能直接询问权威。 GLSB 图片还是两家都更新了，^_^；阿里的风格变了，立项了？可能，腾讯基本没变。不过隐藏了GLSB关键信息。 关于\"DNS的调度系统\"，这里弱化为BIND的智能DNS，其中就涉及VIEW和ACL的使用 题外话：acl：路由器交换机里的acl、linux文件的fileacl、还有这里的dns的acl；其实acl叫access list，所以都是过滤而已。 实验-智能DNS 然后创建ACL 推荐写到named.conf的options之前，便于后面调用，匹配是顺序匹配的，所以小网段写到前面。 编写view 写了view后zone文件就都得放入view视图里， 1、将文尾的include \"/etc/named.rfc1912.zones.bj文件放入view里，并分别命令区分，稍后要创建这些文件。 2、将原先的根域的配置段👇删除后，合并到上面view里的各个zone文件里。 zone \".\" IN { type hint; file \"named.ca\"; }; +易犯错误1>> acl名称这里调用别写错，复制过来 创建编写好各个view指向的zones配置文件 [root@django001 ~]# cp -a /etc/named.rfc1912.zones /etc/named.rfc1912.zones.bj [root@django001 ~]# cp -a /etc/named.rfc1912.zones /etc/named.rfc1912.zones.sh +易犯错误2>> view里的include的文件路径和名称对应的文件要创建好， +易犯错误3>> 对应的zone定义文件的权限也要注意 将根的zone配置段，从/etc/named.conf里复制进这些区域文件 y 思考，zone里的顺序问题，恩，思考，先把上面的other后面的;分号补上。 +易犯错误4>> 格式要注意，分号会频繁出现，类似 python里的并发args传参的写法，最后一个参数也要后跟一个分号。 创建编写好各个zone数据库文件 +易犯错误5>>注意zone数据文件通常是vim直接创建，所以权限必然不对，需要改。 奇怪了，不奇怪！因为配置文件里没有语法错误，知识named.conf的VIEW里的路径---zone定义文件的路径----zone数据库文件名称，没有对应上。 哪里没有终结，代码块的东西 奇怪 发现named.conf里写的名字不对 反正各种名称路径写错，真TM操蛋 又把asia写成了aisa。 测试下 这个是外面宿主机直接cmd 去dig的，源IP为192.168.126.1，命中的acl是othernet： 192.168.126.131命中acl shanghai，通过zone配置文件指向到了 zone数据库结果正确 再来看192.168.126.130，发现有点问题 排错1： 排错2： 写错了，老是这样，操 OK了 这就实现了源IP地址的分流，所谓的归属地的查询--智能DNS多少就有这个影子在里面，至于是具体是不是写了很多IP段在里面就不得而知了，我尝试过acl里写正则，都失败了，也没有找到相关资料。 测试匹配次序 这样三个都是beijing acl索引过去的zone数据库文件了 汇总： 1、主配置文件 vim /etc/named.conf acl beijingnet { 192.168.126.0/24; }; acl shanghainet { 192.168.126.131; }; acl othernet { any; }; # 删除zone . IN 根的那段，将include \"/etc/named.rfc1912.zones同样删除， view view_beijing { match-clients {beijingnet;}; include \"/etc/named.rfc1912.zones.bj\"; }; view view_shanghai { match-clients {shanghainet;}; include \"/etc/named.rfc1912.zones.sh\"; }; view view_other { match-clients {othernet;}; include \"/etc/named.rfc1912.zones\"; }; 2、区域配置文件 vim /etc/named.rfc1912.zones zone \".\" IN { type hint; file \"named.ca\"; }; zone \"oneyearice.asia\" { type master; file \"oneyearice.asia.zone.other\"; }; vim /etc/named.rfc1912.zones.sh zone \".\" IN { type hint; file \"named.ca\"; }; zone \"oneyearice.asia\" { type master; file \"oneyearice.asia.zone.sh\"; }; vim /etc/named.rfc1912.zones.bj zone \".\" IN { type hint; file \"named.ca\"; }; zone \"oneyearice.asia\" { type master; file \"oneyearice.asia.zone.bj\"; }; 3、编写zone数据库文件 vim /var/named/oneyearice.asia.zone.other $TTL 86400 @ IN SOA ns1 admin ( 2023022150 1M 10M 12H 1 ) NS ns1 ns1 A 192.168.126.129 websrv A 10.2.1.100 websrv A 10.2.1.101 www CNAME websrv vim /var/named/oneyearice.asia.zone.sh $TTL 1D @ IN SOA vip1 oneyearice.126.com. ( 20220227 1H 10M 12H 1H ) NS vip1 vip1 A 192.168.126.129 www A 192.168.100.150 vim /var/named.oneyearice.asia.zone.bj $TTL 1D @ IN SOA vip1 oneyearice.126.com. ( 20220227 1H 10M 12H 1H ) NS vip1 vip1 A 192.168.126.129 www A 192.168.100.100 4、 amed-checkconf named-checkzone oneyearice.asia /var/named/oneyearice.asia.zone.other named-checkzone oneyearice.asia /var/named/oneyearice.asia.zone.bj named-checkzone oneyearice.asia /var/named/oneyearice.asia.zone.sh 同样别人的配置来一份： 学习了这个VIEW也就是智能dns，还需要再次知道一下，这东西是落在哪里的，是落在CNAME过来的DNS调度系统上的，如下图 尝试做一个完整版的， 原来的智能DNS修改一下 cnd的域名后缀修改为tbcdn.com也就是www.oneyearice.tcdn.com 而www.oneyearice就是tcdn.com的子域，可以建一个下级域 前面顶一个权威DNS NXDOMAIN就是$minum缓存时间里的查不到记录的结果，NX就是Not eXist DNS本身的负载均衡效果 这是ping 两个解析后的IP都不通，所以看不出来DNS是否有默认 健康性检查的效果，改成一个通一个不通的情况测试 发现全是129通的那个ip DNS虽然解析是由100不通的那个IP的，但是这里的ping以及包括CURL的测试，进一步包括浏览器打开都是不会负载到不通的那个IP的。 做成负载的两个IP都通的情况，测试 发现统统变成了131 改回只有一个129通 rndc reload后发现，又只有129了 再次改成都不通，又轮询负载均衡了 要查资料了 这次看到了不一样的效果，.1其实是我的宿主，通的，但是icmp被防火墙干掉了，ping是NG的。 再131上ping ，130上firewall firewall-cmd --permanent --add-icmp-block-inversion 禁掉了ping，结果还是给我一直解析的是130. ping测试负载没有健康检测，而且负载轮询不可靠 再看看http的情况 并没有负载 然后129好的130好了就抢先了， 停掉130，129就回来了，是有健康检测机制的 关于DNS的rr轮询查资料： https://blog.csdn.net/zhu_tianwei/article/details/45071085 还得看官网 https://bind9.readthedocs.io/en/v9_19_9/reference.html 1、默认行为 轮询，通过nslookup可见每次的顺序是轮询的， 通过顺序不一样，来引导客户端自己选择不同， 所以决策者还是client端。 2、人工干预 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-02-28 14:13:45 "},"22-DNS服务和BIND/7-实现internet架构和DNS服务.html":{"url":"22-DNS服务和BIND/7-实现internet架构和DNS服务.html","title":"第7节 实现internet架构和DNS服务","keywords":"","body":"第7节. 实现internet架构和DNS服务 拓扑 搭建权威dns的主从 67作为httpd server，提供一个测试页 测试OK 47上安装bind作为主MASTER 注释掉listen-和allow- 添加只允许从服务IP来抓取信息（-t axfr） 57上配置从SLAVE 同样yum -y install bind 两行注释 一行拒绝所有 zone数据库文件从上面就无需创建了，重启同步过来就行了。 测试主从解析情况 client的dns指一下主从 看下是否生效--也就是/etc/resovle.conf里自动写进入了 测试解析OK 测试主从复制 slave上文件日期已经变了 37配置成.com域 属于父域的知识应用 在zone数据库里配置子域 magedu是com的子域，被委派给了ns2和ns3，分别对应两个ip地址。 测试下，委派成功👇 27作为根 这里是自己实验里自建根，所以原来的根zone改一下 chgrp named /var/named/root.zone chmod 640 /var/named/root.zone 测试 17作为forwardDNS 修改默认的13个根的zone数据库文件 只需要写一行：27就是实验的根 测试下，失败： 关闭安全选项 然后就OK了 7作为LOCALDNS 安全关了 测试OK👇 测试curl之前改一下默认的dns OK Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-02-28 16:45:20 "},"23-MYSQL数据01/23-MYSQL数据01.html":{"url":"23-MYSQL数据01/23-MYSQL数据01.html","title":"第二十三章 MYSQL数据01","keywords":"","body":"第二十三章 MYSQL数据01 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"23-MYSQL数据01/1-数据库基础原理1.html":{"url":"23-MYSQL数据01/1-数据库基础原理1.html","title":"第1节 数据库基础原理1","keywords":"","body":"第1节. 数据库基础原理1 开局一张图： DBMS server:比如mysql-server；DBMS client：比如mysql-client tidb：天生分布式，兼容mysql，程序可能无需改动。 mysql 这些库里： 一行row就是一条记录record， 一列columm就是各种属性的数值 null表示该字段未空，没有赋值，pk主键是不能为null的 ... ... Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-03-10 09:03:27 "},"23-MYSQL数据01/2-数据库基础原理2.html":{"url":"23-MYSQL数据01/2-数据库基础原理2.html","title":"第2节 数据库基础原理2","keywords":"","body":"第2节. 数据库基础原理2 外键：一对多 上图100是外键FK，如果在外部另一张表里没找到100，就不让你添加。 一对多可以使用主外键的方式来表示出来。 多对多：第三张表 构建第三张表来实现多对多，但是第三张表里的stu_id和class_id不能是凭空写出来的，下图的200和100就不对了 所以需要使用FK外键 通过第三张表，通过主外键的关系，把原来两张表的多对多关系表达出来。 范式 一般掌握前三范式，否则范式遵循太多也会导致数据的查询麻烦。 第一范式： 下图就违反了第一范式： 1、列必须是不同类型 因为mage可能教10门课，而其他的某位老师可能就教1门课，所以其他字段在这一行就都是空。 2、列不能有多个值 可以另起一行，不过也不太好，如果mage教了10门课，mage的个人信息就会重复10行。 为了解决上述单列多个值和单人重复多行的问题，于是可以构建第二张表和第三张表。 第三张表就是FK外键使用上面两张表的PK主键就行了。 第二范式2NF， 首先2NF肯定满足1NF了 下图的PK在那个字段上都不合适，name、city都不存在唯一性 此时需要设置复合主键PK 此时code电话区号依赖于city，现在主键不是city而是name+city这个复合PK。2NF范式2就要求每列的字段也就是属性要与整个PK有直接相关性。只是和部分主键有关联，这是不符合2NF的。 怎么解决呢，方法就是把城市和区号拿出来单独列一张表。然后原表里删除code和city，改为city ID来关联。👇 现在在第一张表(左)里整个属性都是和整个复合主键直接相关的。符合了2NF第二范式。 上文是使用了复合主键来做唯一标识，还可以重新做一个主键 此时就一张表，code虽然存在多行重复出现的问题，不过code和id本身区别也不大。可以接收。 真正的问题是这就违反了3NF第三范式，当然你要是无所谓打破范式也不是不行。 3NF就是属性不能和非主键产生关系 非PK字段之间不能有从属关系 解决方法就是将从属关系的字段，独立出来一张表。 满足1NF 2NF 3NF这三个范式后的好处是数据存放紧凑，没有什么重复冗长多余的情况。 带来的负面影响就是：数据规划要花时间、查询只需要一张表就能查到了，无需跨表查询。跨表查询有一定复杂度和时间的消耗。 3个范式就是推荐建议，范式就是用来违反的，具体情况具体解决。 设计DB的一般是软件开发人员。他们来设计结构。DBA应该可以吧 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-03-13 10:24:29 "},"23-MYSQL数据01/3-mysql安装和基本使用.html":{"url":"23-MYSQL数据01/3-mysql安装和基本使用.html","title":"第3节 mysql安装和基本使用","keywords":"","body":"第3节. mysql安装和基本使用 基本概念 数据观察角度 1、物理层：这点是运维关注的，磁盘上怎么保存这些文件，将来性能更好。磁盘文件、分区、LVM、raid 2、逻辑层：数据库里存放的哪些数据，数据和数据之间的关系；表之间的关系咯，一对一，一对多，多对多。 3、视图层：用户看到的结果，比如电商网页上看到的页面上的商品价格，但是看不全，比如进货价用户必然看不到。哈哈 运维人员可能更多是关注 物理层和逻辑层，开发更多关注视图层。 ORM，对象关系模型 将面向对象的语言比如PY，和关系型数据库联系在一起 说人话就是，SQL语句你可能就是学一下，后面用python调用库去处理DB的时候都是面向对象的语句，就是比如xxx.value()，这种CLI命令行封装成了python的CLASS调用了。 Mysql安装 1、yum源安装 一般测试环境要求不高的安装方法 2、源码编译安装 3、二进制安装 企业更多是使用2、3两种方式安装 yum -y install mariadb-server rpm -ql mariadb-server 其中 /etc/my.cnf.d/mariadb-server.cnf是配置文件 /var/lib/mysql是数据库存放的路径 /usr/lib/systemd/system/mariadb.service这是服务 mariadb-server是一个单进程多线程的程序，mysql一样 花括号的就是线程 1、yum源安装特定版本 https://mariadb.org/download/?t=repo-config&d=CentOS+Stream&v=10.11&r_m=neusoft 新建repo文件，复制后，yum repolist看下 安装的时候大小写注意下 安装的默认行为，server顺带就安装client了，老的一些lib库会自动升级 rpm -ql MariaDB-server 查询注意大小写 client 包也安装好了 之前的版本 我的报错 上图报错是因为之前安装过并启动过，解决方法就是删除/var/lib/mysql文件夹，重新安装mariadb-server就好了 这样就可以了 可以做安全加固，后补 进入mysql的交互模式后的常用cli 查看帮助 查看状态 user: root@localhost mysql的用户账号是带client端主机地址的，所你同一个用户在机器A上root进来，不代表同样一个用户在机器B上root就进得来。 mysql 服务端的连接，走的是socket，一种是tcp/ip，一种是UNIX socket也就是文件形式--这种就是同一台主机上的不同进程之间通信； 现在client和server都是在一台linux上的，所以没必要走tcp/ip网络socket套接字，直接使用文件套接字就行，节省报文开销。 利用该文件实现了两个进程的通信，client和server 其实上文的mysql回车就是没有跨网络就是走的文件socket的 none就是进来的时候不在任何一个DB里的 默认安装mysql后，默认就自动创建多个数据库。 数据库的概念 和 实例instance 的概念 mysql Ver 15.1 Distrib 10.11.2-MariaDB, for Linux (x86_64) using EditLine wrapper 10.11.2就是版本，不同版本安装在同一个linux就是实例了；可以一台机器上安装多个mysql的版本，错开监听端口，这就叫多实例；一般这样用的不太多，测试环境中使用下。mysql属于比较重的应用 数据的访问压力较大，所以不会使用多实例。 这就是默认安装后生成的数据库 然后msyql这个默认的库里有哪些表 同样在cli里看 mysql是系统数据库。 用户后面自建创建的数据库，也会在/var/lib/mysql里生成自己的文件夹。 可以认为msyql里所谓数据库就是文件夹，然后在文件夹里有若干个表。 看下表的文件，每个表里有3个文件 比如视频版本里的 user.MYD就是MyISAM的引擎 user.MYI就是innoDB的引擎 现在的版本好像没有这么多引擎了 cli命令行 分为client端cli和server端cli 刚才myql进入的\\h看到的就是client命令，是没show的，show是server cli show 这个命令，client上是没有的，是client端发送给server，在server上执行的。 注意：客户端命令，只能是用mysql-cllient工具也就是mysql命令进入才会有的，换个客户端工具就没有上图这些命令。 而服务端命令，不管是什么客户端，只要能连到server上来，就能执行的。 数据库的命令和客户端的命令 表现形式上一个很大的不同，就是行尾带不带分号 server cli要求加分号 而客户端命令比如status不用加分号 然后通过show databases;可见有5个默认库，但是在/var/lib/mysql里只有4个，少了一个information_schema库文件 然后比早期版本多了一个sys库 information_schema不是磁盘文件数据库类型，是内存中的。 test 测试的，可删 performance_scheme放了数据库性能相关的数据 进一步学习如何查看当前有哪些用户， 通过上文知道在/var/lib/mysql/mysq/下面有一个user.frm表文件，可以进入数据库里查看该表内容 这个表列特别多，不可能一下都展现出来。需要赛选 不进入的查表: 进入数据库好比cd进入文件夹 其中就有user表 查看表结构和列 除了select * from user;以外还可以看有哪些列： Field就是域，就是user表的列，就是属性 Null里的NO，就是不允许为空 PRI就是主键，而且如果两个都是PRI就是复合组件，低版本的mariadb里还是看得到的 host+user组合起来成为了一个主键。 版本差异看下也 只看3个字段，的专业术语叫做投影，哈哈了解一下 所以python打开文件，读取文件，设计open，close就可能没有db来的专业方便。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-04-21 08:59:53 "},"23-MYSQL数据01/4-mysql基本使用.html":{"url":"23-MYSQL数据01/4-mysql基本使用.html","title":"第4节 mysql基本使用","keywords":"","body":"第4节. mysql基本使用 空的意思是用户名随便写，上图👆框错了哦，user为空的是最后两行，PUBLIC本身就是用户名 空用户进来的权限👆 进行安全加固 这是我之前用直接yum的mariadb，是有安全加固脚本的 但是新的mariadb版本改动了一下，👇 https://mariadb.com/kb/en/mysql_secure_installation/ 结合文章，看来软连接就是过渡一下用的，现在的新版本呢都没有mysql_secue_installation这个软连接文件了。 https://mariadb.com/kb/en/authentication-from-mariadb-104/ 文中说“Remember, the best way to keep your password safe is not to have one!” 服了U~ 回到这里学习的安全加固脚本： 跑一下 10.11版的情况 视频中的低版本👇，主要区别是swith to unix_socket authentication吧，反正上面走完root密码是不生效的，因为有插件要改一下。emm不过，人家官网说了没有密码就是最安全的密码。 脚本到这里已经起作用了，要密码登入了，当然我说的是老版本 这个centos7.localdomain是禁止root远程登入干掉的，因为它担心有人使用域名解析将cento7.localdomain解析成远端mysql的IP地址，从而使用这个hosts进来。 回到我的新版mariadb 密码已经改好了，如果非要使用root密码生效，则需要 https://blog.csdn.net/tiny_du/article/details/123924376 https://www.orcy.net.cn/1410.html 修改global_priv里的unix_socket ALTER USER root@localhost IDENTIFIED VIA mysql_native_password USING PASSWORD(\"你的密码\"); 文中的这个方法，记不清我之前是不是直接修改了global_priv里的内容。 ALTER USER root@localhost IDENTIFIED VIA mysql_native_password USING PASSWORD(\"xxxxx\"); 然后再看 我再找找文章 https://blog.whsir.com/post-6795.html 这个靠谱，在配置文件中禁用unix_socket 不过是不是可以直接修改gloabl_priv里的参数的，好像没有唉，👇官网也是这个方法： https://mariadb.com/kb/en/authentication-plugin-unix-socket/ 然后\\G的排版看下 -uroot不写也行，默认就是root，你换linux的用户，也一样，Pia!(ｏ ‵-′)ノ”(ノ﹏ 一样个毛👇 Pia!(ｏ ‵-′)ノ”(ノ﹏ mysql -uroot -pxxx -h a.b.c.d 这个是完全命令 注意-h 127.0.0.1和-h localhost不一样，前者是走的tcp/ip socket，后者是走的unix_socket文件socket 下图虽然是本地就是192.168.126.129自己登自己，但是还是判定为root@django001，解析成了hostname所以不对了。 尝试改host为192.168.126.129看看，果然被反向解析成了hostname了 GRANT ALL PRIVILEGES ON *.* TO 'root'@'192.168.126.129' IDENTIFIED BY 'Cisc0@123' WITH GRANT OPTION; 然后将192.168.126.129改成hostname也就是django001看看，不行，就是IP，虽然显示的是root@django001，但是只是反向解析的结果，只认IP。 报错的情况：update不行？ https://stackoverflow.com/questions/64841185/error-1356-hy000-view-mysql-user-references-invalid-tables-or-columns-o ALTER USER root@localhost IDENTIFIED VIA mysql_native_password USING PASSWORD(\"xxxxx\"); 或者使用SETPASSWORD https://mariadb.com/kb/en/set-password/ Example For example, if you had an entry with User and Host column values of 'bob' and '%.loc.gov', you would write the statement like this: SET PASSWORD FOR 'bob'@'%.loc.gov' = PASSWORD('newpass'); If you want to delete a password for a user, you would do: SET PASSWORD FOR 'bob'@localhost = PASSWORD(\"\"); 查看的细节 新版本就是-server，-client这种 老版本就是 这个就是client mysql-client里的mysqldump很关键 mysqladmin的用法 -？等价于--help 检测mysql服务是否正常 远程测试要密码和端口： 超时时间要设置下的 实测是2m的超时时间 调整探测时间上限方法就是--connect-timeout https://dev.mysql.com/doc/refman/8.0/en/mysqladmin.html 但是密码要想办法隐藏好，否则监控存在密码泄露风险。 关闭服务： 数据的进程，一定不要用kill来杀，一定不要！！！，杀完就可能起不来了。 改口令 以什么身份user@host 连进去的，就改的谁的密码。 还可以直接创建数据库 不进入交互式的cli方法 mysql -e \"show databases\" mysql进入是交互模式，也就是有标准输入的，所以重定向文件内容进去就行了 表格式没了 mysqld_safe 是mysqld的父进程，上图是通过ps auxf看的 pstree -p可见 新版本没有这个safe父进程了 进程是以mysql这个用户运行的。 而该用户是安装程序的时候脚本创建的。 后面源码编译，二进制安装的时候，需要手动创建用户 多实例，也可以同一个版本来做 rpm -ql MariaDB-server可见 端口错开，用户透明，测试环境用 用户账号 _就是等价于regex里的?，可能吧 疑问：172.16.%.%，%匹配任意长度字符，那为啥不写成172.16.% 修改mysql交互模式的提示符 man手册里看 进到/etc/my.conf.d下面，可以看到client.cnf和mysql-clients.conf等文件 打开mysql-clients.conf进行编辑 生效👇 数据库的路径，可以改成LVM里，优点就是可以伸缩空间。 上图还有socket文件的路径，就是mysql -uroot -pxxx 回车走的文件socket 这是日志，进程ID文件 自动补齐 看到没有带任何默认值👇 修改一个选项，然后看下 说明还是可以补的，好吧， 如果源码安装，将来上文提到的路径，就需要自己定义了，包括 1、socket路径 2、数据库路径 3、log日志路径 等 直接连进数据库 -D 可省略 -C 压缩可节省带宽 -e 上文讲过了 -V 版本 -v 明细 上文也做个实验了，127.0.0.1不是走的unix sock而是走的TCP/IP 查看当前用户👇 查看当前版本 注意哦，我这是自己的10.11和视频的5.5混着截图了，意思到了就行 大小写-库名、表名区分大小写，命令和字段不区分大小写 命令不区分大小写 数据名称区分大小写 表名大小写敏感 表里字段也就是列属性不区分大小写 推荐SELECT这种命令也是大写 删库的方式又增加了 配置文件也可以合在一起 通过名称区分 这些配置内容的格式就是上图说的 parameter = value 而value的启用和禁用，又可以有1 ON TRUE等写法如上图所示。 如图配置文件里是不区分_和-的 配置文件路径 优先级上图的从上往下，但是不同的安装方式，优先级的结论不同 不要可以记这些，就是实际使用，配置文件就放一个地方，避免混淆。 维护模式 上图=1可以省略不写，就是=1了 skip-networking=1就关闭了3306，相当于维护模式，外界就连不进来了。 vim /etc/my.conf 再看下端口号就不在了 但是自己可以连 因为走的是unix_socket 配一个配置文件路径 /etc/mysql这个路劲是默认没有的，没有就创建一个 和刚才的配置相反了 重启服务看下 说明/etc/my.cnf是优于/etc/mysql/my.cnf的 二进制安装 二进制安装，配置文件/etc下的XX、用户账号、DB文件 都没有 指定了家目录，就是用来放DB文件的，而/data将来推荐做成LVM 同样的所有者和所有组参考原来的DB文件设置下 文件名有linux字样的的就是二进制的包，大小也不一样，二进制的编译后的肯定大很多。 注意，有个安装路径是固定的，人家编译成二进制的时候就写死了 /usr/local要手动补上的，当初人家configure 编译的时候指定的类路径。 /usr/local/mysql就是当初人家编译的时候指定的路径 这里就是一些mysql的程序 配置文件 二进制安装后有一个模板my-large.cnf复制过来用，然后为了不和/etc/my.cnf冲突，就另起炉灶放到新建的/etc/mysql文件夹下 这就是计划数据的路径，下两行再说是优化的 二进制安装后DB文件时空的，需要生成出来，mysql、test、performance_scheme这些 yum安装其实也是依赖这个脚本生成的 centos7上也能用这个service xxx start，可以参考现在的做成systemctl start xxx的service文件。yum安装的mysql里service文件写法看看。 PATH变量 初始化 源码包编译安装 和二进制差别不大，就是多一步编译 tar解压 cmake编译安装，以前我们都是用configure来弄，这里推荐用cmake，原来的configure make makeinstall也能用，不推荐 支持很多存储引擎，不代表就用得到。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-04-23 10:49:34 "},"23-MYSQL数据01/5-mysql二进制和源码编译安装及多实例.html":{"url":"23-MYSQL数据01/5-mysql二进制和源码编译安装及多实例.html","title":"第5节 mysql二进制和源码编译安装及多实例","keywords":"","body":"第5节. mysql二进制和源码编译安装及多实例 二进制安装 MSI格式点击安装就好 一、创建账号以及数据库的目录 确定没有使用该账号，再创建 (1) 准备用户 groupadd -r -g 306 mysql # 没必要，删掉这句，本身useradd -r 就会创建同名组，id都是 -r系统用户了，-d就不会创建家目录了，所以没必要-d带上目录， 所以创建账号优化为 useradd -r mysql mkdir /data/mysql chown mysql.mysql /data/mysql 或者 useradd -r -s /sbin/nologin -m -d /data/mysql mysql # -m就是-r的情况下不会-d所以就-m cd /data/mysql rm -rf /data/mysql/.* # 删除家目录里的隐藏文件，否则会有问题 然后这里强调下 useradd -s /bin/false 和/sbin/nologin一个意思，不过false的本质还是 你给了用户/bin/false 的shell后，用户登入使用这个/bin/false后发现返回的是false是错误，于是就不会继续登入了。 二、解压二进制和创建软连接以及文件权限 注意/usr/local路径是固定的，当初官方编译的时候指定的 解压后就得到带版本号的文件夹，大小从600M+变成了1.5G 但是人家编译的时候的路径是/usr/local/mysql，所以创建一个软连接 权限的问题 解释：加不加斜线 1、chown -R root.root mysql # msql是软连接文件，-R也是不认为是个文件夹，不存在递归、 2、chown -R root.root mysql/ # 这样就会判定为文件夹，-R就会做递归了 这里就完成了二进制文件的解压，得到了一堆mysql程序。然后考虑使用这些二进制文件生成DB文件。 三、生成数据库文件 现在/data/mysql里是空的 关注这两个文件夹 /usr/local/msyql/scripts里的mysql_install_db是用来创建数据库文件 创建的时候要指明，在哪个目录下生成DB文件，并这些文件属于哪个用户 执行的时候报错了 解决方法是到/usr/local/mysql下使用相对路径执行 这就是安全加固的指令👆运行完后，就生成了DB文件👇 配置文件一般系统自带就有，也要看什么系统呢，如果是最小化rocky-linux就没有 可见该/etc/my.cnf文件不是二进制安装得来的。 四、从二进制安装包里找到配置文件推荐模板复制到常用配置文件路径下 这些参数就是老文件保留下来的，现在不会给这么小的内存。 和原来的/etc/my.cnf区别开来，放到/etc/mysql/my.cnf👆 修改/etc/mysql/my.cnf里的datadir为之前指定的/data/mysql，其他不用动 五、启动服务 由于是二进制安装的，启动靠脚本 脚本里有start status stop这些动作的 设置为开机启动了已经👆 然后启动服务 六、客户端连接 修改一下PATH路径，便于使用mysql命令 PATH变量写到独立的/etc/profile.d/mysql.sh里 此时就可以连接mysqld了 七、开头提到的家目录里的隐藏文件的问题 如果当初创建用户使用-m -d生成了家目录来作为DB文件路径，然后又没有删除里面的隐藏文件夹，就会遇到问题 删掉就好了 system是在mysql交互界面里调用linux系统命令👆，当然这里仅仅是演示知识点，工作中千万不要这么操作，太危险了，数据库文件都在那呢。 rm -rf .[^.]* 这是删除隐藏文件的准确方法。 八、安全加固 以上就是二进制安装方法的详情👆 源码编译安装 考虑到数据库后面可能需要扩容，所以这次使用逻辑卷。 分区 注意上图👆error 需要同步一下 创建物理卷并加入卷组 加组的时候，指定单个PE大小为16M，将来空间就是16M，16M地分出去的。 创建逻辑卷 磁盘空间用光100%free 挂载文件夹 创建文件夹，记得格式化LVM 持续挂载👆 查看确认下 修改文件夹属性 创建账号先 -------------开始源码编译------------ 安装依赖包👆 yum install bison bison-devel zlib-devel libcurl-devel libarchive-devel boost- devel gcc gcc-c++ cmake ncurses-devel gnutls-devel libxml2-devel openssl- devel libevent-devel libaio-devel 解压缩源码压缩包并进行编译 编译采用cmake而不是configure预编译，记得CPU给够，否则待会make编译的时候耗时更长； cd mariadb-10.2.18/ cmake . \\ -DCMAKE_INSTALL_PREFIX=/app/mysql \\ # 这个是二进制程序安装路径 -DMYSQL_DATADIR=/data/mysql/ \\ # 这是数据库文件存放路径 -DSYSCONFDIR=/etc/ \\ -DMYSQL_USER=mysql \\ -DWITH_INNOBASE_STORAGE_ENGINE=1 \\ -DWITH_ARCHIVE_STORAGE_ENGINE=1 \\ -DWITH_BLACKHOLE_STORAGE_ENGINE=1 \\ -DWITH_PARTITION_STORAGE_ENGINE=1 \\ -DWITHOUT_MROONGA_STORAGE_ENGINE=1 \\ -DWITH_DEBUG=0 \\ -DWITH_READLINE=1 \\ -DWITH_SSL=system \\ -DWITH_ZLIB=system \\ -DWITH_LIBWRAP=0 \\ -DENABLED_LOCAL_INFILE=1 \\ -DMYSQL_UNIX_ADDR=/data/mysql/mysql.sock \\ -DDEFAULT_CHARSET=utf8 \\ -DDEFAULT_COLLATION=utf8_general_ci make && make install 提示：如果出错，执行rm -f CMakeCache.txt make -j 16 && make install && echo -e '\\a' && date 后续安装和二进制安装一样👇 准备环境变量 echo 'PATH=/app/mysql/bin:$PATH' > /etc/profile.d/mysql.sh . /etc/profile.d/mysql.sh 生成数据库文件 cd /app/mysql/ scripts/mysql_install_db --datadir=/data/mysql/ --user=mysql 准备配置文件 cp /app/mysql/support-files/my-huge.cnf /etc/my.cnf [mysqld]中添加三个选项： datadir = /data/mysql innodb_file_per_table = on skip_name_resolve = on 禁止主机名解析，建议使用 准备启动脚本 cp /app/mysql/support-files/mysql.server /etc/init.d/mysqld 启动服务 chkconfig --add mysqld ;service mysqld start 记录编译安装遇到的问题 多实例mysql 其实也可以直接用docker咯，这里先不管容器的事 不管是哪种，端口号必须分开来 开始操作，使用的是yum安装的mariadb进行实验 当前单个实例的情况 1、端口一个3306，要分开 2、数据文件路径一个，要分开 数据库的路径yum安装的是这里👆，待会要做多实例，路径重新规划成三个独立的。 ①创建独立的目录用来存放DB文件、bin文件、etc配置文件、log日志文件 socket就是mysql通过本地socket连接的文件。 ②跑数据库生成的脚本，生成多个DB文件 就是把yum安装的/var/lib/mysql/下的文件，生成到自己创建的多个分开的路径里 yum安装就会自动生成的一个文件mysql_install_db，用它来生成DB文件 如果是二进制安装的就是在scripts路径下，注意不要进去运行，就是在外面运行。 生成动作👇 yum安装的时候自带脚本就会创建mysql用户，所以直接用就行了👆 --datadir 指定DB文件目录 tree可见 已生成了 同样另外两份生成一下： ③修改目录的权限 已经通过mysql_install_db生成指定的权限如下 整个目录都设置一下 ④创建多实例的配置文件 就放到刚才定义的多实例文件夹下各个/etc下 先改一份，再复制到其他实例路径下 因为是多实例，PORT默认是3306也顺便统一都写上 上面的配置优化成变量的方式，可以吗，哈哈 修改一下各自的端口 至此 二进制文件本来共用的不用动、账号共用不用动、DB文件搞定、配置文件搞定、就剩下启动脚本了。那些socket路径、pid、log都是指定后随着服务启动会自动生成的。 ⑤启动的方式，采用脚本后台启动 服务脚本是网上找，或者自己写 拖进去即可 这个脚本的路径要修改的，因为它原本是针对源码编译安装的 比如mysqld_safe和mysqld的路径当前所在👇 找不到是因为which是只在PATH路径里搜索的，招不到没事，服务起一下，ps aux可见 启动后就能看到mysqld的路径 修改的截图 至此就搞完了 3306这个文件夹下的bin下的启动脚本就有了 data下的DB文件也就是数据库也有了 etc下的配置文件也有了 log 、pid 、socket 这些自动生成的 启动程序 ⑥怎么连接 指定各自的socket文件 status看下路径 3307的👇 3308👇 ⑦关闭数据库 报错了👆 应为服务启动关闭的那个脚本里写了固定的口令，口令是错的 就可以啦👆 通过ss -tlnp看看是不是关掉了3308这个实例 ⑧补上root的口令 记得改的时候也带上socket参数-S 改完口令，由于原来是空口令所以现在必须带密码才能登入了 把启动关闭脚本里的密码补回去👇，否则关闭服务还得输入密码。 同样修改另外两个实例的密码 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-09-07 16:45:51 "},"23-MYSQL数据01/6-sql各种语句1.html":{"url":"23-MYSQL数据01/6-sql各种语句1.html","title":"第6节 sql各种语句1","keywords":"","body":"第6节. sql各种语句1 基础概念 IBM开发出来的SQL语言 SQL语言规范 命名规范 常见SQL语句 DDL：CREATE,DROP,ALTER DML：INSERT,DELETE,UPDATE DCL：GRANT,REVOKE,COMMIT,ROOLBACK DQL：SELECT 创建数据库： CREATE DATABASE|SCHEMA [IF NOT EXISTS] 'DB_NAME'; CHARACTER SET 'character set name’COLLATE 'collate name' 修改数据库： ALTER DATABASE DB_NAME character set utf8; 删除数据库 DROP DATABASE|SCHEMA [IF EXISTS] 'DB_NAME'; 查看支持所有字符集：SHOW CHARACTER SET; 查看支持所有排序规则：SHOW COLLATION; 获取命令使用帮助： mysql> HELP KEYWORD; 查看数据库列表： mysql> SHOW DATABASES; 创建数据库 Name: 'CREATE DATABASE' Description: Syntax ------ CREATE [OR REPLACE] {DATABASE | SCHEMA} [IF NOT EXISTS] db_name [create_specification] ... # create_specification就是指定的属性，包括 # CHARACTER SET 默认字符集：明确当前默认字符集是什么 show character set # DEFULAT COLLATE 默认排序规则 create_specification: [DEFAULT] CHARACTER SET [=] charset_name | [DEFAULT] COLLATE [=] collation_name | COMMENT [=] 'comment' Description ----------- CREATE DATABASE creates a database with the given name. To use this statement, you need the CREATE privilege for the database. CREATE SCHEMA is a synonym for CREATE DATABASE. # SCHEMA和DATABASE是同义词 gb2312是简体中文 big5是繁体字 utf8 全球语言编码 图中Default collcation是排序规则，就是最左边一列的字符集，它默认使用的排序规则是什么，通过show collation查看一下排序规则的具体内容 这👆就是以排序方式作为线索的表单，最左边是排序方式，第二列是可以使用该排序方式的字符集，同时第三列就是字符集是否默认使用的这行的顶头那种排序。 现在不主用UTF8了，数据库里要存放表情包之类的符号，就需要👇utf8mb4才是推荐。 占用字节也是比较大的4个字节，UTF8时3个字节。空间也就是硬盘也便宜。 创建db，实际上的默认语句，其中默认字符集时latin1_swedish_ci，默认数据库就是不支持中文的，需要修改。 创建的时候制定字符集 此时去DB文件里看看 db.opt里两行内容，默认的字符集，默认的排序规则 一个数据库就用统一的字符集，虽然可以针对某个字段设置字符集，但是非常不推荐。 修改数据库的字符集 ALTER DATABASE DB_NAME character set utf8; 如果DB里已经放了数据了，所以调的时候就要小心了。一般不会改。 删除数据库 DROP DATABASE|SCHEMA [IF EXISTS] 'DB_NAME'; 三种创建方法，主用第一种 data_type数据类型 tinyint:8bit，正好是IPv4地址一段的空间。可用在此处规范格式 数据库存角、分，也是单独建立字段角、分，都是整数型而不是小数型。 查看官方文档里的定长和变长 https://dev.mysql.com/doc/refman/8.0/en/char.html CAHR(4) : 代表，不管多少，多砍少补，视频里老师讲是4个字符而不是4个字节，就是说最多可以存4个汉字的。 修饰符 比如员工编号自动增长可以用AUTO_INCREMENT 确保全是正数没有负数，可以使用UNSIGNED tinyint 8bit 最高位如果为0就是正数，为1就是负数。所以真正的数据也就是7位。使用UNSIGNED后符号位就去掉了，8bit全是整数，范围从0-255了 DEFAULT 没赋值的默认值，比如IT行业默认值设定为男... create table student(id int unsigned auto_increment primary key,name varchar(20) not null,gender ENUM('m','f') default 'm',mobile char(11) ); 定义了id为int类型，有点大好处嘛不烦神，坏处就是4B占空间，用不了这么多可能，unsigned就是都是正数，auto_increment自增长的id序号，主键默认就是not null name就是varchar类型20个字符，注意是字符。not null不为空， gender类型是ENUM枚举表示几个中选择一个，default默认值为m， mobile手机号就是，char(11)个字符串，注意手机用数字int这种不合适，因为还要进一步做138开头的匹配过滤操作。数字可能不行，regex好像针对的是字符串来匹配的。 查看默认字符集拉丁，不支持中文。 表格式不要改，能改的不多，比如varchar(20)就不能改小了会造成数据截断，改大倒是可以。 DROP TABLE ALTER TABLE Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-03-31 10:07:32 "},"23-MYSQL数据01/7-sql各种语句2.html":{"url":"23-MYSQL数据01/7-sql各种语句2.html","title":"第7节 sql各种语句2","keywords":"","body":"第7节. sql各种语句2 DML语句 insert 前后一一对应 id默认自增长、gender性别有默认值 添加多条记录 只要前后的域名和值一一对应就行，顺序不固定 字符集，表是集成的库的 现在的版本都不让你插入不支持的字符。 换个数据库测试一下字符集的支持情况 创建表方法1👆，顺便也换种方式创建表， 创建表方法2：以一个查询语句的结果来创建表， 创建表方法3：复制表 (2) 通过查询现存表创建；新表会被直接插入查询而来的数据 CREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name [(create_definition,...)] [table_options] [partition_options] select_statement (3) 通过复制现存的表的表结构创建，但不复制数据 CREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name { LIKE old_tbl_name | (LIKE old_tbl_name) } 但是复制创建表的字符集还是latin是原表的字符集 而新建的表就是集成了数据库的字符集utf8mb4 创建方法3， 此时依据查询结果来创建表，不涉及原表的默认格式比如字符集，所以表本身还是新建的，字符集集成了数据库的utf8mb4。但是！要注意的是，此时依旧无法在此表中创建中文，因为仔细看上图，虽然ENGINE引擎里是修改了utf8mb4，但是name字段还是latin1_swedish_ci，所以姓名依然不能写中文。 三种方法的创建，只有select 结果创建，是带上了原表内容了 insert 插入可以不写域名，就是values里必须写全，如下： 还有一个客户端的字符集的情况 客户端的字符集时auto 自动的 制定一下字符集 对比一下制定字符集和不指定字符集的区别 db并没有区别，然后client characterset客户端字符集同样没啥变化，都是utf8mb4，这不是OK得啊，还指啥指呢。 进入一个DB后，status发现变化了 server charactoerset是整个mysql实例用的字符集，所谓实例，就是mysql这个服务，一般多实例就是多监听端口。 db charactoerset是实例下面的某个db使用的字符集 client characterset是客户端使用的字符集 conn characterset望文生义就是链接的字符集，不明觉厉 但是table里的name还是拉丁字符集啊，对不对，我不用继续听你讲， 都知道你的思路是不对的。 退出一下，改为不制定字符集的进入方式 show variables like \"%character%\" 总结：字符集定义的地方 1、实例 2、DB 3、table 4、字段 除此之外，还看到了client、conn 改字段的字符集 ALTER TABLE student3 CHANGE name name VARCHAR(20) CHARACTER SET utf8mb4; 终于支持中文了，其实一开始创建实例的时候就制定好支持utf8mb4就行了 数据库相关的变量 修改配置文件 客户端的字符集，上面是命令选项，下面是写入配置文件里 虽然这个修改不用重启就能看到效果，但是还是要重一下，因为，如果你改的是/etc/my.cnf里的 这样是语法错误，重启服务报错的，但是不重启，mysql 进入竟然client字符集是修改成功的。所以奇葩吧。 查看default效果 导入一个现成的脚本，生产数据库文件供练习使用 mysql -uroot -pCisc0@123 除了insert语句还可以用的别的 StuID有自动增长属性，所以insert的时候不用手动指定了 set这种格式用的不多👆这是insert的第二种语法 还有insert第三种语法，也不多用的，了解一下， 适合把一个表中的查询结果批量导入到另一个表种 更改的指令 要制定更改的哪条记录里的哪个字段 如果update的时候不加where限制条件，那么所有的记录都被改了，这就是灾难性的操作了，和删库也差不多了 为了避免这种情况的发生 dummy笨蛋的意思 -U是命令里的，也可以写到配置文件里，提到配置文件要知道是 server的配置文件 还是 client 配置文件 这里的mysql -U应该是客户端的命令，所以是client配置文件里修改 效果OK DELET删除命令 由于开启了安全模式，所以不让清表，👆这是清表，不是删表，删表是DROP 当你的表中记录非常多的时候，清表速度就要快，此时就不能用DELETE，而是用TRUNCATE 因为DELETE删表记录的时候，还要记录日志的，所以速度没有TRUNCATE(不生成事务日志)快 事务日志后面讲 DML insert update delete DDL create drop alter 下面继续学习DCL和DQL 之前的一个编译报错，版本较新的包，解决思路如下 但是rm -f CMakeCache.txt删除后要重新cmake可能。然后yum install libdb-cxx-devel要补一个这个包。要么就是和AMD的CPU有关导致的编译到后面失败了。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-05-11 10:02:05 "},"24-MYSQL数据02/24-MYSQL数据02.html":{"url":"24-MYSQL数据02/24-MYSQL数据02.html","title":"第二十四章 MYSQL数据02","keywords":"","body":"第二十四章 MYSQL数据02 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"24-MYSQL数据02/1-sql语句DQL单表查询.html":{"url":"24-MYSQL数据02/1-sql语句DQL单表查询.html","title":"第1节 sql语句DQL单表查询","keywords":"","body":"第1节. sql语句DQL单表查询 select的其他作用 打印字符串： 数字运算： select * from table_name *表示这个表中所有的字段 挑列 1、挑选的字段，可以自定义顺序，所以设计表的时候，字段的前后顺序并不重要，只要查的时候把它改一下顺序就行了。 2、字段名大小写问题不大，注意规范就好。 别名-优化显示，配合页面的显示 as可写可不写 多表查询的时候的优化表名 挑行 非标准SQL比如!= 不等于的这种写法，别的数据库里就有可能不支持，mysql里是支持的。 不等于的写法 注意where里的表达式里，除了数字其他一般都需要加引号。 多条件选择 是真不区分大小写啊 登入的逻辑， 就是在网页里，输入用户名、密码，最终就表现为一个查询语句， select * from students where username='admin' and password='centos'; 查到了就是存在用户和密码匹配的，如果没查到，就是用户名或者密码不对 构建非法输入字符绕过常规select 利用下面的这个查询or的逻辑，加上面的手法，就可以绕过检查。 构建奇怪的密码 这就是sql注入，很多年前针对DB的安全攻击。大部分软件JAVA PHP都针对这种有相应的措施。 上图admin\\'-- 是用户名，密码是一个单引号 \\' LIKE通配符 % _ % 前后都有的，这种是不推荐写的，因为会严重的影响数据库的性能，因为它不能利用索引。利用索引，才能提升性能。 当数据百万级别的时候，这个前后都有%%的写法就非常不好了！ RLIKE、REGEXP正则 也是不推荐使用的，影响性能 去重-distinct 查空置NULL 不为空 表中查询统计 分组统计，聚合函数，group和聚合函数通常成对出现 GROUP：根据指定的条件把查询结果进行“分组”以用于做“聚合”运算 avg(), max(), min(), count(), sum() HAVING: 对分组聚合运算后的结果指定过滤条件 函数在DB中都是要加()的，括号里放的就是函数的要求 count()统计非空记录数也就是行数 count()，括号里放字段，\\就是所有字段，也就是所有列，不可能所有列都为空 所以也就是表的行数也就是记录数，所以统计表的记录数可以用count(*)还有count(主键)，因为主键也不能为空 max() 和 min()以及avg() 分类汇总-分组汇总 针对性别分别做平均年龄 但是男女没有标明 做分组分类的时候肯定要带上分组的字段名，比如gender分组的，就要select上gender group by 要注意下图的效果 如果group by不配合聚合函数，那么就是查的是第一个分组内容的信息，比如 group by gender就是性别分类，结果不配合聚合函数，就是第一个女生的信息和第一个男生的信息 所以，使用group by分组的时候，前面select后面跟的只有两个东西，一个是group by本身的字段，还一个就是聚合函数 where和group by的组合 要么where放前面，过滤之后再分组 要么改where 为having，分组之后再过滤， as还是比较不错的👆 上面的where也是可以写成having如下👇 分组 再 分组 对上图进行班级分组后，再对性别进行分组 ORDER BY排序 升序ASC 降序DESC 针对数字型的有效 升序中，null石排在前面的 倒叙NULL虽然排到后面了，但是整个也倒叙了 group by 和 oder by组合使用 按班级分组统计学生年龄，按班级别号正序显示 如何去掉null，注意having和order by的前后次序 大概就是：group by 再 having 然后order by，但是having是group by分组汇总后的过滤，就不太好了， 运算减少的思路，就是，先过滤，改成👇 LIMIT限定记录数(行数) 跳过前2行，取后续的几行👆 in的语法 等价写法 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-05-16 15:28:38 "},"24-MYSQL数据02/2-sql语句DQL多表查询和视图.html":{"url":"24-MYSQL数据02/2-sql语句DQL多表查询和视图.html","title":"第2节 sql语句DQL多表查询和视图","keywords":"","body":"第2节. sql语句DQL多表查询和视图 两张、三张，四张，都是从两张开始的， 两张表查询，应该就是先讨论两张表的组合起来。 JOIN 两种形式的组合 纵向和横向合并 纵向union合并 就像两个文件内容cat file1 file2 追加在一起一样，但是db.tables纵向合并需要title对齐 两张表的TID和stuid不一样没关系，也可以合，只要内容相匹配就行。 union合并 错位合起来，没有意义了就 union的去重功能的开关 通过两张一样的表来测试 去重方法2：distinct 横向合并的逻辑较为复杂 联想paste file1 file2这个shell命令，虽然关系不大 横向1：cross交叉连接,也就是笛卡尔乘积组合，就是10条*20条这种200条结果的组合 好像A CROSS B 和B CROSS A 其实是一样的 cross一般用的少的，一般是找到相关联的信息 内连接-inner join 限制制定列，需要标明哪个表 别名简化下输入 左外连接-left outer join, outer可不写 就是A的全要，并且根据A关联B里的信息都捞出来。 观察下图，理解left out join的意思👇 写命令的时候 left join的左边的表就是全部要，右边的表就是写关联过去的交集。 右外连接 as真的哪哪都可以加哦，优化下表头便于理解： 对查询出来的inner join 、left join、right join进一步做过滤 表的别名和字段的别名，表的别名定义了，调用就要用别名，字段的别名只是一次性有效，调用还得用原名 left join 去掉交集 上图👆是A left join B，下图👇是A left join B and xxx is null： 👆图写错了，不应该是and而是having或者where right join 去掉交集 全连接 full outer join 理论上是full join，可惜mysql和mariadb不支持所谓的full 换种写法 排版换行下 full join去除交集 如果👇这样写是没有用的 要用到子查询：select的结果嵌入另一个select语句或者DML语句。 比如：查询年龄大于平均年龄的学生， 把老师的平均年龄 覆盖到 20号学生的年龄 然后就做一下FULL JOIN 去除交集 所以这个name，age，gender的冲突是和tearcher表里的冲突了 至此，就得到了FULL JOIN 的去除交集的写法👆 现在回头来，👇这些都是存在冲突隐患的 案例1： 需求：查询每个员工的姓名和 上级负责人的姓名 如果是两张表，就可以这么做 这样就学到了自连接👇 涉及三张表的一个关联操作 表1，得分表 表2，学生表 表3，课程表 挑选一些字段 select语句流程图 select的处理次序，看图可以知道select columns这个语句是在from xxx 之后的，所以也能解释from tables as t的t可以在select t.name1里进行调用的原因了。 VIEW试图 视图，在CCNA-SEC里见过，在BIND里见过，现在又在MYSQL里看到视图这个概念。反正不一样，知道一下就好了。 mysql里的VIEW长的像表，但其实是虚拟出来的表，不是真实存在的。 1、作用有点像linux的alias别名，固化查询语句，下次直接调用，省的再次输入长长的SQL CLI。 2、隐藏了真实的表结构。 create databases create tables create view 注意view和tables长的基本一样，所以命名的时候要认为区分注意规范 这样就创建了一个视图，所以和alias别名不一样，alias是将cli简化，而view是将cli的结果固化，相当于多了一个表，只不过是虚拟的表。 如何区分这是一个真实的表table还是一个视图view呢 like是通配符，rike是正则，但是show table status里不支持rlike 试图的tables status一眼看过去都是NULL，只有comment表达一些这个是VIEW 真正的表里是由引擎、不能把、字符集各种设定清空的。而且Comment是空。 这个view是动态的，修改视图里的源表格看看效果 删除学生，在看看view里的 是动态的，这里为什么还有NULL，因为VIEW生成的原SQL是left join的。 view可以插入如何理解 插入50岁的可以，因为创建视图的时候就是age>30 创建20岁的就不行了，因为你这个操作是对view的insert但实际上是修改了原表，而且view本来就是过滤了age>30的，所以就有一个现象：你insert了view，但是view里却看不到👇 所以实际工作中，不推荐用VIEW，因为存在这样的情况。 对视图的操作会影响原表 如果是三张表的join呢，，此时对VIEW的操作，又是对哪张表进行的呢？测试下，拿之前的那个view_test来测 哈哈，不让~ 我感觉就不应该对VIEW进行操作！ 而且也不建议使用VIEW drop view xxx;删除视图 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-05-25 17:57:54 "},"24-MYSQL数据02/3-函数存储过程和触发器和用户管理.html":{"url":"24-MYSQL数据02/3-函数存储过程和触发器和用户管理.html","title":"第3节 函数存储过程和触发器和用户管理","keywords":"","body":"第3节. 函数存储过程和触发器和用户管理 函数-例1 创建函数 查看函数列表 函数是保存在mysql.proc表中的 排版换一下 删除函数 函数-例2 上图的注意点：改变以往;分号作为一个命令去断句执行的行为。而//才是断句。 然后最后结尾又改回去了，所以DELIMITER是一个全局命令。类似交换机的user-interface里的screen-length 创建函数deleteByid，并传递参数uid，类型是SMALLINT 正数， RETRUNS返回的是字符串 BEGIN和END是标明函数体，如果简单的一句话搞定就不用写BEGIN和END，但是多句就不行了。 对比，跑函数之前的students里的行数是21 跑一下函数后的行数是 第10行没了 函数里 赋值的方法①：set a =x 👇 注意 END// DELIMITER; 其实是错误的写法，它表示已“END // DELIMITER;”结束的，而不是以//结束。 函数里赋值方法②：select into xxx DELIMITER // CREATE FUNCTION deleteById(uid SMALLINT UNSIGNED) RETURNS VARCHAR(20) BEGIN DELETE FROM students WHERE stuid = uid; RETURN (SELECT COUNT(stuid) FROM students); END// DELIMITER ; 可以改成 DELIMITER // CREATE FUNCTION deleteById2(uid SMALLINT UNSIGNED) RETURNS VARCHAR(20) BEGIN DECLARE x int; DELETE FROM students WHERE stuid = uid; SELECT COUNT(stuid) FROM students INTO x; # 这里是将select的结果放到了x变量里，这也是一种赋值。 RETURN x; END// DELIMITER ; 👆DECLARE申明看来要放在函数体的最前面，紧跟着BEGIN才行。 存储过程，更似shell里的函数 调用的时候比上面的讲的函数更像shell里的函数。 IN是给存储过程找个函数功能传递参数，是传进去 OUT是传出来 INOUT是双向的。 存储过程的案例 create创建、call执行 存储过程 show procedure status;查看👇 注意对比函数的type mysql库里也是存放了很多重要信息的：比如用户账号、还这里看到myql.proc里的函数、存储过程。 所以备份一定是要备份的。 存储过程参数的传递 注意如果换一个数据库就会报错，需要指定找个存储过程在哪个库里执行 自定义变量在FUNCTION和PRODECURE里的类型 1、局部变量：var 这种 2、全局变量：@var 这种 理解一下上面的mysql里的脚本，哈哈 变量是会话级别的变量，就是说 退出mysql的当前交互，变量就没了 看下out参数的效果，从函数里传出来给到了全局变量。 上图中的row_count()函数是上一次命令更改了多少行的意思。 本例中就是 select row_count() into num;上一条cli，也就是DELETE xxx 更改了18行。 同样测一下 流程控制--存储过程和函数中可以使用IF CASE这些语句，这些专业叫法叫做“流程控制” LEAVE相当于break ITERATE相当于continue 触发器--准确来讲应该叫事件触发器 举例：比如你在jd购买了100个手机，下单了，那么库存里就要去掉100个【手机，所以事件就是下单100个，触发就是库存里自动减去100个。 DEFINER 是以什么身份来执行 TRIGGER就是定义触发器的名称 BEFORE 在 INSERT|UPDATE|DELETE之前进行的动作，换句话说就是在你增、改、删之前触发了某个动作，实际上就是不会去执行增、改、删了。就是说BEFORE就是用自定义的动作来代替trigger_event事件了。 触发器示例 附带主键的定义写法补充 一般是在定义字段的时候 比如 stu_id INT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY，这样后跟一个主键来定义。 也可以单独PRIMARY KEY(stuid)去定义主键，那么这种是一般用来定义复合主键的。 做两个表student_info和student_count两个表供触发器来测试效果， 然后👇做两个触发器： 插入一行记录后再查看 可见触发器生效了，因为触发器就是检测到该表的row数量，insert就是将另一个表student_count +1 插入两行，就是增加2个计数 而删掉一行，就计数减一 触发器trigger是放在information_schema里的triggers表里的。 但是information_schema库 并不是磁盘上的文件，所有在磁盘上以文件形式存在的库👇 information_schema是在内存里，所以理论上在information_schema里的后果就是重启mysql服务后触发器丢失。但是我甚至重启centos后发现触发器还在！说明其实触发器还在其他地方存放 如果将teachers表里的TID=3的那行删掉，那么students表里的TearcherID=3的怎么办？理论上是不让删的， 这个时候就会有一种做法--叫 级联删除，就是上面的teachers表里的删了，下面students里的涉及对应老师的那些行也都删了。 但其实，好多公司规范里是不让用外键和级联的。阿里的JAVA开发手册里有提到👇 用户账号和权限管理 mysql新的版本，password不是放在这里的，可能放在authentication_string里。 删除drop好了 改密码-方法1 看下passwrod函数：加密口令的方法，password()就是加密口令的。 改密码👇 密码必须加密 看个localhost的坑，生产中也是要关闭反向解析的。 先说结论，就是localhost和127.0.0.1不是一回事，举例 现在有两个root，一个是root@localhost，一个是root@127.0.0.1 然后使用root@127.0.0.1这个账号和centos这个密码登入 发现明明是127，结果被反向解析成localhost，然后localhost的密码又不是centos，所以deny了 关闭反向解析，让127.0.0.1回归IP，就可以对上root@127.0.0.1 centos这个账号密码了 然后去配置文件做永久关闭就行了，这里OFF就是做解析了，ON就是不做解析。 skip_name_resolve 是忽略名词解析，ON，就是打开就是忽略的意思。 然后故障就解决了 改密码-老的方法2失灵了 https://stackoverflow.com/questions/64841185/error-1356-hy000-view-mysql-user-references-invalid-tables-or-columns-o 验证很简单啊，之前view也学过， 可以用alert就可以了 忘记root密码-破解 1、最粗暴的方法就是，肯定不能用了 rm -rf /var/lib/mysql/* 这样数据里的所有东西都没了，重启服务后，自动初始化一些必要的库会。 2、正常方法 重启后就可以不用密码了 但是此时远程用户也同样不用输入密码就直接进来了 这就不太好了，这就需要开启维护模式--也就是只能本地连接，远程就无法连接了如下👇 PS：mysql配置里-和_等价的，重启服务后，远程就挂了 其实就是3306端口关闭了 同样本地通过tcp/ip这种sock一样也进不去了 只能本地走文件socket才能进去 然后言归正传，进行口令修改 刷新一下，再修改就行了， 取消授权REVOKE Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-06-25 11:26:25 "},"24-MYSQL数据02/4-mysql架构和存储引擎详解.html":{"url":"24-MYSQL数据02/4-mysql架构和存储引擎详解.html","title":"第4节 mysql架构和存储引擎详解","keywords":"","body":"第4节. mysql架构和存储引擎详解 权限类别 管理、程序、数据库、表、字段，这些都可以设置权限 管理类：create、shutdown、show databases、 结尾带上：with grant option就是被授权的用户拿到权限可以转赠给别人。 GRANT SELECT (col1), INSERT (col1,col2) ON mydb.mytbl TO 'someuser'@'somehost'; PS：授权，只能select col1只能查询col1这个字段，只能对col1和col2进行插入赋值，在mydb.mytbl这个库的这个表上，针对‘someuser’@'somehost'这个用户。 就OK啦；所以现在的新版本依然可以用grant去授权的时候直接创建用户。 取消授权REVOKE 上图就是ALL里面单单去掉了delete权限。 查看当前用户权限 一般授权可能需要结合flush privileges使之生效，有时候也不用补。当然忘记密码的步骤里需要改密码cli前flush一次。而授权这里通常是授权cli后补一个flush。 单单授权cli 就是 第一步，创建用户 ​ create user user2@'127.0.0.1' identified by 'centos'; PS：identified by 'centos' 不管在create user还是在grant 授权里出现都是设定密码了。 第二步，授权 ​ grant all on hellodb.* to 'user2'@'%'; mysql的架构 1、connector：连接器也就是API： 理解：各种API咯，JDBC就是jAVA调库的API，此外还有python和其他语言调用mysql的API。 2、connection pool：连接过来后要验证身份、分配线程、等等，这些处理模块就是connection pool连接池： authentication，就是验证是不是合法的用户，验证完了以后，系统会分配一个为你服务的线程。 thread ，就是mysql是单进程多线程的服务。用户上来，验证过了后，分配的就是一个线程。 reuse，用户使用线程查询完后，断开了，线程不会销毁。系统会清理该线程的用户信息，然后重新使用，叫reuse重新使用。 thread，其实有一个pool，池子。从池子里取线程分配。如果池子里总共有1000个线程，来了1w个用户连接，此时就超量了，就有一个连接限制connection limit。这个默认连接数是100，我以前批量并发获取400台SW信息并发写道mysql里就遇到了这个问题，最后查出来就是连接数限制要调大些就好了。 生产中这个连接数的值肯定要调大的。 还有check Memory和cache都是在连接池子connection pool里 cache下文介绍 3、SQL接口 用户通过connection pool拿到线程服务了，就可以通过线程向mysql发送指令了。而client发送过去的cli，server就会检查cli的语法，检查语法就是靠SQL Interface接口来完成的。 SQL语法检查通过了以后就进入了下一阶段 4、Parser：解析器 把用户发来的cli解释成SQL自己身能理解的内容。 在做解析的时候，同时要做权限检查，应该是给到具体的权限吧。然后还要做优化 5、Optimizer,优化 DB在资源访问的时候，访问方式不是单一的，比如：用索引和不用索引。 到底用索引好还是不用索引号，就需要一个优化。 根据这个优化，最终判断出来这个最佳的路径，来进行查询。 6、Caches和Buffers 如果查询过了，则可以利用缓存。 如果缓存里也没有，就需要去磁盘找了那些数据了。 7、数据是放在文件系统上的db格式 数据库底层的数据，除了 数据库本身--db文件，还有一些日志也很重要。日志是一个大的话题，后面会讲各种各样的日志。正常软件就一个日志，而数据库里的日志就很多：redo、undo、Binary、error、查询、慢查询。 这些db文件要对其进行访问，就需要存储引擎进行支持 8、存储引擎 存储引擎负责和磁盘打交道 数据库通过存储引擎连接到磁盘文件系统上来访问磁盘的文件里的数据。 历史上有上百种引擎，目前都是使用innoDB了。 9、数据库其他功能 备份、还原、集群等 存储引擎 历史上出现过上百个存储引擎，现在只需要了解MyISAM和InnoDB了，其实MyISAM都不用了已经。 mysql5.5之前的版本默认用的MyISAM。 1、存储数据大小，MyISAM是256TB，要远远大于InnoDB引擎的支持，但是没有用，因为mysql的整体定位就是中小型数据库。达到TB级别，就要考虑分库了，支持不了这么大的访问量了。 2、Transaction事务，MyISAM不支持，事务里有很多重要特性：稍后介绍CIDB特性，还有很重要的特性-原子性。 原子性：一个事务里面由很多小步骤组成，要么这些所有的小步骤都完成，要么都不做，不能只完成一部分，必须作为一个整体，这就是原子性。 举例：转账，从A转1W给B，A扣除1W和B增加1W，这两个事务就是一个原子了吧，这才是一个完成的操作，如果用MyISAM这种不支持事务的引擎，就有可能这边扣除1W，然后突然停电了，那头钱也没收到，钱就丢了。而InnoDB不会出现这种情况，如果同样出现上面的A转出钱突然的停掉，当A扣除1W的时候，就会记录在事务日志里了，然后那边加了1W也会记录到事务日志，由于一头扣除1W和一头增加1W是一个完整的事务。结果你只是扣了做了一半，结果数据库突然停掉或宕机了，等你后面启动的时候，就会检查发现里面只有扣钱的一半动作，这就是一个不完整的事务，此时就会果断采用一个undo撤销操作--扣除扣钱的动作。 所以如果DB不支持事务，就极度不安全。 3、locking granuarity锁的颗粒度 MyISAM的锁表，会影响并发 InnoDB是锁行也就是锁一条记录的，可以多人同时修改不同的行。并发好。 4、MVCC(多版本并发控制机制)，并发用 InnoDB支持MVCC 数据中的表不是看到的那么简单，你表里由2个字段，比如id和value，innodb引擎的数据 就会给你自动添加两列-字段，分别是create和delete 这两个字段分别存入的是，insert 一行-记录的时候，当时创建记录的时间点记录下来，其实不是时间点，而是事务ID，而事务ID只会递增不会减的，就跟时间一样只会不断增加，所以你也可以理解成时间。 如果第二条记录，删掉了，那么delete字段里就会记录删除的时间点，也就是事务ID。 假设一个人1200的时候(事务ID具有时间特性的，可以理解成时间点的)执行了select查询 问1，此人能看到上表的哪些记录？ 1000的可以看到，其他大于1200的事务ID的记录都看不到了 这个人是1200的时候开始操作的，然后持续到了3000才结束。 他看到的是1200以前的记录。 问2，下图用户1200的时候select能否看到第一行记录？ 答：看不到了，因为1100的时候已经删掉了 以上就是MVCC机制👆 所以在有MVCC机制的数据库中，所谓的删除记录并没有真正的删除。 再问：此时t2这个查询事务能否看到id1的记录 答：可以，因为1050这个事务点再id1记录删除的事务点1100之前，并在创建事务1000之后。 总结：MVCC表里，有create和delete事务ID，而查询有查询的事务ID，所谓事务ID就是时间节点去理解好了。不同的事务查看的的结果是不同的。 所以，MVCC的DB是你访问呢你的，我访问我的，大家不打扰的。原来是这种并发性哦，我TM服了... 这应该叫你看到我看不到的，是吧 然后好像现在mysql这个默认地库还是MyISAM引擎的库文件 xxx.frm 存放表定义，也就是表结构、几列、数据类型 MYD数据本身、MYI存放的是索引，索引可以压缩。 压缩，MyISAM压缩有前置条件和使用限制；而InnoDB应该是数据和索引都支持的。 现在高版本的mariadb的mysql库的引擎好像不是MyISAM，但也不是InnoDB。其实是Aria--事务部的MyISAM。 可见MAD的后缀其实对应的引擎是Aria，而Aria就是MyISAM的事务版 其他的库默认就是InnoDB 但是新版本的mariadb是既有ibdata1合并文件，也有各自的库文件的 上图👆frm就是表结构文件，ibd就是数据库文件和索引文件共用的一个文件。 其实老版本也可以分开来，当然是分开来好的，因为所有库文件和索引合在一起，单个文件很大，你也不知道哪个库变大了。 新版都是默认开启的 performance_schema引擎专用于performance_schema数据库的 Memory引擎，内存里的，临时存放。 Archive引擎：不支持删除，存档用的。 csv引擎，是excel那种？ blackhole，主从 复制的时候，可以用来加快复制。就是A--复制到B.C.D，不是直接复制多份过去，这样会加重机器负担，所以A-复制给Z，Z再分发到BCD行，而Z作为中间人，如果使用InnoDB引擎就会存到本地，而使用blackhole就不会存到本地而是内存中放着的，直接分发出去，减少了磁盘I/O。 查看当前DB支持的引擎类型： 注意InnoDB在不同的mysql版本里可能不是一个东西 上图5.1的mysq的innodb和后面较新一点版本的mariadb的innodb不是一回事。 都叫innodb，但是不同阶段的innodb可能是不同组织开发的， 早期的innodb可能是orcale公司开发的，后面innodb可能是Percona-XtraDB开发的。 修改默认的存储引擎 重启mariadb服务 show tables status from db_name\\G;也可以看到表用的是什么引擎 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-06-26 12:13:01 "},"24-MYSQL数据02/5-mysql服务器选项变量和性能优化.html":{"url":"24-MYSQL数据02/5-mysql服务器选项变量和性能优化.html","title":"第5节 mysql服务器选项变量和性能优化","keywords":"","body":"第5节. mysql服务器选项变量和性能优化 区分mysql选项、服务器系统变量、服务器状态变量三个东西 1、服务器选项，是写道配置文件里需要重启服务的一般是，可能mysql -u -p --option也行。 这就叫选项，就是运行时候的option咯； 选项来自于哪儿：在/etc/my.cnf里添加就行。 当然新版本就不是cli option的方式显示了，但是也要知道还是在my.cnf添加的那些就是服务器选项--myslqd 选项。 然后选项标准据说是用减号-，下划线只是支持而已，其实也就是不区分-和_的。 2、服务器变量是随时更新的，无需重启服务 然后很多情况下，有些东西，它既是服务器选项 又是 服务器变量。 变量通过show variables;查看 又分类 全局变量 和 会话变量 所谓会话变量，就是mysql -uroot -pxxx 进入的一个交互界面就是一个会话。 比如 这个选项同时也变量，可以如下方式查看 或者这么看 修改变量 这样直接该就是当前会话里生效，推出后失效。 然后再看一个my.cnf里的服务器选项，这里面写的都是服务器选项，既然写在里面能生效的都是选项，至于这个选项还是不是变量就要看了。 比如： 正儿八经上图选项要统一用减号-而不是下划线的，只不过人家不区分而已。然后看看这个innodb_file_per_table是不是同时也是变量，而查看变量的时候就要区分\\减号和_下划线了 上图说明这个变量不是一个局部性的会话级变量，要改就是基于全局去修改的。 然后看一个仅仅是服务器选项，不是变量的东西 哈哈，新版本也是变量了 老板本就不是变量哈哈，所以这个东西研究没啥具体价值可能 上图就是老版本的情况。 show variables \\G; 看所有变量 show variables like 'var_name'; 查看特定变量 show variables like 'var_na%'; 查看特定变量 show variables like '%var_nam%'; 查看特定变量 %就是等价于ls xxx*里的*就是通配符 关于服务器选项和服务器变量的官方表格 https://dev.mysql.com/doc/refman/5.7/en/server-option-variable-reference.html 既是命令行cli、又是option选项、还是var变量。 然后看下skip_grant_tables的这个跳过密码直接登入的东西 在mysql里就是cli、option、但不是var 在mariadb里既是option也是var 👇，同样这一点上文也说过了。 PS：--xxx就是option选项，不带--的就是var变量。 然后同样再次提醒一个写法规范性 - 减号就是纯选项的写法 _下划线，就是只要是变量就用下划线了，有没有纯变量的 还真有👇 还有一个服务器状态变量 这个一般不用改的，就是用来看服务器的当前状态的 登录了两个 msql -uroot -pxxx，所以是两个thread线程。 show status;或show status\\G; 查看状态变量 show status like '%thread%'; 使用通配符看命中的变量 修改最大并发连接数 默认是151 这是个全局变量，需要加上global参数；全局变量就是所有会话生效，意味着退出重进全局变量的值一样保留的住的；重启服务后失效。 那么这个是不是选项呢，去写到配置文件里，重启服务，如果能重启OK，就是选项咯 如果做到限制为最多3-5个用户 思路，可以从系统层面做连接数的限制， 如果仅仅从mysql或mariadb本身来做👇 mysql的最大连接数1-100000 mariadb的最大连接数就有点，最小必须是10起步 然后根据视频上说的，版本小于10.3.5是可以做到1-100000的 关于并发： 数据库的并发一般是1-2k，1w就崩了可能 web的httpd也就是apache可以达到1W nginx可以达到2W 考虑监控这件事，你要从这半百一千个变量中找到你需要的就行了，这么多肯定能满足你拉。 mariadb的状态变量有964个 mysql的状态变量有568个 同样考虑一些需求要找数据库是否有自带的功能的时候，就去服务器选项和变量里找 https://mariadb.com/kb/en/full-list-of-mariadb-options-system-and-status-variables/ 然后可以通过cli方式看选项的启用情况 老的版本呢ps aux能看到一些选项，新版本都看不到了，其实看也看不全，要通过cli去看。 sql_mode，综合性变量 NO_AUTO_CREATE_USER：进展用grant命令创建密码为空的用户 就是要规范命令：你用什么分组的，就要select里面写出来👆，ONLY_FULL_GROUP_BY就是这个意思，可能select出来的几个列，必须在group by里都出现才行呢。不过group by跟多个列是什么意思啊？可能就是先按名字后按日期进行排序比如👇，不过此时聚合函数就没啥意义了： 来个聚合函数有意义的 所以说select后面的几个，必须是在group by后面出现是有一定道理的。 报错error可以在warnings里直接看到 上图是error直接报错，就没写进去，而下图👇 同样有的版本出现warning个数提醒，但是没有详情，也可以这么看 上图是warning，然后截断后写进去了的， 两张图 不同的行为，一个是写不进去，一个是截断后写进去了，其实就是sql_mode的配置区别。 这个就是traditional，其实是一个意思 拿掉就可以做 截断插入了 配置文件就是my.cnf里写 CLI就这样👇 就可以实现截断了 两张图对照理解 这里就是根据优化的结果，可以选择采用索引或 不采用索引。 缓存的利用 必须前后两次的sql语言的哈希值一样才能利用上一次的缓存，也就是说大小写、空格、sql cli必须一摸一样才行。 缓存的不利用 有一些即时你启用了缓存，也用不上的情况：比如：动态的时间、日期、特意不使用缓存、还有什么临时表、共享模式的锁？ 数据有几个query打头变量 query_cache_type：是否开启缓存功能，取值为ON, OFF, DEMAND ON就是开启缓存机制，但是要注意开启了以后，还得设置query_cache_size才行，有的版本size默认=0，就是开了也是白开。 query_cache_min_res_unit：查询缓存中内存块的最小分配单位，默认4k，较 小值会减少浪费，但会导致更频繁的内存分配操作，较大值会带来浪费，会导 致碎片过多，内存不足； 缓存4k、4k地分出去地，如果查询地数据量是5K，但是缓存的占用其实就是8K。或者是查1K，浪费3K。 query_cache_limit：单个查询结果能缓存的最大值，默认为1M，对于查询结 果过大而无法缓存的语句，建议使用SQL_NO_CACHE 单个sql cli捞出来的结果超过1M就无法利用缓存了，所以针对这个sql cli就直接使用SQL_NO_CACHE来告诉数据直接就不去尝试使用缓存。 query_cache_size：查询缓存总共可用的内存空间；单位字节，必须是1024 的整数倍，最小值40KB，低于此值有警报 如果这个值=0，就代表当前缓存未启用，而上图是1M和quer_cache_limit单个查询缓存一样了就，肯定 不好啦！常识就是觉的不好。 query_cache_wlock_invalidate：如果某表被其它的会话锁定，是否仍然可以 从查询缓存中返回结果，默认值为OFF，表示可以在表被其它会话锁定的场景 中继续从缓存返回数据；ON则表示不允许 别人正在查看一个数据，该数据被lock，此时其他人去访问就不给访问了，其实也可以让他访问缓存里的数据，实现方式就是将query_cache_wlock_invalidate=OFF就行了。不过此时由于他是访问的缓存，所以数值可能不正确。 退出重进试试 果然 改size 换种改发，写道配置文件里 结果一样，还是 缓存的启用另一种方法-按需启用 就是使用cli里加sql_cache关键字，但是有前置条件的 query_cache_type的值为DEMAND或2时，查询缓存功能按需进行，显式指定SQL_CACHE的SELECT语句才会缓存；其它均不予缓存。 通过状态变量去看下缓存是否启用 状态变量一般就是看的，不能改的。 Qcache_hits | 0 表示没有一次缓存命中 下图可见cache命中啦👇 所以通过监控这个Qcache_hits可以知道缓存利用率高不高，命中次数越多缓存利用率越高。 内存free的和blocks块free的👆 总块数是4块，空闲的就1块？啥意思 系统看情况自动分的？ Qcache_inserts | 1 这个就是未命中缓存的次数， 解释：本意是缓存插入次数，就是记录缓存的次数，既然是记录缓存，就是第一次查询没有缓存利用，只能从磁盘文件查询，自然就是未命中缓存的次数啦，然后cache inserts记录缓存 查询总次数就是 命中次数+未命中次数 然后命中率就是 hits/(hits+inserts) 通过利用率可以判断你的业务适不适合用缓存，如果太低可能你的业务本身就不适合使用缓存。 注意些sql一定要注意大小写，而且是在web前端开放给用户比如网点查看商品的页面，用户其实是通过web去调db的，所以一定要将sql的cli统一大小写（多一个空格都不行），所以规范就是用SELECT * FROM XXX这种大写去做，才能利用好缓存。 | Qcache_lowmem_prunes | 0 | Qcache_lowmem_prunes：记录因为内存不足而被移除出查询缓存的查询数 内存不够了分配的小，缓存空间不够了，只能利用LRU算法淘汰缓存中的记录。 如果这个值比较多，可以考虑加点内存 | Qcache_not_cached | 2 | 输入的sql cli 无法被缓存的次数 多敲几次select发现 total_blocks变大了 查 询 缓 存 中 内 存 块 的 最 小 分 配 单 位 query_cache_min_res_unit ： (query_cache_size - Qcache_free_memory) / Qcache_queries_in_cache 查询缓存命中率 ：Qcache_hits / ( Qcache_hits + Qcache_inserts ) * 100% 查询缓存内存使用率：(query_cache_size – qcache_free_memory) / query_cache_size * 100% 如果缓存利用率很高，可以考虑调大一点。 优化查询缓存 “发生了很多验证工作”： 验证就是 查询的结果这个，数据频繁的发生了变化，一旦变化，就要验证缓存是否有效，肯定啊，缓存里的结果都不对，肯定要重新查拉。 所以缓存生效，①sql cli是否有hash②有hash也不行啊，本身缓存的sql cli捞的结果都频繁变化，db也来不及刷新了吧，我在想。。算了我不想了，按他的来。 就是设置的单位4k比如，太大了，碎片空间多，就减少。 没有碎片化，就看看是不是内存过低导致。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-06-27 21:01:55 "},"25-MYSQL数据03/25-MYSQL数据03.html":{"url":"25-MYSQL数据03/25-MYSQL数据03.html","title":"第二十五章 MYSQL数据03","keywords":"","body":"第二十五章 MYSQL数据03 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"25-MYSQL数据03/1-索引类型和结构原理.html":{"url":"25-MYSQL数据03/1-索引类型和结构原理.html","title":"第1节 索引类型和结构原理","keywords":"","body":"第1节. 索引类型和结构原理 索引可以极大的提升数据库的访问速度，好像缓存命中和也能提高哦 全表扫描，效率太低了，需要索引。 B树的特点 1、数据也是放在指针层的 2、找17号和找28号，耗时是相差很大的，也就是说查找的速率不是很平均 3、根上只有17和35两个索引号，分成了3个指针，太少了，要多一点，然后整体树结构要成矮胖型的才好一些；而数据也是和索引放在一起的，就导致数据如果太大，就占用了索引的空间，一层空间如果被数据占用太多，索引能用的空间就少了，整体就胖不起来了。 ​ 但也不能太胖哦，胖到极端，就是所有数据铺在根，那TM还有个屁的树结构哦，就变成了所有数据挨个查找了。 4、每次从根开始查找，效率低；比如要找10-30，就每次都要从根开始台麻烦了。而实际上上10-30就是连续的空间。 优化方案就是B+树，不仅仅是mysql这么用的，其他数据库也是这么玩的。 B+树 1、只放数据的摘要比如元数据，比如学生的信息不放，只放学生的编号 这样单层里存放的元素个数会更多，显然不仅仅是图中的3个 5 28 65这么少的了。 2、根和分支仅仅放索引，不放数据，叶子节点才放真实的数据信息 3、查询速度平均了：不管找8号学生的信息还是找28号，由于真实信息都放在leaf层，所以都需要从根编列到底层，但是由于每层索引指针多，整体查询就快了。 4、查找连续的数据，无需每次从更遍历，因为leaf层的数据之间也是有指针的 leaf层之间也是连续的指针指好的，连续的数据段查找不必每个都从根从头查找。 这个指针在叶子节点之间，这个数据结构叫做列表。 在mysql中存放的数据，就是用B+树来存放的。 不一定对数据建立索引，也可以对姓名建立索引 刚才就是对数字(学生编号)建立索引 就是对学生编号从小到大进行排序--看leaf层。 如果现在对姓名建立索引的话 而数据建立的时候有默认的字符集，而字符集有自身默认的排序方式，这个前面的章节里讲过的 简单点举例就是按字母排序，简单举例👇，当然真正的结构还得是B+树的结构。 本质就是将数据的无序变有序，将随机的I/O变成了顺序的I/O，这里是指的数据的r/w咯，从而便捷查找。 有序化后，就不需要全盘扫描，自然降低了磁盘I/O。 索引的缺点 1、目录要随着内容更新而更新，也就是说数据变化了，索引也要变化。比如插入一个章节10章查到11章前面，那么原来的11章就变成了12章，往后章节都要+1。好比插入一条记录。 2、所以db如果查询多，修改少，加你索引是合适的。 3、如果是频繁的更新数据，查询的少，索引该不该建立，就要考虑清楚了。 4、索引还比书的目录，目录本身也要占空间，一本厚点的书，光是目录就要占十几页了。索引就有点 利用磁盘空间 换取 查询的时间的意思在里面。 5、那也是值得的，索引利用好，查询效率提升显著。前提就是数据足够多。 6、1w或10w条记录，10w对于计算机来讲也不算多，建不建索引意义不大。 建立复合索引 firstname+lastname建立索引，不仅仅是某个字段，而是2个或者3个字段的复合索引 建立的时候，要指定谁是第一个字段 这就是复合索引👇： 大致如上图创建好复合索引后，如何利用呢? selcet from xx *where firstname like 'a%' 这种可以利用复合索引吗？可以的！ 但是： where lastname like 'b&' 这种可以利用索引吗？不能！ 1、首先lastname就不是按字母顺序排序，更本质的就是lastname不是独自排序的，是在firstname排序(后固定)的基础上再排的。 2、所以复合索引，只拿第二个或者叫第一个以后的索引，是无法利用的，因为本身就不是有序的（独立来看，自然也无法独立利用）。 where firstname = 'a' and lastname like 'b%' 这就可以了，因为firstname固定了，lastname就是有序的了。 where firstname like '%a' 这种可以利用上面的复合索引吗？where firstname like '%a%'这种自然也无法利用索引。 firstname 以a结尾的查，是利用不起来索引的，因为上图可见很多a结尾的firstname是无序的。 sql写法很关键 1、在经常写where的那里的条件上创建索引，是比较推荐的做法。就是说经常过滤的条件就是你创建索引的点。 2、越是不重复的，越是适合建立索引。反面例子性别总归就两个 男/女，还建个啥索引哦；手机号就比较适合创建索引。 这个图和上面的B+树是一个意思，同样看到叶子之间是由指针的，这就比较适合连续查找，也就是范围查找。 适合用B+树索引来实现的场景 比如查姓名，本身索引里就放着呢，所以直接查索引就行了。 不适合利用B+tree的场景 1、三个字段，姓+名+年龄，你查 姓+年龄就只能利用姓的索引，因为年龄的有序性需要固定住姓和名。 2、两个思路：①开发写好SQL，你去看看怎么创建索引，因为开发可能不会考虑索引的事；②写好索引后，开发去根据索引写SQL。 ​ 据说索引是运维来写的。 3、一般就是分析sql语句，找到适合建立索引的字段。 HASH索引默认就有不需要创建 看看note8 默认就是内部使用的。 比如30岁的哈希，就是这个30岁的哈希索引就会指向多个30岁的人，然后进到这些人里面查找。 但是哈希索引是无法支持连续(范围)类的查找的，因为哈希之间是没有关联性的。 这个哈希索引也是DB自身维护的，不用去太关注。 B+tree才是我们需要手动创建的。 R树用的也不太多 这是和定位相关的，比如手机定位。 全文索引 这和关系型数据没有太多关系，这是文本里的关键字查找。 数据里就不会存入什么视频文件吧，不适合放大量的数据。 聚集索引和非聚集索引的区别就是数据和索引是否在一起 创建主键的过程就是创建索引了，因为主键会自动创建索引。 观察上图的leaf层，此处索引和数据是放在一起的，此时就是聚集索引。 当然人家是创建主键的时候自动创建出来的索引。比如学生编号这种主键索引。 讨论下一个表中 主键不能多个的原因：这里从索引的角度就能解释，假设 1、你创建了学生编号作为主键，那么连带就创建了主键索引，同时数据也要按照学号来排序； 2、假设可以创建第二个主键，此时你按照姓名创建了索引，那么连带就创建了姓名这个主键索引，同时数据也要按照姓名来排序； 3、那么问题就来了，此时数据到底怎么排吗？难不成复制一份数据出来再排成别的结构，肯定不行吗！所以DB中primarykey只能是一个。 除了MYSQL的MyISAM，其他的Oracle或者微软的SqlServer，他们的数据库特性都是和InnoDB引擎差不多的。 再来看二级索引 主键就一个，自然主键索引就是一个， 然后要创建非主键的索引，比如用学生的姓名创建索引，这个姓名又不是主键，索引没问题。 此时按学生的姓名按字符(字母)排序，然后看上图，按B+tree的方式，leaf层就是索引此时，数据也会放在姓名索引这里吗，那岂不是又要复制一份数据啦，不可能！数据只是可主键索引放在一起的。 上图的ROW一行就是一条记录，就是主键索引和记录本身数据在一起的，就是上图的主键索引里的Row一行里面既有主键(本身就是索引)和数据(行记录)，这就是聚集索引。 如果我们创建的是非主键索引，也叫做二级索引，此时的索引指向的就不再是数据本身，而是主键PK。 比如二级索引，假设是年龄排序的，那么17+3，就是17岁+3主键。 想想为什么叫二级索引，就是非主键的索引是指向主键，而主键才是和真实的数据在一起的。 所以索引利用上，直接利用主键效率是最高的，二级低一点。 而MyISAM不管是主键索引还是二级索引都是和数据分离的 联系一下前文学习的，MyISAM每个表都有三个独立的文件 .MYI就是专门放索引的，MYD是数据文件的，索引和数据都不是一个文件，肯定是分离的了，不管是主键索引还是非主键索引 肯定都是分离的。 所以MyISAM，全部都是 非聚集索引 InnoDB，是默认所有的表、数据、索引都是在一起的 但是可以分开，虽说分开来，其实分的是不同的表的东西分开来，各个表里的东西也就是数据和索引还是在一起的，还是不分的。 重启后，hellodb drop删掉，重新导入。 从这个角度看 什么 叫“聚集索引”就清晰了，innodb即使用innodb_file_per_table分开，也只是各个表分开来存放，单个表里的 idb就是索引+数据。 所以MyISAM的 主键索引和二级索引，没什么次序，效率也是一样的。 InnoDB里，一建立主键(即主键索引)，数据的排序就和主键一致了，主键的次序就是数据的次序。 所以进一步讲，InnoDB你插入记录，就会影响插入位置后面的记录的索引编号。所以如果踩坑--管理的不好，就会导致大量的磁盘I/O，因为它要重新排序。所以适合于读多写少的场景。 效率待会演示差多少，有索引和没索引。 稠密索引和稀疏索引： 下图👇就是稀疏索引，索引不是全部都指向了数据的。 就是索引对应的是指针， 而leaf层的索引才是对应的数据👇 比如5号本身里面就存放了数据记录的。 下图👇这个就是稠密索引，所有索引都是指向了真实的数据了 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-06-29 20:57:44 "},"25-MYSQL数据03/2-索引管理和并发访问的锁机制.html":{"url":"25-MYSQL数据03/2-索引管理和并发访问的锁机制.html","title":"第2节 索引管理和并发访问的锁机制","keywords":"","body":"第2节. 索引管理和并发访问的锁机制 冗余和重复索引： 冗余索引：（A），（A，B）。比如firstname是创建了索引，然后firstname+lastname又创建了复合索引，此时其实两个索引都有firstname的排序，就是说不一样的两个索引，其实内部又重复的，存在冗余。 重复索引：已经有索引，再次建立索引。就是比如主键索引，你又创建一个唯一键是主键的索引？ 索引优化策略： 独立地使用列： 尽量避免其参与运算，独立的列指索引列不能是表达式的一 部分，也不能是函数的参数，在where条件中，始终将索引列单独放在比较 符号的一侧 ​ where age > 30 可以利用索引 ​ where 30 ​ where age+10 > 40 这样就不能利用索引 左前缀索引： 构建指定索引字段的左侧的字符数，要通过索引选择性来评估 索引选择性：不重复的索引值和数据表的记录总数的比值 ​ where xxx like 'zzz%' 针对name列做索引，发现name的一个字符已经具备区分性了，所以后面的字符就不要参与索引计算了，name(1)就是截取了索引列的第一个字符。 这就节约了建立索引占用的磁盘空间。 进一步比如：name char(20)，在其上建立索引name(10)取前10个字符就行了可能就能区分了。 这个取多少个能区分，的衡量度是啥，就是name char(20) 是20个字符的长度，你建立索引name(x)取钱x个字符，如果能区分出来90%，就可以了。 多列索引： AND操作时更适合使用多列索引，而非为每个列创建单独的索引 多列索引，就是复合索引，比如经常 将 firstname和lastname做个and一个条件来进行查找，可以考虑把fistname+lastname组成一个复合索引。而不是分别在firstname上建立索引，然后又在lastname上建立索引。 选择合适的索引列顺序： 无排序和分组时，将选择性最高放左侧；比如firstname选择性更高，就放在左侧。 只要列中含有NULL值，就最好不要在此例设置索引，复合索引如果有NULL值， 此列在使用时也不会使用索引 尽量使用短索引，如果可以，应该制定一个前缀长度 对于经常在where子句使用的列，最好设置索引，但是比如性别这种即使where上经常出现，也没必要设置索引，因为类别太少了。 对于有多个列where或者order by子句，应该建立复合索引 对于like语句，以%或者‘-’开头的不会使用索引，以%结尾会使用索引 尽量不要在列上进行运算（函数操作和表达式操作） 尽量不要使用not in和<>操作，确定范围的才能利用索引，比如age > 30 这种就可以利用，age ≠ 30 或者 age <> 30就只能进行全表扫描了，这种不确定范围的就不能利用索引。所以可以分开来？ age 30 这样来利用索引？ 查询时，能不要*就不用*，尽量写全字段名，不然捞出来的表可能多出来别的列。这样原来的sql cli不用动，不会受表格变动的影响。 大部分情况连接效率远大于子查询，用到了子查询的时候，想想能否用外连接的方式来做。 多表连接时，尽量小表驱动大表，即小表 join 大表，这个好像即使你用大表join小表，数据库也会自动给你优化成小表join大表的。 在有大量记录的表分页时使用limit；用limit限制一下，分批取数据，每次取个1w条就差不多了。 一般来讲，生产中数据库的性能好坏，很大程度上就是SQL 语句写的不好。如果你发现数据库性能达不到预期，就去查查sql语句写的是不是不好。 据说很多sql语句都是ORM自动生成的，生成的sql执行效率一般都没有人工手动写的高。所以程序员的sql基本上都是有优化空间的。 对于经常使用的查询，可以开启缓存 多使用explain和profile分析查询语句 这两个工具很好用据说 explain 可以看到你sql的细节，比如是否使用了索引，用的是哪个？ 查看慢查询日志，找出执行时间长的sql语句优化 管理索引 创建索引 1、创建表的时候就会创建主键的时候就会自动创建主键索引 2、表建好了已经，创建索引的方法 CREATE INDEX [UNIQUE] index_name ON tbl_name (index_col_name[(length)],...); UNIQUE就是要确保你的这个字段是具有唯一性的，比如手机号，身份证这些。 inde_name：是索引名称 ON tbl_name：是哪张表上去创建的 index_col_name(length)：字段的名称，在哪个字段上的前多少个字符来创建索引的，如果，逗号再跟一个字段就成了复合索引。 ALTER TABLE tbl_name ADD INDEX index_name(index_col_name); help CREATE INDEX; help CREATE INDEX; 删除索引： DROP INDEX index_name ON tbl_name; ALTER TABLE tbl_name DROP INDEX index_name(index_col_name); 查看索引： SHOW INDEXES FROM [db_name.]tbl_name; 优化表空间： OPTIMIZE TABLE tb_name; 查看索引的使用 SET GLOBAL userstat=1; SHOW INDEX_STATISTICS; key_name，key就是键就是索引。这个key_name是PRIMARY是个主键索引。 Colume_name-StuID：这个主键索引是在StuID上创建的索引。 Index_type: BTREE，写的是BTREE其实是B+TREE。 针对students表来创建 如果没有在age上创建索引，是无法where age = 30 这种就无法利用索引的。 type : ALL 全表扫描 possible_keys：可能用到的key NULL就是没有用到 key：NULL就是确实没有用到 rows ： 25行就是扫描了25行。也就是type：ALL全表扫描了。 创建索引，注意命名规范idx_xxx,比如在age上创建索引，就命名未idx_age 再来select 语句是否利用了索引 possible_keys 可能用到的索引idx_age，用了吗？ key: idx_age看到确实用了。 rows，返回最终结果有两条。 https://dev.mysql.com/doc/refman/5.7/en/explain-output.html name字段上没有建立索引，所以👇 再创建name字段的索引 此时再次对name里s开头的进行搜索，就有索引利用了 然后看下这个现象，视频讲解里的是这样 而我的实验是这样 老师说是数据库自己算出来不利用索引反而更快，不是大小写原因。 创建复合索引 先删除之前创建的两个索引 创建复合索引 注意上图复合索引也是一行一个，但是关注seq_in_index里的两行的值name的索引是1；age的索引是2。 看下复合索引的利用情况 1、对name先排序的，所以可以这样利用索引 2、跳过name_age复合索引的name，直接查age，就无法利用索引了 3、好像通配符类的，除了左前缀的都不能利用索引 4、name固定后，age就有序了，就可以利用索引 看下主键的索引利用情况 1、主键的范围查询，是可以利用索引的 2、想用索引，就别带上运算符 这个其实还蛮重要的，代码里上图的+10可能是个变量，可能会这么写的👇 stuid + $var_number > 30 ; 这样就是变量要放到右边才行：stuid > 30 - $var_number 3、不等于也不能利用索引 <> 这个等价于 != 查看索引的使用情况的统计 需要开启才能看到，开启方法👇 不用重进哦！上图写错了，就是要select 利用到索引才能看到统计值，explain是不记录的。 确认是否开启还可以 删掉这个不怎么使用的索引，就比较好，好在：1、节省磁盘空间，呵呵，2、减少磁盘I/O，插入记录还得重新计算后面的排序，这会导致磁盘I/O的增大。 先看一个字符串拼接👇： 其实可以用concat()来做 再看一个sql的存储过程 创建表testlog，id 自增长 delimiter $$ 定义EOF符号， 然后开始创建 存储过程 循环100000次，插入name,age，然后id没有插入就是从1自增长的。然后插入的name的value就是concat('wang',i)，就是wang1、wang2、wang3的插入， i ++ 然后将这个大表创建出来，供后下面索引的效率展示。 导入这个testlog.sql的方式有了两种 1、进入mydql交互界面后 2、不进入mysql交互界面导入 这样就可以了，不过之前我们用source testlog.sql 敲过一次，sql就执行过了一次存储过程的创建，所以这里会有ERROR报错，没关系，删掉重来。 再来 导入OK，这次表格和存储过程都导入了， 然后此次表格是空的，还需要跑一边存储过程来生成一个大表格。 然后call调用一下函数，也就是存储过程，什么名字记不住，除了上面的查法，还可以这么查👇： 执行存储过程 执行完后，看看一共生成了多少行 主键是id，所以索引也是默认创建在id上的，上图👆where 写的是name，所以没有事先创建号name的索引的。 通过explain确认没有利用索引的 create index idx_name on testlog(name)创建索引👇 所以，从0.017s 无索引到 0.001s有索引。 然后看统计， 确实是2次利用 下图就是👇说明，果然是利用的缓存 所以这里其实有优先级咯 1、缓存有先用缓存 2、缓存不中，再用索引。 创建唯一键索引 就是加个关键字unique就行了 观察上图的Non_unique字段，0就表示是唯一键；主键primary肯定是唯一键咯。 冗余索引举例 已经有了一个复合索引idx_name_age，然后你又创建一个name索引，这个name就是冗余的。 上图可见，idx_name是属于possible_keys可以利用的索引，但实际上key只用了idx_name_age，所以idx_name其实是没有利用上的。 上图是视频里的老师创建age索引，系统判定无需使用，呵呵，我自己敲了一边是用的 总之这里要说的，就是冗余索引的存在意义，针对 1、复合索引 name_age 2、再创建name索引就是冗余的 3、而创建age索引就是不是冗余，因为name_age复合索引里的age本身是无序的是依赖于name固定的情况下才有序，不是独立的索引，不会和单独的age索引重复。 所以你不能导出创建索引，比如100个字段全都创建索引，磁盘占用不说，你加条记录，加记录是很正常的事情了吧，然后所有的索引都要更新。一条记录上的所有字段创建了所有，所以加一条记录，100个字段的索引都要更新，这样会造成性能下降的。 一般就是where条件常用的，才会加索引。不经常出现在where后面的条件字段，就不需要创建索引。 下面看看数据库的并发控制这个话题 并发控制 数据库 vs 文件 的一大特点，就是db可以并行r/w吧，文件不行，确实python读取一堆pdf文件里的邮箱，然后并行写道excel里就不好弄，你怎么并行呢，除非你事先定义好pdf文件的序号，然后序号作为excel表格写入的行号，这样倒是可以理论做到数据不会被覆盖，但其实excel文件本身操作系统可能就不会让你并行写入。应该的是，比如ssh 两个人到同一个机器，然后vim打开同一个文件，后打开的就会提示冲突 所以并行访问在文件级别经常出现冲突，不过IM里的在线表格不知道是怎么做的，还有wps的在线共享不知道怎么解决并行的。 锁粒度：表级锁和行级锁，MyISAM是表记锁，InnoDB是表级锁。 读锁：读锁是共享锁，一个人读的时候，其他人都可以读，但是读的时候不能写。 写锁：写锁是独占锁，一个人写的时候，自己可以读；别人不能读也不能写。 备份数据，应该是所有的数据库都是统一的时间节点，所以需要加服务器级别(也就是实例级)的锁。此时如果备份1小时，那么就锁1小时，用户就无法访问了，业务影响比较大，这种情况也是有办法解决的，在innodb里支持事务，事务可以并行访问。 存储引擎就是自行实现的锁，比如innodb的行级锁，是自动的锁，也叫隐式锁。 显式锁：用户手动加的锁。 自己加了个读锁，自己也不能写了，只能读。 别人能读，但是无法写。 以上就是一个经典故障案例：当然是软件层面读锁导致的，软件打开了读锁，怎么处理呢？ kill调哪个starting的进程：使用kill 3; 此时再看之前卡在那的那个update就发现，能够执行下了 上图可见卡了5分钟👆。 写锁，自己可以写可以读 有人加了写锁，别人就不能读不能写 枷锁还可以用FLUSH命令，不加tb_name表名就是全部实例加锁。 FLUSH TABLES [tb_name[,...]] [WITH READ LOCK] 可用在备份实例的时候进行全实例加锁。 自己查是OK的 别人查也是OK的， 自己写不行了 别人写也卡住了 创建用户也不行，因为创建用户本身就是在mysql数据库的表里插入用户， 使用innodb的时候通常因为有事务的机制，往往不会人为的去加锁，因为事务会自动加锁。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-07-03 10:26:35 "},"25-MYSQL数据03/3-事务特性和四种隔离级别.html":{"url":"25-MYSQL数据03/3-事务特性和四种隔离级别.html","title":"第3节 事务特性和四种隔离级别","keywords":"","body":"第3节. 事务特性和四种隔离级别 事务的概念 事务Transactions：一组原子性的SQL语句，或一个独立工作单元 事务日志：记录事务信息，实现undo,redo等故障恢复功能 ACID特性： A：atomicity原子性；整个事务中的所有操作要么全部成功执行，要么全部 失败后回滚 C：consistency一致性；数据库总是从一个一致性状态转换为另一个一致性 状态 I：Isolation隔离性；一个事务所做出的操作在提交之前，是不能为其它事务 所见；隔离有多种隔离级别，实现并发。 ​ 隔离有隔离级别：一个修改事务过程中，另一个事务能否看到是取决于隔离级别的，比如你你修改1000未1100，别人不一定能看到1100。 ​ 一个事务没有结束，中间过程的数据就叫做“脏数据”。 D：durability持久性；一旦事务提交，其所做的修改会永久保存于数据库中 撤销叫做回滚，commit就确定了就永久保存在数据库中了。 事务日志类似于ext3的文件系统日志 1、100变成200，200变成300，然后还没来得及commit就停电了 此时后面来电mysql起来后，会对这个100->200,200->300的 事务日志 做undo撤销动作。 1、2、3本来只是完成到事务的日志记录，实际上并未提交 此时就是100大不了没有改成300，就是100不变。 事务日志已经commit提交的是一个完整的事务，就redo--在数据库里重新执行一遍写进数据文件里，没有的undo撤销。 所以事务日志里有redo日志和undo日志。 事务的执行过程 1、刚开始数据库是初始化状态 2、开始一个事务，事务开始的标志是：人工手动，或者 隐式的开始 3、事务中：增、删、改；查应该不算在是事务里了，看来不是说算不算的问题，而是你放不放的问题，你手动制动select就是事务里的，就是啦，隐式估计不放吧。 4、commit，如果事务确定要提交了也就是结束了，就是commit。相当于订单提交，不过也可能是加入购入车哈哈。 ​ 一旦提交就进了新的数据状态了。 5、rollback，回到原来状态。 事务的CLI 自动提交：回车就默认commit了 同样我的测试 主键就是理解成主键索引，同理唯一键也是等价于唯一键索引，比如你创建一个唯一键，其实就是默认创建了唯一键索引 drop index uni_age on testlog;删除唯一键，就可以使用存储过程插入了。 10万条记录，所以耗时13.74 看看我自己的测试 这个call执行完就是自动提交了，而且可能还是一行行的提交的，因为10万行嘛 你也可以改成像orcale一样的方式--默认不自动提交。 可以修改为不自动提交。 然后删除一行记录看看 删掉后，自己看确实删掉了 但是别人看--另外开一个终端ssh去看👇还在： 所以 1、修改autocommit自动提交为OFF 2、自己删除一行，自己看得到；但是属于事务中间状态的数据， 3、别人看不到；如果别人看到就是脏数据。 4、能不能看到和隔离级别有关，默认是看不到的。 这就是事务的隔离性，你没commit就不是一个完整的事务。 5、把shell窗口关掉，模拟事务没有提交的异常断开效果，看看undo效果 肯定的啊，这个动作不就等价于别人看嘛，还验证个啥哦。不过这里和别人看不到是两回事，这里涉及一个undo也就是rollback。 6、commit后别人所见不变；这还是 事务的隔离性，事务的隔离性后面讲，一共有4种。 自己删除25行后，提交后，别人还能看到25行 人为的起止事务 启动事务：下面3个cli照抄就行就是事务开始的cli BEGIN BEGIN WORK START TRANSACTION 结束事务： COMMIT：提交 ROLLBACK: 回滚 注意：只有事务型存储引擎中的DML语句方能支持此类操作 再加一条 撤销 一旦提交，就真的把数据库文件改了 但是我这边没做出来，奇了怪了，难道是mariadb版本太高了？ 我靠，什么时候改掉了，默认不应该是InnoDB吗 靠，删掉，重来一遍看看效果 emmm，删表，重建 好了，再试试call pro_testlog；的手动begin，整体事务的方式 1、直接call就是存储过程里的没一行都会默认自动提交，就会很慢 而且可见innodb的这个调用10w行的存储过程要比MyISAM慢的多的多，可能是MyISAM没有事务，也就没有事务日志，所以快？ 感觉下面begin可能时间也是和MyISAM一样，因为整个call xx就是一个事务，感觉相当于MyISAM的没有事务了。 2、其实innodb手动指定事务还是要比没有事务的MyISAM要快一半的时间。 3、结论innodb 调用10万行的存储过程，使用整体一个事务的方式，耗时也是要比MyISAM要快的，我的机器配置是4s的7s。当然老师的就是更快了，看前面的图1.55s。 以上就验证了 同样drop table这种DDL语言，不是DML语句，也不会支持rollback操作 发现DDL(drop create alter)语句是没法rollback的，这些是和select一样会记录到事务里，但是不是DML(INSERT UDDATE DELETE)，不支持rollback，自然也不需要commit。 事务支持保存点：savepoint SAVEPOINT identifier # 定义保存点 ROLLBACK [WORK] TO [SAVEPOINT] identifier # 回到对应的保存点 RELEASE SAVEPOINT identifier 就是在事务执行的过程种，在某个节点打标签，将来rollback到对应的savepoint。 现在表里加了3条记录 1、直接rollback就全部撤销了 2、rollback to aa_tran 3、撤销过了，一些savepoint没了就没了，bb_tran整个保存点也就没了。 事务的隔离级别 事务隔离级别：从上至下更加严格 READ UNCOMMITTED 可读取到未提交数据，产生脏读。 READ COMMITTED 可读取到提交数据，但未提交数据不可读，产生不可重复读，即可读取到多个提交数据，导致每次读取数据不一致 A分别在事务t1修改100为200，又子事务t2修改200为300， B在一个大的事务t3中，两次时间节点看到的值不同，前面是200，后面又变成了300。 B就在一个事务中读取到了多个不同的值，这就是产生了 不可以重复读的结果，因为重复读数据不同了。 REPEATABLE READ 可重复读，多次读取数据都一致，产生幻读，即 读取过程中，即使有其它提交的事务修改数据，仍只能读取到未修改 前的旧数据。此为MySQL默认设置 说明repeatable read可重复读，就是B在整个事务t3的执行期间，每次读取的数据都是一样的。从结果上来讲就是可以重复的去读数据，数据是一致的。 ​ 但是！数据早就改掉了，甚至删掉了，结果B还是一直认为数据还是原来的样子，这就是幻读。 ​ 结论：虽然可能存在幻读，但是恰恰就是保证数据一致性了，所以这个就是mysql的默认机制--mysql默认事务隔离级别为“可重复读”。 ​ 举例：备份期间，如果以事务开始，就是备份的前敲一个begin的意思了，无论备份执行多久，数据就是一开始时候的样子，是不变的，哪怕别的用户提交了修改数据，在备份的这个事务期间都是不变的，带来的好处就是：数据的一致性，就是在以事务方式进行的备份中，数据都是一个时间节点的数据。 SERIALIZABILE 可串行化，未提交的读事务阻塞修改事务，或者未 提交的修改事务阻塞读事务。导致并发性能差 ​ 就是我读的时候，别人不能改；我改的时候，别人也不能读。 ​ 优点：数据很可靠；缺点：无法并行了。 MVCC 多版本并发控制，和事务级别相关 并不是4个隔离级别都能用上这个MVCC 事务隔离级别对比表 说明： 列上的 \"不可重复读可能性\"，就是读出来数据可能不一致，就不能重复读了，就是这么个意思。 read-uncommitted和read-committed都能读出不一致的情况的。 幻读可能性： 所以：前3个read-uncommitted、read-committed、repeatable-read都能出现幻读。 问：事务和锁的关系： 答：就在上表最后一行啦，串行化事务里就会加读锁。总之锁是锁，事务是事务，锁是并发读写保证数据一致性，事务时讲多个操作看成一个原则来保证数据一致性；前者多个用户I/O数据库的一致性；后者是多个一系列操作的原子性或者叫一致性也行，而且后者事务还提供了隔离级别，这个就是会造成和锁理解冲突或者联系的点。 四种事务级别的设置 默认级别： 可见这是一个服务器变量，这个是不是一个服务器选项呢。 1、官网查咯：该参数不是服务器选项👇 2、自己试咯： 详情倒是没有指明是这一行，不过有unkown variable这个未知变量 该关键字可以联系起来 然后注意看 这是mariadb里的 这是mysql里的 这个transcation_isolation(只是一个选项)，用来对应tx_isolation(只是一个变量) 其实眼神好一点，一开始查到的是可以看到了 同样mariadb也有 继续修改配置文件 OK啦 此时变量就改过来了 开始体会下事务 1、第一种事务级别read-uncommitted 两个窗口都开启事务 左边的用户insert一条记录，但是没有commit， 此时由于事务级别是 READ-UNCOMMITTED 这就是脏数据了 然后左边的用户rollback撤销 左边用户自己肯定也就没了 右边用户自然也就同步了 这种情况对于右边的用户，看到了事务中间过程的数据--未提交的就是脏数据，然后换个角度来讲，对于右边的用户来讲，这个\"33 zz\"行 一会出现，一会又消失，就是幻读啦。 2、再看看地中事务级别-read-committed 重启服务后看下当前两个窗口的事务级别： 左边的用户插入 左边自己自然可见 未提交的时候，右边用户select是看不到的，因为当前事务级别是read-committed 然后左边用户commit提交一下 此时右边的用户就看到了👇。 虽然上面演示完了，但是存在一个点，就是右边的用户开不开其事务，其实在这个实验中效果是一样的，已测试。 存在第二个点，这个是疑点，就是用户begin;开启事务后，你别的人重启数据库，然后该用户虽然界面看起来没有变化--还是在myslq交互界面里的，但是他继续commit就会报错了，当然commit之前insert的数据其实就丢了。看下面的过程演示：👇 1、用户begin一个，然后insert一行，未提交 当然自己可见：👇 还未commit哦。 2、别的用户重启服务 3、回到左边的用户，myslq还是登入着的 但是像接着之前的事务，进行commit，就发现报错了，server has gone away 然后实际上，之前的insert 记录就丢了，下图👇39记录o5o就没了。 3、看第三个事务级别repeatable-read 重启服务，哦，对了删掉，这是默认的事务级别，不用特地手动写。 确认事务隔离级别 开始实验测试可重复读的效果 可重复读嘛，就是B一开始读了后就不会变，但是要注意右边窗口要开启事务的，左边随便开不开都一样，因为这个级别就是可以重复读机制。 左边删了好多，并自己可见，且commit了 右边还在 右边用户只要退出自己的事务commit一下，就可以看待最新的数据了。 所以这个默认的repeatable-read重复读机制是说的一个用户开启了事务后，重复读的结果一样不变，适用于备份，也就是说备份的时候要开启这个事务日志来备份。 4、第四个也就是最后一个事务级别serializable 重启服务后确认 这种begin只是开启事务，但是没有读也没有写，所以不叫 \"未提交的读事务 \" SERIALIZABILE 可串行化，\"未提交的读事务\"阻塞修改事务，或者未 提交的修改事务阻塞读事务。导致并发性能差 此时右边有一个 未提交的读事务 ，所以其他人的 修改都不可以了，看下 此时右边窗口随便开不开事务了应该， 开启事务也是一样的效果 插入一样阻塞在那 这个时候，只要左边的窗口提交commit一下，右边卡住的就可以继续进行下去了。 时间太长也不行， 上图commit也可以缓存rollback一样的效果。 commit是提交+退出了事务，rollback直接是撤回+退出事务 19.254sec的耗时👆， 上图的毛病在于，右边的查看要开启事务的，才会被阻塞；不开启不会被阻塞 ①未提交的读事务，可以阻塞别人的修改事务，别人读，开不开都会被阻塞。不影响别人的读； ②未提交的改事务，可以阻塞别的读事务，但是别人需要开启事务，在事务里读才会被阻塞。不影响别人的改。 恢复默认的事务机制后，研究下死锁现象 死锁现象 这里有两张表t1和t2 1、A用户去需改t1表，B用户修改t2表。互相没关系咯应该~ 2、innodb是行级锁， 现在A 修改t1表的100行 ，那么那个100行就lock了 B修改t2表的200行，200行lock 各改各的，没关系吧 此时，新的动作来了A又尝试访问t2表的200行，B呢又尝试访问t1表的100行。 此时就出现了 一跟独木桥，两个人走到中间的情况 这就是死锁了，死锁不用担心，因为数据会自动发现，会自动选择一个事务牺牲掉(rollback撤销掉)。牺牲哪一个呢？哪个下的成本大支持哪一个，放弃另一个，所以基本就是看执行时间哪个久一些，就放弃另一个。实验看下是不是这样的👇 所以接下来看下死锁的实验 1、两边都开启一个事务 2、然后用两张表来模拟一个是students表，一个是teacher表 左边用户相当于用户A，update一下，注意哦之前是两个用户都开启了事务的。 左边修改teachers表：相当于这个 右边的窗口就相当于用户B去修改一下teachers表 各改各的，目前不相干还。 然后左边A同样改右边B已经改的那一行 因为B已经加了行锁，注意实验的时候会超时哦，上图会自动断开的，趁着还没断开，去右边的B用户执行一下A已经加锁的哪条命令， 会立马发现两个现象 ①B命令敲下去的瞬间，就会报错 ②同时A卡在那边的继续进行下去了，就是A人家已经干了那么久，系统就优先保障A了。 一些猜测 左边A 右边B 此时 左边A可以读右边B修改的那个表的 同样右边B也课可以读左边A修改的那个表的 不是说写锁是别人不能读的嘛？ 如何解决死锁的问题 死锁的原因是👇 避免死锁就要规范用户行为 查询的次序是一致的。上图可以避免死锁，不过锁还是在的哦，就是 A改T1表的时候，B去改就阻塞着，等就行了，不过现在又超时机制的，也没事，就是死锁是程序问题，而正常的锁就是阻塞超时就行了 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-07-06 18:54:09 "},"25-MYSQL数据03/4-各种日志管理.html":{"url":"25-MYSQL数据03/4-各种日志管理.html","title":"第4节 各种日志管理","keywords":"","body":"第4节. 各种日志管理 已经删掉了这一行，且提交，由于默认的事务级别是 \"可重复读\"，所以另一个窗口由于实现开启了事务，所以还是可以看到整个被删掉的数据的。 既然这个用户出现了幻读，那么站在他的角度就是可以改的，看看效果 结果发现没有变化 delete也看起来可以敲下去，但是并不会变化，幻读的结果还是比较稳定的，这种\"可重复读\"的机制，不仅仅是当初修改的人怎么修改提交，这边都看到的是进入事务的时候的看到的值；而且不管自己怎么改、删，自己看到的值还是当初进入事务的时候看到的值，所以这里又对REPEATABLE-READ有了新的认识。 而且敲下去显示的结果是0行受到了影响。 事务日志 MyISAM是没有事务日志的，所以改数据是直接修改的，怎么个直接修改呢，就是把数据库里的数据调到内存里，内存里改完后，直接覆盖到磁盘上的数据库的文件里去了。 InnoDB是有事务日志的，是把数据库的数据调到内存中，把内存里的数据修改后，存放到事务日志中，把什么存放到事务日志中，把内存中修改的过程。事务日志操作一段时间后，再把数据库的更改写入磁盘里。 ​ 写入事务日志有磁盘I/O，将事务日志的更改写入数据库也有磁盘I/O。效率就收到影响。但是多了一层I/O也没有太大问题，因为两个I/O没错，但是事务日志的I/O其实就是类似echo xxx >> filexxx 这种顺序磁盘I/O，然后有无事务都涉及的数据库的修改的磁盘I/O这个是随机的，因为你也不清楚数据库上修改的是哪一行，哪一个数据块（因为你可能是改的第一条记录，也可能是改的第二条记录），所及磁盘I/O。 ​ 事务日志就是追加的磁盘I/O，是顺序性的。所以性能消耗没啥。 预写式的，write ahead logging其实就是，有I/O log的一半都是先写日志，再写磁盘，类似ext3文件系统。 数据库的日志文件 事务日志 transaction log 1、规范：和数据文件分开放，好像log和data本来就得分开来，就像程序和data一样--否则项目程序文件移植后，数据混在里面会有问题。 我遇到得问题就是我是 windows本地编辑，远程调试得，结果呢数据也是放在同级别的代码目录的，所以我的windows上的项目程序里式没有数据的，而远端linux上的项目文件里是有数据的。移植起来就不能说windows同步到另一台linux上，这样没有实时数据支撑，代码的结果可能就不是最新的也就不对了。 2、事务日志的相关信息 innodb_log_buffer_size： innodb_log_file_buffering： innodb_log_file_size innodb_log_group_home_dir 事务日志存放路径，默认写的是相对路径./ 其实就是当前数据库的路径也就是/var/lib/mysql/下，具体的文件就是这两个文件ib_logfile0和ib_logfile1。写满0号文件，然后去写1号文件，写满1号文件后再覆盖0号文件，就是这样来回写。 ​ 为什么是2个，因为变量innodb_log_files_in_group，同时它也是服务器选项。但是我修改了重启服务后，还是看不到该变量，不过默认倒是1，因为ll /var/lib/mysql里就看到1个ib_logfile0。 参考一下视频里老师的变量情况吧，聊胜于无看看呗 上图👆这个file_size就是ib_logfile0/1的大小5M，而in_group 2就是有两个ib_logfile0/1的原因。生产中 大小和数量都需要调大一些。为什么呢，举例①如果一个大事务，第一个文件ib_logfile0写满了，然后写ib_logfile1又写满了，然后有翻过头来写ib_logfile0这样一个事务日志都不全了。 此外上上图还有个buffer_size8M，是缓存 还有个bock_size块大小，512字节， 顺带一提ibdata1就是 包含了 数据库的数据+索引。当使用服务器选项innodb_file_per_table后就会拆分出来放到每个数据库目录里，具体见https://oneyearice.github.io/25-MYSQL%E6%95%B0%E6%8D%AE03/1-%E7%B4%A2%E5%BC%95%E7%B1%BB%E5%9E%8B%E5%92%8C%E7%BB%93%E6%9E%84%E5%8E%9F%E7%90%86.html?h=innodb_file_per_table 看下重要变量： innodb_flush_log_at_trx_commit 看到了1这个值，其实一共可以设置成0 1 2 3 ，共4个值。 注意哦，不是数据库文件的写入哦，是logfile--是日志文件的磁盘写入--是以这个作为数据的最终存放目标来讨论的。 1、理解buffer(缓冲)和cache(缓存)，浏览器的叫什么叫cache 飞机着陆叫什么缓冲，所以一般来讲，读-缓存，写-缓冲。 2、上图没有画出来的是磁盘里面也有自己的缓冲buffer。 3、然后才是上图本身要表达的意思 0 ，该机制，当你insert into tab 并且提交的时候；首先提交到日志的缓冲log buffer；然后每秒写到系统内存并且紧接着写到磁盘里去，到了磁盘自然就是磁盘的缓冲啦，那个这里不讨论。 1，该机制，插入，提交后；首先一样也是提交到logbuffer里，于此同时立刻写到系统缓冲里紧接着写道磁盘里，就是说commit一提交，就直奔磁盘去了，中间该走的log buffer,system memory就按部就班的走。 这个机制磁盘I/O消耗大，磁盘停不下来。 2，该机制，插入，先提交到logbuffer里，紧接着写入os cache，然后1s一次写入磁盘。也就是说你可能1s中有大量事务并发到os cache里后，才会一起写入磁盘，这就降低了磁盘的I/O。 缺点：1s没到呢，还没写磁盘呢，如果此时有100个事务已经提交logbuffer+写入os cache里，此时断电了，还没写入磁盘呢，所以数据就丢了。是确确实实丢失了100次事务，100次的订单提交，100次啊，一百遍,一百遍,啥看不懂，唐伯虎点秋香啦。 其实很好理解和记忆啦 你要问我推荐哪个，我从来不推荐，我强制你用1，哈哈~，买高IOPS的硬盘得了。 你看哦，之前我们提到事务日志的好处，就说了如果没commit提交断电了故障了，于是有这个undo，如果commit了出了问题就会redo。 ​ 那好，问题来了，commit了，0 1 2 甚至没讲的3 都出现问题，怎么不redo了？啊，啊字在这里是语气助词，表强调，恩，恩在这里也是语气助词，同样表强调，对，对在这里...哈哈哈，哈哈哈给个屁，傻逼东西，redo是会发生的，人家讨论的是事务的ACID没了，又没讲redo不做了。这是两码事，事务的commit后数据没落地本身就丢失了一致性，但是还有redo来保证，也许可以用2这个机制？ ​ 研究下这个redo 和0 1 2的问题； 回答的太好了，虽然我没看懂~但是它明确的知道了redo和事务日志优化0 12 的区别。 redo不能保障ACID，同样事务日志commit提交按理说能够了，其实commit，哦我知道 总结 1、事务的ACID是通过一系列操作的整体堪称原子，原子性，就是要么都行，要么都不行。所以commit提交了意味着一个原子诞生了，了结了。但是从实际上来看，commit了，数据其实可能是还没落到磁盘上，甚至除了问题都不会落到磁盘上！所以事务的原子性没了！所以1 commit直达磁盘的机制会更加能够保障ACID。 2、再来说redo，可能就是commit了，但是数据库文件里没有，他就redo了。 不知道瞎几把讲的什么东西~，继续学，后面好像专门有讲redo日志。那里肯定有我要的答案。 mysql的磁盘I/O是比较频繁的，监控一定要做磁盘I/O的。 事务日志要放在一个专门的性能好的磁盘上，SSD固态是必要的。①事务日志是顺序往里写的，不存在随机访问的问题，要放在干净的独立的哪怕不是一个硬盘，至少是也给分区也是好的。为什么分区/磁盘要独立的啊，因为你不把事务日志独立开来，你和其他日志也好，数据也好合在一起，虽然事务日志是顺序的，但是一个分区来看数据块由于还有别的日志/数据往里写，所以数据块(磁盘空间)对于事务日志来讲就不是连续的了。什么磁盘碎片化就不连续了。 ​ 那么放到一个独立的磁盘或者分区就是修改这个值了 1、加一块硬盘2G的 我用的VMwareWorkstation 2、发现硬盘 3、分区 看情况lsblk看不到就同步一下👇 4、格式化 5、挂载 创建文件夹用来挂载 挂载 修改所有者所属组为mysql 6、修改mysql的对应变量 重启后报错了 当然status也能看，但是对比journalctl看，可知 还是缺少文件的原因， 缺少就拷过去，就OK了，老师演示的直接就是重启自动生成日志文件了，无需像我一样复制或移动过去，不过我用的高版本的mariadb。 再检查下变量 这样就是得到了一个干净的分区，且分区时高速磁盘哦你要生产中换成SSD之类的硬盘的。 错误日志 error log 错误日志不仅仅时错误日志，还包含数据库的启动关闭日志也里面。一些重要事件可能也会放在里面。 我的mariadb时空值 还是和mysql不太一样，这个是默认空值，然后默认文件是 而且现在的配置方法也变了 视频里的默认值这是之前的版本 该值来源于 测试错误日志 重启服务后，就看到错误日志👇 报警信息log_warnings 这是视频里的值 现在的版本值是2，估计是level，从2级开始记录的意思咯，0就是不记录咯，我猜的。 告警也是放在error日志里的，只不过是👇用括号Warning括起来了。 一个error 日志里不仅仅是error还有很多其他的 通用日志 general log 记录的是各种数据库的操作，比如sql语句 中间断了一下重连了，就是因为另外开了窗口去添加了服务器选项打开了普通日志 通用日志的文件 此时就可以看到通用日志了，比如show 比如select 这个文件就是刚才①配置文件里加了选项②重启了服务后才生成的。本来generl_log是OFF，文件时不存在的。 然后写错命令也一样也看得到 一般不推荐启用，估计也就是找bug找故障的时候才会开一下，毕竟什么都记录太费磁盘，费IO了。 进一步思考，这些通用日志，本身也是数据，何不把日志放到数据库里呢！找张表放呗 这个值👇 FILE就是将log输出到FILE文件，改一改，改成输出到数据库也就是将FILE改成TABLE表，而这个表就是mysql库里的general_log表👇 好，改一下 此时日志就要去mysql.general_log里看了 这个通用日志可以用来干啥呢，有个debug的好处，就是程序开发写的web页面，页面上点点点比如购物，其实底层就是去数据库上select 的，可以看到开发程序上写的的sql语句是不是合适~是不是有优化的空间~。 慢查询日志 slow query log 1、打开页面慢，通过浏览器比如chrome的F12查看network的响应时间，也可以通过curl分析http的性能 curl -Lo /dev/null -s -w time_namelookup:\"\\t\"%{time_namelookup}\"\\n\"time_connect:\"\\t\\t\"%{time_connect}\"\\n\"time_appconnect:\"\\t\"%{time_appconnect}\"\\n\"time_pretransfer:\"\\t\"%{time_pretransfer}\"\\n\"time_starttransfer:\"\\t\"%{time_starttransfer}\"\\n\"time_total:\"\\t\\t\"%{time_total}\"\\n\"time_redirect:\"\\t\\t\"%{time_redirect}\"\\n\" https://oneyearice.github.io/ 一旦发现是TTFB耗时时间长，就可以判断是服务响应慢，而服务响应慢，基本上对于一个业务系统来讲，大概率就是数据库的慢查询了。 2、默认是10s 系统认为10s以上才是一个慢的查询，所以不行，得改。 而且只是有个10s的定界值，实际上没有启用慢查询日志，通过查看slow_query_log可见 同时3s就认为是慢查询了。 此时就看到了慢查询日志xxxslow.log 打开挂着看效果 然而并没有，原因就是我的配置里还保留这上一次配置的log_output=table这就是所有日志输出都不走文件， 查看就去mysql.slow_log表里看 恢复输出为文件 重启服务后 要注意都是DML语句执行结束后，那边才会有日志，当然慢查询日志可不是仅仅select，通过之前的call pro_testlog可知也包括了一个慢的存储过程--其中就是循环了很多次的insert。 · 另外log_slow_filter就规定了哪些类的查询会记录慢查询日志，就是当这些操作超出long_query_time的时候。一般不会改这个值，还有就是这里面没有列出的既是超出long_query_time也不会记录到慢查询日志里。 问题来了，如果一个查询速度没有超出long_query_time，但是有提速空间，比如没有利用索引，可以利用起来加速以下，这种查询操作能否也记录下来呢？ log_queries_not_using_indexes=ON，开启后就会同样记录在慢查询中。 默认是关闭的 开启后确认 此时，哪怕查询没有超出long_query_time，只要没有使用索引，也会记录在慢查询日志中。 select * from students where stuid=20; 这就会利用主键索引进行查询了 1、全表查询肯定不会涉及索引，此时慢查询里就有日志了 2、使用where查询对比有索引和没索引的日志 没有利用索引的就会log_queries_not_using_indexes=ON记录在慢查询里 你再看这个利用索引的查询 此时慢查询里就没有日志啦，因为这是利用了主键查询，是用到了主键索引的，所以log_queries_not_using_indexes=ON不会记录了。 再来，刚才select * from students where name='o6o';是记录在慢查询里的，现在添加name的索引后，就不会记录在慢查询里了。 mariadb的特有配置 log_slow_rate_limit ，就是慢查询达到一定占比此以上才开始记录到 慢查询日志里，图中将1改成5试试，所以这个5不是5次，而是5%的意思。 空的，然后输出格式是 改一下 重启后确认 但是要注意哦，如果连着两下或多次select同样的命令，就会有重复的日志记录了哦，因为有命中缓存了我觉得，所以就不会记录在不利用索引的日志里了。 复习下缓存吧👇 然后explain xxx 每次都是记录的 如果查到确实存在一条慢查询了，那么像继续深入研究下这条语句到底慢在哪里，可以这么看，一个负复杂的select语句说不定里面还带有子查询什么的，甚至涉及连接、多表查询等。到底这个复杂的语句中哪一块导致它慢了？ ​ 举例：select sleep(1) from students; 这个是每一行休眠1s的意思；该表里一共20几条记录，大概就要20几秒才能执行完。 通过tail /var/lib/mysql/tail -f django001-slow.log可见 我把这个slow_log的格式恢复成默认形式先 注销掉，恢复成默认空值👇 再看看slow_log就恢复成原来的简短格式了 然后继续深入研究慢在哪里，就得看profiling这个变量 简单点，就用cli开启了，不配置服务器选项了 然后再次执行慢查询的语句，当然此时就会担心会不命中缓存，不是哦，\"索引利用不到\"本该记录slow_log但是却命中缓存所以不会记录；而这里确实不会命中缓存，所以会每次都记录slow_log的。 然后show profiles可见 关注这个Query_ID，输入show profile for query 7;查看具体详情 可以看到sleep了这么多， 图中涉及一些时间 checking permssions 检查权限 opening tables打开表 等等，发现其中sleep 好多花了很久，而在生成中这个sleep很有可能就是某些sql语句。 👆这招很有意义的 再看个其他例子 默认是分开来放的👆 跑一下这个存储过程，就会导致数据库文件不断变大 然后以事务的方式跑这个存储过程 在跑到时候，就可以看到testlog.ibd这个数据库文件在不断的变大；就是说事务的写法不是说单纯地只写道事务日志里地，其实也会写道磁盘里的，其实就是那个事务优化地0 1 2级别好像是 不过我的这个以事务运行的怎么还卡这么久啊，都TM5分钟过去了 好了 此时记住这个数据库文件大小 此时rollback，撤销，数据就写入，理论上应该文件大小会缩回去，但是不是！ 大小是不变的 也就是说事务撤销了，数据不写到表里了已经，但是数据库文件大小还是涨上去了，不变地。 然后再看不以事务方式，就是真正地往里面添加记录了；注意此时testlog.ibd的大小还是上图的33554432字节。 等你执行完，真正添加记录进去后，就会发现testlog.ibd文件大小没有变化 1、rollback，后悔了表里的内容请了，文件大小不会缩回去 2、说明增加的空间大小，其实里面内容是空的，占了磁盘空间，但是里面没有内容。就相当于一个空文件。 3、所以如果把这个表整个情况了，还是一样的ibd文件大小还是不变 所以你就会发现命名数据都没了，数据文件大小还是老样子。数据都没了，还占什么空间呢。 4、所以可以做一下优化，optimize table testlog;整理一下， 之前的占用的空文件就释放了👇这样testlog.ibd大小就缩回去： 数据库的操作日志 用户账号家目录里的隐藏文件 二进制日志 binary log 见下篇 中继日志 reley log 见下篇 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-07-13 20:34:54 "},"25-MYSQL数据03/5-二进制日志管理.html":{"url":"25-MYSQL数据03/5-二进制日志管理.html","title":"第5节 二进制日志管理","keywords":"","body":"第5节. 二进制日志管理 介绍 二进制日志就是二进制数据，不是文本文件 上图可见之前学习的各种日志都是文本文件，事务日志也不是文本文件。 事务日志就是利用事务的操作记录，但是几个文件反复覆盖保存的，只是记录最近的操作，就几个文件来回写的。 二进制日志不依赖于存储引擎，不是说一定要支持事务才行。不管是MyISAM还是InnoDB都可以使用二进制日志。 二进制日志记录的就是对数据库的增删改，不清理的，不断记录的，如果能够打开这个二进制日志就可以知道，什么时间做了哪些操作。 默认二进制日志没有启用的，微软的SQL Server和oracle也是一样都默认没有开启二进制日志的，也是只有事务日志，其中oracle不叫这个名字，而是叫\"在线的重做日志\"；其中二进制日志叫\"归档(重做)日志\"。 二进制日志不仅仅是审计，关键知道做了哪些增删改，所以还可以做数据库的还原。 1、完全备份结合二进制日志就可以做到恢复数据 2、比如上图的周五数据崩了，你用周一2:00的完全备份+之后到周五的二进制日志进行\"重放\"就可以恢复数据。 3、启用二进制日志后，默认是和数据库文件放在一个目录下的。 默认sql_log_bin是开启的，但是还不够，磁盘上还看不到二进制日志文件， 还需开启另一个日志开关--log_bin sql_log_bin和log_bin都启用才行，才算启用二进制日志功能。 可能正常会觉的开关设置两个有毛病，其实还真不是，sql_log_bin可以临时在会话里修改，log_bin只能在服务器选项也就是配置文件里修改。 所以一般玩法：①log_bin在配置文件里开启②然后用sql_log_bin去临时关闭二进制（潜台词就是sql_log_bin就是默认开启的）③也就是说一般都是开启二进制，然后要临时禁掉就用sql_log_bin去在会话里禁掉就行了，而且也只是session级别的，不是全局的。这样就比较好些。 这里有个点，就是log_bin=ON和log_bin=1和上图只写log_bin的区别。都是开启，但是有文件名生成的区别。①log_bin=xx，二进制日志的名称就是xx.00001和xx.index②所以log_bin=xx，xx是用来表示的文件名的前缀。 而不管xx写啥，进去看变量都是ON的。 然后就看到二进制文件了，不过时间好像有点奇怪，不奇怪，看清楚啊，是一致的，只不过data看到的是PM，而ll看到的时间是+12的。 如果时间真的不一致，是因为mysql有自己的时区设置不是用的SYSTEM了吧，下图倒是用的系统时。 然后思考一下由于默认binlog是和数据库文件放在同一个路径下的，万一数据库挂了，宿主机挂了，都GG了。 所以：1、数据完全异地备份；2、二进制文件和数据文件分开也要异地备份 将bin-log放到别处 1、创建文件夹，同样最好单独一个磁盘SSD的，binLOG肯定也是和事务日志一样顺序I/O的。这里就利用之前事务日志存放的磁盘了做实验，实际生产中肯定要单独存放的。 文件夹也要注意权限 3、修改配置文件里的服务器选项，并制定路径和前缀 mariadb-bin就是将来生产的binlog的文件名的前缀，重启服务器后👇 刚开始就是330个字节，后面随着增删改操作越来越多，该文件就会越来越大，增长速度非常快；更可怕的是bin-log的大小要远远大于数据本身(testlog.ibd)的大小 二进制文件我们知道可以dump的，具体就是hexdump -C hexdump -C mariadb-bin.000001 不过不是这样看的，这样只是二进制的一个通用性看法，聊胜于无的看看。 一个call pro_testlog就是往testlog表里增加10W行记录， ①数据库本身增长多大 ②bin log日志增长多大：27M，近似于数据文件大小的2倍。 所以binlog要找一个 大硬盘、ssd的独立就给他存放。 此时如果将sql_log_bin置为OFF，此时binlog就不会增加了。这是种临时处理方法 注意一定是同一session，因为sql_log_bin我们通常就是临时在交互模式里手动改一下改成OFF的，所以必须在原来置为OFF的窗口或者会话里DML才不会导致binlog增长，别的会话不受影响--也就是别的会话如果有增删改还是会导致binlog继续增加的。实验就是在OFF的窗口进行DML，然后观察binlog就会停止增长。 说是DML，其实DML不涉及select查操作，也就是select不会导致binlog的增加， 二进制日志binLog存放的数据的格式 STATEMNT、ROW、MIXED 3种格式： 举例，delete from testlog; 这个testlog一共有10W行，问，binlog里记录的是一条delete语句还是删了10W条的动作。 1、STATEMENT：表示记录的是delete from testlog;本身这条语句； 2、ROW：表示根据sql修改的哪些行，就记录那行记录的，100W条删除就会记录100W条。 默认格式新版的mariadb是MIXED 改一下，然后看下STATEMENT的效果 由于STATEMENT只是记录你敲的原本命令行，所以binlog二进制日志大小增长的很少 现在改成ROW模式，看看大小增长的幅度，因为ROW模式是你虽然敲的是一条CLI，但是影响了多少条，就记下来多少条。 可以看到同一条delete语句，binlog选择ROW模式就要比STATEMENT模式，实际记录的内容多很多很多 再来，刚才STATEMENT格式下，delete from testlog;是一条语句咯，如果同样模式下用call pro_slowlog;就不是一条语句咯，这个存储过程里其实是2999条的insert，对吧，我们知道binlog，啊你们不知道，哦没事我知道就行了，我知道binlog呵呵，通过上文介绍知道binlog是记录了增删改的操作而不是存储过程的一条操作，所以一个存储过程里while循环了多少次增删改，就会有多少条需要去记录到binlog，而格式又是STATEMENT，所以此时binglog就记录存储过程里循环的insert条数了。 然后通过服务器选项--也就是配置文件里修改的方式来做binlog的格式修改 1、首先，你会发现重启服务后，binlog会新建一个文件来保存，原来的文件留着的。 不管你该不该配置文件，只要重启，就会另外创建binlog文件。 对比下STATEMENT和ROW 举例，update test set col1=now(); 这句话就是把col1列改成当前时间，如果你用的是 ①STATEMENT，就是这句话原封不动记录下来，这就危险了，十天后DB故障，你恢复就会错误的恢复成现在的时间，而不是十天前的时间。 ②ROW，就不会，就会真正的记录当前的时间，而不是now()这个函数本身，所以就可以保真，所以生产种推荐使用ROW格式。 但是为什么是MIXED默认呢，也许MIXED才是比较合适的。 首先ROW太占空间了对吧，既是数据库自身判断，如果安全起见就用ROW比如它发现insert里有now()可能就会用ROW，而发现没有歧义就可能节省空间使用STATEMENT格式。 二进制日志可以定义自动删除规则 通过expire_logs_days来做，默认0就是为空了，就是不限不删除 反正要监控磁盘的 二进制日志的最大值 max_binlog_size 最大值size文件满了怎么办，没事就新建一个呗都是自动的。 syn_binlog类似事务日志的优化级别012这种 就是是否理解写磁盘，就是binlog文件里先不捉急写，先放在缓存里； 事务日志那会讲过类似的机制，是数据不捉急写磁盘文件里，而是先写内存里再写道磁盘的日志文件里。 syn_binlog=1：只要发生二级制binlog就立即写磁盘logfile，当然这里的logfile就是binglogfile。 这种和之前事务日志1一样会带来磁盘I/O飙高不是合适。 syn_binlog=0：就是操作系统来决定什么时候同步到日志文件，哎，是OS啊，我以为是数据库呢。哦对的，是数据由mysql放到OS的缓冲buffer区，然后就交给OS自己调度了，人家OS看系统进程资源去安排调度什么时候轮到你写道磁盘文件里去。 index文件就是记录了一共由几个binlog binLog的管理方式 是通过mysql自身命令来操作的 1、比如看binlog大小，不用跑到磁盘上去ls看，肯定一样的 show binary 和show master一样的哦。 2、显示当前正在用的binlog文件信息 注意这个344看着是Position位置，其实对比上上图344就是文件大小的意思。当然叫position位置也没错，就是新发生日志数据往这个位置以后去写的意思。 这个Position位置有啥用，首先大小字节是它的单位，将来操作的时候就知道从这个position之前的是旧数据，用于定位恢复数据的。 比如：早上10点不小心执行了一个drop table误删了表，就可以通过binlog把删表的这个位置给找到，找到这个位置用来定位故障点，进而想办法来还原数据库。emm这边比如比如的不太好，后买你看例子吧。 后面两个参数是数据复制用的，后文讲。 3、查看binlog内容 cat基本是乱码看不掉，虽然binlog不是纯粹的二进制文件，cat可以看到一些明文信息，但是肯定不能这么看啦 show binlog events in 'binglog文件名称'就行了 上图看了寂寞，是个空文件，看看实的吧 show binlog events in 'mariadb-bin.000001'; 👇 具体的cli完整版是这样的，还可以指定查看的日志的位置 记住这个位置899722 现在就开始操作这个表，比如insert一条记录 位置从刚才的899722→899980了 所以查看binlog就从这个位置开始去看show binlog events in 'mariadb-bin.000003' from 899722; 可见确实有一条操作记录insert，其实老版本里面是ROW格式的binlog是看不到这个原来的insert语句的，估计还需要打开某个开关才能调出来，老版本的截图入👇。 其实这行就是insert的ROW记录了，write_rows就是写记录了。 下面一行还有一个commit提交。 再插入一行 现在版本里event_type列里有Annote_rows可以明确写出来你敲的命令，还是挺省心的。 以前版本就只有delete_rows,write_rows可以参考，不过可以调出来应该。 这里的show binlog events in 'mariadb-bin.000003' from 899722 limit 2,3; 就是从899722开始，limit2，3就是跳过2行，看3行。 mysqlbinlog专业工具 mysqlbinlog --start-position=899722 --stop-position=899753 /data/logs/mariadb-bin.000003 这个--stop-postion不写就是默认看到最后 也不是加密咯，是base64编码。然后这个base64编码的特点就是用于网络传输比较规范。 加一个-v就能看到了 目前是ROW格式，我们看下delete from students;的记录 还有，别急，这个cli截图还有往下开，要注意上图👆的#Q> 标识，这就是原始sql cli了。而下面的就是ROW格式所记录的影响到的所有行的操作记录。 所以ROW格式，其实就是影响了多少行，就结论多少行的。 然后注释掉 就是变成statement语句型的格式了 得~新版本是MIXED，算了就看看混合型得了 MIXED混合型，系统自行判断得，显然这里不是ROW，否则就是记录4个delete动作了 再看一个删除操作，这个表行数多，效果也明细 就一条~， 数据重做 mysqlbinlog --start-position=508 /data/logs/mariadb-bin.000004 -v > /data/test.sql 具体怎么还原，下一篇整理。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-07-14 16:00:47 "},"26-MYSQL数据04/26-MYSQL数据04.html":{"url":"26-MYSQL数据04/26-MYSQL数据04.html","title":"第二十六章 MYSQL数据04","keywords":"","body":"第二十六章 MYSQL数据04 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"26-MYSQL数据04/1-数据库备份和还原原理详解.html":{"url":"26-MYSQL数据04/1-数据库备份和还原原理详解.html","title":"第1节 数据库备份和还原原理详解","keywords":"","body":"第1节. 数据库备份和还原原理详解 binlog重置 flush logs刷新binlog日志，就是重新新建一个binlog。 清除binlog，可以rm，但是肯定没有purge来的专业 删除binlog日志文件3之前的日志、删除某某时间之前的日志。 不仅仅文件删掉了，Index文件里的内容也更新了。 reset master 初始化binlog文件名称。 reset master to No 初始化的编号人工指定。 相当于把原来的二进制全清空了。 备份概念 差异备份 1、周日是1T的数据做了完全备份， 2、周一做了差异备份，100G的差异做了备份，问题来了，增、删、改都是差异，这写备份的细节是什么，增100G很好备份，改100G呢，我认为就是所以变化的行就都会备份下来的。 3、周二的差异备份，就是从周日开始的差异，而不是和周一比较的， 4、周三周四的差异备份，都是和周日比较的。 5、假设周五的时候数据坏了，还没备份呢，此时如何还原。 6、先还原周日的数据，再把周四的备份还原一下，就行了。 7、周四的差异备份既然是从周日开始的，问，周三的差异备份是否可以删了，周一、周二同问。不能删！因为如果有一个操作时周二和周三之间做的，你想还原到这个操作之前就可以还原到周二的差异备份。 8、周五差异备份还没做，数据崩了，用周日全备+周四的差异将数据恢复到周四备份的那个点，那么从周四差异备份后到周五数据崩溃的时候，这段时间的数据如何恢复，此时就靠binlog了。此时由于binlog日志通常是独立磁盘进行存放的，所以既是数据库坏了可以利用binlog的。 增量备份 1、就是周日全量，周一基于周日的差异，周二基于周一的差异，周三基于周二的差异。 2、故障点如图，如何还原，周日、周一、周二、周三，依次还原，然后再用binlog日志来重做。 3、事实上，msyql的所谓的增量备份，配合一个mysql备份工具，底层用的就是二进制日志。就是每天复制二进制出来作为增量备份来着。 数据的备份策略怎么指定，和业务需求和数据库的大小有关的。 备份方式 冷备：读写均不可操作 1、简单粗暴，就是cp -a /var/lib/mysql 全部复制出来，同时看看log放在哪里的，也一并cp -a ①、比如mysql.sock这个sock文件服务一停了就没了，也无需备份的。 ②、performance_schema这个也不用备份，和性能相关的。 2、配置文件/etc/my.cnf 或者其他地方也有的配置文件也要备份下来。 实验来一个：👇 另外开一台linux，然后将之前的linux上的db备份还原过去。 ①打包数据库 便于网络传输，这点还蛮能提高效率的，一般人get不到这个点，因为如果不压缩，就是散文件，而散文件的传输存在N次TCP的慢启动，所以速度永远上不去；而tar一下后就一个整体文件，此时慢启动慢慢的启动后，达到传输的最大值了就。既然打包了，顺便也压缩一下更加便于网络传输拉。 使用J就是xz的压缩格式 压缩比还是不错的 ②打包binlog ③/etc/my.cnf配置文件也要备份 ④合并一下scp到另外一台机器上 会自动创建/databack/文件夹，结尾的/也可以不写。 ⑤然后去新的一台linux安装maradb-server 要考虑mariadb的版本兼容性，最好是一样的。我这个都是这几天yum安装的，版本问题不大直接yum -y install mariadb-server确认下就行 我靠，版本低了，删掉重做，我才用undo 的方式，一并卸掉之前安装低版本mariadb的时候安装的依赖包 先undo 16，在undo 15 然后找一下原来10.11.2的版本 ①找到原版本的思路有2，第一个就是去原来linxu的yum源文件看 ②就是去mariadb官网找10.11.2啦，一般可能就是10.11也就OK了 https://mariadb.org/download/?t=repo-config&d=CentOS+Stream&v=10.11&r_m=neusoft 发现及时用原来的yum源文件，此时安装也已经是10.11.4了，没关系，继续 注意安装后的检查也要使用大小写的，虽然yum的时候不分大小写，但是rpm检查的时候却区分大小写的。 ⑥此时由于服务没起，所以/var/lib/mysql下还是空的 然而并不是，我发现里面安装后有东西 删之~ 覆盖也行，好习惯cp的时候cp -a 啊，还有 -b 啦 然后binlog复制过去 担心父目录权限？ 默认有x就行了， 错了错了，无需事先创建文件夹，直接解压就会自动递归创建所需目录 权限也是OK的。 关键你是带目录压缩的吧，你试试当初不是tar -Jcvf /var/lib/mysql 估计就不行了 启动服务查看数据是否过来了 都OK了没问题 冷备的缺点是需要停服，好处是备份快，但是一般用不上，除非已经停了或者就是要维护一下，可以顺带cp一把。 温备：读可以，写不行 热备：读写均可以操作 热备是比较实用的，据说是读写都行，不知道性能是否受影响，然后MyISAM不支持热备，只支持温备--备份的时候不能写只能读，InnoDB是读写都行的。 你做备份的时候，热备的时候，本身是支持读写，如果有大量的增删改操作，你备份的数据其实就不是可靠的！因为数据本身都在变，要保障备份数据是一个时间点的所有数据状态。虽然备份这个动作的过程是半小时，但是备份的数据必然是一个时间点的所有数据。 1、如果是锁表不让写，那么就是温备了，MyISAM就是加共享式-读锁，不能写了就，进行温备。 2、其实很自然就想到事务的级别里的 \"可重复读\"的隔离级别，利用这个来做备份，记得将事务的上文里肯定也提到备份例子的。 3、mysql这个系统数据，到现在也还是基于MyISAM的，不是！老版本还是得，新版本都是Aria引擎，而且mysql.user也只是一个VIEW视图了，本身上还是 即使现在Aria引擎，也不支持事务 aria其实可以理解为不支持事务，但是有一点点的修正就是 https://mariadb.com/kb/en/aria-storage-engine/ 涉及到mysql这个库的，一般就是账号、授权、存储过程这些了吧，一般这个库不大，也不怎么变动。这个库就是不管是早期的MyISAM引擎还是现在的Aria引擎都不支持事务级别去做热备，不过由于这个库和业务不想管，别人也不会频繁去读写它，所以完全可以做温备--也就是加上共享锁，不让别人写，这个时候再去备份就是温备就行了。 通常就是热备针对业务数据库，温备就是针对系统库mysql这种。冷备就是停服维护的时候复制便捷。 物理备份 冷备就是物理备份，或者磁盘dd if=/xxx of=/xxx ：注意一下如果是冷备的复制文件，要知道即使看到文件的大小是比如100G，但是可能很多表格里都是空的也是有可能的，前面章节👇就讲过optimize整理一下表格就释放了。 一般来讲，不可能让你运维进到db的库里去optmize的，所以运维人员如果做冷备，其实就是明明知道实际数据可能没有这么大，也还是要复制这一堆文件的。也就是说冷备存在空间占用较大的情况，说白了就是有点浪费空间。 逻辑备份 逻辑备份时备份的实际数据，是把数据抽出来，进行备份。 而且也不是热备或是温备，而是相当于一个大的select ，所以和存储引擎无关。 缺点：相当于一个大的select，内部的一个client和server的sql语句啦，就是交互的cli方式，效率是低的。再一个就是如果数据库里存放的是二进制数据或是其他非文本数据，导出来的时候可能就会失去准确性。 1、数据肯定要备份的， 2、事务日志如果是正常stop服务，事务日志的记录其实都是已经写到文件里去了，当然最好是也备份一些；二进制日志一样最好也备份。 3、程序代码，这些存储过程、函数、触发器、事件调度器，这些其实不推荐用的，但是有的就用了，此时就需要备份了。不过这些比如存储过程，好像都在mysql系统库里的。 4、然后就是服务器的配置文件，也需要备份的！ 上面讲了备份的一些概念，冷、温、热；物理、逻辑，其实也就是一个冷备进行了操作，下面解释备份工具， 1、cp、tar、chown改权限这个都是冷备，或者是/etc/my.cnf配置文件的备份。 2、LVM利用逻辑卷的快照，这个一般来讲还是比较快的，我的泛微OA 500G的EC，快照在15分钟的样子，当然不包含sqlserver哦，那个是物理机windows的。做法就是①加读锁，②做快照，不过我的泛微OA是vsphere快照要15分钟唉，难道LVM的快照会秒做的？ 视频里老师说是几乎是1s就做完了，几乎达到了热备的效果，所以写个脚本先做读锁，在秒快照，然后解锁恢复。 但是生产中用了VM的快照来做数据的备份，这种方式是用的不多的。 (5) 解释一下：快照里的数据其实是老数据，你不是lock了嘛，挂载一下看到老数据，直接cp出来，这里就和冷备一样 (6)解释一下：快照里的东西cp出来后，完成备份后，立马要删除快照，否则一旦有新的数据发生变化，量一大，就会生成原始数据（什么意？就是快照里的东西你看得到其实还是老数据，只有这些老数据发生变化了，才会真正地生成一份老数据落下来，所以有问题的还是，因为数据没变，老数据其实是链接，你解锁后，哎没关系啊，解锁后发生变化大不了，老数据就从链接变成了真实的落地数据不就行了么，也不影响你的复制的时间一致性的） 当然这个LVM的快照本身不涉及conf文件和binlog的。 mysqldump属于常用的备份工具，不过这个是针对全备的，其他差异、增量 都不支持的其实，他的增量备份是借助于手工处理binlog来实现的。 xtrabackup是支持各种复制的备份，全备、增量都OK，是直接cli就支持的。 mariadb backup是高版本的mariadb才支持，不过这个视频是好多年的了，现在用基本上就支持了，然后这个mariadb backup是基于percona xtrabackup2.3.8也就是上面一个备份工具做的二次开发，个人感觉可能更优秀。 mysqlbackup，听名字就是mysql的专用，然后也是收费工具。他其实就是MySQL Enterprise Edition 企业版的功能来着。 mysql是orcale公司的，做了两个版本，一个社区版，一个是企业版。 mysqlhotcopy，名字里有hot，其实是冷备来着！是perl语言写的，这个perl语言本身国内用的就少。 稍后重点学习mysqldump、xtrabackup，然后个人觉的mariadb backup也要学，应该看着是优化了的。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-07-19 14:59:51 "},"26-MYSQL数据04/2-mysql备份还原mysqldump使用.html":{"url":"26-MYSQL数据04/2-mysql备份还原mysqldump使用.html","title":"第2节 mysql备份还原mysqldump使用","keywords":"","body":"第2节. mysql备份还原mysqldump使用 mysqldump mysqldump是mariadb-client安装的时候就自带的 查看mysqldump的帮助信息： -A 也不是真的如上图所说是all-databases，不会备份information_schema，也不会备份performance_schema， 比如可以这么写 mysqldump hellodb # 必须指定一个数据库 mysqldump hellodb students mysqldump hellodb mysqldump -uroot -pxxx mysql 对 mysql这个系统库进行备份👇 1、mysqldump db_name 是把数据库里的东西做了个一个显示，可以看到user的视图，slowlog的insert等等 看提示，关闭binlog 这样就可以了 然后去用mysqldump 看看是否能看到这个函数 先看下一种错误的mysqldump 全备可以使用重定向到一个文件里 mysqldump -uroot -pxxxx hellodb > /data/hellodb.sql 所谓mysqldump db其实就是保存了之前配置的各种命令 下面开始利用这个dump出来的文件进行还原测试， drop 掉先 由于mysqldump出来的备份文件，你们没有创建库的命令，所以还原之前要手动创建库。 同样由于mysql dump出来的内容里没有创建数据库，所以你手动创建的时候其实可以改个名字的， 进去看一下 1、这种方法备份数据就不太好了。万一原来的db名称你忘了呢。随便写一个，用户那边前端底层sql里面人家还是老的库名，业务肯定恢复不了的。 2、还一个，由于这种mysqldump出来的sql内容里没有涉及库，也就是不知道人家当初创建库的时候是否涉及了一些特性，比如字符集，比如引擎，等。这些都是问题。 mysqldump --databases | -B 原来是这样👇 现在改成这样👇 再来看备份的文件，此时-B就会有创建数据库的命令了 删库 然后恢复一下，此时就不需要手动创建一个可能都不知道的具体参数的数据库了 同样也可以不用cli交互模式，不过-e的方式，无需考虑结尾的分号了;就 如果不是drop删库，而是库里的表格丢了，也一样可以用这种方式， 因为mysqldump -rtoot -pXXX -B hellodb里的create语句里是由IF NOT EXISTS条件判断的。 备份多个一样是-B 注意上图一样hello mysql其实不加-B就判定未hello库里的mysql表了。 再看看-A全备，就是不备份information_schema和performance_schema 果然少了那两个：一个元数据，一个性能 进一步思考-A不会备份information_schema和performance_schema，那么会不会丢失数据呢？ 存储过程、触发器是放在mysql这个系统库里的，所以不会丢的。 上图就是说明一下函数、存储过程、触发器这些可能都是跟这个某一个数据库走的，drop database hello;后，里面的函数也就没了。 -A就包含了-E 和-R因为这些东西基本都在mysql库里，包括--triggers触发器也是在-A里就包含了，都是在mysql系统库里。 mysqldump和binlog 1、夜里2点mysqldump做了全备，第二天18点数据库崩了； 2、二进制是独立的日志记录，是独立于全备的另外一条线索 3、此时用mysqldump的全备文件，只能恢复到夜里2点的数据，还需要结合binglog才能补全恢复数据。 4、此时就需要知道2点全备的时间节点(也不一定是用时间来比对，可能就是记录下全备对应的binlog位置就行了)对应的binlog日志里的位置 5、为了记录下来当时做全备的二进制哪个位置点，就需要mysqldump --master-data这个选项。 --master-data=1和=2的有意义，没有涉及主从复制的时候=2就行了。=1就是加了个change master的命令；=2就是只是一个comment symbol注释而已，不会像=1一样生成一个change master to这个命令。=2是加注释，注释里面记录全备动作对应的binlog的位置。 这样就能在注释里看到binllog的位置position了 -- 两个横线，被注释掉了；这就是--master-data=1的效果，=2就是注释取消--删掉。 所以看到这个MASTER_LOG_POS=2998040;就知道mysqldump全备的动作是对应在binlog里的2998040这个位置的，对应这个位置做了全备，也就是之前的binlog是老日志，之后的就是新日志了。全备要+上从这个位置以后的binlog。 比如现在开始有数据更新了，模拟从这个位置开始以后存在数据变动 数据变动了，binlog就增长了 再加一条 此时二进制日志被我们独立的存放了，也不太担心数据库崩坏。 现在就模拟故障场景 有全备，然后又二进制的新增，然后坏了 删库模拟数据库崩了 就只删除mysql/下面的文件，mysql文件夹保留了，这样就无需再手动创建文件夹+修改所有者。 虽然此时数据库没了，但是二进制文件binlog分开放的，还在 还原操作开始 1、重启数据库服务，会生成崭新的数据库文件。 我实验的时候报错了， 我先重启下看看，重启还是不行，修改 没用，还得谷歌 https://stackoverflow.com/questions/60248748/could-not-increase-number-of-max-open-files-to-more-than-4096-request-4214 找到了，AI有时候还是不靠谱 不过，重置mariadb也行的，啊哈哈 改一下 有进展，但还不够 重装算了，操！ yum -y remove mariadb-server yum -y install mariadb-server 好奇怪啊，重装后，rm -rf /var/lib/mysql/* 后重启立马就起不来了 算了故障演示就不能用rm -rf /var/lib/myqls/*了，就算用这中方式，也只能用重装来弄，否则查这个错太麻烦了 反正重装后， 这个值也不用动了。 好了，小插曲，继续恢复数据吧 现在重装mariadb-server后的数据都是光的，开始恢复 1、准备好全备文件，binlog文件 完了，我没有备份配置文件，哈哈哈!反面教材，算了手动意思意思吧 2、要还原之前假设好数据库一部分用户还在用着，此时需要停服维护 ①再一个停服维护的文本里写上这个机器的信息，让相关人员可以看到，其实优化出来就是一个web展示页面 ②修改/etc/my.cnf里的选项，补一个skip-networking=1就关闭3306端口 3、先把全备文件还原掉 注意，mysql ①停止数据库的binlog先 一般生成中binlog已经开了，两个开关，都需要打开，所以关闭binlog就是进入cli交互模式去关一个就行了。之前我是重装了mariadb，所以 binlog没开，我先开了去配置文件里。 OK了，然后，使用cli关闭binlog，导入全备文件 使用 set sql_log_bin=off；就行了，这个变量是会话级的，不会影响别人，且退出失效。 此时binlog就临时禁用了。 此时binlog的位置在 而全备的动作所在binlog的位置在 上图可见是从mariadb-bin.000004这个文件的2990804这个位置之前的binlog有全备。 这个时候的一个规范操作就是，①由于你停服了，所以数据库不会变化了，binlog不新增了②所以此时可以刷新一个binlog，从新的binlog之前到--master-data那个位置就是全备以后需要补充的binlog 所以就是需要从全备补充的binlog涉及这些文件 呵呵，虽然好多就是空的，但是这里是演示嘛，严谨些也是要这么做的。 关键cli： mysqlbinlog mariadb-bin.000004 >> /data/inc.sql 下图写的有点问题，就是第一个文件它只是精确到了文件，没有精确到位置，所以cli要修改 mysqlbinlog --start-postion=2998040 mariadb-bin.000004 > /data/inc.sql mysqlbinlog mariadb-bin.000005 >> /data/inc.sql mysqlbinlog mariadb-bin.000006 > /data/inc.sql mysqlbinlog mariadb-bin.000007 >> /data/inc.sql mysqlbinlog mariadb-bin.000008 >> /data/inc.sql mysqlbinlog mariadb-bin.000009 >> /data/inc.sql mysqlbinlog mariadb-bin.000010 >> /data/inc.sql mysqlbinlog mariadb-bin.000011 >> /data/inc.sql mysqlbinlog mariadb-bin.000012 >> /data/inc.sql 马上就开始还原了， all.sql全备+inc.sql里的all.sql里的--master-data的位置到行尾 source /data/all.sql 先还原全备 你看就已经恢复全备的东西了 在还原inc.sql这个binlog补全的 source /data/inc.sql 两个数据就回来了 退出，sql_log_bin就直接恢复成ON啦。或者set sql_log_bin=on; 然后修改/etc/my.cnf里的选项打开对外服务 以上就是数据库的备份和恢复， 不过前提就是，binlog得安全得保存起来，以及全备一样得妥善保存。 1、二进制日志启用 2、msqldup -A --master-data=2 > /data/all.sql 数据修改 insert students (name,age) values ('a',20) insert students (name,age) values ('b',40) 3、删库 rm -rf /var/lib/mysql/* 模拟故障，实际上可能生成中就是部分业务故障。 4、还原 卸载mariadb-server，重装 4.1、通告维护 4.2、对外停服，修改skip-network=1 4.3、systemc restart mariadb 4.4、mysql > show master logs; 查看当前binlog位置，就是为了取--master-data到这个位置的binlog去还原。记录此位置值 mysqlbinlog --start-postion=xxxx mariadb-bin.0000x >> /data/inc.sql mysqlbinlog mariadb-bin.0000x >> /data/inc.sql mysqlbinlog mariadb-bin.0000x >> /data/inc.sql 5、mysql > set sql_log_bon=off; 5.1、mysql > source /data/all.sql 5.2、mysql > source /data/inc.sql 6、mysql > set sql_log_bin=on; 开个屁，直接\\q就行了，session级退出就没了。 7、恢复配置文件里的skip-networking，或放开防火墙对外。 8、检查数据，确认恢复。 如果是人为故障比如删表了 下午2点完全备份 18点老6删表 18点10你开始处理去恢复数据 好了故事讲完了，开始恢复吧 思路和之前一样，就是 ①全备文件恢复到2点 ②找到binlog，vim进去去掉18点的那个drop table students;这个删表的命令，恩？你问我为什么去掉，你不去掉，待会恢复binlog一样还是删了啊 ③恢复的操作就和上面一样了，这样的好处是能将数据恢复到18点10分。 再来一遍实验 看着像靠谱的，就是mysqldump默认是单表事务，但是有外链就要多表一个事务了。👆后文会讲事务下备份。 1、全备-模拟图上2点的全备 2、接着模拟2点以后数据变化，以及删表操作。 模拟18点删表了 模拟后续新的数据变化，你只是删了students表，其他业务可能还是可以正常，比如teacher表的写入。 这个时候你收到故障告警了，或者有人找你，删库的老6电话你了，这个肯定不比告警慢了~ ①禁止用户访问，就是skip-networking=1或者iptables deny掉；或者加锁flush tables with read lock；这样不是太好，因为还是能读，数据都被删了，读也有问题了；然后skip-networking=1也不是太好，因为还要重启服务，iptables不需要重启服务，比较方便，其实无所谓。一般都停服维护~ ②开始还原 要注意，还原的时候，要去掉18点的drop删表cli，然后就可以还原到18点10分停服的时候了。 去全备的文件里看下--master-data里的binlog位置。 是15编号的344位置做的全备。 也就是从15binlog344位置往后一直到停服的时候 其实停服的时候binlog也要停掉了，不过停服了binlog自然也不会有了，待会还原的时候停掉binlog就行了。 我们可以刷一下日志 就是17以前的，15以后的都是要处理的文件。也就是看起来舒服点的操作。 就是说17这个新binlog，是我们拒绝了别人访问后刷出来的，不应该再有什么新的数据了，不用管了就。 mysqlbinlog --start-position=344 /data/logs/logbin/mariadb-bin.000015 > /data/inc.sql mysqlbinlog /data/logs/logbin/mariadb-bin.000016 >> /data/inc.sql 找到drop那一行，删掉，规范点就是先复制一份出来，然后再改。 关闭binlog 现在有个问题，你全备里面是普遍存在删表后重建操作， 1、你删掉所有库，拿全备去恢复 2、你直接不删所有看，直接用全备覆盖，这个就有一个问题：如果全备动作之后创建了一个表，你拿全备去恢复，它就不会DROP掉，不知道会不会有什么影响。 然后你还有binlog去补差价，到时候这个表就有问题可能，所以可能还是推荐删掉所有的库。 cp -a /etc/my.cnf /root 备份配置文件 systemc restart mariadb 17以后都不用管，包括17，都是rm和yum自动生成的。 关掉binlog source /data/all_2023-07-20.sql source /data/inc.sql 然后就是退出，修改注释配置文件里的skip-networking，对外服务。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-07-20 16:27:34 "},"26-MYSQL数据04/3-mysqldump实战和xtrabackup介绍.html":{"url":"26-MYSQL数据04/3-mysqldump实战和xtrabackup介绍.html","title":"第3节 mysqldump实战和xtrabackup介绍","keywords":"","body":"第3节. mysqldump实战和xtrabackup介绍 -F --flush-logs：存在滚动多次数据库-A -B涉及多个数据库，估计一个数据库就会滚动一次；所以需要配合--single-transaction来做一次事务滚动一次，就是相当于不用 人工flush logs刷新binlog了。--master-data肯定要的，mysqldump动作对应的binlog位置得记下来的。 这个就直接STD 输出到屏幕上了哦，然后再看看binlog 从34开始到45，多了12个。 只会刷出一个binlog -F 滚动的好处也就是flush logs的好处，就是上图的000046号文件是新的日志，和老日志分开来放了，就是新老日志存放清晰，处理备份还原就有明确的000045--老日志，000046新日志，明确的文件分界线就出来了，无需去文件里扒位置去定界了。 看下这条优化备份CLI的实操效果 mysqldump -F -A --single-transaction --master-data=2 > /data/all_`date +%F`.sql 现在000046号文件389， drop table coc; show master logs; 好，此时000046的size达到了711，从389。日志增长了很多。 -F的效果就出来了，结合--single-transaction以及--master-data=2 就是新的binlog文件000047的389这个位置作为mysqldump的节点，去看看all_date +%F.sql文件里必然也写着000047 389这个位置点 相当于flush了一个新日志文件，从这个文件以前的binlog就包含在了全备文件了，从这个节点开始以后就不包含在全备里。 全备已经包含的binlog就可以清一下了，哦，所以binlog清里是这么清的！ 磁盘上自然也同步了 👇这个reset没必要吧，不然你还原的全备没问题，补差价的时候处理binlog就不能直接复制mysqldump --master-data 产生得binlog编号和位置了 得改成新的binlog编号，和位置，不过-F是刷新得，位置不用写了直接编号就行了。 温备-MyISAM不支持事务，要加锁保证数据一致性。 MyISAM备份要用-x，全部加上读锁，这样才能保证数据一致性。 -l 别用了，会导致数据不一致，因为一个库一个库的加锁，可能导致数据不一致。 所以InnoDB不要用这些选项，这些选项是MyISAM才需要的。 热备-InnoDB，开启事务 就是所有的mysqldump在也给事务里，而事务的默认隔离级别是\"可重复读\"，所以可以做到所有数据库的数据一致性。 ​ 但是事务可以隔离DML，不能隔离DDL。请看下图👇 DDL语言：drop table, rename table, truncate table；这些事务针对这些是不具备隔离性的。 注意truncate table和delete from的区别，前者是DDL，后缀是DML。这些事务具备对其的隔离性。 -q就是--quick看来还不错 处理方式 一般来讲MyISAM，-x 对于InnoDB，--single-transaction 但是对于数据库来讲，又有mysql这种系统库是MyISAM的，又有常规的其他所有库就都是InnoDB。 如果 mysqldump -x --single-transaction ，-x就失效了，上图里有提到的。 -A应该就包含了-E -R --triggers --default-character这些了，因为-A包含了mysql系统库。 但是-F和--hex-blob理论上是需要的，然后--deafult-character-set这个需要特定指定吗？不写会不会更好，写的就要看下是否和原本的数据库的默认字符集一致，要写成一致的字符集。 --master-data=1就是有主从复制了。 InnoDB建议备份策略 mysqldump –uroot –A –F –E –R --single-transaction --master-data=1 -- flush-privileges --triggers --default-character-set=utf8 --hex-blob >$BACKUP/fullbak_$BACKUP_TIME.sql MyISAM建议备份策略 mysqldump –uroot –A –F –E –R –x --master-data=1 --flush-privileges -- triggers --default-character-set=utf8 --hex-blob >$BACKUP/fullbak_$BACKUP_TIME.sql MyISAM就是需要加上-x选项。 分库备份 之前-A可能备的太多了，没必要，于是这里开始学习一下分库备份 来看看错误得案例： 上图得grep 用的倒是挺溜得，不过也就是-w的事，写成了^xxx$； 然后上图用for 循环里的--single-transaction是不是有毒，一个循环一个数据一个对立的事务，TM有10个db就要开启10个事务，数据的一致性还有吗？ 明明-B就可以跟多个db，非要秀for。 优化下，取出所有需要备份的数据库 这样👇就可以啦： OK，库都备好了👇： 或者👇这样： 看着有点问题，但是echo出来的cli直接复制是可以的，看着像没有调用bash 优化下就可以了 OK了，大小和第一个命令写法一样 和压缩打包结合一下 然后补充一个视频里错误的思路（还是-B 只带了一个db），但是有意思的写法（sed写的6） 但是生成的命令没有执行，还需要重定向到bash，或者``反斜杠才行。 xtrabackup-更专业的备份工具 他有很多产品，👆这是xtrabackup，其实人家还有监控，还有管理，还有号称比mysql更牛逼的db https://www.percona.com/downloads 8.0对应的应该是mysql8.X 2.4对应的就是mysql5.x 这个工具对比mysqldump的优势 1、速度更快，而且不是像mysqldump那种其实就是通过mysql命令进入数据库然后通过大的select命令来查的。extrabackup是通过数据块文件的复制。 2、备份的时候打断正在执行的事务 3、有压缩功能节约磁盘，这个不算什么优点吧，mysqldump出来也能自己zip一下。 4、备份的自动检验，这个是否能保障备份出来的文件可以正常还原的意思呢？如果是，还不错。 5、开源、免费，应该是对标的红帽企业级的备份工具mysqlbackup。 xtrabackup工具的内部的一些工作机制 2.2版本之前比较烂：其实主要有两个程序组成 innobackupex：per脚本 xtrabackup：C/C++写的 还两个不怎么用：xbcrypt加解密的；xbstream并发用的 xtrabackup 不能备份非innodb表， innobackupex 可以用来备份非innodb表。和mysqlserver的交互就是指进入mysql进行锁表之类的操作。 一个innobackupex脚本，一个bin文件，一个还会调另一个，讲完了。 redo拷贝线程：就是os_thread_create，系统创建线程来做redo也就是事务日志的复制。 ibd拷贝线程：就是系统创建线程，来做innodb的ibd文件(里面有数据和索引)的备份。 innodb拷贝完就开始弄MyISAM引擎的数据库了，主要是mysql系统库吧。 MyISAM的被，本质就是复制frm、MYD、MYI文件，etc说明还有别的文件，难道是相关的log？当然要加全局读锁。当然这些动作都是在一个大的事务里进行的。 停止一开始开启的事务后，解锁，退出xtrabackup二进制程序。接着结束innobackupex脚本。 以上就是老版本的xtrabackup的被过程👆。 从2.4以后，就不再是分来的文件了，而是合在一起，都是C写的了。 下面就是开始安装xtrabackup 注意启用epel源因为需要libev.so，这个在epel源里。这是视频里讲的，我发现libev好像现在也在base源了。反正一个rock.repo里有很多源：base、appsteam 现在的版本早就没了innobackupexu这个文件了，可能2.4以后还保留了它作为xtrabackup的软连接，这是考虑一部分人的使用习惯，后面干脆就连软连接都都没有了。 xtrabackup的用法 --defaults-file --user --password --hosts --databases 就登入的用户名和密码，登入主机，备份的数据库 --defaults-file是读取配置文件，比如/etc/my.cnf，这个选项要置顶 --incremental --incremental-basedir，增量备份，已经基于前一次全备或增倍的目录。 差异备份、增量备份的区别 增量备份，可以手动指到前面去，不一定能够是紧接着上一次的增量。 --incremental-dir：是指定还原备份的增量备份的目录 --include=name：指定标明，格式：databasename.tablename xtrabackup备份还原大致分为三个阶段： 1、备份 上面一小段文字就是讲的备份； 2、预处理：看到这就会想到mysqldump的时候存在这些情况的吧，这个最常用的mysqldump怎么考虑和处理这些事情的呢？印象中mysqldump也就是skip-network一下然后开启单个事务备份，还原就完了 3、还原 下面讲讲细节 图中没有画出①，①其实就是第一步备份咯；\"③就是还原，就是等第②步预处理完了得到完全的数据库文件后，复制到/var/lib/mysql/下，就是这么个意思。\" ②就是预处理；是将1的全备和2、3的增量整合在一起，这个整合并不简单。 看这个图，就能看出来xtrabackup比myslqdump专业的地方了，就是担心你mysqldump在做停服或者dump的时候存在跨越备份时间节点的事务--图中t1事务。 来，重新讲讲上图，当进行备份的时候，比如2这个增量备份的节点，有一个t1事务进行了一半，此时2节点处备份下来的事务log肯定会回滚，回滚到前面；还有一个t2事务它是已经执行完了在2节点备份动作的时候就已经执行完了。所以2节点备份的东西不是一个时间节点的了，因为2节点本来备份的节点理论上时间节点是一致的，但是t1由于是半个事务，是后来回滚了的，数据自然就不一致了。这个说法对吗，t1在事务里，外界是可重复读，哪怕commit也是可重复读的，所以不会影响外界吧，对于外界来讲t1是不存在的对吧？问题是，前一半事务你其实备下来了只不过是回滚了，后一半事务在3节点处其实也是在后一个增量备份里备份下来了，所以t1的前一半事务不要回滚，而是等后面一个增量备份后再去拼t2的后一半事务，否则整体上t1就丢了，一旦t1丢了，这个整体事务丢了，那么就和实际数据不一致了，及时t1执行的时候是 可重复读，外界是不受影响的，但是t1整体是会结束commit的，所以外界就受到影响了的，所以t1的事务需要合并的。 如果3节点处也出现了执行一半的事务，那就回滚啊，也没啥大问题。 所以最后一个备份点的跨越事务才会回滚，而前面的跨备份点的事务是需要整合的，做了一半的事务凑全了就不会回滚了，所以才有了②预处理步骤。 所以需要在cli也就是命令敲的时候，要体现出是不是最后一次备份节点的还原动作，如果不是就存在拼凑不完整事务的情况的，有这个情况就要拼凑的；如果是最后一次备份节点，如果存在不完整的事务就回滚啦。这个情况简称为 \"封口\"，同样存在于sqlserver和orcale。 封口就是不完整的事务不回滚，等后续另一半事务拼凑，就叫做不封口，而cli里明确是最后一次还原--这个动作所涉及半个事务是直接回滚的无需等待因为没有后续，所以就叫做封口。这是口语化沟通的时候存在这么个说法。emm就是行家一出手(口)就知有没有。装B用的现在是。当然正途就是理解别人用的，自己说出来就是装B用的。 备份时不会回滚的，只有还原的时候才会回滚！比如，1节点做的备份，如果也截断了一个事务，没关系，备份里的事务只有一半没事，就时一半在那的，还原的时候才会说这个一半的事务回不回滚。 如果你就是那2节点的备份进行还原，那就是要回滚啦，封口在哪里，那里就回滚。 还原的时候，最后一次你定在那里，那里就会回滚。 备份CLI的选项见后面实验，然后xtrabackup备的时候，会生成一些辅助文件，比如xtrabackup_info文件用来记录工具的版本、cli用了哪些选项、花费了多长时间、备份了LSN--日志的序列号。 这个LSN号其实类似binglog的位置，是OS组织数据以PAGE为单位类似块的概念，然后这个PAGE的 继续解释下LSN： 磁盘上的DB组织数据是按页page来存放的， 类似block--块是OS以及上次FS都是这么组织的，不过OS的块和FS文件系统的块不是一回事。 所以这里我们来总结下，os-block，fs-block，db-page page的一个单位容量要比block大的多了去了，一半yum下来或者编译的时候不改源码，也不会改它，默认就是16Kbytes一个单位分配的。 1、数据备份的时候，会记录PAGE里的一个数值，这个数值就是LSN 2、LSN就是事务的编号，在数据库做任何修改操作的时候，会把事务日志的编号写道PAGE里去。 比如PAGE里都放了一些数据，如果你修改了某个PAGE里的数据，那么这个PAGE页里就会记录LSN号。这个LSN号只增不减。 现在接上图继续说，现在xtrabackup备份数据的时候，就会把最大的事务编号LSN记录下来，比如上图就是10002。 ​ 现在又有新的改动，比如10002变成当时的事务日志编号比如是：20000。 现在再一次备份-做增量备份，也就是说从10002上次备份的点到现在20000这个点，中间涉及的数据做增量备份，那么对应到PAGE上，也就是涉及到的几个PAGE（15000和20000这两个页）才会去处理。 就是根据LSN来判断哪些PAGE需要备份，哪些不用，从而实现增量备份。 xtrabackup_checkpoints：这个就是涉及备份时候记录的LSN和备份后再记录一次的LSN，涉及是全备还是增量，涉及是否是prepared状态，也即是上面讲了这么多LSN的内容介绍。 xtrabackup_binlog_info：同样也会涉及binlog的位置记录，上面讲的是事务日志的位置记录。 所以备份还原的时候也是基于binlog的位置的，不需要认为修改，然后事务日志估计是用来\"封口\"--也就是回滚和同步用的吧。同步就是commit后还确认写道磁盘里的意思咯。 backup-my.cnf 就是备份配置文件 xtrabackup_logfile：该工具自身的日志记录。 使用xtrabackup来做备份 说要密码，好的， 结果说xtrabackup版本不支持 https://mariadb.com/kb/zh-cn/percona-xtrabackup-percona-xtrabackup/ 看看视频里老的版本的时候，支持的情况吧 图中可见mysql是MyISAM的，所以本质上就是锁表+复制。 一些备份产生的文件 除了个别之前就有👇 binllog位置👇 上图就是做了一次全备，从lsn=0到lsn=1541816 compact=0应该是没有压缩 👆这是备份过程的一些信息。 这是个data文件，看不了。 这些就是备份下来的文件了👇 下面就是恢复也就是还原，2大步 第一步，预处理，就是上文讲的得到一个完整的数据 xtrabackup --prepare --target-dir=/backup/ scp -r /backup/* 目标主机:/backup # 将备份文件scp到需要还原得机器上 第二步，还原，也就是将预处理得到的完整数据复制过去 配置文件里的datadir可以重新定义👆，不一定要和原来一样。 xtrabackup --copy-back --target-dir=/backup/ # 不用指定数据库的存放路径，会自动读取/etc/my.cnf配置文件里的路径 如图，可见/data/mysql路径是自动读取配置文件里的进行复制过去的，所以备份的db路径和还原的db存放路径可以不一致的。 复制的时候，要保证数据库不能启动，目标文件夹得为空。 所以还原得时候，都会影响业务，源数据库得清空。 最后，恢复下文件得权限 chown -R mysql:mysql /var/lib/mysql systemctl start mariadb xtrabackup增量备份和还原 --target-dir=/backup/base 文件夹不需要手动创建，会自动生成的。 --incremental-basedir=/backup/base 指定基于上一次全备的增量。 --incremental-basedir=/backup/inc1 增量就是基于前一次的增量继续的 还原的时候就要涉及回滚了，涉及是否回滚，也就是黑话-封不封口。 其实只有最后一次还原才会封口，才会回滚，前面的都不会回滚--不会封口。 --apply-log-only 就是仅仅应用日志，就是仅仅恢复日志，但是不做日志的回滚。 其实最后一次也可以加上--apply-log-only去让他不做回滚，无所谓，大不了就是做了一半的未提交的事务，你启动数据库服务的时候也会给你自动回滚的。反正没提交嘛有什么关系。 下面是实验 清理一下备份文件夹 ①做一个全备 全部做好了👇 ②增加点数据 这是第一次做增量备份，基于base内容做的第一次增量备份 inc1增量文件就出来了👆而且做增量是能够很好的节约磁盘空间的，且能提供备份速度的因为备份的数据少啊。 ③第二次增量备份前，再改改数据 然后做第二次增量备份 👆注意--target-dir是基于上一次的增量文件，来做--incremental-basedir新的增量文件。 到此，做了①全备②第一次增备③第二次增备。 复制到新的一台机器上 ④然后开始还原，在新的机器上 还原2大部，预处理 和 复制，当然chown和restart收尾也是自然。 现在是23M的文件 因为有3个备份文件，所以需要分别整理也就是预处理3次。 4.1 第一次prepare 然后就会发现 这个/backup/base全备文件变大了，看来，预处理就是将增量备份文件往前面的全备里添加啊。 4.2 第二次prepare👇 然后发现inc1变大了，base没变还是28，没关系，它内部有一些机制，不过最终确实是往base里整的。 4.3 第三次prepare 也是将inc2往base里整和啊 此时👇 ⑤将上面第4步整合好的文件复制过去，不过是用xtrabackup的cli进行复制的，而且要先清空目标库文件夹。 注意保留文件夹，这样就不用重新建再改所有者了。 停服 图中👆由于是服务器开启的状态进行rm -rf /data/mysql/*的，视频中的老师怕服务停掉会产生什么文件比如日志啥的吧也许，所有又ll /data/mysql/确认是空才放心。 👆复制过去，就好了上面命令敲完👇就有了如下内容： 大小看看 原来的数据文件大小要小一点， 因为还原出来的会又一些xtrabackup_*文件 ⑥修改属性和启动服务 ⑦验证数据 以上就是xtrabackup的内容，不过现在也知道这个不推荐了，虽然还不错。不过呢，也可用用percona的DB，那样备份的方式可能就和xtrabackup一样了，不过xtrabackup虽然不用了，但是它的思路肯定是必须要账务的。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-07-31 18:38:20 "},"26-MYSQL数据04/4-mysql主从复制原理和实现.html":{"url":"26-MYSQL数据04/4-mysql主从复制原理和实现.html","title":"第4节 mysql主从复制原理和实现","keywords":"","body":"第4节. mysql主从复制原理和实现 主从可不是备份，主上面DDL删库，从上也没了，DDL也不是事务日志能够记录的，也无法回滚，更别说恶意的commit了；所以备份时备份，主从是主从。 scale up,scale out 纵向和横向，前者指提升硬件资源cpu，内存、硬盘等；后者指提升横向计算机数量，类似主从，集群来提升性能。 主从复制要配合读写分离 proxy就是当sql操作来的时候，进行识别： 如果是DML就送给主，主要时进行数据的修改； 如果是DQL查询语句，就送给从进行查询； 这种proxy读写分离器，或者叫代理器，或者叫路由器，或者叫调度器。 proxy有很多产品，看你喜欢哪一个了。 下面先搭建主从架构 如果主挂了，从可以在秒级顶替上来。 升级可以先拿一个从节点开始升级，然后用用看，没问题就继续升其他的。 主从架构 sync 主从复制，是依赖的binlog，所以binlog是要在master上启动的。 然后是怎么把二进制日志拷贝过去的，下文会细讲。 很多时候，主从架构的搭建不是一蹴而就的。要知道一个事实规律，架构这种东西从来不是生下来就一个样子的，是不断演进的。所以不能为了好看的架构而架构，一定是适合业务发展需求。 复制依赖于二进制日志，master---slave---slave，如果是这种级联，其实中间的slave对于右边的slave来讲也是主了，而主就需要启用binlog。 1、当数据更新，就会自动生成binlog日志里的内容； 2、因为要主从复制，所以启用了一个服务--叫dump的线程，在Master上启用的。这个线程会负责读取新的二进制日志，把它通过网络发送给Slave。 3、有发就有接收啊，所以在slave上有一个线程来接收--小IO thread。这个io线程就是负责从网络中接收来自于master的binlog。 4、slave的io thread接收下来，放到relay log中继日志文件里，放到中继日志文件也不是最终目的，最终目的是要让从数据库的数据也发生更新。 5、此时就需要slave上的sql thread线程来读取 中继日志里的binlog，在本地slave数据库里运行，从而实现slave的数据同步。 6、主从复制涉及 两个线程，master 那边1个，slave那边2个。dump thread、io thread、sql thread。 7、涉及两个日志，主节点的binlog；从节点的relaylog。 主从架构的主是复制写操作的，主就是一台，如果写压力大业务大，主从，从再多也没用。此时，就需要分库、分表来解决。 拆库和主从不搭嘎，原来一个主服务器拆成3个，这3个依然都是主服务器 拆库的原则，是三个部分或者本来是三个表没有关系，不需要join表，所以就可以拆成各自的库。 上图👆是纵向切片，下图👇是水平切片 1、比如用户表、消息表、其他表，表和表之间存在join关系；此时纵向拆就不行了。 2、可以考虑横向拆，原来1000W条拆成500W+500W两张表，然后放到2个数据库机器上去。 3、拆开来后表的结构都一样的，只是放了其中一部分的数据 4、比如按13579奇偶数拆，奇数放一个服务器上，偶数放另一个服务器上。 5、比如按范围拆，1-500W，501W-1000W。 6、按地区拆，北京、上海 7、按用户级别拆，vip、svip 8、前端还得有调度也就是proxy，查和写都得知道去哪个库。 分库也好，主从也罢，都涉及到调度器proxy去将 读写负载分担到主也好从也好，拆分出来的库也罢。 这里就涉及一个调度器这个负载设备点的 单点故障。 调度器的单点故障是通过keepalive来解决的，nginx，f5应该也可以吧。 组合架构：拆库A+B，然后针对A做从节点，B同样也做从节点。再做好备份就行了。 分库的考量点，不是简单的数据量，而是用户访问量大到一定程度才会考虑分库。数据大，硬盘空间大一些就行了，用户量大了就不是简单加硬盘了，要考虑整体资源，所以分库是要考虑的。考虑的是访问量而不是数据库多大。 master.info里涉及给到slave的也给replication复制的一个权限。 relay-log.info是slave讲复制过来的binlog和relaylog的对应关系，复制了哪些binlog进来。 relay-log.info无需维护，就看看里面的处理的binlog和relaylog的对应关系就行。 复制不及时的问题，就会造成主从数据不一致，这是常见的 1、同步机制就是binglog从dump线程-io线程-中继线程-重放，这套机制就是会延迟的。数据不及时是必然的。 而且会出现延迟很大的情况👇 ①并行转串行： 并行写数据，但却是串行写日志。且网络传输也会涉及FIFO的一个先进先出的默认队列。 PS： 1、dml并发写入db表里 2、日志binlog就是串行写入了 3、binlog再复制到各个下面的从节点，每个节点又是串行传输的。 4、类似上高架，多车道并单车道，类似吧。 5、如果持续出现这种现象--就是用户高并发太频繁了，串行跟不上，且网络FIFO，日积月累的延迟就大了，在有些企业里延迟可能会高达1小时。比如做活动用户访问量大，等活动过去用户访问频次下来，FIFO也就慢慢能够处理得过来了，总之要将队列里的数据先处理掉才行。如果此时主服务器宕机了，从有没有同步到数据，长达一个小时的数据就没了。 6、遇到这种情况，就是备份+binlog来恢复数据吧。 主从复制的流程特定 异步 同步， 如果4 5 遇到高并发，大延迟，此时6就会很慢才会得到处理: 1、用户发起dml 2、proxy转发器代理区分dml往master送，如果是读DQL往slave上送。 3、此时是DML，master收到后，就开始写到本地数据库 此时，如果写完后，直接往proxy回应，说完了，不等从同步确认。就是异步也是默认的方式。 如果，不立刻回复用户，而是先同步，等slave回应同步ok后在回复proxy，则是同步。 半同步，介于异步和同步之间 常见架构，或者也叫mysql复制模型 一主一从，一主多从 级联复制，一主一从级联带多从:这个好处就是master只需要复制给一个，剩下的从都重那一个中间节点复制就行了。master压力小。这让我想起了之前《第二十四章 MYSQL数据02》- 第4节 mysql架构和存储引擎详解里的这张图👇，就是说级联的中间点加速复制不做本地落数据，叫做黑洞技术。 主主会造成数据不一致，因为都能写，但是M/M是可以这么玩的，前置调度器，比如F5将DML都往MASTER-A上送；然后MASTER-B要去从MASTER-A上取数据--本质上MASTER-B还是从只不过是已经提升为MASTER的SLAVE；如果MASTER-A宕机了，就直接F5通过健康检查快速切到MASTER-B去了，MASTER-B因为已经是主了无需从SLAVE再繁琐的提升到主了。 但是主主+调度器，主主里的实为从的那个主，如何做到只接收数据，不去覆盖到真正的主的呢？ 主从的情况，从变成主，需要修改配置。 两主，一从，这是省钱的玩法，啥意思，就是 master-A里是db_1 master-B里是db_2 slave一个没错，但是分别复制db_1和db_2，物理上是一个从，其实是两个从库。所以主从式精确的来讲是库的主从。 slave一个没错，但是分别是两个实例--就是两个mysql服务，mysql_1同步master_1里的所有库；mysq_2同步master_2里的所有库，哈哈，一个套路。 本质上还是一主一从。 这个压根不会用了 其他的都有存在性和落地的可能。 复制的时候是复制的binlog 而binglo是格式的： STETEMENT--语句型，不推荐 ROW--行型，推荐 MIXED--混合型，也凑合 mysql复制配置 主节点配置 关键配置就两个 然后还得授权从能够访问主进行复制权限不必给大 复制的时候不确定是哪个数据库，所以就写*.*所有库的所有表。 从节点配置 ①server_id是主从都需要配置的 ②read_only是防止从节点被改了，被改了就无法去同步主节点了。且数据库就不一致了。其实不加也没事，要从架构考虑，因为主从前端还有一个调度器呢，只要保证前端的调度器能够正常的分离读写就行了，写别发送到从节点就行。 然后用户也不会直接连到从节点，也不会改得到数据。 read_only是针对普通用来将的，不包含root，root这个管理员还是该写还是能写。 ③指定主的host也就是ip，指定从节点以什么账号密码进行复制，指定从什么binlog文件里的哪个位置开始进行复制，从那个点开始复制往后所有的binlog。 mysql > CHANGE MASTER TO MASTER HOST='host',MASTER_USER='repluser',MASTER_PASSWORD='replass',MASTER_LOG_FILE='mariadb-bin.xxxxx',MASTER_LOG_POS=#; 这个MASTER_LOG_FILE，mysql5.6以后就不需要指定了binlog文件自然也无需指定位子了。 然后这里的CHANGE MASTER TO 在前面学到过，就是 ④最后启动一下从节点去复制主节点的binlog的动作 因为，要启动从节点的两个线程IO和SQL thread；需要 其实不必分开启动，直接START SLAVE就默认会启动IO_THREAD和SQL_THEAD两个线程了。 一旦启动，后续就自动持续复制了，不用管了。 主从复制实验 修改配置文件 master上配置 slave上配置 创建复制用的账号 看下slave从哪里开始复制 从mariasb-bin.000032的548位置开始复制 slave那边的cli如果忘记了可以help一下 CHANGE MASTER TO MASTER_HOST='192.168.126.129', MASTER_USER='repluser', MASTER_PASSWORD='centos', MASTER_PORT=3306, MASTER_LOG_FILE='mariadb-bin.000032', MASTER_LOG_POS=548, MASTER_CONNECT_RETRY=10; START SLAVE; 再输入上面的CLI之前的slave的状态是Empty空的👇。 然后数据库文件目录下当前文件如下，待会等cli敲下去就看看新生成的文件是那些。 敲下去后，此时 master.info的内容 上图发现IP地址写错了，重新敲一遍上面的CLI就行了。 👆中继日志就是复制过来的的master二进制日志和本地中继日志的对应关系。 master那边的mariasb-bin.000032的548相当于本地的bind-2-rely-bin.000001 上面的mariasb-bin也写错了，将上上面的cli重一遍就行 这两个文件是中继过来的binlog文件，类似binlog一样的，index是binlog的文件名。 敲完上面的CLI之后，从节点再看一下👇 上图可见 这个👆是slave上的参数，表示从节点同步主节点的延迟时长多少秒。其实就是差多少秒的数据了。 说明IO thread和SQL thread都未开启，去master上看看进程 同样slave这边也看一下线程情况 在从节点上启动两个线程 主节点也看下线程也已经启动了 然后测试同步情况 在主节点上创建db 再测试一个大的数据生成的同步情况 主那边存储过程创建，从那边自然也有了 从节点的表格也同步了， 此时在主节点上执行存储过程，然后观察从节点的表格同步情况 主👆节点， 👇从节点 此时从节点的进程如下 目前没有延迟同步的时间，然后主节点那边的binlog文件和位置是多少，从节点自己的rely-binlog的文件和位置是多少的一个对应关系。这比较一开始要多了很多数据。 然后要注意一点，主节点那边的call 调用存储过程 所消耗的时间未1min59s，这个里面由于是要做主从同步的，所以时间要比单节点来的要长些。 所以主的压力就明显变大了，此时前端就需要部署一个调度器来实现读写分离，让读操作DQL就别往主节点发送了。 总结 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-08-07 11:47:36 "},"27-MYSQL数据05/27-MYSQL数据05.html":{"url":"27-MYSQL数据05/27-MYSQL数据05.html","title":"第二十七章 MYSQL数据05","keywords":"","body":"第二十七章 MYSQL数据05 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"27-MYSQL数据05/1-主从服务故障恢复和级联复制.html":{"url":"27-MYSQL数据05/1-主从服务故障恢复和级联复制.html","title":"第1节 主从服务故障恢复和级联复制","keywords":"","body":"第1节. 主从服务故障恢复和级联复制 半途做主从 一半业务刚起步也不会做什么主从，就单机，随着业务体量起来才会考虑架构的事情。所以需要处理主从复制的时候主节点上已经有很多数据的情况。 思路就是：先将主节点的数据备份-还原到从节点--其实如果是VM直接克隆出来一台就行了连mysqldump都不需要，再开启主从复制，复制的位置就是show master logs的位置。 实验一下 1、弄一个干净的mariadb服务 然后这里报错，就是文件夹的权限问题 binlog就有了 2、制造一些数据，代表单节点的数据起来了--我认为因该要做这个 然后备份，还原一下，这里就不偷懒用VM克隆，实际工作中反而是克隆直接，不过具体情况具体看咯，两种方法都得会。 主节点的账号要不要复制过去给从节点，要！主从复制本身从节点上不用有账号库，但是从节点万一成为了主节点，此时其他的从节点就会和这个提升上来的从节点上同步数据，此时该节点就需要有同步用的账号库了。这就是考虑问题的时间跨度要有，所以当面临一个不擅长的问题，就需要有这个时间跨度的意识去拉自己一把。 所以做主从的时候，就是先创建账号，再备份还原过去，这样账号就一起还原到从节点了。 3、有了一些数据了，也先于主从复制创建了账号。现在还是备份使用mysqldump 关键语句如下👇 这条语句其实就是主从复制的，从节点上面用的复制配置CLI。 msyqldump里的--master-data=1这个=1就是在从节点上面还原的时候直接顺带执行了change master to xxxx 了，不过还缺一个mater的IP是多少。 所以直接在从节点执行也是不行的。还得补齐master的IP，复制的账号。 4、将dump出来的备份复制到从节点 将从节点的mariadb 删库，卸载，重装，发现，/etc/my.cnf会自动给你备份，新建，还是挺不错的。 重新安装好mariadb后，不要启用服务，否则会自动生成/var/lib/mysql/的一些文件，这样不利于还原主节点那边的数据。 # 当然这视频里说的，现在版本又不这么回事了，yum install后，直接/var/lib/mysql/下就会直接生成文件，不用启动也会又文件初始化生成的。所以不用管这些。而且你恢复dump文件的时候就是要先启动服务的。 然后vim 进去备份文件all.sql补全从节点的change maser to的相关信息 5、修改从节点的配置文件 6、恢复dump文件 启动服务 db也是默认的几个，slave status也是空的 serverid没问题，注意是下划线。/etc/my.cnf里面可以-可以\\，但是mysql交互模式进来就是变量去看，变量就是_。 但是这个read_only ON是防不住root的哦，root依然可以修改的。 由于vim过all.sql补齐了change master to的相关信息，所以可以直接mysql 此时从节点的配置好了，就差一个启动 然后此时一些 relay文件就生成了 目前没有启动，从节点和master节点的网络连接还没有 待会启动了slave start后，从节点就会主动连接主节点的3306端口去了。 然后就报错鸟 不过由于IO thread起来了，所以ss -nt tcp连接时已经建立 然后拍个错 这对这个报错 flush priveleges；就行了，然后start slave；一下。 然后就发现继续报错 我只能说FUCK，然后我继续排错，过程嘛就是remove \\install \\remove\\install， 发现了一个all.sql这个dump文件里的错误，就是分号 好像就是这个原因，我再改回分号试试，破案了，就是这个分号导致了上面的start slave后的show slave stauts\\G看到的报错，而且细究一下其实mysql 但是你要是进入mysql，敲source /data/all.sql，就看不到报错了，所以由此看来，还是建议在外面做mysql 。 👆应该root不受限，所以可以导入了 总之就是 yum -y remove mariadb-server rm -rf /var/lib/mysql/* yum -y install mariadb-server \\cp -a /etc/my.cnf.rpmsave /etc/my.cnf systemctl start mariadb systemctl status mariadb mysql OK了 tcp 建连也没问题 数据也还原的没问题 然后看看主从复制是否OK能否复制了 同步的很丝滑~ 总结，在现有的mysql服务器基础上，实现主从复制 生成中主从复制的错误案例 1、案例1 有人本该去主上创建库，结果跑到从节点上创建了；发现后又跑到主节点上创建了一遍。 错误如下 然后去主上创建同名的库 但是我这个没报错啊，难道是高版本优化？ 然后我在主节点上删掉这个db003试试 从节点此时就自动同步了，貌似高版本确实优化了 老版本是由这个问题的，如下图👇 这个问题的严重性在于：一旦发生这个错误，后续的主从复制就停滞了，继续在主节点上创建数据库，从节点就不会同步了。 这种冲突不仅仅是数据，这里只是举例，冲突可能存在于表，表里的记录都是可能的。 这里处理的方法不是在从上drop掉冲突的库，及时删掉，也不会继续同步的。需要stop salve和start slave，重启一下。但是生成中不能人工去处理的吖~而其是报错明确的，万一报错里的内容没有明确指出来呢，万一不止一条呢。 按视频里说法就是忽略这个报错的意思咯，我先不急记录他的处理方法，我先看看高版本里的这种错是否由优化自动处理掉了。 结果该问题确实有的，没有自动优化一说，继续处理吧。 此时主节点那边开始写入大量数据，从节点就卡在那边不同步了 此时从节点并不会同步 skip忽略错误-sql_slave_skip_counter 其实不仅仅是忽略错误，只是一般用在忽略错误上，sql_slave_skip_counter是忽略几个同步事件，错误也好，正确也罢，都算！如果忽略2个，结果第一个是错误，第二个是正确的，一样也会被忽略。 此时就可以同步复制了，之前主节点跑的存储过程其实就是创建和insert的testlog也同步过来了👇 当然忽略的1个报错，只是临时解决让数据继续同步下去，但是如果存在关联性，就不太好了，还是要回头过来去解决。 如果问题实在太多，还不如从的删掉，重新同步呢。 skip指定的error 再一个，尝试通过忽略错误编号的方式而不是忽略几个，这里要明确这个错误编号我测试下来不是说代表某一个错误，至少我insert 两次，忽略一次，1062的错误编号没变。 不行唉，read-only也碍事了，改一下 还是不对啊 算了该配置文件去 就好了。。。 所以那几个insert都是1062类型的错？我理解成类型不知道对不对啊。 对的吧，官方有的https://mariadb.com/kb/en/mariadb-error-codes/ 如果主服务器宕机了 1、创建出1主2从的架构先 在主节点上执行 mysqldump -A --single-transaction --master-data=1 > /data/all2.sql scp /data/all2.sql 192.168.126.131:/data 在从节点上执行 yum -y install mariadb-server vim /etc/my.cnf server-id=131 read-only wr systemctl restart mariadb vim /data/all2.sql ----补齐----- CHANGE MASTER TO MASTER_HOST='192.168.126.129', MASTER_USER='repluser', MASTER_PASSWORD='centos', MASTER_PORT=3306, #MASTER_LOG_FILE='mariadb-bin.000032', 这两行是自动就有的 #MASTER_LOG_POS=548, 默认就有 MASTER_CONNECT_RETRY=10; # 注意最后一个才是分号 wr mysql 上面执行的过程中报错了 ①是版本不一致导致的 ②是 https://stackoverflow.com/questions/1814532/mysql-error-1071-specified-key-was-too-long-max-key-length-is-767-bytes ③所以看懂了没？真实的意思就是，你的所有的字段，就是列的字符总和长度超了，而且还涉及一个字符占多个Bytes的情况。 这里不换版本，处理很麻烦，搞不懂的，除非你vim进去修改各个字段的长度，保证加起来不超过2000，但是没这么玩的；然后innodb_large_prefix这个10.5.x版本也不让改的-配置文件里修改了启动不了服务了。 ④处理方法就是换一样的版本， 好啦，瞎鸡巴搞，主从还不搞一样的版本！找抽！ 模拟主从切换 此时存储过程大量insert正在进行中，然后关闭虚拟机。 此时两个从节点，都瞎了。 此时需要提升一个从节点未主节点，提升谁的依据就是 谁的同步的二进制日志的位置新就提升谁， 一样的，谁都行。不一样，找编号文件大，文件编号一样，再找Pos位置编号大的。 这里两个从节点同步状态一样，就随便选择一个，这里选择192.168.126.130吧 提升为主的从节点的操作： ------------------------------------- mysql > stop slave; mysql > reset slave; 这个只是删掉master.info文件,删掉了relay-log.info，xx-rely-bin.000xxx也没了？老版本是好像清空但是这个rely-binlog还在的。 vim /etc/my.cnf log-bin # 最好独立路径，这里偷个懒。做主了，从就要开启binlog了 #read-only # 要去掉。做住了，从就要支持写了。 账号之前就复制过来了，所以授权复制的账号不需要再创建了，可以确认下 mysql > select user,host,password from mysql.user; mysql > show master logs; # 看下提升为主得从，binlog从哪里开始的，待会还有一个从节点就从这里开始复制。 reset slave;清的不干净，需要加个all 不过新版，加不加all，/var/lib/mysql/的东西都是一样的效果了。 修改配置文件，这回儿提升为主了，需要修改一下 提供从节点复制的账号本来就是复制过来的，有的 然后还有一个从节点也要修改master信息 msysql > stop slave; mysql > reset slave all; mysql > CHANGE MASTER TO MASTER_HOST='192.168.126.130', MASTER_USER='repluser', MASTER_PASSWORD='centos', MASTER_PORT=3306, MASTER_CONNECT_RETRY=10, MASTER_LOG_FILE='bind-2-bin.000001', MASTER_LOG_POS=329; mysql > start slave; mysql > show slave status\\G; 测试下同步效果 主节点上drop库，从上看 以上就是主从切换的手动过程，真实生产中，肯定不会这么手动搞吧，太慢了。 如何实现自动切换捏~(￣▽￣)~*有的，有个软件，呵呵，我还以为自己写脚本呢，对吧，自己写就是精度可能是s秒级的了不起了，后面学到这个软件再说。 减少主节点的压力 主从，主节点的工作就是复制写和同步，如果从过多，就会导致复制的IO过大，此时就会考虑：一主---中间节点----多个从节点，这样的架构👇 从节点照旧，只是修改master指向中间节点就行； 中间节点的配置比较特别而已 那么问题来了 中间的级联节点，是没有dump线程的，slave如何去取数据呢。 要知道简单的主-从，是靠dump thread讲binlog dump出来传出去得，从那边就是靠io thread接收数据，存到realy.log里，然后rely.log文件里得东西，又靠sql thread读取后写入数据库里得。 1、所以级联节点，必须启用binlog 2、而且这个binlog里记录得内容，必须是从master传递过来的内容，可不能是自身的binlog哦哦，哈哈，而默认恰恰是自身的binlog。 3、binlog默认是记录本地写入进去的，而不会记录 sql thread 从relay.log读取写入db的内容。而且中继上要只中继relay.log里的binlog才对。 4、还得dump thread来送出去。 总之 ，dump线程起来，然后dump只会从本地binlog取数据，不会从relay-log取，所以这里要做进一步处理。 要让relay.log的数据写到数据库，然后让数据库里的数据再写道binlog，这样再利用dump进程才可以把从master来的binlog送出去。 讲了辣么多，结果就是一条选项的事咩？ 其实我还知道，这个TMD的处理逻辑还得优化成BLACKHONE的方式。 master上 -------- yum -y install mariadb-server vim /etc/my.cnf server-id=1 log-bin wr systemctl restart mariadb mysql > grant replication slave on *.* to repluser@'192.168.126.%' identified by 'centos'; mysqldump -A -single-transaction --master-data=1 > /data/all.sql scp /data/all.sql root@192.168.126.130:/data/ 中间proxy上 -------- scp -r root@192.168.126.129:/etc/yum.repo/ /etc/ yum -y install mariadb-server vim /etc/my.cnf server-id=130 log-bin read-only log_slave_updates wr systemctl restart mariadb-server vim /data/all.sql CHANGE MASTER TO MASTER_HOST='192.168.126.129', MASTER_USER='repluser', MASTER_PASSWORD='centos', MASTER_PORT=3306, MASTER_CONNECT_RETRY=10, wr msyql show slave status\\G; mysql > start slave; # 不用再proxy上创建复制账号，本意是创建账号给 从节点们用，其实没必要，proxy拿这个账号同步master，本身也会同步到这个账号到本地，然后从节点就用同样的账号来同步proxy。 mysqldump -A -single-transaction --master-data=1 > /data/all_proxy.sql scp /data/all.sql root@192.168.126.131:/data/ scp /data/all.sql root@192.168.126.132:/data/ slave节点上 --------- scp -r root@192.168.126.129:/etc/yum.repo /etc/ yum -y install mariadb-server vim /etc/my.cnf server-id=131 read-only wr systemctl restart mariadb-server vim /data/all_proxy.sql CHANGE MASTER TO MASTER_HOST='192.168.126.130', MASTER_USER='repluser', MASTER_PASSWORD='centos', MASTER_PORT=3306, MASTER_CONNECT_RETRY=10, wr msyql show slave status\\G; mysql > start slave; 以上配置OK，测试过了，过程截图略了，都是从yum -y remove mariadb开始的 最后验证： OK， 这种的搞定 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-09-07 15:03:39 "},"27-MYSQL数据05/2-mysql主主和半同步复制.html":{"url":"27-MYSQL数据05/2-mysql主主和半同步复制.html","title":"第2节 mysql主主和半同步复制","keywords":"","body":"第2节. mysql主主和半同步复制 补充几个选项 5个写磁盘的及时性： sync_binlog=1 binlog的及时写磁盘， innodb_flush_log_at_trx_commit=1 事务的及时写磁盘，当然不是说及时就一定是好的，也要考虑IO的负担。 sync_master_info是 多少次 事件后 master.info的信息 写磁盘 sync_relay_log 多少次 后同步到relaylog磁盘文件，应该也是指relay-log.info文件吧。 sync_relay_log_info 多少次事务后 后同步到relay-log.info磁盘文件。 skip-slave-start=ON # 要知道一个事实--重启mariadb服务后，slave的两个线程IO和SQL都是OK的，也就是第一次手动start slave;后面都不用管的，都是随服务启动就启动的。这个特性就是依赖于skip-slave-start这个选项，如果置为ON，就不会随服务启动了，到时候就只能手动每次start slave了。 主-主 复制，需要调度固定分配成主-从 主-主前面一篇就讲过了，这种的好处，是多活吗，无需从节点提升 这么一个动作。 所谓主主，其实是互为主从，A-B 两个机器，A是B的主，又是B的从，B一样。 不过有人就是要真正意义上的主主，多活，A/A，类似ASA的A/A，人家就是要并发写，我那个去，怎么搞，这么搞。 所谓的并发写，A/A，其实就是通过 auto_increment：也就是奇偶区分，不同的主起始不通，间隔一样，错开序号了就。 然后再配合前置调度器，比如，来了2条写操作，调度器就直接并发的扔给2个主，而2个主处理的时候又是错开PRI主键ID的，于是就实现了多主。 节点A上 ------ yum -y remove mariadb-server rm -rf /var/lib/mysql/* cp -a /etc/my.cnf /etc/my.cnf.bak yum -y install mariadb-server vim /etc/my.cnf [mysqld] server-id=1 log-bin auto_increment_offset=1 auto_increment_increment=2 wr systemctl start mariadb mysql > grant replication slave on *.* to repluser@'192.168.126.%' identified by 'cisco'; 节点B上 ------ yum -y remove mariadb-server rm -rf /var/lib/mysql/* cp -a /etc/my.cnf /etc/my.cnf.bak yum -y install mariadb-server vim /etc/my.cnf [mysqld] server-id=2 log-bin auto_increment_offset=2 auto_increment_increment=2 wr systemctl start mariadb // mysql > grant replication slave on *.* to repluser@'192.168.126.%' identified by 'cisco'; # 这句就不用敲了，直接复制过来从A。 mysql > CHANGE MASTER TO MASTER_HOST='192.168.126.129', MASTER_USER='repluser', MASTER_PASSWORD='cisco', MASTER_PORT=3306, MASTER_CONNECT_RETRY=10, MASTER_LOG_FILE='mariadb-bin.000001', MASTER_LOG_POS=330; # 去A看下show master logs;将binglog文件和pos位置复制过来。不过这个要配合mysqldump 从A备份还原到B，如果不想这么麻烦，直接将这里的binglog设置成第一个文件的第一个位置一般是330左右。可以刷新一个binlog，看看初始值多少。放屁！这样从头复制直接报错！哈哈因为复制的时候可不会想mysqldump出来的有IF判断存在就DROP的语句，主从复制如果存在就直接报错卡住了。 所以这里的binlog和pos需要先去master上show master logs;复制过来的，然后master前面的数据需要dump过来的。 报错啦 还是去A上dump吧 mysqldump -A --single-transaction --master-data=1 > /data/all.sql scp /data/all.sql root@192.168.126.130:/data/ 去B上还原下 msyql > stop slave; mysql show databaes; 可见hellodb同步过来了 mysql > start slave; mysql > show slave status\\G; 这回就OK了。 这就好了，果然是primary主键可能不让写奇数吧，因为/etc/my.cnf里是做了偶数限制 果然个屁，再仔细看看报错，是dupicate 这就是已经说主从复制的时候，已经有的数据库，里面的表，再次写的时候就报错了， 但是mysqldump 出来的all.sql里其实也是大量的sql语言，但是人家是写了IF 条件判断的，如果存在这个表格就DROP的啊，哈哈，对吧mydqldump是先铲除后还原啊，所以不会报错啊👇 而复制就不是啦，存在的就冲突了。现在知道为什么每次都dump而不是从头做复制了吧。 现在传统的主-从就OK，测试一下 然后把节点B也就是slave也变成master B上也就是slave： ------ mysql > show master logs; A上也就是master： --------- mysql > CHANGE MASTER TO MASTER_HOST='192.168.126.130', MASTER_USER='repluserB', MASTER_PASSWORD='cisco', MASTER_PORT=3306, MASTER_CONNECT_RETRY=10, MASTER_LOG_FILE='mariadb-bin.000002', MASTER_LOG_POS=2539205; 上面的binglog文件和pos位置就是B上看到的复制过来的，敲完A就是从了，当然还得start slave一下； mysql > start slave; mysql > show slave status\\G; 然后就报错了 奇了怪了，用户确认同步过去了啊，密码通过哈希值都能判断是一致的👇 不管先在B上新建一个用户试试 在B上 ----- grant replication slave on *.* to repluserB@'192.168.126.%' identified by 'cisco'; 靠！好了，难道用户要单独创建咯，好吧。难道主主，复制用户必须各自单独创建。不是，后面我又把A的复制用户换回去又可以了。感觉是这个用户没有在B上生效。 好像flush privileges;就好了，不过我记得我刷过啊，估计就是没生效当时，然后过一会生效了，或者是创建repluserB的时候相当于又刷了一次，我当时应该多刷几次的，(￣▽￣)\"。 A->B 和A 模拟写表看看是否冲突-主主的时候 A上 ----- mysql > use hellodb mysql > create table test (id int auto_increment primary key, name char(10)); mysql > desc test; 此时B上也有了 通过xshel的批量下发cli，给A和B同事敲入insert insert test (name) values ('wang'); 这样就同时键入了sql insert 不冲突，左边A是1，右边B插入的是2偶数，奇偶错开来的。 还是一样左边1 3 5 ，右边2 4 6 创建表，理应冲突 但是高版本确实不会了，不知道怎么实现的。 我理解一定是有一个被回退了，内部忽略了，去找找相关资料。 中文会翻译掉了一写 重要的 专业词汇，就是人家起的名字吧，通过英文去问得到英文的回答 通过GPT找到了关键信息，然后通过关键信息去官网再找 https://mariadb.com/kb/en/about-galera-replication/ 然后看看默认的值就是1👇 确认了👆 还有这一篇也写的不错 https://galeracluster.com/library/documentation/certification-based-replication.html 虽然主主现在高版本有write set replication API辅助，但是生产中是不可能直接用的，会在主主前面加上调度器的，只往一个主节点上写数据，另一个虽然是主，本质上是做查询操作的，这样的主主好处就是当主节点挂了，另一台可以快速替代，不用像以前从那样还要费劲地操作一下才能提升为主。 如果是三个环形指主，如果是4个环形指主 都是串起来，头尾相连，本质上和主主一样地，无非是从2个串，变成了3个，4个环型罢了。 上图👆是主主地间隔，如果是3个串起来， 将auto_increment_increment=3就行了；就是1 4 7 ，2 5 8，3 6 9。 同步虽好，异步落地，半同步为优 同步和异步前面讲过了，这里补充一下半同步，所谓半同步就是，只要众多从节点中，有一个回复了(下图中第4步)，master就回复proxy，进而回给用户。相当于一次update在用户那边就完成了，不必像同步那样等太久。 默认是不支持半同步的，需要安装插件，好像确实数据库里也有很多插件。 下面开始实验 1、拓扑：master--带 两个 slave，一个slave断开网络模拟未同步，然后master也能完成记一次updata交互。 2、开始 master上 -------- vim /etc/my.cnf serer-id=1 log-bin wr systemctl restart mariadb mysql > show master logs; # 记一下binlog的编号和pos复制到下面CHANGE MASTER cli里 mysql > grant replication slave on *.* to repluser@'192.168.126.%' identified by 'cisco'; 左一 master； 中间 slave1； 右一 slave2； slave1上 --------- vim /etc/my.cnf server-id=2 wr systemctl restrat mariadb msyqll > CHANGE MASTER TO MASTER_HOST='192.168.126.129', MASTER_USER='repluser', MASTER_PASSWORD='cisco', MASTER_PORT=3306, MASTER_CONNECT_RETRY=10, MASTER_LOG_FILE='mariadb-bin.000003', MASTER_LOG_POS=781; 遇到一个报错 重启服务后，就可以了，我日，肯定有什么残留导致直接 授权的方式无法创建用户了。 好像有时候flush一下可以，有时候flush 也不行，下图是OK的截图 遇到报错，stop slave还不行，还必须reset！ slave2一样要reset一下，因为之前有做了其他实验 然后两台slave就都好啦👇 下面做半同步啦，安装插件：rpl_semi_sync_master 高版本都是wsrep-write set replication这种API了。 不管，硬上，直接看变量SHOW GLOBAL VARIABLES LIKE '%semi%'；有唉~我日 估计这个插件名称变了，被集成到别的插件里了，可能就是wsrep这个 然后看插件的方法 老版本视频截图 master上安装master字眼的插件 👆安装后，👇看看 看到这我猜这个rpl_semi_sync_master就是被高版本里的👇这个取代了 都是REPLICATION 先不管wsrep这个事，先看老版本的操作流程 插件rpl_semi_sync_master有了，但是还需要启用，通过变量看看状态👇。 这个_enabled是启用与否；_timeout 10000是万一主--从同步从迟迟没有回应，主也就等这么久10000是10s，就会往client/proxy那边回应了。 启用一下-在maser上的半同步 然后看看状态变量 可见👆ON了，然后client那边还没有使用半同步的插件，也没有开启，所以client是0。 回到我的实验，我用的高版本的mariadb，我试试蒙一下，我估计插件不用安装 直接set一下长得像的变量on试试👇 果然，新版本无需安装什么半同步插件了，至于这些个变量的功能来源于哪个插件，或者是不是 被取代了，再说回头我去翻一翻一资料 https://jira.mariadb.org/browse/MDEV-17908👆 官网上也说了 https://mariadb.com/kb/en/semisynchronous-replication/ 好像也没将是集成到wsrep里，呵呵，不管了。 启用一下-在slave上半同步 老版本具体就是10.3.3之前 然后show plugins;看下👇 高版本就不用安装了，默认就有半同步功能 不管是老还是新版本，启用都是要启用的，启用的变量和查看状态的变量都是一样的。 slave2一样启用一下 最后还需要重启slave的线程，stop slave,start slave 记住！不是reset salve。我日你奶，想要reset 还得先stop，不过reset也不会真的清空就是了，只是重新设置的时候有时候需要reset一下。 开始测试同步机制 1、当前状态是同步OK 2、然后半同步不是已经配置且master上认到2个client了吗，所以将两个slave都停服，这样就一个同步都不会发生，理论上master就遇到sql写入，就会卡住，就不会回应cliet/proxy了。但是也不会永久卡在那，因为有超时时间10s 测试 slave2 停服 slave1 正常 master创库之类的写入正常 再继续将slave1停服 此时master 创库卡住，时间卡了10s OK！ 然后看看状态，就有变化了 要知道原来是0都是基本上 再一个slave只要启动mysql，也会自动同步过来，因为slave是默认 第一次手动，后面都是随服务启动而启动的。 但是我发现半同步没有启动，client还是0 哦，不是的，是之前set设置的global变量，所以重启服务后失效了， 去配置文件配置下。 slave上 ------- vim /etc/my.cnf rpl_semi_sync_slave_enabled wr systemctl restart mariadb jiu ok la~ 此时master上show得到client了 相反，set global rpl_semi_sync_slave_enabled=ON;是需要stop 和start slave的👇 这是最终的效果 slave上倒是都是0哦，呵呵 这些变量的意思，去官网看咯 https://mariadb.com/kb/en/full-list-of-mariadb-options-system-and-status-variables/ 一堆，所以dba说白了就是要去学习这个几千个变量~ 复制延迟演示下 1、slave上删掉hellodb库 2、master上在hellodb里执行存储过程，创建大量数据 3、此时slave上就会因为没有hellodb库，而出现同步失败， 4、在slave上补齐hellodb库，然后stop start一下slave。及时show slave status\\G;看看延迟。 开始👇 reset 用了就真的清掉额了👇连master的binlog文件编号都没了。 对比slave2的正常情况 确实reset造成的，翻看了上图的历史截图，重新截了上下文 但是我在slave2上反复测试，都没有看到reset的这种效果了，需要手动 stop slave; reset slave; CHANGE MASTER TO MASTER_HOST='192.168.126.129', MASTER_USER='repluser', MASTER_PASSWORD='cisco', MASTER_PORT=3306, MASTER_CONNECT_RETRY=10, MASTER_LOG_FILE='mariadb-bin.000003', MASTER_LOG_POS=781; start slave; 反正能搞好也是了，呵呵。感觉slave 复制还有点坑。 其实很好理解吧，就是同步的binlog是 如果没有hellodb库，没有testlog表，就不行，所以同步的哪个，你将上图往上翻一翻看看从master那边复制的binlog起点，如果这个pos始终在hellodb.testlog创建之后，那么报错必然始终都在。 你只有将复制的位置POS点提前去覆盖到库表的创建才能消除报错。我不管你reset是怎么清空了master的binglo位置--其实就提前了吗，也不管你有时候reset slave又不清空，我只管复制的post位置是否符合逻辑对吧。 你看哦，这个现象就对了 下面是一个整图哦，受限屏幕才分开来的 reset后，start 的瞬间是两个YES就是OK的 但是又瞬间报错了 很简单啊，就是，我说的复制的主上的post点又读取了缓存记录--类似的吧，没有从头开始读取。 说了这么屁话，其实就一句话，操作上讲★就是要 stop slave; reset slave; CHANGE MASTER TO MASTER_HOST='192.168.126.129', MASTER_USER='repluser', MASTER_PASSWORD='cisco', MASTER_PORT=3306, MASTER_CONNECT_RETRY=10, MASTER_LOG_FILE='mariadb-bin.000003', MASTER_LOG_POS=781; start slave; MASTER_LOG_FILE='mariadb-bin.000003', MASTER_LOG_POS=781一定要确实是否合适！ ★其实规范操作就是先mysqldump出来master的数据，还原到slave后，再做slave的复制。 再说回来，你要看复制延迟，简单啊，直接POS指到前面去就行啦👇 那么问题来了3395是秒，还是记录还是，啥，简单 官网变量走一波，你麻痹，别学了，secondes_behind，你跟我讲去查资料。(●ˇ∀ˇ●)，而且明确告诉你没有这个变量的。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-08-11 18:06:29 "},"27-MYSQL数据05/3-mysql复制过滤器和基于SSL的复制加密.html":{"url":"27-MYSQL数据05/3-mysql复制过滤器和基于SSL的复制加密.html","title":"第3节 mysql复制过滤器和基于SSL的复制加密","keywords":"","body":"第3节. mysql复制过滤器和基于SSL的复制加密 部分数据复制，采用过滤器 两种实现方式： 1、仅写入需要复制的数据库，master节点配置 ​ 缺点：binlog不仅仅是用来实现主从复制，更多是用来做备份的一个增量还原用的。这样肯定不行，你本地binlog都不全了。 2、slave节点配置，在rely-log中继日志中挑取出，哪些特定数据库的特定表需要同步到本地。 ​ 缺点：rely-log中继日志里东西是全的，是从master复制过来了，然后再sql thread进行挑选的，所以已经从master复制过来，意味着网络和磁盘IO就花费出去了。 ​ 注意slave过滤需要在所有的slave上都要配置一边。 方法1：只生产特定binlog master上： ----------- vim /etc/my.cnf server-id=1 log-bin # binlog-do-db = binlog-ignore-db = hellodb wr systemctl restart mariadb mysql > show master status; 可见binlog黑名单数据库👇 此时hellodb的binlog都不会生产，自然就不会参与主从复制了，测试👇 slave那边test003还在，确实不同步了 其他数据还是同步的 此时就实现了数据的一个过滤过程 方法2：slave服务器上进行过滤 slave上： ------- vim /etc/my.cnf replicate-do-db=hellodb,db1 # 这里定义了一个白名单只从中继日志里取出helldb,db1两个库的binlog进行sql thread写入slave本地。 wr systemctl restart mariadb 此时没有加白的就不会复制了👇 加白的就继续复制 上图的\"hellodb,db1\"呈现出来的貌似是两个db用逗号分开，其实不一定的，要去my.cnf里看如果是replicate-do-db=hellodb,db1这种写法，系统可能就判定为一个叫\"hellodb,db1\"数据库了，鬼知道；如果是下面的写法，系统就虽然slave status里显示还是一样\"hellodb,db1\"，但是确实是逗号分开的两个数据库了。 结果就是加白的也没有复制，但是slave 状态时OK的啊，奇怪了。 就是写的格式有问题，不支持hellodb,db1这种逗号的方式，一行一个， 此时slave的状态倒时用逗号分开的，貌似和以前一样，但事实上时两个db了，以前时一个db 此时test在slave那边就确实同步 也删掉了 再看一个现象--就是目前的过滤器，必须切到use db进到哪个库里才能同步👇 你看master在none下操作的，没有use进到对应的库，所以就没有同步，下面对比测试use一下就同步了👇 实际工作中不要使用这种跨库操作就好，注意下，都使用use dbxxx进到某个库里进行操作。 数据主从复制安全加密下 mysql -uroot -pxxxx -h xxxx这种是明文的，抓包可得 可见cli和查看的结果数据都能看得到。 利用SSL加密，就是要有SSL证书 实验，在192.168.126.129和192.168.126.130之间实现加密 证书怎么申请， 证书是用来证明公钥的安全性的，每个服务器都有自己的证书，将来才能利用证书交换彼此的公钥，才可以进一笔利用公钥来加密对称密钥，进而实现数据传输的安全。 mysql的ssl是做了双向认证的，和平时https上网-只做服务器的认证，不太一样。 1、ca自己给自己版本证书：生产私钥，生产自签名证书； 2、然后在颁发证书 3、这次做都在一台机器上做完，包括CA、各个节点的证书生成，然后分发下去。 mkdir /etc/my.cnf.d/ssl # 专门放证书信息，利用现成的my.cnf.d文件夹，ssl是创建的 cd /etc/my.cnf.d/ssl 我们需要3个证书：CA的证书、主服务器证书、从节点证书。 有证书，就得有私钥， ①生成CA的私钥： openssl genrsa 2048 > cakey.pem # 以前是专门一个目录，现在简单放一起就行 可能最好加个密，或者改个cakey.pem的权限，安全些。 ②利用私钥生成自签名证书 openssl req -new -x509 -key cakey.pem -out cacert.pem -days 3650 ③生成master的私钥和证书申请文件 openssl req -newkey rsa:1024 -days 365 -nodes -keyout master.key > master.csr # 利用一条命令生成私钥文件master.key，并利用该key生成证书申请文件。 注意！1024得改成2048，否则mysql起不来。可能是之前用得2048的CA私钥吧。 ④有了证书申请文件，就可以签名了--也就是颁发证书 openssl x509 -req -in master.csr -CA cacert.pem -CAkey cakey.pem -set_serial 01 > master.crt 利用CA的信息，根据证书申请文件，来实现生成证书。 _set_serial 01 指定证书编号？ ⑤同样再生成slave的私钥和证书申请文件 openssl req -newkey rsa:2048 -days 365 -nodes -keyout slave.key > slave.csr # 利用一条命令生成私钥文件slave.key，并利用该key生成证书申请文件。 注意：-days 365 好像是默认就有的。 ⑥同样再给slave节点颁发证书 openssl x509 -req -in slave.csr -CA cacert.pem -CAkey cakey.pem -set_serial 02 > slave.crt 利用CA的信息，根据证书申请文件，来实现生成证书。 _set_serial 02 指定证书编号 到此就有了master和slave的证书和私钥了，就可以利用证书来加密了 开始给mysql配置ssl证书 默认是未开启ssl加密的 一些和加密相关的变量 题外话：%ssl%不区分大小写。 需要指ssl_ca CA的证书；ssl_cert自己的证书，ssl_key自己的私钥。 vim /etc/my.cnf ssl-ca=/etc/my.cnf.d/ssl/cacert.pem ssl-cert=/etc/my.cnf.d/ssl/matser.crt ssl-key=/etc/my.cnf.d/ssl/master.key 但是服务起不来 查看报错日志 发现是SSL error: Unable to get certificate from '/etc/my.cnf.d/ssl/master.crt' 可能是之前的master.crt证书文件生成的有问题。 一般是文件权限问题，但是这里不是，需要修改一下相关命令。 https://stackoverflow.com/questions/42145925/mariadb-over-ssl-not-working-certificate-verify-failed 👆这篇是OK的，只不过sha1要去掉就行了，我怀疑只要将上面的cli里的后缀改成pem就行了，试试看。不是，破案了👇，还是用上面的原cli改成2048跑一遍再。 下面对比排障测试： 这段NG： ----------------- openssl genrsa 2048 > cakey.pem openssl req -new -x509 -key cakey.pem -out cacert.pem -days 3650 openssl req -newkey rsa:1024 -days 365 -nodes -keyout master-key.pem > master-req.pem # 1024 改成2048就OK了 openssl x509 -req -in master-req.pem -CA cacert.pem -CAkey cakey.pem -set_serial 01 > master-cert.pem 这段OK： ----------------- openssl genrsa 2048 > cakey.pem openssl req -new -x509 -nodes -days 3650 -key cakey.pem > cacert.pem openssl req -newkey rsa:2048 -days 730 -nodes -keyout master-key.pem > master-req.pem openssl x509 -req -in master-req.pem -days 730 -CA cacert.pem -CAkey cakey.pem -set_serial 01 > master-cert.pem chown mysql.mysql * 如果常规就是起个server名字👇 openssl genrsa 2048 > ca-key.pem openssl req -new -x509 -nodes -days 3650 -key ca-key.pem > ca-cert.pem openssl req -newkey rsa:2048 -days 730 -nodes -keyout server-key.pem > server-req.pem openssl rsa -in server-key.pem -out server-key.pem openssl x509 -req -in server-req.pem -days 730 -CA ca-cert.pem -CAkey ca-key.pem -set_serial 01 > server-cert.pem chown mysql.mysql * ssl路径配置，重启服务OK后，此时status和show variables like '%ssl%';就可见 通过SSL相关变量可见 两个都YES了，也有了相关路径👇 此时就把ssl的配置都弄了，但是还没有启用加密方式连接。瞎说，上上图status可见 说明就已经启动了，至于有的低版本还需要这样启用，那是低版本太low。 不管是本地登入自己还是别人远程登入自己，还是本地用socket或是tcp套接字登入自己都是自动的启用了SSL的，status 可见SSL Cipher in use is TLS_AES_256_GCM_SHA384的。 低版本才需要链接的时候调用配置里的ssl证书和key mysql --ssl-ca=cacert.pem --ssl-cert=master.crt --ssl-key=master.key 然后强制某个账号必须使用ssl，高版本默认就是会用ssl，应该这也是低版本才需要的操作 grant replication slave on *.* to repluser2@'192.168.%.%' identified by 'cisco' require ssl; 此时使用repluser2 低版本就需要加上ssl选项，高版本不需要 进一步实现主从复制用SSL，将之前在master上一并产生的slave的证书也复制到slave上 其实用这个三个文件就行了 但是slave这样起不来！ 查看报错，说是SSL路径不对， 其实是权限没有，拿不到ssl文件 起来了，但是有错误 这个报错是主从复制的报错， 也就是不同步的报错，按之前的处理方法试试 SLAVE IO都没有Yes啊，解决思路有2 1、重新从master dump 出来一份，记得带--master-date=1选项，导入后，启动slave即可 2、在master上看看当前的binlog 位置，直接在slave上stop; reset slave all; 充型配置同步信息CHANGE TO 。。。。;在start slave试试，差不多就能同步，当然这里推荐用1而不是2.因为这是你从最新的位置复制过来的，前面很多数据都没有同步，而且2还不一定成功，可能报错👇如下图，不过只要按提示改成'mariadb-bin.000003' at 4 也能同步，呵呵，实验就无所谓了，同步就行了。 CHANGE MASTER TO MASTER_HOST='192.168.126.129', MASTER_USER='repluser', MASTER_PASSWORD='cisco', MASTER_PORT=3306, MASTER_CONNECT_RETRY=10, MASTER_LOG_FILE='mariadb-bin.000003', MASTER_LOG_POS=4; 此时搞同步了就，但是SSL还没有在主从同步环节启用，默认配置了ssl在/etc/my.cnf里只是登入(远程本地也好，socker/tcp也好)默认使用ssl。 Slave服务器配置 mysql> CHANGE MASTER TO MASTER_HOST='MASTERIP', MASTER_USER='rep', MASTER_PASSWORD='centos', MASTER_LOG_FILE='mariadb-bin.0000xx', MASTER_LOG_POS=xx, #这里写master的 MASTER_SSL=1, MASTER_SSL_CA = '/etc/my.cnf.d/ssl/cacert.pem', MASTER_SSL_CERT = '/etc/my.cnf.d/ssl/slave.crt', MASTER_SSL_KEY = '/etc/my.cnf.d/ssl/slave.key'; CHANGE MASTER TO MASTER_HOST='192.168.126.129', MASTER_USER='repluser', MASTER_PASSWORD='cisco', MASTER_LOG_FILE='mariadb-bin.000023', MASTER_LOG_POS=691, MASTER_SSL=1, MASTER_SSL_CA = '/etc/my.cnf.d/ssl/cacert.pem', MASTER_SSL_CERT = '/etc/my.cnf.d/ssl/slave.crt', MASTER_SSL_KEY = '/etc/my.cnf.d/ssl/slave.key'; 我看别人演示里不写三个ssl文件路径唉，我试试 CHANGE MASTER TO MASTER_HOST='192.168.126.129', MASTER_USER='repluser', MASTER_PASSWORD='cisco', MASTER_LOG_FILE='mariadb-bin.000023', MASTER_LOG_POS=691, MASTER_SSL=1; 结果一样的报错，而且，人家会自动去找到三个ssl文件路径并给你显示出来的--这是因为第一次配置了，这点和老版本不一样。放屁！stop slave; reset slave all;exit systemctl restart mariadb就好了，不用配置证书路径！ 尝试去掉ssl，发现去不掉👇，reset slave all;后并未配置ssl，也为启用，但是就启用了YES 手动写MASTER_SSL=0来关闭， start slave一下发现报错变了 问问GPT 实测操作，有效 此时在开启SSL看看 Last_IO_Error: error connecting to master 'repluser@192.168.126.129:3306' - retry-time: 10 maximum-retries: 100000 message: SSL connection error: error:00000000:lib(0)::reason(0) 还是报这个错， master上敲mariadb-admin flush-hosts也没有用！ 如何清空ssl文件路径，需要重启服务 stop slave; reset slave all;exit systemctl restart mariadb就好了，不用配置证书路径！ 你要说用户repluser2是只能ssl的， 没事，换，，改成repluser也一样，至少这里repluser2 成功就说明已经使用了ssl加密复制了。 那么问题来了，要不要配置，如果配置了是否应该配置master而不是slave呢，试试 不行，一样报错，只要配置ssl三个文件的路径，就有问题 这样就实现了带ssl的主从复制，上图hellodb002复制OK，001没有，是因为之前有个白名单 去掉就好了👇 再次尝试一下 去掉配置里的ssl路径，改为配置slave的时候指定ssl文件 CHANGE MASTER TO MASTER_HOST='192.168.126.129', MASTER_USER='repluser', MASTER_PASSWORD='cisco', MASTER_LOG_FILE='mariadb-bin.000023', MASTER_LOG_POS=691, MASTER_SSL=1, MASTER_SSL_CA = '/etc/my.cnf.d/ssl/cacert.pem', MASTER_SSL_CERT = '/etc/my.cnf.d/ssl/master.crt', MASTER_SSL_KEY = '/etc/my.cnf.d/ssl/master.key'; 不管是master的ssl证书还是slave的证书都不行，报错一样。算了，就在/etc/my.cnf里配置就行了，别在slave里配置ssl文件了。 CHANGE MASTER TO MASTER_HOST='192.168.126.129', MASTER_USER='repluser', MASTER_PASSWORD='cisco', MASTER_LOG_FILE='mariadb-bin.000023', MASTER_LOG_POS=691, MASTER_SSL=1, MASTER_SSL_CA = '/etc/my.cnf.d/ssl/cacert.pem', MASTER_SSL_CERT = '/etc/my.cnf.d/ssl/slave.crt', MASTER_SSL_KEY = '/etc/my.cnf.d/ssl/slave.key'; Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-09-07 15:29:15 "},"27-MYSQL数据05/4-基于MySQL5.7的二进制安装和GTID复制.html":{"url":"27-MYSQL数据05/4-基于MySQL5.7的二进制安装和GTID复制.html","title":"第4节 基于MySQL5.7的二进制安装和GTID复制","keywords":"","body":"第4节. 基于MySQL5.7的二进制安装和GTID复制 GTID复制-slave配置的是省去指定masterbinlog位置的方式 之前主复制都是指定MASTER_LOG_FILE='mariadb-bin.000023', 和 Master_log_pos=xxx CHANGE MASTER TO MASTER_HOST='192.168.126.129', MASTER_USER='repluser', MASTER_PASSWORD='cisco', MASTER_LOG_FILE='mariadb-bin.000023', MASTER_LOG_POS=691, MASTER_SSL=1; 这么多配置，还不如老方法手工指定呢，呵呵 GTID 全局事务ID GTID = server_uuid:transaction_id，在一组复制中，全局唯一 server_uuid 来源于 auto.cnf 开搞 1、下载mysql5.7算了我还是直接用新的吧 https://dev.mysql.com/downloads/mysql/ 没找到新版的二进制安装包，，，5.7的到时候有 算了直接用高版本的mariadb不香嘛，操 视频演示的mysql5.7的一个二级制安装备注： 同样注意下mysql5.7的二进制安装，的一个初始化差一点，它使用mysqld --initialize来初始化数据库的，并且直接在结尾给你生成了root的密码了。这个是和前面单独二进制安装的章节是不一样的点。 这里多了auto.cnf这个文件，和sys默认库 这个就是server的uuid来源了 需要添加client的socket，说什么不然本机连不了，client登入的时候也会找不到socket？之前多实例也没有说配置client的socket啊，优点奇怪👇 其他和之前章节的 二进制安装一样的操作。 登入的时候密码有特殊字符的处理方式 mango里python我是这么处理的 mysql5.7的二进制安装全过程👇 GTID配置举例 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-09-08 10:48:13 "},"27-MYSQL数据05/5-基于proxySQL实现mysql的读写分离.html":{"url":"27-MYSQL数据05/5-基于proxySQL实现mysql的读写分离.html","title":"第5节 基于proxySQL实现mysql的读写分离","keywords":"","body":"第5节. 基于proxySQL实现mysql的读写分离 简单介绍下工作原理 proxySQL通过read-only选项来识别谁是slave的，然后讲DML写道主上，DQL查询往从上发。 官网的指南： https://proxysql.com/documentation/installing-proxysql/ 我用的是rockylinux，通过它的这个URL 网上层看 所以待会可能用centos8来试试 通过上述就知道直接用他的指南肯定报错，因为我的rocky和他的URL对不上的 直接epel里就有这个proxysql 版本也不低了2.4.8，直接用吧 ProxySQL组成 服务脚本：/etc/init.d/proxysql 配置文件：/etc/proxysql.cnf 主程序：/usr/bin/proxysql 基于SQLITE的数据库文件：/var/lib/proxysql/ # 读写规则调度策略配置信息都是放到这个小型数据库里的。不是有配置文件吗，奇怪了，继续看吧，据说是配置文件仅仅可以改一小部分，基本上全部的配置信息都是放到SQLITE里的。所以将来管理proxySQL不是修改配置文件，而是通过像连接mysql一样去配置SQLITE。而且sql修改了SQLITE其实也会自动不配置文件里的内容给改了。 启 动 ProxySQL：service proxysql start 启动后会监听两个默认端口 ​ 6032：ProxySQL的管理端口 就是进入SQLITE的途径。 ​ 6033：ProxySQL对外提供服务的端口 6033默认面向用户的，可以改成3306这样用户那边就不要变动了，直接把proxySQL当做mysql连就行了，透明处理--对于用户来讲他只会以为连接的就是DB。 proxySQL默认数据库 main 是默认的”数据库”名，表里存放后端db实例、用户验证、路由规则等信息。 表名以 runtime开头的表示proxysql当前运行的配置内容，不能通过dml语句修改， 只能修改对应的不以 runtime 开头的（在内存）里的表，然后 LOAD 使其生效， SAVE 使其存到硬盘以供下次重启加载 disk 是持久化到硬盘的配置，sqlite数据文件 stats 是proxysql运行抓取的统计信息，包括到后端各命令的执行次数、流量、 processlist、查询种类汇总/执行时间，等等 monitor 库存储 monitor 模块收集的信息，主要是对后端db（主从）的健康/延迟检查 开始配置 192.168.126.129 - master 192.168.126.130 - slave 192.168.126.131 - proxySQL 搭建主从 master的配置：在129上 vim /etc/my.cnf server-id=129 log-bin wr systemctl restart mariadb mysql -e 'show master logs' # 从这里开始复制，把下面的创建账号也复制过去，其实正儿八经是先dump在开主从 ，就是按前面专门讲主从的章节来配置就行了 mysql -e \"grant replication slave on *.* to repluser@'192.168.%.%' identified by 'centos' \" mysql -e \"select user,host,password from mysql.user\" #检查下上一行的用户是否创建成功 slave的配置：在130上 vim /etc/my.cnf server-id=130 read-only wr systemctl restart mariadb msyql # 进入mysql的交互cli模式 MariaDB[(none)]> CHANGE MASTER TO -> MASTER_HOST='192.168.126.129', -> MASTER_USER='repluser', -> MASTER_PASSWORD='centos', -> MASTER_PORT=3306, -> MASTER_LOG_FILE='mariadb-bin.000001', -> MASTER_LOG_POS=xxx; # xxx就填上面master里的log的位置。 MariaDB[(none)]> start slave; # 如果不是干净的slave之前配置过，就stop slave;reset slave all;再start slave; MariaDB[(none)]> show slave status\\G; # 看到两个yes就基本OK了。 再测试一下同步是否OK，去master上创建也给库看看同步与否 到此主从就搭建好了，下面开始弄proxySQL 安装直接yum，epel里就有版本不低，反正没有rockylinux9的，有aws的新版倒是。这里选择直接yum了。 这里👇有最新版 https://github.com/sysown/proxysql/releases 也许rokcylinux可以用almalinux9的，试试~ [root@bind-child ~]# curl -OL https://github.com/sysown/proxysql/releases/download/v2.5.5/proxy sql-2.5.5-1-almalinux9.x86_64.rpm % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0 100 22.0M 100 22.0M 0 0 1458k 0 0:00:15 0:00:15 --:--:-- 1690k [root@bind-child ~]# ls anaconda-ks.cfg go lib64 pyvenv.cfg bin lib proxysql-2.5.5-1-almalinux9.x86_64.rpm tcping [root@bind-child ~]# yum -y install proxysql-2.5.5-1-almalinux9.x86_64.rpm # 当前目录下的rpm包直接yum它就行了 再安装一个mysql-client用来做msyql db的client连接用，不知道是不是必须的哦，继续梳理 [root@vpn001 ~]# rpm -qf `which mysql` mariadb-5.5.64-1.el7.x86_64 [root@bind-child ~]# yum -y install mariadb # 注意不是mariadb-client，直接mariadb就行，mysql这个命令就是来自mariadb这个包的。 [root@master ~]# rpm -qf `which mysql` MariaDB-client-10.11.5-1.el9.x86_64 [root@master ~]# 虽然显示mysql这个客户端命令就是来自于MariaDB-client,但是也可以 yum -y install MariaDB-client 同时也可以 yum -y install mariadb 一个效果。 有个用户组没得，先不管它 有的吖，操，瞎报什么...安装后脚本看看 哈哈，果然，这标志着我的这种慢慢吞吞就是吞吞怎么滴，学的法子，就不差，就能反映过来，yum的时候是安装报错没有group，就是一定是没有gorup的，但是结果id又看到了group，说明是安装后脚本，对吧，我是查看之前判断的，还不错。 版本还可以这是目前最新的了，毕竟是AlmaLinux9用的proxysql。 https://www.51cto.com/article/705594.html 启动proxysql服务后可见监听端口6032 6033 老版本是通过service启动的 6032是管理端口，进行配置proxysql的 6033是用户去连接的。 proxy的配置文件一般不用去改，一般都是通过sqlite这个小库去dml修改配置，sql语句修改了sqlite，就会自动把这个配置文件/etc/proxysql给改了。可以看一下配置文件 配置文件里就有端口号，可以自定义修改。 备份配置文件 ①注意用-a ②覆盖不想看到交互让你y，就用\\cp \\就是转义转成原始的cp，要知道cp一般是alias 但是没有改过来 改不过来就算，直接进SQLITE去用sql去改吧，反正后面都是用这种方式。 恢复一下 注意 移除的是server，其实client也会被当做依赖一并移除。 可以直接yum mariadb就是client 也可以MariaDB-client,一样的效果。 有了mysql 这个client命令，就可以进入proxysql的sqlite了👇 连接proxysql的sqlite mysql -uadmin -padmin -P6032 -h127.0.0.1 默认db 默认看的就是main库👇 monitor库可以看log了解相关信息，比如复制是否成功 看下这个表 select * from sqlite_master ;这个命令中sqlite_master没有指定哪个库，就是默认的main库 通过select * from db_name.sqlite_manster;可以看到每个db都有一个默认的表，且内容不同，且show tables from db是看不到的！ select * from main.sqlite_master where name='mysql_servers'\\G;可以看到当初是怎么创建定义字段的。 同时mysql里的desc命令在sqilte里是没有的，就是通过👆上图的方式来查看类似信息的。 开始配置proxySQL 添加mysql节点，默认就是操作的main，无需use main，等价于use main。 MySQL > insert into mysql_servers(hostgroup_id,hostname,port) values(10,'192.168.126.129',3306); MySQL > insert into mysql_servers(hostgroup_id,hostname,port) values(20,'192.168.126.130',3306); insert后检查： load和save，一个是加载到内存，一个是保存到磁盘，类似juniper，vyos的commit和save； MySQL > load mysql servers to runtime; MySQL > save mysql servers to disk; 创建登入mysql节点们的账号，用来查看read-only选项，以判断主从。 在mysql节点上 master节点： MySQL> grant replication client on *.* to monitor@'192.168.%.%' identified by 'cisco'; 一般此时主从都是正常同步的，所以slave上也会自动创建同样的账号密码。 在proxySQL上使用该密码用来做监控，其实就包含主从的判断 MySQL [main]> set mysql-monitor_username='monitor'; MySQL [main]> set mysql-monitor_password='cisco'; mysql > load mysql variables to runtime; mysql > save mysql variables to disk; MySQL [main]> select * from runtime_mysql_users; 但是找不到配置的信息在哪里查看，虽然可以肯定已经生效了，因为后买你可以通过log看到连接OK的。 本质上就是proxysql通过这种方式来判断主从的👇 查看相关日志，看连接有无问题 查看监控连接是否正常的 (对connect指标的监控)：(如果connect_error的结果 为NULL则表示正常) MySQL> select * from mysql_server_connect_log; 查看监控心跳信息 (对ping指标的监控)： MySQL> select * from mysql_server_ping_log; 查看read_only和replication_lag的监控日志 MySQL> select * from mysql_server_read_only_log; MySQL> select * from mysql_server_replication_lag_log; 从上往下插入的，上面很多都是一开始没有配置密码的时候的报错，账号是一致的，没有配置前默认就是用monitor作为账号的。 默认密码在proxysql的配置文件里可见👇 但是这两个日志还没有记录👇 通过前面的配置此时proxysql已经能识别出来谁是master，谁是slave了。 读写分离：分组，那个是写组，哪些事读组 MySQL> insert into mysql_replication_hostgroups values(10,20,\"test\"); 修正为： MySQL> insert into mysql_replication_hostgroups values(10,20,\"read_only\",\"test\"); MySQL> load mysql servers to runtime; MySQL> save mysql servers to disk; 通过下图可知，前面写的是写的，后面是读的，不过疑问就来了这里的10，20是否一定要和前面定义节点的时候的10，20保持一致，为了得到验证，这里先把10，20改成100，200 按PPT来，报错了，自行排错 好了加了ready_only的变种关键字，应该是新版本的变动。 别忘了load和save 为了测试10，20是不是要和前面的定义节点的时候保持一致，我觉得肯定要一致就是把定义节点的hostGroupID写到这里来的，才符合逻辑，这里先改掉，改个屁，给老子改回来，明摆着的事情不要瞎弄。 特意将两处的id改为不一致 改回来，不浪费时间！ 这个不知道怎么查看主从判断的结果。 读写分离：proxySQL使用的业务用户做DML和DQL用 配置发送SQL语句的用户，在master节点上创建访问用户，让它同步到slave上。 MySQL> grant all on *.* to sqluser@'192.168.%.%' identified by 'cisco'; 在ProxySQL配置，将用户sqluser添加到mysql_users表中， default_hostgroup默认组设置为写组10，当读写分离的路由规则不符合时，会访问10这个默认组的数据库；关注这里的10，从①定义节点②分组写读③默认路由要串起来理解。 MySQL> insert into mysql_users(username,password,default_hostgroup) values('sqluser','cisco',10); MySQL> load mysql users to runtime; MySQL> save mysql users to disk; 使用sqluser用户测试是否能路由到默认的10写组实现读、写数据 mysql -usqluser -pcisco -P6033 -h127.0.0.1 -e 'select @@server_id' mysql -usqluser -pcisco -P6033 -h127.0.0.1 -e 'create database testdb' mysql -usqluser -pcisco testdb -P6033 -h127.0.0.1 -e 'create table t(id int)' 就是在proxysql上通过127环回口连自己，模拟用户进行DQL查询，发现的到server_id都是129，说明都是走的proxySQL的默认路由其实人家叫default_hostgroup 10，10里放的就是192.168.126.129这个master。 同样用真实的client测试，在windows上要注意引号不能像linux那么随意👇 就是外面用双引号，里面用单引。 linux倒是不问，其实就该这样 继续测试路由功能-也就是proxysql的分发功能，目前都是默认转到10这个hostgroups里的成员，也就是master。 读写分离：添加路由规则 MySQL> insert into mysql_query_rules (rule_id,active,match_digest,destination_hostgroup,apply)VALUES (1,1,'^SELECT.*FOR UPDATE$',10,1),(2,1,'^SELECT',20,1); MySQL> load mysql query rules to runtime; MySQL> save mysql query rules to disk; 注意：因ProxySQL根据rule_id顺序进行规则匹配，select ... for update规则的 rule_id必须要小于普通的select规则的rule_id 看似条，实则，有条默认就是👇从上到下，漏下来的就路由到10组里。精细匹配的放在前面和交换机的ACL一样~其实在哪都一样，全TM从上往下匹配的，宇宙通用法则 测试：select一下 mysql -usqluser -pcisco -P6033 -h127.0.0.1 -e 'select @@server_id' windows cmd 也看看👇 好了，这些路由到slave了 再看下这个图👇 由于规则是select开头， # 注意哦，不区分大小写，通过上图就知道小写select也是命中rule2的。 所以show 走的是默认规则，看到的也就是129的server_id了。 测试：用事务的方式测 一个意思，begin自然也不会命中rule2 👇这些都直接会写到master，并同步到slave的，不会说事务没结束巴拉巴拉 slave就直接有了👇 测试：创建表 题外话-试试不进到库里create 发现是可以同步， 再试试不进到库里insert 竟然可以！看看前面的章节发现是过滤器的bug 去到交互模式试试事务 事务不提交倒是不会同步到slave的 事务级别默认就是 ，不提交，对于本地master来讲，也只是当前session里看到而已，本地都没有commit，如何能同步给slave呢。只不过上面的不进入交互模式是由区别的。 为什么上图的操作都是往slave发送的呢 没有commit的就没有结果，当然这里疑问是问什么往slave上发送。 当然！不是，你看rule就是走的默认发到master的，你为什么只是salve上看到，是因为你的master交互界面还在上一个事务里，没有commit 提交后就看到啦 路由的信息：查询stats库中的stats_mysql_query_digest表 MySQL > SELECT hostgroup hg,sum_time, count_star, digest_text FROM stats_mysql_query_digest ORDER BY sum_time DESC; 别学了前面忘记后面，as的用法：别名 SELECT hostgroup as hg,sum_time, count_star, digest_text FROM stats_mysql_query_digest ORDER BY sum_time DESC; 主从学过了，proxySql读写分离学过了，主从故障手动切换也学了，那么问题就来到了HA了，所以学技术好听点就是永无止境，难听点就是没完没了，本质上还是和自己争斗，希望各位能知止而后能定有所得，艮土乾金山天大畜。 proxy的单点故障、master/slave的切换后、proxy的路由变化 下面是一些高可用技术的介绍 1、MMM：很老的软件了，过时了，基于perl写的 Multi-Master Replication Manager for MySQL，Mysql主主复制管理器是一 套灵活的脚本程序，基于perl实现，用来对mysql replication进行监控和故障迁移，并 能管理mysql Master-Master复制的配置(同一时间只有一个节点是可写的) 官网：http://www.mysql-mmm.org https://code.google.com/archive/p/mysql-master-master/downloads rockylinux9都搜索不到这个软件了 2、MHA 也是perl语言写的，也是老产品了，但是不排除可也用 Master High Availability，对主节点进行监控，可实现自动故障转移至其它从 节点；通过提升某一从节点为新的主节点，基于主从复制实现，还需要客户端配合实现， 目前MHA主要支持一主多从的架构，要搭建MHA,要求一个复制集群中必须最少有三台 数据库服务器，一主二从，即一台充当master，一台充当备用master，另外一台充当从 库，出于机器成本的考虑，淘宝进行了改造后，淘宝TMHA支持一主一从 官网:https://code.google.com/archive/p/mysql-master-ha/ 3、更好的解决方案Galera Cluster Galera Cluster：wsrep(MySQL extended with the Write Set Replication) 通过wsrep协议在全局实现复制；任何一节点都可读写，不需要主从复制，实现多主读写 类似之前主-主结构--那个会出现冲突-通过autoincrement错开自动增长的键，但是建表没办法，但是Galera Cluster应该可以避免这些冲突，而且支持多主不仅仅是2个，3个也行~。 4、GR GR（Group Replication）：MySQL官方提供的组复制技术(MySQL 5.7.17引入的技术)， 基于原生复制技术Paxos算法 5、此外还有天生牛逼产品，分布式db Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-09-15 15:20:14 "},"27-MYSQL数据05/6-mysql的主从复制高可用性解决方案MHA.html":{"url":"27-MYSQL数据05/6-mysql的主从复制高可用性解决方案MHA.html","title":"第6节 mysql的主从复制高可用性解决方案MHA","keywords":"","body":"第6节. mysql的主从复制高可用性解决方案MHA 我为什么要用这个东西呢，一个perl 语言写的东西，最新版本2012年，难道是因为免费实用够用？好吧 MHA架构 manager节点，管理着多个主从，某一堆主从的master挂了，就会把在那堆主从里的找一个slave提升为master。 manager管理节点，是单点，但是问题不大，因为用户访问的业务不走它走，它挂了，不影响业务；除非运气好，manager挂了的时间段里，某个主从的主也挂了，此时由于没有管理节点，所以就无法自动提升slave，所以也就导致业务出问题了，按传统的思路写是要分流到master上的，此时master都没了，所以业务收到了影响。 MHA的工作原理介绍 先复习一下主从的底层 再来理解下图MHA的思路 1、三根柱子代表什么 2、柱子之间的落差，就是binlog落差 3、slave(i)这个i是变量，就是很多个slave的意思，u known~，这些不太优秀的slave(i)们，不仅仅从master那拿到的binglog比最优秀的lastest slave要少一截，而且写到本地还写的慢。 4、所以矮子当中选将军咯，新的master选出来后， 5、想办法补齐DeadMaster和LatestSlave之间的binlog差，怎么想办法：①dead不是机器dead只是服务dead就去找binlog文件；②binlog是否有异地备份；③没有异地，本地重启看看也行啊对不对，总之找到dead master上的binlog，补齐到LatestSlave上，不过这些理论上都是MHA实现的，所以MHA不太可能说给你异地取备份，也不太可能给你重启deadmaster机器，所以MHA能自动处理的应该就是机器没死mysql服务死的的情况去去binlog文件。 6、slave(i)同步之前可能也要做两个事情：①SQL Thread进程走完，把已经拿到的binlog写到本地文件里；②把和Lastest Slave之间的差距通过I/O Thread补齐；然后就继续同步。 看它意思， 这么麻烦的吗，难道不是slave 所有的save包括最优的那个slave，统统从deadmaster同步X，唉不对，同步各自的差异binlog嘛。 估计是怕deadmaster连机器都挂了，ssh上不去，MHA的manage拿不到binlog，就做不了X，所以才有了i1-->i2-->X这么一个先后同步的过程，就是每次同步的动作不大，能成功的同步先做了。 i1就是本地的sql线程将relylog写到库里，i2就是slave们从最优的slave去取差异binlog；X就是deadMaster上取binlog这个可能就不一定成功。 所以MHA要利用到ssh，scp这些协议 manager工具包需要epel源，node工具包不需要epel源。 manager工具包安装在manager节点上，node工具包安装在监控的主从节点上和manager节点上。 半同步复制，默认是异步会存在slave和master差异越来越大的可能，而半同步，就能保证只要有一台slave回应我master了，master就回答client了。参见 第二十七章 MYSQL数据05-第2节 master作为半同步的一个关键点，它的行为就是只要收到一台slave的响应就会回应client。那么问题来了，这种行为下，slave(i)们是否是保证一定有一台是最优的，会不会出现不同的数据分散到不同的slave上，不会！同步的机制就是binlog的posti位置，按序复制的，所以某台slave回应了master，那么这台slave一定已经取到了最新的数据了！ 呼~~~ 简单了解👇 MHA有个配置文件： ​ 其中global配置：就是为各个主从(它叫做application)提供默认的统一配置模板 ​ 如果想为单个某个主从，配置，就针对他们配置application关键字的配置。 在管理节点上安装两个包 mha4mysql-manager mha4mysql-node 在被管理节点安装 mha4mysql-node 在管理节点建立配置文件 vim /etc/mastermha/app1.cnf # app1就是应用1，就是对应一组主从，另建一个app2.cnf就是对应第二组主从 [server default] user=mhauser # 用来提升slave为master的账号，就是需要登入mysql去修改配置的。 password=cisco manager_workdir=/data/mastermha/app1/ manager_log=/data/mastermha/app1/manager.log remote_workdir=/data/mastermha/app1/ # 远端主机上的存放路径 ssh_user=root # binlog利用ssh scp拷贝过来 repl_user=repluser # 主从复制的账号也要 repl_password=cisco ping_interval=1 # 1s ping探测主服务器是否在线 [server1] hostname=192.168.126.129 candidate_master=1 [server2] hostname=192.168.126.130 candidate_master=1 [server3] hostname=192.168.126.131 在Master上配置 vim /etc/my.cnf [mysqld] log-bin server_id=1 skip_name_resolve=1 # 在MHA里必须要配置，否则默认MHA行为是做ip地址反向解析，导致用户ID识别出问题。 mysql>show master logs mysql>grant replication slave on *.* to repluser@'192.168.8.%' identified by ‘cisco'; # 主从复制账号和授权 mysql>grant all on *.* to mhauser@'192.168.8.%’identified by‘cisco'; # mha的管理账号，用来提升slave为master，需要修改配置的。 在slave上 vim /etc/my.cnf [mysqld] server_id=2 #不同节点此值各不相同 log-bin # 从节点本来无需binlog，但是将来要提升为master，所以需要事先开启binlog read_only relay_log_purge=0 # 默认会清除中继日志，这里不清楚，将来可能恢复使用。 skip_name_resolve=1 mysql>CHANGE MASTER TO MASTER_HOST=‘MASTER_IP’, MASTER_USER='repluser', MASTER_PASSWORD=‘cisco’, MASTER_LOG_FILE='mariadb-bin.000001', MASTER_LOG_POS=245; 在所有节点实现相互之间ssh key验证 MHA验证和启动 masterha_check_ssh --conf=/etc/mastermha/app1.cnf # 检查ssh key验证是否OK masterha_check_repl --conf=/etc/mastermha/app1.cnf # 检查主从复制是否OK masterha_manager --conf=/etc/mastermha/app1.cnf # 启动MHA集群，此时就可以正常使用了。 排错日志 /data/mastermha/app1/manager.log # 比如服务起不来，可以看看日志。 实验 4台就够了 命名 hostnamectl hostname mha-manager hostnamectl hostname master hostnamectl hostname slave1 hostnamectl hostname slave2 配置主从 ​ master上创建了两个账号，slave 配置的时候就从binlog的初始pos开始(通过flush logs刷新binlog可知初始位置在哪我的是389)；就可以把这两个账号带过去，不过最好手动配置吧。 修改一下，我的操作是在master下flush logs; show master log;然后手动在slave那边创建账号，master我们本次实验就当作是干净，或者不用同步之前的数据。 CHANGE MASTER TO MASTER_HOST='192.168.126.129', MASTER_USER='repluser', MASTER_PASSWORD='cisco', MASTER_PORT=3306, MASTER_LOG_FILE='mariadb-bin.000030', MASTER_LOG_POS=389, MASTER_CONNECT_RETRY=10; # 这个就是默认值 START SLAVE; 这样slave2也就同步了，slave1一样的，略 两个slave确认下 read_only变量 这个只读，mha后面就而已直接改了，好像是通过set 设置变量，而read_only本身就是变量，所以mha可以直接修改为OFF的。 我就想问了，不能修改/etc/my.cnf吗，ssh都有了，估计底层不是用走的修改配置文件的逻辑。 安装mha包 直接yum可没有的，都是老软件了，不过可以用的。 https://code.google.com/archive/p/mysql-master-ha/downloads 跳过报错试试 可能少一个perl-Log-Dispatch包 slave节点安装没问题 基于key的ssh配置 这里偷懒，直接做成4个机器 两两 ssh key 互通，所以操作如下 这样就实现了ssh-key 一个主从对应一个app1.cnf配置文件👇 上图👆就表示，这个包安装有问题了，还是之前的报错，不能跳过了就。 算了算了，👆按这个跑一边还是报错 估计就是el5的版本，太老了，算了，放弃这个工具了，也就只能在centos5\\6上跑跑了。 以下是视频里的老板不能继续演示，不过视频，应该是centos7，所以centos7也能用咯，还不错 ...中间省略... 最后就执行mha运行👇，从warning消息可见，是有一个默认的cnf存放路径的，我们这里手工指定的。 这个程序是一个前台执行的程序，就是一直盯着集群，只要master挂了，就提升一个slave。只要master正常，这个mha程序就卡在这里。 做mysql集群的时间也要同步 最好用ntp一级chronyd 模拟测试集群的HA 此时直接down掉master，然后看manager上 发现此时manager已经推出了 然后看看日志 最后可见从192.168.37.17切换到了192.168.37.17这台新的master。 此时192.168.37.37由于是master，show slave status\\G;就是空信息了。然后read_only就通过set的方式修改了变量为OFF了，但是配置文件是不会改的-->这就带来了只要重启服务就会变成read_only=on了，需要手动去改一改的。 此时192.168.37.27就指向了新的master37 挺好的一个软件mha，怎么不更新了，rocky9，直接无法安装manager了。。。回头再搞搞 接上面主从切换，原来的master挂了，然后slave升为master，然后业务OK了，去修复老的master，然后将其配置为slave即可。然后重新在manager上运行管理命令masterha_manager --conf=/etc/mha/app1.cnf 然后这里的mha不能解决proxySQL读写分离的场景，因为主从自动切，但是proxySQL的分组我记得是写死的hostgroup就固定了，比如10组里就是写操作层，10组里加入得就是master了，这个地方就存在自动切得需求，而mha方案里没有提到，所以mha也不是很好得一个方案。 重点学习Galera Cluster这个工具 mha还是单主多从，总归有数据没有同步丢失的可能；多主可能才是更极致的方案，percana、mariadb、mysql都有各自的多主方案。 多主存在的冲突如何解决的？下一篇说明 calera cluster 至少3个master，每个机器都可以读和写 多主架构，对于client来讲，到底访问谁呢？ 这里是不是就涉及负载均衡啦，不过还可以轻量化的用keepalived的VIP虚拟IP来做--只不过就是单节点读写了-应该。而LB就是针对不同session可以做到负载分担的。 https://galeracluster.com/library/documentation/certification-based-replication.html 图中关键字：global trx id就是 全局事务ID，关于GTID前文也讲过👇 上图说明了如何保证多主集群下的数据一致性： 1、client往多主--Galera Cluster集群里写数据，多主至少是三主了，图中简单画成了2个server示意； 2、client update 数据，不管是LB还是keepalive都是发送到一个master上的； 3、这个master，也就是图中server，就开始处理啦，OK，后就提交，因为涉及事务，还需要提交； 4、提交能否真正提交成功，还不一定的，往下看，此时就会触发replicate writeset应该也叫write set replication (wsrep)写集复制这个功能， 然后所有的server就都收到一个GTID全局事务ID，然后就开始处理 5、接收到update的server就检查，检查不通过就rollback_cb回滚，通过就是commit_cb提交到db里去。 同时；别的server也会检查，不通过就discard--由于数据不是本地提交的是别的server的，所以直接discard，如果通过，就应用数据apply_cb就是update一下，然后commit_cb提交事务。 有时间可以看看这个 https://mariadb.com/kb/en/getting-started-with-mariadb-galera-cluster/ 其中提到了 所以我的实验环境是默认就有的应该，无需安装，同时也可以安装吧。 Galera Cluster官方文档 http://galeracluster.com/documentation-webpages/galera-documentation.pdf http://galeracluster.com/documentation-webpages/index.html https://mariadb.com/kb/en/mariadb/getting-started-with-mariadb-galera-cluster/ Galera Cluster包括两个组件 ​ Galera replication library (galera-3) ​ WSREP：MySQL extended with the Write Set Replication WSREP复制实现 ​ PXC：Percona XtraDB Cluster，是Percona对Galera的实现 ​ MariaDB Galera Cluster 参考仓库国外的慢：https://mirrors.tuna.tsinghua.edu.cn/mariadb/mariadb-5.5.X/yum/centos7-amd64/ 注意：都至少需要三个节点，不能安装mariadb-server Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-09-19 11:09:39 "},"27-MYSQL数据05/7-实现galeracluster和性能测试.html":{"url":"27-MYSQL数据05/7-实现galeracluster和性能测试.html","title":"第7节 实现galeracluster和性能测试","keywords":"","body":"第7节. 实现galaracluster和性能测试 老版本的安装就是uyum install MariaDB-Galera-server，老版本的方法这里不管了，直接集成到新版里的。 然后就是看配置文件，在/etc/my.cnf里明确说了include galeracluster的配置就在这里 wsrep_provider= 其中wsrep_provider=要填写一个叫做libgalera_smm.so的库文件，而这个文件是安装mariadb自带安装的， 而且就是mariadb的yum源安装的@mariadb可见。 👇这个源就是按官网的yum源复制过来就行啦，详情将前文mysql安装吧。 好了，基本零件都不缺了。 wsrep_cluster_address= 三个节点的各自地址 binlog_format=row，就是二进制格式，一般默认新版都是MIXED，这里取消注释用ROW吧，忘记了，看前文👇 default_storage_engine=InooDB肯定是InnoDB了，MyISAM都不支持，官方就是说仅仅实验环境吧我看到好像。 innodb_autoinc_lock_mode=2这个不管默认就好 其实就是改wsrep_provider和wsrep_cluster_address以及binlog_format=row。 具体配置选项👇 https://mariadb.com/kb/en/configuring-mariadb-galera-cluster/ 实际需要的操作 vim /etc/my.cnf.d/server.cnf [galera] wsrep_on=ON # 10.1.1多了个开关 wsrep_provider=/usr/lib64/galera/libgalera_smm.so wsrep_cluster_address=\"gcomm://192.168.126.129,192.168.126.130,192.168.126.131\" binlog_format=row 这个gcomm是协议，就好比ftp://还比https://一样，gcomm是glaeraCluster内部通讯的协议。 👆就改这么多，其他不动 优化设置 wsrep_cluster_name = 'mycluster' # 默认my_wsrep_cluster wsrep_node_name = 'node1' # 本机器的名称，这里暂时不加 wsrep_node_address = '192.168.126.x’ # 当前机器的IP，不用写，这里只是强调写出，实际不写 通过scp复制到其他2个节点 启动注意点 三台不是一样的方法启动； 集群存在/不存在，启动方式也是不同的。 1、原来没有cluster的启动方法和原来有cluster集群的启动方法是不同！ 2、首次启动，其他节点，systemctl restart mariadb就行 本实验是初始化集群，开始启动 任意一个节点，来初始化集群 galera_new_cluster 其他节点就 systemctl restart mariadb 这里我就用192.168.126.129，这里的master主机名，不要在意，不用纠结，这是以前实验 主从起的名字，这里多主，每个节点既是master也是slave。 其他节点重启报错 而且初始化集群的node，直接重启也会报错 此时处理方法，在没有头绪的情况下，俺是第一次接触这个集群，所以注释掉/etc/my.cnf.d/server里的galer模块配置，重启mariadb。 然后再重新走一遍就行了。注意重新启动就用galera_recovery来启动集群 然后莫名其妙再敲一遍就OK了？ 然后去重启其他节点的服务，看看能不能成功， 不行 排错 之前的配置注释掉 没用，重新做吧，把mariadb remove掉重弄？ 重新rm -rf /var/lib/mysql/* 反复3次后倒是成功了 mb的怎么弄都OK了现在！！ 应该就是/var/lib/mysql/下要干净， 然后有个明确的故障点处理方式就是 👆这个文件要么删掉，要么修改safe_to_bootstra:1就可以启动服务成功。 错误-2 这是cli用错了，重启不能这么干， 好像所有的node 都stop mariadb就起不来了，因为可能没有gcomm的通信方了 我的理解，就是集群里必须有一个活着才能重启成功，测试下 现在3个node都挂了，如何起来了，简单， 这样处理就行了 随便找一台node，一般是最优的吧 果然就好了，所以前面的配置OK就是这里的处理手法要注意，这里你可以理解为是技术细节，也可以理解为产品不傻瓜化。 此时理论上另外2个node直接restart就行了 本来创建集群的那一台tm的竟然起不来 判断失误，没事，老方法，狗屁啊，safe_to_bootstrap=1这个参数是针对the most advanced node最优节点也就是数据最新的节点的操作，就是确定后要敲galera_recovery的，前面已经有一台node初始化了cluster，此时其他只能是加入了，所以操作就是systemctl restart mariadb，通过报错日志可见 说明是SSL证书问题，关掉ssl 重启就好了 总结 1、初始化cluster 2、重启cluster 操作要小心 galera_recover重启cluster，报错没关系，集群不受影响👇 总结2：重启集群 上图👆就告诉你了，如果nodes及群里的节点全部都stop了，此时就需要有一个node去做bootstrapped创建集群，如果只是简单的started normally就是systemctl start mariadb就会找wsrep_cluster_address里的IP地址去做gcomm协议连接，如果没有一个nodes是起来的，那么就会启动服务失败，这很关键。 测试下： 当前集群OK 停掉3台中的2台node，尝试将两台stop的start 没问题，处理方式OK 集群里的所有nodes全部停掉，这里就是3台咯 此时就需要恢复集群， 1、galera_recovery 按上文的说明，就是要修改 还是起不来 再次查看，发现人家让你找最优的node，何为最优，就是seqno 找到了，去84这台敲 galera_recovery 不行啊，操！ 不过通过上面的操作已经知道了 不是恢复而是创建，用galera_new_cluster就可以了 而且集群ID也不会变 剩下两台node就简单了，重启服务就行了 到此不为此，基本的处理方法就有了。重点看总结就行，然后之前不行的原因就是①ssl没有弄好，之前实验遗留的，只配置了2个node的ssl，这里涉及3个呢，不过有一次ssl没关也OK，不过通过上文的报错可见确实有问题的；②就是集群的启动和重启有讲究的，重启有问题还是用的初始化创建的命令来解决问题的。 继续看集群的数据读写处理 说明：hostname无所谓master slave，这仅仅是之前实验的遗留，这里是多主，都是master。 导入一个sql脚本，会创建新库和表，这是在第一个节点上做的。 然后其他所有nodes也就自动同步了👇 表同步自然也OK 变量查看 SHOW VARIABLES LIKE 'wsrep_%\\G'; 有当前自己的IP信息👇 有/etc/my.cnf.d/server.conf里配置的信息👇 SHOW STATUS LIKE 'wsrep_%'; # 状态变量 SHOW STATUS LIKE 'wsrep_cluster_size'; 查看集群nodes数👆 添加新成员node 不过人家官方说了，the first node has x.x.x.x，才能加入x.x.x.x，呵呵~。👇 其实就是每台node都补一个IP，然后一个个重启就行了 只要cluster里有一个活着，就能重启服务OK，除非同时down了 人家说的就是这个意思，所有nodes都down了，才需要重新初始化(这个我走成功了），或者没有走成功的galera_recovery； 然后新加入的node，也会很快同步db的 建表也不会冲突，因为有wsrep机制啊 只会有一个成功👇 然后看看大量数据写入的一个速度，是明显比主从慢很多的，因为👆 下班关机 算了明天继续弄吧，由于机器关机了，之前就是临时做实验，所以mysql服务都停了，这里正好重演一次cluster的启动 可见👆所有服务都没起来 随便选一台初始化集群 查看seqno虚拟号，👇下图注意哦，135的seqno最优秀，所以safe_to_bootstrap:1就是1，其他都是0，这是系统给默认设置好的，然后有个node3的1是我改的！我之前准备用node3初始化新建的，所以看到的是1。 node2最优秀，尝试不初始化，重启的专用cli试试 起不来啊~ 直接new吧哈哈 然后其他node 都systemctl start mariadb就行了 同时创建的cli的没问题👇 测试开始 然后就看看数据的增长 发现这个速度比简单的主从还要慢很多，然后其实可以做成事务，事务就是一起提交，会快一点。 像这种就好比大量用户的写咯，所以具体用的时候还存在问题，需要优化吧应该！好像他们业务实际也不这么玩。 还发现一个现象👇 就是galera cluster默认就给你做了table的插入的自动间隔，以前是这么配置的。 👇12分钟终于结束了： 试试 事务的方式，理论上会快一些 这TM也太夸张了，不对吧 第二十运行事务，一样是6秒种，一共插入了3次，每次99999行，300000-3=299997行，对的👇 再次不跑事务看看 结论，galeraCluster集群，大数据并发写入，使用事务就很快！不使用事务就灰常慢！ 复制的问题和解决方案 其实以下这段文字算不得什么问题和方案，聊胜于无，看看吧👇 (1)数据损坏或丢失 Master： MHA + semi repl Slave：重新复制 (2)混合使用存储引擎 MyISAM：不支持事务 InnoDB： 支持事务 (3)不惟一的server id 重新复制 (2)复制延迟： 需要额外的监控工具的辅助 一从多主：mariadb10版后支持 多线程复制：对多个数据库复制，好像是高版本的特性。 TiDb概述 主从、多主，对于写操作，本质上都是在一台上操作的，所以mysql这种HA，本质上就是有瓶颈的。这话欠妥，没有讲到点子上，我们将LB的行为，在很多地方体现：①portchannel②f5这些其实都是针对多个session多个会话或多个用户去负载分担的，mysql的瓶颈本质的一个点就是如果是一个session里的一个事务，而这个事务里面有大量的操作，那么这个事务肯定是往一台机器持续读写的，而针对这个单个事务的负载分担解决方案就是TiDB它可以做到分布式事务。 牛逼👆 而更优的解决方案就是TiDb分布式数据库。 RDBMS关系型数据的 数据一致性ACID特性；NoSQL性能好但是没有保证数据的一致性；TiDb结合了两者的优点，又叫做NewSQL 所以DB分为了：RDBMS、NoSQL、NewSQL 据说：mysql的业务迁到TiDb，基本上不用改动，直接搬过去就能用，不用改代码。 TiDB的核心特点 1 高度兼容 MySQL 大多数情况下，无需修改代码即可从 MySQL 轻松迁移至 TiDB，分库分 表后的 MySQL 集群亦可通过 TiDB 工具进行实时迁移 2 水平弹性扩展 通过简单地增加新节点即可实现 TiDB 的水平扩展，按需扩展吞吐或存储，轻 松应对高并发、海量数据场景。 3 分布式事务 TiDB 100% 支持标准的 ACID 事务 4 真正金融级高可用 相比于传统主从 (M-S) 复制方案，基于 Raft 的多数派选举协议可以提 供金融级的 100% 数据强一致性保证，且在不丢失大多数副本的前提下，可以实现故障的自动 恢复 (auto-failover)，无需人工介入。 5 一站式 HTAP 解决方案 TiDB 作为典型的 OLTP 行存数据库，同时兼具强大的 OLAP 性能， 配合 TiSpark，可提供一站式 HTAP解决方案，一份存储同时处理OLTP & OLAP(OLAP、OLTP 的介绍和比较 )无需传统繁琐的 ETL 过程。 6 云原生 SQL 数据库 TiDB 是为云而设计的数据库，同 Kubernetes （十分钟带你理解 Kubernetes核心概念 ）深度耦合，支持公有云、私有云和混合云，使部署、配置和维护变得十 分简单。 TiDB 的设计目标是 100% 的 OLTP 场景和 80% 的 OLAP 场景，更复杂的 OLAP 分析可以通过 TiSpark 项目来完成。 TiDB 对业务没有任何侵入性，能优雅的替换传统的数据 库中间件、数据库分库分表等 Sharding 方案。同时它也让开发运维人员不用关注数据库 Scale 的细节问题，专注于业务开发，极大的提升研发的生产力. 数据库的整理差不多了就 下面介绍以下压力测试 性能衡量指标 数据库服务衡量指标 QPS: query per second # 查询性能： 每秒处理的查询次数，简单的单表select和多表join对系统资源的消耗是截然不同！所以压力测试的时候是要事先定义select查询规则--涉及哪些查询方法。 TPS: transaction per second # 事务的处理，主要指的就是数据的修改性能了，涉及增删改。 压力测试工具 mysqlslap # 系统自带，无需安装 Sysbench：功能强大 https://github.com/akopytov/sysbench tpcc-mysql MySQL Benchmark Suite MySQL super-smack MyBench mysqlslap使用 该工具来源于MariaDB-client软件👇 注意：虽然这个工具测试完成后不会在DB中留痕，但是binlog肯定会大量被它修改的，所以测试的时候binlog要么关闭，要么单独存放。 binlog除了在/etc/my.cnd里定义，也可以放到/etc/my.cnf.d/server.conf里一样的，👇涉及集群galera里定义了binglog的格式row，所以也可以log-bin开启也放在这个配置文件里。 binlog是否启用，最好还是看变量，而不是ll /var/lib/mysql/去看相关文件有没有对吧，你这样还得去先看看cnf人家配置在哪里了。 生产了大量的binlog 如果要停binlog，set 变量这种挺不掉，因为是基于你当前cli交互进去的session的，而压力测试是多session并发的，完全没有一点效果，因为session完全撞不到一起去，哈哈。而且sql_log_bin是session级别的变量，没有全局的。真的是session的，看看官方 再试试 果然👆，无法实现：关闭全局binlog的效果，只能去cnf文件了。 等等👇这TM什么回事： 问👆binlog基于本会话到底是关了还是没关？ 确实关了 测试引擎之间的差异👇 [root@node1 ~]# mysqlslap -a --concurrency=50,100 --number-of-queries 1000 --iterations=5 --engine=myisam,innodb --debug-info -uroot -pmagedu --concurrency=50,100 # 50到100个并发数，是个范围区间。 案例 也不是绝对的👇，网速随便搜搜都有推荐配置优化方案，也可以参考他们的。 max_connections的默认值看看 因为这个默认限制，所以并发测试看下效果👇,并发就是多个sessions同时测试的。 修改并发数👇 重启服务后 那个遇到低版本的并发改不上去(mariadb5.5.60就是上不去151只能通过my.cnf改成214的上限)的处理方法，这里也做一下记录，因为涉及底层逻辑：151的默认，明明mysql的配置文件里改的是2000，但是实际只能到214，是因为并发底层走的是文件socket，这个socket要调上去的，是系统层面的东西，底层的东西。打开一个socket就会开启一个文件描述符fd。 1、mysql的配置文件里 /etc/my.cnf里或者/etc/my.cnf.d/server.cnf的max-connectsions=2000 2、系统级别的socket，文件socket的限制扩容 ulimit -n 66666 # 设置 ulimit -a # 查看 就可以看到open files这项改了，不过这个命令是基于session修改的，也就是当前shell窗口有效。 3、LimitNOFILE 高版本就是改了的，至于第二点ulimit应该不用改！确保下面👇的数据足够以及mysql配置文件里max_connections改了就行了。 一般数据库1000-2000并发就差不多了，不想apache或nginx上万都行。 所数据库的并发数，不是越大越好，设置一个你的服务器资源能够承受的值就好，如果设置过大比如8000，结果真的来了这么多并发，就会导致db处理不过来，结果就是一个用户都访问不了了。 back_log 并发加入是2000，那么如果超出2000，又来了10个人，那么10个就是进入backlog进行排队。这个排队好像和QoS里的队列不是一回事，是保持的tcp连接数，本来2000个tcp连接上线，超出了也不是说就拒绝掉，而是用back_log机制暂存以下这些tcp连接。 max_connect_errors 针对单个用户，如果连接报错的次数达到一定的值，就会禁止该client连接过来。直到mysql服务重启，或者flush hosts命令清空此client主机的相关信息。所以这个参数的计数周期也就是两次服务重启或者flush hosts之间的时间。 比如黑客不断尝试连接，密码出错了10次，此时应该就可以触发此机制。 open_files_limit 这个其实就是 /usr/lib/systemd/system/mariadb.service 文件里的LimitNOFILE参数 两个都是干一件事的，不过使用场景不同 open_files_limit是适用于二进制安装或者编译安装的，这两类的服务启动都是二进制文件启动的，此时调整socket文件的打开数就这么调，这就是一个配置选项直接配置在my.cnf配置文件里。 LimitNOFILEs是用于 systemctl 启动的服务 本身就是一个配置选项，也是变量，所以直接配置到/etc/my.cnf里就行啦，他👇这里的三个配置方式，最后一个是/etc/security/limits.onf估计也是一个意思。 就是知道有这么个东西，具体最合适的还需要自己修订，和找最新的实践分享。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-09-20 16:40:58 "},"28-运维自动化之ansible/28-运维自动化之ansible.html":{"url":"28-运维自动化之ansible/28-运维自动化之ansible.html","title":"第二十八章 运维自动化之ansible","keywords":"","body":"第二十八章 运维自动化之ansible Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"28-运维自动化之ansible/1-自动化运维介绍.html":{"url":"28-运维自动化之ansible/1-自动化运维介绍.html","title":"第1节 自动化运维介绍","keywords":"","body":"第1节. 自动化运维介绍 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"28-运维自动化之ansible/2-ansible安装和架构介绍.html":{"url":"28-运维自动化之ansible/2-ansible安装和架构介绍.html","title":"第2节 ansible安装和架构介绍","keywords":"","body":"第2节. ansible安装和架构介绍 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"28-运维自动化之ansible/3-ansible常见模块.html":{"url":"28-运维自动化之ansible/3-ansible常见模块.html","title":"第3节 ansible常见模块","keywords":"","body":"第3节. ansible常见模块 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"28-运维自动化之ansible/4-ansible相关常见工具.html":{"url":"28-运维自动化之ansible/4-ansible相关常见工具.html","title":"第4节 ansible相关常见工具","keywords":"","body":"第4节. ansible相关常见工具 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"28-运维自动化之ansible/5-playbook的实现软件配置和部署.html":{"url":"28-运维自动化之ansible/5-playbook的实现软件配置和部署.html","title":"第5节 playbook的实现软件配置和部署","keywords":"","body":"第5节. playbook的实现软件配置和部署 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"28-运维自动化之ansible/6-playbook的高级用法模板template.html":{"url":"28-运维自动化之ansible/6-playbook的高级用法模板template.html","title":"第6节 playbook的高级用法模板template","keywords":"","body":"第6节. playbook的高级用法模板template Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"28-运维自动化之ansible/7-ansible的高级用法role1.html":{"url":"28-运维自动化之ansible/7-ansible的高级用法role1.html","title":"第7节 ansible的高级用法role1","keywords":"","body":"第7节. ansible的高级用法role1 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"28-运维自动化之ansible/8-ansible的高级用法role2.html":{"url":"28-运维自动化之ansible/8-ansible的高级用法role2.html","title":"第8节 ansible的高级用法role2","keywords":"","body":"第8节. ansible的高级用法role2 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"29-HTTP协议和APACHE/29-HTTP协议和APACHE.html":{"url":"29-HTTP协议和APACHE/29-HTTP协议和APACHE.html","title":"第二十九章 HTTP协议和APACHE","keywords":"","body":"第二十九章 HTTP协议和APACHE Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"29-HTTP协议和APACHE/1-httpd基础知识.html":{"url":"29-HTTP协议和APACHE/1-httpd基础知识.html","title":"第1节 httpd基础知识","keywords":"","body":"第1节. httpd基础知识 通过man socket查看 man 2 socket 开发看的 这里的accept bind connect都是C语言写的，他们都是也给tcp连接的更加底层的功能模块。 man 3 socket 也是开发看的 BIND 模块，是socket套接字绑定用的 1、创建socket描述符 2、绑定socket描述符和协议|IP|PORT 3、listen，打开socket监听 4、client，同样打开socket，通过connect函数发起请求，连接的时候指定目标服务器的IP和PORT。 5、请求发过去后，server端就有一个accept函数负载接收用户的connect请求。 6、到此就形成了一个连接。比如TCP/UDP的连接，什么UDP无连接，谁说无连接的，只是不面向连接，什么叫不面向连接，就是不时刻维护连接信息。但是连接的初始化工作还是要做的，否则怎么通信呢。 同样进一步理解socket的函数模块和工作思路 还是和上文一样，打开socket，bind协议IP端口，监听socket，处于accept状态 此时client1来了，就开启一个New Socket，然后发送/接收数据， client2来了，同样新建一个socket，来处理，多个不同的socke连接来实现不同client的请求。这里面可以联想到一个窗口一个软件一个页面打开可能涉及多个session会话，一个session应该就是对应一个连接(socket)吧。 看下函数调用，py案例 注意看下小端口的一个保留特性，权限不够的报错，这个在一些linux比如centos7上可能是存在的，但是我用rockylinux9并没有发现什么问题。 结果并没有出现小端口不让普通用户用的情况， Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-10-02 12:04:23 "},"29-HTTP协议和APACHE/2-http协议各种版本详解.html":{"url":"29-HTTP协议和APACHE/2-http协议各种版本详解.html","title":"第2节 http协议各种版本详解","keywords":"","body":"第2节. http协议各种版本详解 网站要防盗链的，否则，比如人家的图片都引用的你的网站的图片， 1、网站1盗链网站2的图片 2、用户打开网站1，看到的图片，其实都是网站1链接的2的图片 3、网站2的带宽白白被网站1的访问给占用了。 这里视频讲了一些HTML\\CSS\\JS的知识，只是简单的说了说，还不如走一遍《python编程从入门到实践第二版》P371的django案例。这块东西接触过了就知道确实不错有时间可以继续折腾下，做好了可以收纳自己的脚本工具到页面方便管理和用户入口。 MIME是邮件的一个功能，HTTP集成了👇 text是大类，/css这些是小类型。 然后浏览器里对应txt文件或者conf文件，都是不能直接打开看的，都是判断为下载，原因就是MIME里没有这个后缀的支持👇 浏览器的源代码点不比操作系统简单； 都是浏览器给你下载好资源，比如图片。 动态文件和静态文件 动态：3P：php、jsp、asp都是执行程序，用户看到的是这些3p程序执行后的结果--实在server端执行后的结果，而不是程序本身。 静态资源下发到CDN，动态资源需要回源。 访问https://oneyearice.github.io/其实就是打开这个根目录下的index.html文件。 HTTP的串行和并行连接 上图👆并行连接时，近乎同时发送多个tcp连接。 👇这篇的两个图，应该和串行和并行的案例还不同，👇这里提到的是一个tcp连接里传多个http的请求。 https://cloud.tencent.com/developer/article/1893815 3.1 Fully multiplexed 解决了队首阻塞的问题。对于同一个TCP连接，现在可以发送多个请求，接收多个回应了！在HTTP/1.1里面，如果在一个连接里上一个请求发生了丢包，那么后面的所有请求都必须等第一个请求补上包，收到回应以后才能继续执行。而在HTTP/2里面，可以直接并行处理。 回到并发，服务器本身并发支持是OK的，浏览器的并发，发起是有限制的。 对于大的网站资源，表面上打开的是首页，其实背后的很多资源(首页的index.html里会涉及很多url)，比如图片、JS 都是放在不同服务器上的，相当于client同时从不同的服务器上下载资源。其实是大大消耗的是客户端的带宽。 持久连接，这个好像就是上文提到的Fully multiplexed 👆图(a)就是串行，针对多个资源的下载，tcp连接一个个建立，http请求一个个发送； (b)是优化了tcp就一个，在一个tcp连接里，串行的发送http请求； (c)是进一步优化，tcp一个，然后在这个tcp连接里，并行的发送http请求。 不过，这理论感觉看看就就好，正向gpt所说，也不是并行就好的，早在硬盘的IO上就知道串行才是王道，并行干扰解决不好，同样http传输就涉及两个并行①tcp连接②http请求；干扰我不知道有没有，也许这里不同于硬盘不存在干扰，但是并行一定涉及排序重组，本身就消耗CPU了，所以也不一定就很好，考虑到浏览器的复杂性，这没必要深入，大概浏览器本身也会择优应用机制。 不过，串行的最大问题就是 one by one 一个过不去，后面都阻塞。 HTTP工作机制总结 HTTP协议 head是什么，头，就是数据包的头，类似于IP头，TCP头一个意思。 IP|TCP|HTTP|DATA 这个HTTP的头就是涉及http数据包格式了。 head里会涉及的内容，头部本身就是个文本。 1、content-type：告诉上层应用，拆包的机器一开，就是里面是啥，比如是data是也给音频、文本、图片啥的。就是MIME的大类/小类值咯。 比如用户收到这个response的头，看到这个image/png，浏览器就会用对应的图片解释模块来渲染DATA，来显示图片来。 2、表示http服务是什么软件提供的，nginx、github、tencent-cos桶。还真是五花八门，自定义的啊？估计是。 单个TCP的利用效率从Http1.1开始的 注意上图，除了tcp 持久化之外，还有一个浏览器同时6个持久连接，这个我在做URL访问LOG的时候，其实iptables的审计LOG啊， # 👇这是iptables的log配置 -A FORWARD -s 192.168.30.181,10.100.2.93,10.100.2.182,172.16.31.31 -m set --matc h-set xxx.com dst -j LOG --log-prefix \"[ user_name xxx.com ]\" --log-level 4 # 👇这是修改iptables的log默认存放目录，默认是放在/var/log/message下的，当然你这样做，默认里还是有的，无所谓了，这里多一份也OK，通过这里的日志分析，就会知道其实一个web页打开，就会涉及很多个sessions了，就可以和这里所学的浏览器的默认6个持久连接联系起来，不过呢6个也是他说的，不要当真，就算是真的也不要较真。 kern.warning /log/iptables/iptables.log 👇以下截图是流量LOG的说明截图，哈哈，当时就发现了一个网页会有多个tcp连接。 这里面还涉及专业术语，前面没有提炼出来： 1、单个tcp连接的持久化，里面支持多个http应答，不管http是否并发还是串行，这个叫持久连接 persistent connection； 2、一个TCP里，同时发送http请求，也许是有细微的间隔不过近似于并发(我看图猜的)，这个叫管道机制，TNN的真TM不会起名字。但是没办法，可能有的教程里还真这么些的。英文叫pipelining，真TM不会起名字，pipline是gitlab runnerr做CI/CD的流水线啊，操，老外起名字的水平肯定是不行的。 不过老早就http2.0了，这些参数也发生变化了，总之了解一下。 缓存工作原理，前面章节讲过LRU算法，涉及过期时间。 视频举例提到是jd的图片预览，但是实测并不是206而依旧是200的返回码。 问问gpt 虚拟主机，主机名，不过现在都是基于head头转发啊，niginx就可以啊，这也是个老技术了。 可见👆keep-alive也不一定是件好事，关键点就是长连接不释放，占用资源。 SPDY就是私有变公有HTTP2 推消息啊，所有个性化广告就是这么推过来的哦。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-09-26 15:57:58 "},"29-HTTP协议和APACHE/3-httpd软件工作模型.html":{"url":"29-HTTP协议和APACHE/3-httpd软件工作模型.html","title":"第3节 httpd软件工作模型","keywords":"","body":"第3节. httpd软件工作模型 URI URI: Uniform Resource Identifier 统一资源标识，分为URL和URN ​ > URN: Uniform Resource Naming，统一资源命名 ​ 示例： P2P下载使用的磁力链接是URN的一种实现 magnet:?xt=urn:btih:6605589.....890EF888666 ​ > URL: Uniform Resorce Locator，统一资源定位符，用于描述某服务器某特定资源位置。 两者区别：URN如同一个人的名称，而URL代表一个人的住址。换言之， URN定义某事物的身份，而URL提供查找该事物的方法。URN仅用于命名， 而不指定地址 额，看来URI真的很多啊，哈哈哈 其实URL使用是最多的，URI里面虽然包含了很多，但是URL是最最多的，所以通常人们提到屌丝的时候，大概也不是什么赞美，哎哎哎，通常工作中URI和URL其实是混为一谈的，不必较真。但是你自己说出来的就得是URL URL组成 URL格式： ://:@:/;?# scheme:方案，访问服务器以获取资源时要使用哪种协议，比如https://，这就是scheme，ftp://也是schema，不同的scheme其实就是不同的协议，自然后面的port也就不同。 user:用户，某些方案访问资源时需要的用户名 # 基本不用 password:密码，用户对应的密码，中间用：分隔 # 基本不用 Host:主机，资源宿主服务器的主机名或IP地址 port:端口,资源宿主服务器正在监听的端口号，很多方案有默认端口号 path:路径,服务器资源的本地名，由一个/将其与前面的URL组件分隔 params:参数，指定输入的参数，参数为名/值对，多个参数，用;分隔 # 名/值对，就是在说 键值对的形式 query:查询，传递参数给程序，如数据库，用？分隔,多个查询用&分隔 # 这个比较常见，👇cat是类型的简写。 上图👆?cat=670,671,672实际上就是mysql的select * from goods where cat='670,671,672'; frag:片段,一小片或一部分资源的名字，此组件在客户端使用，用#分隔 这个是跳转，比如业内跳转到下面的内容。 ​ 当点击M的时候👇，就等价于在URL后面补一个#m，这就是frag片段，可用来直接跳转到下面的特定行。 &就是select里的and，翻译成DQL就是select * from goods where cat='670,671,672' and ev='exbrand_华为(HUAWEI)^' and cid3='672'; 这里还涉及%2C就是,逗号 然后%5E好像是^脱字符， 网站访问量 IP(独立IP)：即Internet Protocol,指独立IP数。一天内来自相同客户机IP地址只 计算一次，记录远程客户机IP地址的计算机访问网站的次数，是衡量网站流量 的重要指标； ​ 需要注意的是，IP不代表一个用户，一个公司可能出口就是一个IP。 PV(访问量)： 即Page View, 页面浏览量或点击量，用户每次刷新即被计算一 次，PV反映的是浏览某网站的页面数，PV与来访者的数量成正比，PV并不是页 面的来访者数量，而是网站被访问的页面数量; ​ PV,是页面刷新一次就算一次， 叫页面点击量，我觉的前提是你的业务不涉及自动刷新功能吧。 UV(独立访客)：即Unique Visitor,访问网站的一台电脑为一个访客。一天内相 同的客户端只被计算一次。可以理解成访问某网站的电脑的数量。网站判断来 访电脑的身份是通过来访电脑的cookies实现的。如果更换了IP后但不清除 cookies，再访问相同网站，该网站的统计中UV数是不变的 ​ 这里涉及cookies标识用户身份，按上文描述，IP就算换了，缓存还在cookies还在，用户身份不变的，这其实好理解，类似缓存一样，身份老的cookies一直在那呢，所以server还是认为同一个用户。 网站统计：http://www.alexa.cn/rank/ 网站统计实例 网站访问量 web服务请求处理步骤 一次完整 的http请求处理过程 1、建立连接：接收或拒绝连接请求 ​ 三次握手后，发http请求过去，对方收到后去判断是否为合法用户，来判断是否接收和拒绝。 2、接收请求：接收客户端请求报文中对某资源的一次请求的过程 ​ 接收请求会有多种响应模型，统称为web I/O响应模型👇： ​ Web访问响应模型（Web I/O） ​ 单进程I/O模型：启动一个进程处理用户请求，而且一次只处理一个，多个 请求被串行响应 ​ 多进程I/O模型：并行启动多个进程,每个进程响应一个连接请求 ​ 复用I/O结构：启动一个进程，同时响应N个连接请求 ​ 实现方法：多线程模型和事件驱动 ​ 多线程模型：一个进程生成N个线程，每线程响应一个连接请求 ​ 事件驱动：一个进程处理N个请求 ​ 复用的多进程I/O模型：启动M个进程，每个进程响应N个连接请求，同时接 收M*N个请求 就是讲了一个服务器的进程-线程，处理单-多用户请求的情况。 前面提到的tcp连接里多个请求并发，和这里的关系就是tcp连接就是用户连接请求。 web访问响应模型 上图不好说对不对，至少apache不是(b)，apache如果用上图解释，需要将(b)改成多进程I/O结构，然后apache是使用(a)/(b)/(c)三种的，默认是(b)多进程就对了。 (c) 就是单进程 通过\"连接复用器\"来对接多个连接请求，思路如下👇： 不知道这个连接复用器是否是多线程还是指的是事件驱动呢？好像是的，连接服用可能也是事件驱动的一种应用场景，什么应用场景--就是网络连接的事件驱动下产生的连接服用器这么一个效果。俺是这样理解了~ ​ ①这里涉及一个情况：就是一堆用户的请求连接过来，server需要从DB里调用数据资源取到后才能给到用户响应response，所以不是每个用户的请求都能够立即响应的，也不需要立刻响应的，就算该进程就为一个用户服务，也会存在 调用资源没法立即响应的情况。所以这有了连接复用器的 发挥空间。 ​ 同样再梳理一遍：连接复用器 也叫 连接池 ，这个pool里就接收用户发起的请求，比如来个7个用户(7剑夏天山)，但是立即需要处理的请求不是所有的用户，用户的响应，需要server去磁盘上或者db里找到对应的文件数据资源。这些资源在server找到之前，是不需要和回应用户的，此时只需要和用户保持连接(长连接)就行，你看这不就是event MPM的监听线程干的活嘛。 ​ 比如针对某个用户的网页请求，server已经把对应的网页文件已经从磁盘上调度/加载到当前的进程里了，此时就可以回应他了。 ​ 所以server回应用户，涉及后端的 数据查找-网页文件合并？-加载到进程？ 大概这些步骤吧。 结合下图👇理解一下，accept函数调用后，就接收client的connect，开启一个新的socket就是一个连接，通过这个socket连接来响应用户请求，这一个连接就是上面讨论的用户请求，一个socket通常不会独享一个进程，都是多个socket通过连接复用器来共享一个进程的。 在后面讲到nginx的时候，会展开说，一个进程并发给多个用户响应，背后有一些复杂的I/O模型，涉及 阻塞、非阻塞、复用多路复用。 (d) 其实就是(c)的进一步，比如nginx，会开一个主进程，然后有几个颗CPU，就开几个子进程，然后每个子进程来讲，就是一个(c)结构。每个子进程再开多个线程*然后为多个用户提供响应服务。 *再开多个线程*：*不过图中提到的都是线程，而不是进程，这一点也有不同，我猜可能是这样，niginx为例，①主进程一个②几个CPU开启几个子进程③子进程再开启多个线程，此时细化到线程才对应(c)的单线程I/0 连接复用器结构。参考https://cloud.tencent.com/developer/article/1931083* apache是(b)结构，多线程I/0结构；一个用户请求过来就开启一个线程为其响应，所以资源消耗主要是内存消耗比较大。apache并发所以上不去，虽说上不去，但传统行业基本也够用(用户量没有互联网公司的业务大一般情况)，互联网不行nginx才行。 3、处理请求：服务器对请求报文进行解析，并获取请求的资源及请求方法等相 关信息，根据方法，资源，首部和可选的主体部分对请求进行处理 元数据：请求报文首部 HEADERS 格式 name:value 示例： Host: www.magedu.com 请求的主机名称 Server: Apache/2.4.7 HTTP常用请求方式(方法)，Method GET、POST、HEAD、PUT、DELETE、TRACE、OPTIONS 估计是这里一堆东西，不过好像一些关键字变了👇： 比如，GET 方法，然后结合URL里指明的页面，此时server就会去找这个URL所指的资源，于是进入下一步4-访问资源。 4、访问资源 服务器获取请求报文中请求的资源web服务器，即存放了web资源的服务器，负责向请求者提供对方请求的静态资源，或动态运行后生成的资源 资源放置于本地文件系统特定的路径：DocRoot # apache的默认路径找页面资源咯 DocRoot ---> /var/www/html # 默认的页面根路径。 /var/www/html/images/logo.jpg http://www.xxxx.com/images/logo.jpg # images/log.jpg就是去httpd的根路径下找。 web服务器资源路径映射方式： ①docroot ②alias ③虚拟主机docroot ④用户家目录docroot 找到磁盘上的网页文件后，要构建 \"响应报文\" 于是进入下一步 5-构建响应报文。 apache的documentation入口官网竟然没了，不过可以直接进去 https://httpd.apache.org/docs/ 5、构建响应报文： 一旦Web服务器识别出了资源，就执行请求方法中描述的动作，并返回响应 报文。响应报文中 包含有响应状态码、响应首部，如果生成了响应主体的话，还包 括响应主体 1、响应实体：如果事务处理产生了响应主体，就将内容放在响应报文中回送过 去。响应报文中通常包括： ​ 描述了响应主体MIME类型的Content-Type首部 ​ 描述了响应主体长度的Content-Length ​ 实际报文的主体内容 2、URL重定向：web服务构建的响应并非客户端请求的资源，而是资源另外一 个访问路径 永久重定向301：http://www.360buy.com 临时重定向302/307：http://www.taobao.com 不过这个也变成301了，需要重新找一个 https://blog.csdn.net/idwtwt/article/details/90692773 👈这个有时间再研究吧，不研究也行，知道有这个回事就行。 3、MIME类型： Web服务器要负责确定响应主体的MIME类型。多种配置服务器的方法可将MIME类型与资源管理起来： ​ 魔法分类： Apache web服务器可以扫描每个资源的内容，并将其与一个已知模 式表(被称为魔法文件)进行匹配，以决定每个文件的MIME类型。这样做可能比较 慢，但很方便，尤其是文件没有标准扩展名时 ​ 显式分类： 可以对Web服务器进行配置，使其不考虑文件的扩展名或内容，强 制特定文件或目录内容拥有某个MIME类型 ​ 类型协商： 有些Web服务器经过配置，可以以多种文档格式来存储资源。在这 种情况下，可以配置Web服务器，使其可以通过与用户的协商来决定使用哪种格 式(及相关的MIME类型)\"最好\" ​ 看不懂，没关系，GPT来帮你👇其实就是上文的表达方式不太通俗易懂。 “当我们访问一个网页或下载一个文件时” 有个好的开头就能让你 立刻理解整段中心思想 6、发送响应报文 Web服务器通过连接发送数据时也会面临与接收数据一样的问题。服务器可能有很多条到各个客户端的连接，有些是空闲的，有些在向服务器发送数据，还有一些在向客户端回送响应数据。服务器要记录连接的状态，还要特别注意对持久连接的处理。 ​ 对非持久连接而言，服务器应该在发送了整条报文之后，关闭自己这 一端的连接。 ​ 对持久连接来说，连接可能仍保持打开状态，在这种情况下，服务器 要正确地计算Content-Length首部，不然客户端就无法知道响应什么时候结束了 7、记录日志 最后，当事务结束时，Web服务器会在日志文件中添加一个条目，来描述已执行的事务。针对这些日志分析，有可能帮助你进一步了解用户画像，从而更好的规划网站内容，啥不理解？打个比方，如果网站内容都是卖货的，就分析日志多多进好卖的商品呗。 http的7个处理过程弄完，下面看看I/O方面的情况，用户的访问其实涉及很多I/O：磁盘I/O、网络I/O、内核和进程之间的交换。 图中👆是涉及浏览器、服务器和硬盘、网口、内核、socket buffer这是网络缓冲区就在内核中、http应用程序的各方I/O和数据交换。 1、用户的浏览器打开一个网页的请求 2、请求的数据包发送到了服务器的接口，就放入接口缓冲 3、然后 内核就从接口缓冲区里拿到数据，放到内核的网络缓冲区(socket buffer)里。 4、然后进一将请求数据交给应用程序httpd这个服务。 5、httpd软件查看请求，一看是个GET方法用户要得到index.html文件 6、由于用户的进程是无法直接访问磁盘的，所以httpd软件发送一个指令给内核(要知道软件本身也不能直接访问磁盘，都是通过内核去间接打交道的) 7、内核收到指令后内核通过DMA--直接内存和磁盘的交互，这里参见 内核就通过DMA直接把磁盘的index.html文件读入到内存中的内核缓冲区？然后再把index.html文件复制到http进程的内存空间里。 ​ 得到这个文件后，还得在外层封装响应头部，再发送给内核的buffer缓冲区--socketbuffer。 ​ 再发给网卡缓冲区，再发给用户的浏览器， ​ 再记录日志。 HTTP服务器应用 http服务器程序 httpd 应用程序服务器 ​ IIS .asp ​ tomcat .jsp ​ jetty 开源的servlet容器，基于Java的web容器 ​ Resin CAUCHO公司，支持servlets和jsp的引擎 ​ webshpere(IBM), weblogic(BEA), jboss,oc4j(Oracle) 市场占有率统计 www.netcraft.com https://www.netcraft.com/resources/?type=blog # 以前在news现在放到blog路径里了。 https://www.netcraft.com/blog/august-2023-web-server-survey/ nginx不仅仅可以做web服务器，还可以做强大的反向代理。 apache只能作为web服务器。 HTTPD介绍 httpd ​ 20世纪90年代初，国家超级计算机应用中心NCSA开发 ​ 1995年开源社区发布apache（a patchy server） # 补丁服务器，我国也有一个补丁墙-三个佛，哈哈~ 都很牛逼~ ​ ASF: apache software foundation ​ FSF：Free Software Foundation 特性 ​ 高度模块化：core + modules # 核心+模块，都是这样的，包括linux(内核+各种模块) ​ DSO：Dynamic Shared Object 动态加/卸载 # 这些模块 安装/卸载 比较灵活，灵活个屁，据说是编译的时候加进去的。 ​ MPM：multi-processing module多路处理模块 # 这里排版空间不够写道下面去👇下文内容 APACHE不仅仅是HTTPD咯，点开See All Projects可见N多ASF旗下的开源软件。 往下翻，可见tomcat也是他家的，一切都是从apache开始的。 kafka也是，牛逼 hadoop、HBase 也是~ 这些都是大数据里的东西 大数据运维这个岗位，和正常linux应用运维不一样，大数据有开发、运维两个方向。 大数据运维可能就涉及HBase，hadoop的搭建？都是一些专业大数据分析相关的软件维护了吧。 ​ 上接前文跳到前文，MPM：multi-processing module多路处理模块 # 这个和前面的web访问响应模型很像啊跳转前文 MPM工作模式 prefork：多进程I/O模型，每个进程响应一个请求，默认模型 ​ 一个主进程：生成和回收n个子进程，创建套接字，不响应请求 ​ 多个子进程：工作work进程，每个子进程处理一个请求；系统初始时，预先生成多个空闲进程，等待请求，最大不超过1024个 worker：复用的多进程I/O模型,多进程多线程，IIS使用此模型 ​ 一个主进程：生成m个子进程，每个子进程负责生个n个线程，每个线程响应一个请求，并发响应请求：m*n event：事件驱动模型（worker模型的变种） 这个图中没有唉。 一个主进程：生成m个子进程，每个子进程负责生个n个线程，每个线程响应一个请求，并发响应请求：m*n，有专门的监控线程来管理这些keep-alive类型的线程，当有真实请求时， 将请求传递给服务线程，执行完毕后，又允许释放。这样增强了高并发场景下的 请求处理能力 ​ httpd-2.2：event 测试版，centos6默认 ​ httpd-2.4：event 稳定版，centos7默认，现在马上都用rocky-linux9这一类的linux，httpd早就默认yum下来就是2.4了。 https://cloud.tencent.com/developer/article/1931083 https://httpd.apache.org/docs/2.4/zh-cn/mpm.html # 看原版算了 进一步看图 prefork MPM，pre fork就是预先开好fork子进程得意思 注意，这个模式下，一个子进程里只会开一个线程，所以一般就说一个进程服务一个用户请求了。 Prefork MPM: 预派生模式，有一个主控制进程，然后生成多个子进程，使用 select模型，最大并发1024，每个子进程有一个独立的线程响应用户请求，相 对比较占用内存，但是比较稳定，可以设置最大和最小进程数，是最古老的一 种模式，也是最稳定的模式，适用于访问量不是很大的场景。 优点：稳定 缺点：慢，占用资源，不适用于高并发场景 worker MPM worker MPM：是一种多进程和多线程混合的模型，有一个控制进程，启动多 个子进程，每个子进程里面包含固定的线程，使用线程程来处理请求，当线程 不够使用的时候会再启动一个新的子进程，然后在进程里面再启动线程处理请求，由于其使用了线程处理请求，因此可以承受更高的并发。 优点：相比prefork 占用的内存较少，可以同时处理更多的请求 缺点：使用keep-alive的长连接方式，某个线程会一直被占据，即使没有传输 数据，也需要一直等待到超时才会被释放。如果过多的线程，被这样占据，也 会导致在高并发场景下的无服务线程可用。（该问题在prefork模式下，同样会 发生） event MPM，在worker PMP基础上多了回收线程机制，我估计就是前文提到的\"事件驱动\" 不过上图PPT是将事件驱动放到 复用I/O结构里，实际上复用多进程I/O结构里也会有事件驱动，其实apache的event MPM就是在复用的多进程I/O模型基础上又加了事件驱动模型， 我认为 所谓的 连接复用器，其实就是 事件驱动模型。 event MPM：Apache中最新的模式，属于事件驱动模型(epoll)，每个进程响应多个 请求，在现在版本里的已经是稳定可用的模式。它和worker模式很像，最大的区别在 于，它解决了keep-alive场景下，长期被占用的线程的资源浪费问题（某些线程因为被 keep-alive，空挂在哪里等待，中间几乎没有请求过来，甚至等到超时）。event MPM中，会有一个专门的线程来管理这些keep-alive类型的线程，当有真实请求过来 的时候，将请求传递给服务线程，执行完毕后，又允许它释放。这样增强了高并发场景 下的请求处理能力 event只在有数据发送的时候才开始建立连接，连接请求才会触发工作线程，即使用了 TCP的一个选项，叫做延迟接受连接TCP_DEFER_ACCEPT，加了这个选项后，若客户 端只进行TCP连接，不发送请求，则不会触发Accept操作，也就不会触发工作线程去 干活，进行了简单的防攻击（TCP连接） 优点：单线程响应多请求，占据更少的内存，高并发下表现更优秀，会有一个专门的线 程来管理keep-alive类型的线程，当有真实请求过来的时候，将请求传递给服务线程， 执行完毕后，又允许它释放 缺点：没有线程安全控制 上图👆没有提到，前文说的，client请求过来，server从后台捞出数据/文件之前的一个不响应处理，只是维持连接，我觉得可以把这个动作逻辑加到上图的 请求1过来，交给工作线程A处理，但是捞出数据/文件之前，都不会响应，此时这个工作线程A可能去干别的事也是有可能的，期间该线程A向内核发起数据查询后，就将连接交给监听线程，然后等内核通过DMA拿到数据/文件后放入内核缓冲，此时线程A才会重新从监听线程接管之前的连接，将HTTP响应回给用户。event也好，连接复用器也罢，其实正式有了监听线程，才有了单线程多路复用的可能，所以这个监听线程和工作线程之间的协同合作就是连接复用器，就是event MPM机制 ​ 补充一下：线程的一个释放和阻塞问题，涉及①工作线程处理完请求后就会释放线程②处理着请求呢，等待DMA将数据调入缓冲呢此时 是否不是阻塞，是否也存在该线程干别的工作去了，这个调度是否也是内核还是event MPM机制调度的呢？然后③就是空请求不会分配线程；以上就是的事件调度机制event可以做到高并发。 本质上还是 时分复用+用完立马释放+和空请求不分配 这么一套优化动作。 ​ 其实你要说学技术有什么用，学这么细有什么用，反正配置文件一个单词就搞定了。你要知道，上面这套东西是人家apache自身的处理逻辑，当你不用apache的时候就没有这套逻辑了，你自己开发的脚本、软件，如果面对这些场景的时候，此时就有处理思路，这就是学习的本质！对吧，无非是内核函数的调用，线程的分配，连接的维持，这些拆分开来，确实可以想象代码模块可能没有我们想象的那么难，特别是写C的那帮吊人，吊人在这里是羡慕嫉妒恨的意思，想当初C就上课听考试还能70，现在啥都不会了。 其实，别人问你apache的三个MPM多路处理机制，你可以两句话搞定他咯 ①http2.2之前默认是预fork，开启子进程，单一线程，资源占用大，内存消耗高； ②http2.4之后默认是事件模型，子进程里有监听线程和工作线程，监听 负责分配任务给工作线程和绑工作线程维护与客户的连接；工作线程就拼命干活。 ③此时你可以反问，工作线程如果从监听线程接手了一个请求，该请求需要从本地捞取的数据文件量大，此时I/O处理时间长，你反问：工作线程是阻塞态还是干别的活，如果是干别的活去了，这个调度机制是系统内核本身的行为还是apache event事件机制实现的。 所以说apache高并发不行，顶多C10K( connect 10 000，1w的连接)，其实可能是停留在老的版本也就是prefork这个机制上的，我严重这样认为，所以高并发apache也能支持的。 只不过niginx的牛B之处，估计在于 人家支持复杂的反向代理，L4的也OK，所以这就集成了F5和WEB SERVER的功能，你说谁还用apache呢，所以不要用并发去踩人家apache，而要准确的认知。 至于你说结果对了就行，那就没有推导能力咯，用错误的论据得到正确的结论，下次呢？ 然后这里提一个点应用上的：为什么传统公司用apache的prefork，因为event MPM存在一个问题就是，如果一个子进程里的某个工作线程 DOWN了，那么可能会导致整个子进程都DOWN了--影响同一个子进程下的其他线程。 那个，我怎么感觉不一定呢，对吧，哦某个工作线程吊死占用大量资源？也许吧。 所以大家的共识是：追求稳定性用prefork，呵呵，整个共识也许是不对的，早些年的共识吧，这里表示怀疑。 然后APACHE MPM其实最终还是要读官方的 https://httpd.apache.org/docs/2.4/zh-cn/mpm.html 举个例子 默认机制其实很多的👆，不是PPT上仅仅的三种就完事了。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-10-16 16:42:22 "},"29-HTTP协议和APACHE/4-httpd2.4常见配置1.html":{"url":"29-HTTP协议和APACHE/4-httpd2.4常见配置1.html","title":"第4节 httpd2.4常见配置1","keywords":"","body":"第4节. httpd2 apache的文件构成了解 rockylinux9上apache直接yum安装的版本 安装httpd软件时的依赖 其中重要文件，比如conf文件都在httpd-core-xxx这个软件包里。 /etc/httpd 就是apache软件的工作总目录 服务service文件就不在httpd-core-xxx这个包里了，而是在httpd.x86_64这个里 关于modules ①/etc/httpd/modules 模块目录 conf.modules.d这个一看就是conf配置文件的模板不是这里要梳理的/etc/httpd/modules这个模块 还有/usr/lib64/httpd/modules/这个 模块 其实是一样的 /etc/httpd/modules时/usr/lib64/httpd/modules的软连接。 /etc/httpd是作为apache的总目录，后面一些配置上，都以这个目录为相对路径的。配置上直接写的就是相对路径，而相对的就是这个目录。 mod_auth_basic.so模块的作用：用来验证用户名密码的一个基本功能；一般来讲用户登入POST提交用户密码，对比DB里的记录，一致则验证通过，而这一套东西涉及软件开发的过程(...这就涉及软件开发了？不就是POST对比DB库嘛，先估且认同这个观点吧，估计是涉及DB和POST处理吧，正常django好像挺简单的处理这块)。而mod_auth_basic.so这个模块就可以对某一个网站做基本的用户名密码认证。 apachectl 启用关闭的二进制程序，不过一般用systemctl start httpd。 /usr/sbin/httpd是apache的主进程，systemctl start httpd启动的就是这个。 然后apachectl 这个cli也看下效果👇 然后/var/www这个耳熟能详的目录 是在httpd-filesystem-2.4xxxx这个包里了， 刚安装好的httpd的配置检测看看 Syntax OK，语法OK，然后提示消息说的是FQDN的事情，没啥后面会配置。 跟pptp，l2tp的服务一样，vpn服务跑起来针对针对某个用户踢下线，就可以找到用户拨入接口的进程PID； 我的意思就是针对进程的ID，通常服务软件们会自己动态生成xxx.pid文件来保存的，不然ps aux 去看可能有很多不好区分--就比如上图的ppp0、ppp1如果这些很多，ps aux |grep ppp 也不知道哪个接口时哪个进程的。 httpd的配置 [root@node1 ~]# cat /etc/httpd/conf/httpd.conf |grep -Ev '^ *#' ServerRoot \"/etc/httpd\" # 这就是根，所有的配置目录的相对路径都是相对这个目录的 Listen 80 Include conf.modules.d/*.conf # 包含的辅助配置文件，这里就是相对路径了，/etc/httpd/conf.modules.d/了。 User apache Group apache ServerAdmin root@localhost AllowOverride none Require all denied DocumentRoot \"/var/www/html\" AllowOverride None Require all granted Options Indexes FollowSymLinks AllowOverride None Require all granted DirectoryIndex index.html Require all denied ErrorLog \"logs/error_log\" LogLevel warn LogFormat \"%h %l %u %t \\\"%r\\\" %>s %b \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\"\" combined LogFormat \"%h %l %u %t \\\"%r\\\" %>s %b\" common LogFormat \"%h %l %u %t \\\"%r\\\" %>s %b \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\" %I %O\" combinedio CustomLog \"logs/access_log\" combined ScriptAlias /cgi-bin/ \"/var/www/cgi-bin/\" AllowOverride None Options None Require all granted TypesConfig /etc/mime.types AddType application/x-compress .Z AddType application/x-gzip .gz .tgz AddType text/html .shtml AddOutputFilter INCLUDES .shtml AddDefaultCharset UTF-8 MIMEMagicFile conf/magic EnableSendfile on IncludeOptional conf.d/*.conf # 由于当前文件也就是/etc/httpd/conf/httpd.conf里的东西太多，所以建议后面的配置都放到conf.d/下面。 不管怎么说先备份这个主配置文件 HTTPD常见配置 httpd配置文件的组成： 主要组成 ​ Global Environment ​ Main server configuration virtual host 配置格式：directive value # 指令 值得格式，类似字典得键值对。 Directive 不区分字符大小写 Value 为路径时，是否区分大小写，取决于文件系统 官方帮助 ​ http://httpd.apache.org/docs/2.4/ 配置的格式都是类似key value的方式 listen的写法 IP-address 不写就是绑定所有IP。 IP地址本地不存在，httpd都不会让你起来 修改监听端口需要重启服务的，reload不行👇 不是所有的配置都能reload，进而无需重启服务， 将来就可以做两个网站，一个80，一个8080。可以使用虚拟主机技术。是VPS嘛？感觉不是.. ServerTokens 👇下图可见server字段就暴露了apache的版本和操作系统。 使用curl看头部信息 ①好像-i和-I一样，忽略大小写了；其实不对的，-I 是大写，看下图案例 ②就是curl -i可以查看head头部信息。其中就有server字段显示你的apache版本和操作系统。 我把/var/www/html/index.html 拿掉--就该改成xxx 然后呢就有两个现象，① -i和-I不同 ②403报错 然后403页面报错，是页面不存的一个报错，了解下👇，当然也可能是页面文件没有访问权限。这里就是index.html没有创建导致的报错403。 还有一个点，就是如果你修改了index.html的默认位置--/var/www/html/index.html，那么修改后的路径也要让apache这个id有至少读的权限吧。 修改index.html文件无需重启服务，刷新页面就行了 回到serverToken的内容，ServerToken就是用来掩盖真实的server字段信息的。 根据参数说明，可知httpd默认用的full，就是把信息显示全了，然后透露信息最少的是Prod[uctOnly]，方括号是可以省略的意思，linux通用写法。 其实prod暴露的信息也没必要，最好啥都不暴露，这就不是httpd自带的功能了--或者源码修改这些信息(字符串Apache搜一搜改一改就行了)然后编译安装；如果不改源码，就需要前端通过调度器来过滤掉。 修改配置文件推荐不要动/etc/httpd/conf/httpd.conf这个主配置文件 恢复一下之前的listen的修改 /etc/httpd/conf.d/下新建test.conf，编辑所需指令和值 再补一个servertokens 需要重启服务的 👆这张图就看清楚了-i和-I的区别，-i就是include包含头部和页面内容。-I就是仅仅头部。 然后servertokens可见，已经生效了，只有Apache这个简略信息了。 持久连接 Persistent Connection：连接建立，每个资源获取完成后不会断开连 接，而是继续等待其它的请求完成，默认关闭持久连接 断开条件：时间限制：以秒为单位， 默认5s，httpd-2.4 支持毫秒级 副作用：对并发访问量大的服务器，持久连接会使有些请求得不到响应 折衷：使用较短的持久连接时间 设置：KeepAlive On|Off ​ KeepAliveTimeout 15 测试：telnet WEB_SERVER_IP PORT ​ GET /URL HTTP/1.1 ​ Host: WEB_SERVER_IP 前面的章节讲过http1.1版本默认就支持persistent connection的👇 官方说是默认开启的，当然2.4版本的http的，自然也是http1.1协议。 如果知道是否开启了\"持久连接\"--通过telnet 80然后GET方式进行测试持久连接 ①持久连接就是一个tcp连接里，可以处理多个用户请求 ②测试方法： 上图👆就是用telnet开启了80的端口TCP连接--算是一个长连接，然后这里有keepalive timeout的超时(默认是seconds秒为单位，也支持ms毫秒)。 这是👆KeepAliveTimeout Directive的参数解释，这里要注意默认是5秒钟，然后5秒钟的超时表现在什么点上呢，就是你输入host 3.3.3.3 回车发送了个GETrequest出去后，开始计时的，也就是wait for a subsequtent request befor closing the conn。怎一个subsequent了得~随后的，所以两个请求之间超时时间就是keepAliveTimeout。 除了这个keepalivetimeout，还有一个参数设置是 持久连接里 资源下载次数(get其实就是下载页面了) 到了也可以断开。通过poe.com问一下就找到了 测试下👇 👆上图可不是keepalivetimeout 30秒超时哦，没到呢；这是maxkeepaliverequests 2，2次下载超了的限制。 然后补充说明一下，测试方法👇 其实就是类似curl以及浏览器的行为，通过抓包可见 curl一样，就不抓了，然后host其实是可以随便写的。 DSO：Dynamic Shared Object 动态的共享对象，也就是说http的模块是支持动态加载的。 上图其实还有很多，modules，通过ls 去看更方便 这些模块是否都加载了，可以通过👇httpd -M来查看，可见105个模块，加载了93个。 👇这张图就说明了，确实是ls /etc/httpd/modules的模块mod_auth_basic.so加载后通过httpd -M可见的👇 关于模块加载也是由配置的，同样在主配置文件/etc/httpd/conf/httpd.conf里可找到👇 👆说明要进到/etc/httpd/conf.modules.d/下看 👆这样就就看到了LoadModule加载哪些具体的模块了，这就是105个模块，加载了93个的原因。 注释后，再次看看加载模块的数量 果然少了1个 记得恢复该模块的加载，后续要用 所以这也是加载和卸载模块的方法👆 总结如下： DSO： Dynamic Shared Object ​ 加载动态模块配置，不需重启即生效 ​ /etc/httpd/conf/httpd.conf ​ Include conf.modules.d/*.conf ​ 配置指定实现模块加载格式： ​ LoadModule 模块文件路径可使用相对路径：相对于ServerRoot（默认/etc/httpd） ​ 示例：LoadModule auth_basic_module modules/mod_auth_basic.so 动态模块路径： /usr/lib64/httpd/modules/ 查看静态编译的模块 httpd -l # 看的是静态编译的模块区别share的，是绑定的模块。 查看静态编译及动态装载的模块 httpd –M # 看的是全部的包含：share(共享)模块和static(静态其实可以叫独享)模块 然后static模块是无法通过之前上文讲的 配置文件去 卸载，是httpd服务本身自带的默认就有的。 真要想\"卸载\"也可以---就是源码里去掉，重新编译。不过估计卸了也就没法用了，这个自带的估计是core核心的东西。httpd软件组成本身就是核心core+模块modules。 MPM(Multi-Processing Module)多路处理模块 前文讲过prefork，worker，event，这里讲如何进行配置 以前：要进行该处理方式的切换，需要重新编译，因为是绑定在core代码模块里面的。 现在：但是从centos7开始(奇了怪了，难道不是从httpd的某个版本开始嘛，怎么还是从centos版本开始呢)，也支持配置文件的方式来切换了。 默认处理方式是：以前好像是prefork--就是一个主进程-多个子进程-每个子进程里只开一个线程；现在不是了，现在好像是event(可以去/etc/httpd/conf.modules.d/00-mpm.conf可见就是event)，有3680独立的子进程，还有几个了很多线程的子进程。 不过通过ps auxf看到的只显示到子进程。线程就不显示了👇 ps -ef一样 然后进程数不是限死的，如果进程数不够，依然会增加的。不过这里涉及线程，不知道具体的增加细节了，可能先增加线程吧。 没有讲是Unix到底是默认哪个？ 看配置文件，果然是event👇 修改方法，官网查看路径 妈的，哈哈，查个屁，/etc/httpd/conf.modules.d/00-mpm.conf里写的好好的，你上面截图的时候看不到，靠哦，什么眼神。 这里注释原来的，取消所需的就行了 重启后，再pstree -p 应该就没有花括号--也就是没有线程了，结果事与愿违 👆还是有一堆线程啊，一个进程里开了好多线程，奇怪了。不过更像worker。 再切成worker 发现worker开启的线程要多了去了，和event一样多。 所以，我觉的，新版本的prefork也不是原来的prefork了，不是一个进程里就开一个线程了，确实可见开了但开的不多，相比而言 线程开启的数量远远小于event或者worker。 通过pstree -p 是无法区分worker和event的，event是每一个子进程里的多个线程中有一个是监听线程，这是里面程序调度的事情了，无法在pstree中查看的。 不过我好奇的是为什么现在的prefork不是单纯的一个子进程里仅仅一个线程了。 测试mpm的event和prefork的并发能力worker同理 记得修改页面文件的访问权限 测试CLI -C1000就是1000个并发，同时去server上看看并发量；-n 是发动的request个数。 ps aux看到的是进程涨了很多，原来就是几个，现在是258个 pstree看到的都是线程数，1296个了已经。 等了一小会👆结果被 server端reset了，说明请求量太大了吧，减少请求量继续测试 在👆上图ab测试的过程中，多次在server端查看并发情况👇 PS：上图👆提到的此时 restart 会等蛮久，我觉的不一定是ab的并发回收慢造成的，本身httpd服务重启就慢，有时候快，过半的时候感觉都是慢的，从前面不断的重启动作得出的经验这是。 好，第一个prefork mpm的并发结果有了，主要就是看Request per second，每秒处理了3个请求。这是平均测试结果。 再修改为event mpm来测试下 多次查看进程数和线程数没有变化，说明该释放的都释放了，而且6个进程和209个线程基本上就是event的初始开启的量了。 然后ab 命令走一波 然而这里仅仅看requests per second发现event反而只有3.08，要小于perfork的3.13哈哈，怎么可能，不过综合开进程和线程的开启数量，event是要远远小于perfork的。从这个角度来看就是event要更加节省资源的。换句话说如果相同资源的消耗下event的并发处理就会远远高于prefork了。 另外为啥event模式系统服务没有多开写进程和线程，让处理量上一个台阶，这就不知道了，可能服务判断处理的速度还行无需增加资源开销。 然后上图👆测试期间，并发没啥大变化，结束了5分钟左右，也不见回收1个线程 搞不懂。。。哈哈，继续往下看吧，这里先这样，并发测试 偶然看到这篇 https://lvwenhan.com/tech-epic/500.html 需要自行研究下的感觉👆 然后，这个URL只是该作者的一篇，全部的高并发在这里https://github.com/johnlui/PPHC，挺牛逼。不是我现在该去看的，不过像innodb、分布式db、K8S，这些确实是我的方向，所以这个blog我感觉确实是大佬级的。 并发数超了-client的socket打开数 说是收到ulimit -a里的打开文件数限制 连接数，最终就是打开的socket文件，linux一切皆文件。 调大也没有用，可能是不止调这一个地方。 哦，操~~~！ 是CLI敲错了，并发-c 1010 大于总数 -n 1000了，这算乌龙吧~ 搞错了~再来一遍👇 调大socket 文件上限，确实就可以了 并发超了-server端的进程数 在server端改为perfork进行测试 大页面文件的并发，结果就是被server reset了，超出了server的承受能力--就是进程数超了，大页面文件下载的慢，进程占用时间长，回收的慢，不够用了。 改成小文件就可以了，所以下面研究下server的处理上限问题，小文件测试的时候，server的进程数是够用的，因为回收的快，小页面打开(下载)处理的快，进程回收的快，所以够用 prefork 的 配 置 StartServers # 这是一开始的ps auxf |grep httpd 默认开启的进程数 perfork默认是开5个进程数 然后线程开的也不多 StartServers 8 # 初始开启8个进程 MinSpareServers 5 # 最少保留5个空闲进程 MaxSpareServers 20 # 最多保留20个空闲进程 连起来的意思就是，8个初始进程随着用户请求变多，会开启的越来越多； 但是至少保留5个空闲的进程不分配出去，比如从8涨到100进程，那么会开105个。 当用户请求下降了，那么比如100个用户请求大文件，100个进程开着，随着请求处理结束，这个100进程会回收80个，留20个空闲，因为最多20个。 我是这么理解的👆 ServerLimit 256最多进程数,最大20000 2000或者20W可能和MPM模型有关 MaxRequestsPerChild 4000 子进程最多能处理的请求数量。在处理 MaxRequestsPerChild 个请求之后,子进程将会被父进程终止，这时候子进 程占用的内存就会释放(为0时永远不释放） 然后修改一下配置 然后重启服务 然后看下对应的参数是否落实 修改MaxClients为2560发现确实调大了，而且该参数官方网站上是找不到的，可能是早期版本的参数在2.4里没有写，但是依然有效。 然后MaxClients 2560这个调大了以后，StartServers 2000这个初始的子进程数就对了2000个就OK了 以上是间隔3-5分钟多次键入的，👇间隔2分钟多次输入的命令，说明此时子进程数和线程数涨停👇。 这个参数是httpd 2.2版本里的参数。 由于此时进程数调大了，再次用ab测试一下 这是👇本篇 上文的 内容--之前ab测试的结果 这是👇调大参数后的测试结果👇，肯定就可以了因为server初始化了2000个进程，这里ab测试时1500个并发，而且2.4的prefork虽然2000个进程，但是同样也开启了线程1W+了都，肯定支持1500个tcp连接了。 同样此时内存消耗也大：server端👇 看下现在的测试结果👇，确实不再报错，但是内存要够的，好在我的内存还行给的。怎么判断给的内容够不够，简单，free -h 看看涨不涨不就行了，没变化就是够用了--上图就是内存：2.8G用了。 进程数也涨了写，线程同样涨了，说明2000个初始子进程StartServers还不够，因为m.txt太大了 半天10分钟过去了， 1500个并发就瞬间消耗1500个tcp，然后要访问2000次，m.txt又太大，下载耗时长tcp得不到释放，从第一个tcp建立到最后一tcp释放，历经了一共1500*2000=30 00 000 次的tcp连接。前面页面加载完m.txt就会得到释放吧--感觉会释放-不过释放的条件可能时timeout和上面设置的4000个请求数MaxRequestsPerChild。 总结 ServerLimit和MaxClients都是限制最大并发连接的参数，都需要改的。 worker MPM的参数 threads 一般表示线程，python里的import 也是这么表示的 MinSpareThreads 最小空闲线程 ThreadsPerChild 25 就是 每个子进程里开25个线程，直接看GPT的解释吧👇 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-10-05 22:22:47 "},"29-HTTP协议和APACHE/5-httpd2.4常见配置2.html":{"url":"29-HTTP协议和APACHE/5-httpd2.4常见配置2.html","title":"第5节 httpd2.4常见配置2","keywords":"","body":"第5节. httpd2 继续上一篇的配置 主站点页面-DocumentRoot 定义'Main' server的文档页面路径 DocumentRoot “/path” 文档路径映射： DocumentRoot指向的路径为URL路径的起始位置 示例： DocumentRoot \"/app/data“ http://HOST:PORT/test/index.html --> /app/data/test/index.html 注意：SELinux和iptables的状态 这里修改站点的页面存放路径，还需要保证该路径的文件的访问权限。注释掉👆上图的主站点配置。 下面对其进行修改👇，还是使用单独的配置文件，不对httpd.conf这个主文件进行修改 权限👆没问题 selinux没问题👇 修改配置文件， 必须是文件夹，且其下放index.html 重启OK 但是curl 发现不行 这就意味着页面一样是apache的默认页面了，因为index.html打不开 可是对应的文件夹的进入，和文件的可读权限都有的啊，奇怪了 但是就是403 Forbidden了 所谓授权不是linux系统文件的授权，而是httpd服务本身配置文件里要明确授权，所以还是配置文件里的配置不全。 同样写道单独的配置文件里去 ---------------这样就OK👆了------------------ 然后取消/data文件夹的所有权限，哈哈 其上图不用重启服务，因为修改的os操作系统的权限，而不是httpd服务的配置文件，👇证明下： 如果是DocumentRoot下的子目录的index就是补一个路径就好了👇。 如果子目录不在DocumentRoot下呢 1、用软连接行不行：👇可以的，没得问题 那为什么文件默认就是index.html，是否可以修改呢？可以，在配置里面找到关键词DirectoryIndex👇 定义站点主页面 DirectoryIndex index.html 增加一个 上图👆就说明了，配置文件的写法：DirectoryIndex m.txt index.html是优先级从左到右的。 如果m.txt和index.html文件都不存在，那么这个报错的页面403 Forbidden又是哪来的呢？ 在/etc/httpd/conf.d/下有一个叫welcome.conf的配置文件，其中就有403对应的页面👇 这里的/.noindex.html就是相对于DocumentRoot主页根路径来讲的。 但是没找到这个文件，增大俺的狗眼仔细看看上图 找找看，Alias啊，/.noindex.html全文里出现了2次，还不清楚嘛~(/≧▽≦)/ 删掉这个welcome.conf文件，观察页面 重启服务后👇 所以修改一下 页面一样效果👇 站点访问控制常见机制 可基于两种机制指明对哪些资源进行何种访问控制 ​ 两种机制：客户端来源地址，用户账号 ​ 哪些资源：文件系统路径、URL路径 文件系统路径： ①针对文件夹②针对文件③写正则匹配 ... ... ... URL路径： ... ... 示例： # FilesMatch就是REGEX正则 通配符 # 应该是Files 开头就是通配符 # Location就是URL # LocationMatch就是url里的regex正则 具体的写法-带上源 概述 中“基于源地址”实现访问控制 (1) Options：后跟1个或多个以空白字符分隔的选项列表 在选项前的+，- 表示增加或删除指定选项 常见选项： Indexes：指明的URL路径下不存在与定义的主页面资源相符的资源文件时，返回索引列表给用户 FollowSymLinks：允许访问符号链接文件所指向的源文件 None：全部禁用 All： 全部允许 示例： Options Indexes FollowSymLinks Options FollowSymLinks (2) AllowOverride 与访问控制相关的哪些指令可以放在指定目录下的.htaccess（由AccessFileName指定）文件中，覆盖之前的配置指令 只对语句有效 AllowOverride All： .htaccess中所有指令都有效 AllowOverride None： .htaccess 文件无效 AllowOverride AuthConfig .htaccess 文件中，除了AuthConfig 其它指 令都无法生效 Indexes：指明的URL路径下不存在与定义的主页面资源相符的资 源文件时，返回索引列表给用户 就是访问页面不存在，返回当前路径下的列表，页面显示出来的文件夹和文件都可以点击，类似yum源网站的点击浏览一样 然后页面访问是默认的报错页面 删掉该文件也没用！ 找找官网说明 这个模块也加载了啊 搞不懂，继续折腾，发现还是welcome.conf搞的鬼，这样就可以看到了，其实就是👇这里得options -Indexes。 - 减号就是禁止啊，禁用了目录索引功能。 然后dir1不现实，dir2可以的，研究下dir1为啥不显示 搞不懂dir1为啥不显示了，之前可以的啊 就是dir1好好的不行了，哈哈 👇结果发现是软连接得问题，但是之前可以得啊！ 权限OK👆，找到元婴了，👇就是开启indexes就不支持软连接了，奇怪了，先记着这个点 👆同时注意：curl 不同于浏览器http://192.168.126.130/dir2 , 浏览器这样回车自动就是dir2/ 补一个斜杠的/； curl 没斜杆/有问题的。 来一张总结图👇，结论就是 options indexes会导致ln -s 的403 Forbidden。 如果要把软连接也显示出来，需要再配置一下 FollowSymLinks：允许访问符号链接文件所指向的源文件 当然，welcome.conf里的-Indexes要去掉的 补上对应参数后就可以显示软连接了👇 .htaccess ①同样用来针对语句的参数，比如Options Indexes，不过 ②不过，需要在配置文件里开启功能AllowOverride ALL ③.htaccess是优先于配置文件的，不然也不会叫AllowOverride允许覆盖了。 ④.htaccess本身是不会被看到的，因为在主配置文件里有如下配置👇： 当前状态👇 去哪里创建.htaccess整个文件呢，去accessFileName，整个文件其实不是单一的路径，而是一个递归检索的路径。 所以就在documentRoot里创建就行了 上图👆漏了一个AllowOverride All，这就是针对.htaccess的生效开关。 然后就可以了 阶段总结一下 下面开始学习(3)基于IP的访问控制 基于IP的访问控制: 先做一个拒绝所有的conf文件的访问 这里files 就是通配符，filesMatch才是正则表达式了，嗯~ o(￣▽￣)o上面的通配符写错了哦，改下👇： 重启服务后，xxx.conf文件就看不到了， 将通配符改成正则 打开上图注释，就会实现拒绝访问 包含.conf的文件，当然regex要写好一点，优化下 这样就实现了regex的写法，参见上文 进一步实现针对192.168.126.1这个IP，不能访问beijing/index.html，其他都可以 mkdir beijing echo this is beijingbeijing > beijing/index.html ls beijing/ 配置acl后的效果： 其他都OK 由于只是针对192.168.126.1的禁止访问/beijing/index.html，所以其他IP可以访问 改为拒绝整个子网 然后研究下优先级和默认行为 先上结论： ①RequireAll 搭配 all granted 然后拒绝谁，这是黑名单写法 ②RequireAny搭配all denied然后放行谁，这是白名单写法。 ③宇宙法则之--从上到下匹配，被打破了，这里明明all granted还可以下面deny，明明all deny了还可以下面permit所以这里打破了从上往下的宇宙法则。 👆上图的划红线出 文字表达是摸棱两可的，不要按他的思路理解。 就理解成RequireAll是黑名单机制，RequireAny是白名单机制，就好了啊，还折腾啥呢，浅测一下👇 看来不能注释掉，哈哈 改成RequreAny就不行了 可以大概判断出来，就是固定写法当作就行了， any就是任意，任意就是任意一个OK就OK，所以是白名单； all就是所有OK，针对某个拒绝，所以就是黑名单了。 白名单写法👇 两个日志 可能会奇怪log不是应该通常放到/var/log/下吗，怎么在/etc/httpd/下呢，其实都是对的，这里人家用的软连接 这种拒绝访问也是记录到错误日志里的👇 关于FQDN的提示处理 首先，这不是个报错 同样也会在错误日志里存放，当然error_log叫错误日志不一定就单单存放错误信息。 优化处理下，很简单 没啥实际作用吧应该。 再看看访问日志access_log的格式 👆上图定义了LogFormat两种格式，分别命名为combined和common，然后access_log(CustomLog就是用户日志) 调用的格式是combined。 看看是不是这么个格式 官方解释👇https://httpd.apache.org/docs/2.4/mod/mod_log_config.html#logformat https://httpd.apache.org/docs/2.4/mod/mod_log_config.html#formats %h Remote hostname. Will log the IP address if HostnameLookups is set to Off, which is the default. If it logs the hostname for only a few hosts, you probably have access control directives mentioning them by name. See the Require host documentation. %l Remote logname (from identd, if supplied). This will return a dash unless mod_ident is present and IdentityCheck is set On. %u Remote user if the request was authenticated. May be bogus if return status (%s) is 401 (unauthorized). # 这是基于basic的验证，上一章节提到的mod_auth_basic.so干的活吧应该是。 %t Time the request was received, in the format [18/Sep/2011:19:18:28 -0400]. The last number indicates the timezone offset from GMT %r First line of request. # 👇对应下图的\\\"%r\\\"也就是log里的\"GET /beijing/ HTTP/1.1\" %s Status. For requests that have been internally redirected, this is the status of the original request. Use %>s for the final status. # 说的是%s，但是其实用的是%>s。 这里涉及重定向，比如先从page1，301到page2，然后再200；估计%s就是301了，%>s就是200啦，这个后面可以尝试一下。 这个200 403 301 这些数字本身就很大程度上反映除了 页面请求的结果，比如200是页面拿到了，403是禁止访问了，301是重定向。这个和shell里的exit 1000 退出时候的返回1000这个数字一个道理啊；也和echo $?看到的0是cli执行成功和非0执行失败一个道理啊。 %b Size of response in bytes, excluding HTTP headers. In CLF format, i.e. a '-' rather than a 0 when no bytes are sent. 23是对，200请求OK后23字节就是对的，然后403是禁止了199就是那个报错的页面啦-人家是199个字节 200 23 怎么理解👇 不过23Bytes其实是去掉了head头的吧 403 199 怎么理解👇 继续----- 在httpd日志里看到花括号{}就表示头信息，这里LOG里记录了head信息里的 Referer--从哪个站点跳转过来的信息，以及User-Agent用户浏览器信息。这些都是%{xxxx}i 代表的head里的键值对信息，具体用哪个你就写哪个就行了。 关于referer浅测一下 html语言 你好 这是跳转测试你好啊 借鉴上面的跳转写法，做两个页面来实验 此时到test2.html第二个页面就可以看到referer的上一个跳转过来的链接了👇 产生test1.html会有referer的原因有点奇怪，好像是偶尔从test2.html页面返回后退回来F5一下弄出来的。不过有时候出不来，搞不清楚， ​ 噢噢噢，我知道，是这样的，人家写了是从http://192.168.126.130/ 上一个页面来的，所以答案就清楚了 从👆这里点进去不就是httpd默认给你弄出来的跳转嘛， 再开一个机器192.168.126.131做一个图片页面， 然后在192.168.126.130上做跳转referer过去 写错了哦👆上图http://192写错了，导致👇 修改之 这就是盗链，如何发现盗链呢，就是去server上看referer 问：是否可以通过在server上写iptables -A INPUT -s 192.168.126.130 -j REJECT来防止盗链呢？ 答：该方法实现不了，因为跳转的实际效果是让用户重新下载一个新的内容，是用户去访问而不是130这个referer的上一个链接地址去访问。 所以要防止盗链就要继续学习咯... ... 再一个，如果是referer里显示的是百度的IP，说明什么，也是盗链么？应该就不是了，这是广告费没白给，哈哈，或者人家一搜，就你家的网站，总之十有八九算是好事了，这种情况。 关于日志的阶段性总结PPT放着了，随便看看，不看也行，图个完整性 然后日志的一个访问IP排序 字符集 iconv -l # 查看所有字符集 通常可以看得到网页的字符集的 带不带s https的s 也不一样 不过针对使用curl百度，不显示字符集👇 浏览器是有的 改一下字符集看看效果 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-10-08 17:36:30 "},"29-HTTP协议和APACHE/6-多虚拟主机实现.html":{"url":"29-HTTP协议和APACHE/6-多虚拟主机实现.html","title":"第6节 多虚拟主机实现","keywords":"","body":"第6节. 多虚拟主机实现 目录访问的别名 别名在welcome.conf里也见过的，上一篇将/.noindex.html的时候就遇到过👇 开始实验 mkdir /app/forum echo 'thisi is /app/forum/' > /app/forum/index.html 用户通过 curl 192.168.126.130/bbs/ 访问到/app/forum/ 当然你说用跳转，没必要，这里用alias别名 当你还还说用软连接，没必要，这用别名 光写别名还不行，👆还需要补上别名的那个目标地址的访问权限。 问题来了①我待会使用curl 192.168.126.130/bbs/去访问，/bbs这个文件夹我感觉不用存在，感觉正确。 ②/app/forum在os层面也是需要apache可读的。 总结，页面URL里的路径不一定在DocumentRoot下 curl http://192.168.126.130/dir100，实际上就是打开dir100/index.html页面 ①这个dir100文件夹确实在DocumentRoot下，且apache配置文件里有给到访问权限。 ②软连接，不过软连接所在的路径应该也需要在配置文件里给到访问权限 ③别名，就是上文的alias，这个种dir100文件夹 都无需创建。 ④跳转应该也算一个，具体见上一篇文章。 基于用户名密码方式控制访问 之前上一篇讲了基于源IP地址来控制访问已经实现了，这里接着讲基于用户名密码 要支持用户名密码方式控制访问，需要确认开启auth_basic模块，当然默认就开启了 要实现的目标：用户访问页面的时候，弹出对话框让其输入用户名密码。 cd /data/www mkdir admin echo 'this is /data/www/admin/index.html ...' > admin/index.html 需求：访问主站点无需验证，访问admin/index.html的时候要验证。 比如admin里放的是后台管理的页面，所以需要验证才能访问。 而用户名密码肯定不是系统的用户，而是httpd服务的，这种用户就称之为虚拟用户。不是真实的OS的用户。 这种虚拟用户，在不同的服务里都存在，除了这里的HTTP，还有FTP，等，都是服务自身的用户认证，无关于系统用户。 使用htpasswd来创建http的用户名密码，第一次敲这个命令的时候需要-c指定存放用户名密码的文件的。后续不能使用-c，否则原来的文件就被覆盖了。 由于http页面认证的用户名密码也算是一种配置，所以就放到/etc/httpd/conf.d/配置文件路径下。 找出下图👇错误之处 当然第二次别加-c就对了，然后 ① .httpuser前面的.就是好习惯，用户名密码文件用隐藏的就很不错 ②就是交互式的密码2次就很不爽，找一下👇 好创建三个用户吧，重新来一遍 htpasswd -c .httpuser user1 ... 输入密码 ... 再次输入密码 htpasswd .httpuser user2 ... 输入密码 ... 再次输入密码 echo 'cisco' | htpasswd -i .httpuser user3 # 非交互式类似于echo 'cisco' | passwd --stdin user1 果然和passwd很像，同样也加了盐，所以一样的密码，hash值就不一样了👆。apr1可能是类似哈希算法的类型。后面一段$xxxxx$应该就是盐，$分割除了3段，最后一段就是加了盐一起的哈希结果。 这样用户名密码就有了，下面就是在配置文件里写上 调用验证，然后到指定的文件认证就行了。 使用.httpuser密码文件的方法1：写到配置文件 主站无需认证👇 admin路径需要认证 上图没有体现出来AuthName \"xxxxx\" 内容。估计现在没几个浏览器支持这种显示了。 只有输入Require user 里指定的 admin用户名密码才行 👆上图一共3条记录，前两条是弹窗用户名密码输错了的记录401就是未授权的意思，第三条是正确的用户名的记录而且在记录的开头有显示具体的用户名。 另外curl也支持输入用户名密码的方式，不过就不是交互式的了👇 针对 .httpuser里的所有用户都可以访问这个文件夹 使用.httpuser密码文件的方法2：.htaccess 进一步复习下上一篇的.htaccess文件，就是上述配置可以移到这个文件里 先去配置文件里 允许.htaccess覆盖，当然这里选择仅覆盖authconfig就是认证相关的； 然后再将原来配置文件里的4行配置删除，配置到访问路径--也就是需要认证文件夹下 上图修正下，既然已经在这个路径下了，肯定就不需要写Directory了， 修改这些路径下的文件，无需重启服务，验证OK👇 用户组授权的配置 上图👆有错误，httpd -t也检查不出来；①漏掉了AuthUserfile XXXX 路径指定；②随后一行少了group参数。 修改👇 验证效果，符合按组授权👇 前面就介绍了http的访问控制里的基于IP和基于用户名密码的控制，下面学习一下两种方式的选择组合 远程客户端IP和用户验证的控制 浅测一下👇 1、首先我打算把配置都写道页面资源的路径下的.htaccess里 2、于是我就要去到配置文件里去写上\"允许覆盖\"的参数 3、然后去页面资源路径下编辑.htaccess文件 有点问题，就是Satisfy All没有生效！没有做到 双重验证。就是输入用户名后就能访问了，理论上是要备ip 禁止访问的。 这里就会担心这个.htaccess里是否可以这么写，查查官网发现.htaccess支持Satisfy All的 context的意思就是配置在哪里， 不过写法有点变化 IP控制用的是Allow，自然有deny。 然后呢发现 然后发现 结论： ①all确实是 用户认证 + IP acl 都要满足；any就是任一个满足就行。 ②原来那套配置\\XXXXX\\ 在这里貌似不行。 ③尝试写一个白名单出来 OK~ 实现用户家目录的http共享也就是web访问 同样要支持家目录的web访问，要有模块预加载 关于模块加载，见前文👇 下面就是将 用户的 家目录分享出来 修改权限也没用 恢复原来的权限700👆后继续实验👇 待会使用这个ming1的家目录 找到配置文件userdir.conf 修改对应内容 修改如下 这样就①开启了userdir的共享；②家目录共享不是说所有文件，而是要指定家目录下的某个文件夹共享，如上图的public_html共享。 重启服务后，浏览器访问http://192.168.126.130/~ming/即可 这里要记得修改/home/ming1的权限，只要通过facl给到apache就行了，因为用户访问文件夹，其实是通过httpd服务进程区访问的，而httpd都是apache用户运行的。 修改权限 给了apache进入ming1家目录的权限就行了 同样注意一点就是facl设置以后的ll 注意 必须是/~userDir/的写法 加一个验证 👇注意：缓冲会导致弹不出验证窗口：①常规浏览器需要清缓存才能弹；②无痕需要 关闭所有无痕再打开新的无痕才能保证没有缓存；如果有一个无痕没关，则缓存还在。 其实写一个.htaccess就要有一个习惯思维--就是是否可以写进去，如果不行就写道directory里。啥意思 上下文可以写的地方有👇 像有的配置就写在别的地方👇 再一个 这样试试看 结果也是正常的👇并没有说上面的授权全放就全放了，下面没有不起作用。挺好~ 要实现这种哪哪都生效的效果，是不是 代码里 ①将所有配置合并②找出最严格的配置③类似rib里的最长匹配。 ServerSignatrue 和结合serverToken一起梳理知识点 浅测一下 再删掉.htacess做一下放心对比动作 我感觉.htaccess挺好，因为它不是配置文件，无需重启服务就能生效；但是它又能做配置文件里的配置，就很香了。 status页面，可以用来做网站的监控 依赖于这个模块👇 干嘛的呢，就是获取apache的工作状态，默认关闭的。 又可以塞到.htaccess里了，哈哈，开心 当然，你要用directory一样的效果，不过要配置，同样DocumentRoot下的.htaccess或者配置文件里配置： 这倒是个看MPM的方法，默认果然是prefork。 理解下上图👆 __ __ __.................这些 表示的是进程状态，很多下划线和...说明进程太多了 _ 就是等待连接 . 就是打开slot但是没有线程来处理 发现一个问题，得到3种status的配置方法 就是setHandler server-status，这个写在两次， ①配置文件里的 只能是DocumentRoot下带/status访问，就是http://192.168.126.130/status，也不影响http://192.168.126.130/，这就是index.html的访问不受影响。 也不能写成\"/www/data/status\"，不会生效，所以只能放到documentRoot下来访问。 ②写道url路径文件夹下，但这种写法，就是把index.html给覆盖了，就是你访问http://192.168.126.130/~ming/ 后面带或者不带或随便写都是 打开的status页面了 ③其实可以这么玩 去掉配置文件里的相关配置 记得重启服务，验证一下 然后在DocumentRoot下新建一个status文件夹，然后进去编辑.htaccess，里面写一个setHandler 这样这个status文件夹里所有的页面统统不生效，你也无需创建其他任何页面，该文件夹就一个作用--setHandler server-status，显示服务器状态。 这样也自然也不会影响documentRoot的index.html 然后针对这个status页面限定只能特定IP查看 写到配置文件里也行 重启服务后，测试 虚拟主机 host就是你访问的域名/IP，记录在报文的host字段里了，该字段属于head，http的报文头。这是client发送请求的时候携带的，当server收到一看就知道了你访问的是啥了，所以这就是LB的转发最佳实践，而不是基于desti-端口也不是基于dest-IP。 之前用telnet 测试写过host👇，那会host是随便写的，因为没有涉及server检查host做负载均衡的机制，也就是没有做这里的虚拟主机来依据host转发的技术。 下面开始实验 首先、规划三个网站，简单就是三个文件夹页面就行了。 上图👆有错误，index.thml改成index.html才行。 虚拟主机-基于三个不同的des ip 然后编写配置文件，documentRoot、directory、access_log独立开来、virtualhost IP 重启后，access_log_asite文件就生成了，然后在写2个 通过域名访问简单加个host 就可以了👇 但是时间太慢了 浅查一下：结果一查就查了2小时，这里直接回头来写结论，load确实高，但不是load的问题，是allow from any，不用用any的原因，排障过程往下慢慢看。 负载太高了，如何判断高呢，依据如下👇，所以上图👆4 C，load 不能超过12。 然后load 三个值分别是1分钟、5分、10分钟的均值。 解决下，注释掉进程开启过多的配置，只是对于我这个pc的workstation的VM来讲太多了 等一会，等load降下来就可以测试看是否变快了 是快一点，但是也要4s呢，奇怪了不应该啊 难道虚拟主机就是慢？ 昨天也没有这么卡啊，同样的👇cli，估计笔记卡了，但是笔记本资源利用也就45%内存啊。其他都很低啊。 curl www.b.com 卡在那的时候，同时看看I/O也没变化，也不卡啊 浏览器打开，就是用无痕，也不卡，奇怪了，之前负载高的时候浏览器就不卡 TMD curl卡浏览器不卡 是啥什么鬼？ 将除了虚拟主机以外的所有配置全部注释掉，发现竟然好了--速度快了 只要再打开注释，就会变慢，👇 定位具体问题出在哪？ 发现只要这一段打开，就会卡 👆上图结论不一定对，进一步对比，取消上图的框选的部分的注释，然后注释掉虚拟主机部分，发现依然有2-4s的情况 出现频次也不低，发现还是👇这部分问题， 这部分问题不一定是看到的配置出了问题，去/data/www下面ls -a看到 删掉后继续测试，返现速度一直都很快，故障消失了 再补回去，故障又出现了 这里还不是白名单写法，如果是白名单写法应该是 deny from all，这样就是拒绝所有，放行了126.1。 而deny from any拒绝任一，就很不符合逻辑。但是从效果上来讲，就是除了126.1，其他curl都TM会卡。 修改成 黑白名单的坑-1，不能用any：测试过程在上下段落，这里是结论 结论，就是.htaccess的错误的写法(deny from any)导致，这会频繁的出现访问卡顿的情况。就用allow from all，deny from all ，只用all字样就行了。 然后研究下黑白名单 白名单写法，测试有效 但是黑名单失败了， 查资料 图上框出来的还是原因，没框出来的，First, all Deny directives are evaluated; if any match, the request is denied unless it also matches an Allow directive. 这才是原因，所以 直接看表格 https://httpd.apache.org/docs/2.4/mod/mod_access_compat.html#allow 所以这样的👇配置最大的关键点也是疏忽点就是，Match both Allow & Deny 在默认的机制(Deny,Allow)下是放行的，分析下图：whiteList有效是因为126.1和126.131是both命令allow和deny all所以allow，其他没写的Only match deny所以deny了。而下图的黑名单写法192.168.126是同时命中了deny和allow all所以就放行了，没有做到deny 具体IP的效果。 上图黑名单失败，修改一下，去掉deny就行了，这样依然是默认的deny,allow机制，但是deny的126段only在deny语句里，没有说 no match也没有both match。 黑白名单的坑-2，默认顺序(Default: Order Deny,Allow)黑白名单写法，这里是结论，过程见上文 黑名单简单，拒绝什么就些什么，不要写allow all字样！写了就是both match 全放了。 deny from 192.168.126.1 白名单写法 allow from 192.168.126.1 deny from all # 这里底层逻辑与众不同，126.1是 both match，也就是同时满足allow和deny语句的，所以both match是allow放行的，其他没写的IP，就是only match deny的，是拒绝的。 然后statisfy是针对源IP和用户名的一个机制，all就是两种因素认证，any就是(源IP或者用户名密码)任一满足就行。 至此，问题得以解决，什么问题，点这里 恢复load高的场景，修改.htaccess下的allow from any为allow from all 上图不能说明load高，为什么，如果cpu数量多，达不到1个cpu3个load以上就不算高 4个cpu，25个load，平均一个cpu8个，肯定高了。然后恢复配置和修改.htaccess 重启服务测试N次 此时想看之前的故障👇 虚拟主机-基于相同目标IP+不同desti port 把上一个实验的多个IP清掉 修改为端口区分来服务 这就好了，下面测试👇 搞定👆 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-10-10 15:35:54 "},"29-HTTP协议和APACHE/7-基于主机头的多虚拟主机和实现HTTPS加密.html":{"url":"29-HTTP协议和APACHE/7-基于主机头的多虚拟主机和实现HTTPS加密.html","title":"第7节 基于主机头的多虚拟主机和实现HTTPS加密","keywords":"","body":"第7节. 基于主机头的多虚拟主机和实现HTTPS加密 书接上回，虚拟主机的实现继续，上一篇实现了基于dstIp，基于dstPort 虚拟主机-基于主机头head里的host字段实现负载均衡 原理就是client发送http报文请求的时候，http头部里就携带了访问网站的FQDN 抓包是看不到https的head的，TCP以上都是加密的。 HTTP不加密可以抓到head内容 实验 👇就是统一监听80，80本来在/etc/httpd/conf/httpd.conf这个主配置文件里就启用了， 然后documentroot及其all granted授权，documentroot和directory是一对，根和授权。 最后就是servername转发依据和LOG 搞定👆 疑问：为什么cstie没写servername，结果转发到www.a.com了 估计就是 不写servername，然后用的就是第一个 从上往下找 通过官网查看就会自然知道现在servername还不够，还需要知道serveralais 看个现象 问，为什么192.168.126.130的访问变成了www.a.com了 答，因为www.a.com在前面 问，为什么不是原来的 非虚拟主机的页面了，答：从结果判断，就是虚拟主机的转发配置抢先了 其实就是虚拟主机的80和非虚拟主机的80冲突了，结果就是虚拟主机胜利 80变成www.c.com排在第一个，所以和 冲突了，存在优先级了就。 如果ip+port+servername一起用会如何 说明端口 port 优先> servername 不能！因为www.c.com:81 这个主机头就是带81端口的 上图👆192.168.126.103和192.168.126.130都是配置在本机eth0接口的多个IP地址。 绿色线条表示：命中了虚拟主机的ip+port走的是虚拟主机 红色线条表示：虽然curl的是www.c.com域名，但是会dns解析成192.168.126.130:83，于此同时host主机头是www.c.com:83，所以这个一个请求发到server上apache处理是按照ip+port优先来处理的--没有命中任何虚拟主机的配置于是命中的是非虚拟主机的配置，并不是说看主机头去处理的--如果按照host处理结果就应该是www.c.com了。 这样做也是合理的，毕竟IP可能都打到别的机器上去了，你还看主机头不是扯嘛。①主机头只是请求里的一个字段携带的内容②请求的域名对应的IP才是首要的③域名默认会写到主机头里而已，可修改。④不要瞎折腾，简单规范的配置就行了。⑤apache看到请求处理思路1、看IP+PORT啦，如果没有命中虚拟主机就走非虚拟主机的DocumentROOT；2、如果命中虚拟主机 ，此时在虚拟主机层面匹配还是先看虚拟主机的IP:PORT，如果几个虚拟主机的IP:PORT一样，才会去看host主机头。 好好了，回过头复习了一下，溜了溜了~去继续折腾nginx去。 压缩技术，用的也非常多 server在页面发送到网络上之前，做一下压缩，节省带宽用。穿越网络，到达彼岸用户手上后，浏览器会自动解压出来后进行页面展示。 --- 属于典型的时间换空间的打法，时间--CPU压缩耗时，空间--磁盘和带宽的空间节省。 --- 什么时候用什么换什么，有时候也会用空间换时间，具体就看性价比，怎么划算怎么来。 --- 再一个压缩技术，消耗的是两头的CPU：server压，client解压，用户的资源消耗的提升也是一种拉动内需的手段。 上图👆SetOutputFilter DEFLATE不写也行。 AddOutputFilterByTyep DEFALE XXX这是要压缩的文件类型，一般来讲视频压缩效果不太理想(不过具体也看如果视频本身的画面单一，可能压缩比也高的)。 使用压缩技术，server端依赖的是deflate_module，client依靠浏览器 压缩级别的指定👆 下面实验 首先找一个大文件，用来做页面 是的，关键是curl www.a.com 回车后直接默认就是访问的www.a.com/m.txt，奇怪了不应该是www.a.com/index.html嘛 上图403的原因：正式因为访问www.a.com默认就访问了m.txt，而m.txt没有给r权限，所以就403 Forbidden了。 至于为啥不是index.html就不清楚了。 curl 看server有没有压缩，要用--compressed选项才能确定 好上图就说明没有压缩，原文件多大，curl 就下载了多大---conntent-length 开启压缩 重启服务 浏览器可以看到压缩了👇 curl压缩要用选项 压缩的意义在于 money的节省，举个例子，一个图片没压缩钱是4MB，压缩后400KB，结果忘记开启压缩了，结果对外服务大量用户都是下载的4MB，流量哗哗的就出去了，都是钱啊。 HTTPS 逻辑 实现 1、颁发证书的两种方式 自签名证书，自己给自己颁发，就是私网里自己做一个CA证书颁发机器来实现内部的ssl证书颁发，不过这个互联网上是不认得。 申请购买商业SSL证书正儿八经去相关机构比如亚信、godaddy去申请SSL证书。 申请免费SSL证书这个互联网也认 凡是互联网认得，不管是买的还是免费的，关键点在于\"受信任的根证书颁发机构\"这一随OS安装就存在于电脑上的，手机同理。 这些证书就在了，也就是得到这些著名的CA的公钥了。 所以这些CA的颁发的SSL证书--也就是用他们的私钥加密来文件(这个文件往往就是网站的公钥)--也就是Sca(Psite)，PC-client就可以用已安装的公钥解密了，所以就可以解开了 2、加载httpd的加密模块 上图可知：本身105个模块加载了93，12个没有加载，然后105也没有ssl模块，所以ssl模块需要另外安装。安装就用yum install mod_ssl yum 安装后，就有这个ssl模块了，而且也加载了 👆为什么yum后就加载了，其实yum安装本质上也是添加了配置文件，做了加载的配置👇 配置文件相关 证书和私钥是yum安装的时候自动生成的，具体怎么来的，①要么安装出来的-通过 rpm -ql mod_ssl看看②要么是yum安装前或者前后的脚本跑出来的--通过rpm -q --scripts mod_ssL看看 👆确实是yum 出来的两个证书和key文件。 但实际上都没有我的都没有，省流：因为新版本是mod_ssl模块安装后，httpd启动后就会自动生成localhost.crt和localhost.key。而不是什么安装后脚本了。 视频里老师的有，是老版本的打法。 👆上图确实是老版本的mod_ssl确实存在安装后脚本的，ssl证书和key确实是脚本产生的，但是新版不同。 再找一台机器yum mod_ssl可得出结论，新版本确实没有mod_ssl 安装后脚本，通过下面两个图可见证书和key文件都是启动httpd服务后自动生成的。哈哈新版本和老板的区别咯。 再找一台，就是不安装mod_ssl，启动服务，预判是没有这两个文件的，确实没有👇 所以结论是：mod_ssl模块+httpd服务启动一次，就会自动生成localhost.crt和localhost.key文件了。 不过倒是得到了一个证书生成的脚本：就叫做自签名证书脚本 哈哈，天下脚本一大抄嘛，倒是个不错的思路，抄之 其实就是yum 一下 mod_ssl ，重启一下httpd服务，443就监听了，证书也有了，https也启用了 此时80端口也开着，http协议不加密的服务也开着。所以http和https都可以访问，而且mod_ssl配置文件里面是这么配置的👇 虚拟主机的配置方法，也不会和之前的80服务产生冲突 冲突情况 不冲突的情况 其实mod_ssl本质上也是 虚拟主机不过人家是443，不会和 之前的80冲突，冲突的无非是虚拟主机的80和非虚拟主机的80. curl要注意使用-k选项忽略证书的安全性 将message大文件复制到/data/www下进行ab性能测试 此时主站就变成了 导入证书 证书怎么看，👆这样看不到任何信息， openssl x509 -in localhost.crt -noout -text 该 自签名证书👆，好像无法导入\"受信任的根证书颁发机构\"，颁发者和颁发给的都是 主机名node2，也不知道有没有问题，反正一般都是颁发给某某网站，比如👇 上面是利用mod_ssl+httpd服务启动后自动生成的证书去实现的，下面使用手动内部签名的方式 利用私有CA，实现https 先回顾一下mysql里的ssl加密的所有cli mkdir /etc/my.cnf.d/ssl # 专门放证书信息，利用现成的my.cnf.d文件夹，ssl是创建的 cd /etc/my.cnf.d/ssl ①生成CA的私钥： openssl genrsa 2048 > cakey.pem # 以前是专门一个目录，现在简单放一起就行 可能最好加个密，或者改个cakey.pem的权限，安全些。 ②利用私钥生成自签名证书 openssl req -new -x509 -key cakey.pem -out cacert.pem -days 3650 ③生成master的私钥和证书申请文件 openssl req -newkey rsa:1024 -days 365 -nodes -keyout master.key > master.csr # 利用一条命令生成私钥文件master.key，并利用该key生成证书申请文件。 注意！1024得改成2048，否则mysql起不来。可能是之前用得2048的CA私钥吧。 ④有了证书申请文件，就可以签名了--也就是颁发证书 openssl x509 -req -in master.csr -CA cacert.pem -CAkey cakey.pem -set_serial 01 > master.crt 然后SSH里也涉及CA，下面是SSH里的操作，也是本次httpd的证书操作，一样的。 1、建立CA：genrsa生成ca私钥--cakey；利用cakey自签名证书--自己给自己颁发证书 (umask 077;openssl genrsa -out private/cakey.pem 4096) openssl req -new -x509 -key /etc/pki/CA/private/cakey.pem -out /etc/pki/CA/cacert.pem -days 3650 /etc/pki/CA/serial # 存放下一个颁发证书的序列号，0F改成01从第一个号开始分 2、搞一个证书申请文件 mkdir /etc/httpd/conf.d/ssl cd /etc/httpd/conf.d/ssl (umask 066;openssl genrsa -out httpd.key 1024) #1024可能有问题msyql那会的经验告诉我要4096保持一致 openssl req -new -key httpd.key -out httpd.csr 3、针对申请文件进行颁发证书-也就是签名-也就是用CA的私钥进行加密 openssl ca -in /etc/pki/CA/httpd.csr -out /etc/pki/CA/certs/httpd.crt -days 100 scp /etc/pki/CA/certs/httpd.crt root@httpdServer:/etc/httpd/conf.d/ssl # 把证书复制到server上 scp /etc/pki/CA/cacert.pem root@httpdServer:/etc/httpd/conf.d/ssl # 把ca自己的证书也复制倒server上，此举相当于windows预加载了受信任的根证书文件。 实验开始👇 在CA上： 实测👆上图的umask并不会影响到openssl genrsa生成文件的权限，可惜了，(umask 077;mikdir/touch)倒是ok openssl x509 -in cacert.pem -noout -text # 查看证书内容cli 👆对的，上述信息都在的。 在服务器上： 把httpd.csr证书申请文件传到CA上 在CA上进行签名 将证书复制到server上 将CA证书复制到server上 然后去到server上 👆httpd.key就是私钥，httpd.crt就是证书-也就Sca[Pserver]-也就是经CA私钥加密后的server公钥文件。 最后就是在server上的ssl配置文件里使用上面得到的cacert.pem根证书，httpd.crt证书，httpd.key私钥 CA的证书先不配置，看下是否就会报不安全的证书信息 名字改一下好了，结果还是报错，是不是1024和4096不匹配啊，应该不是，仅仅1024太短了，后面改成了2048就好了CA还是4096的长度。 通过err_log看看，重启服务的动作会生成如下错误日志 回过头去修改httpd.key的1024长度为2048试试 就是index.txt里有记录了，就是CN、beijing、admin@ming.com这些申请信息已经有了，重复了冲突了 结果，就牛逼的OK了 屡试不爽啊，myslq里和httpd里，然后httpd其实就是ssh的ssl一样的用法，所以CA ssl证书里的2048这种长度一定要一致啊，具体来讲就是CA的key2048，那么server的key也要2048，等等，一致肯定没问题，但是上述实验CA的key是4096哦，server的key最后2048也行的，就是不能1024，可能是1024的长度被弃用了。 测试-1-目前没有加载CA的证书呢，只是server有了自己的证书 观察证书的信息，就是我们上面申请的信息 注意实验的时候不要点击 继续前往，否则就没有对比效果了 注意细节，没有导入CA证书的时候，证书 详细信息里 的层次结构是看不到的 待会导入证书后，就会看到多了颁发给：www.a.com 的信息 ，而不再是上图👆的颁发者和颁发给都是ca.ming.com了 上图👆这里层次结构不全，是因为我们没有加载CA证书，在httpd的/etc/httpd/conf.d/ssl.conf里 加载一下 重启服务后，httpd网站的ssl证书里的层次结构就全了-就是谁下面的谁的证书。 这页没啥变化👆，主要是第二页 详细信息 但是为什么层级里都是ca.ming.com啊，难道不是www.a.com，稍等我知道了 再改一下，将httpd.csr重置， 注意上图index.txt里由于本次颁发是www.a.com和之前的ca.ming.com不冲突了，所以不会报错 看看是不是www.a.com了👇 issuer，\"颁发者\" subject，这里指 \"颁发给\" 重启服务 这下就顺眼鸟 导出CA证书，放到client PC上去，导入倒PC的 受信任的根证书机构 里去 如何导入呢，修改cacert.pem为caert.pem.crt，就是在linux里pem后缀就认了，但是windows里还得再加个crt后缀 注意上图左1的 \"证书状态\"是 不受信的。 此时，再看证书状态就没问题了👇，这里只是系统层面的判断，浏览器层面只完成了一半。 但是浏览器不管的，还是说 不安全，我怀疑浏览器就是不认私自颁发的证书了。 https://support.huaweicloud.com/ccm_faq/ccm_01_0098.html 如何解决浏览器的不安全提示 下了个火狐，人家明确说了自签名，不认，啊哈哈，牛逼。 那么问题还在吖，自签名证书就没办法让浏览器认了吗？ https://blog.csdn.net/a735131232/article/details/80526859 试试这招👆不具体，再看看别的教程 https://blog.51cto.com/u_296714/5754713 这篇👆貌似可以解决，但是我就想用openssl生成的ca自签名证书呢 导出后加个.crt后缀，在windows里打开看看 发现没有 \"使用者可选名称\"啊 搜索 openssl如何生成这个选项，准备重新颁发 https://blog.51cto.com/u_11508007/5674376 # 他这个只是配置文件写对了。# 一切OK后补说明：但是颁发的时候也要加上v3_req选项，他就没讲。而且只适用于自签名和颁发，csr文件无需这么操作。这些都是后话，回顾写道这里的，可以不看。 修改openssl配置文件 备份 cp -a /etc/pki/tls/openssl.cnf /etc/pki/tls/openssl.cnf.bak1 修改vim /etc/pki/tls/openssl.cnf 取消req下被注释的第2行 删除req_distinguished_name下的0.xxx 的标签，把0.xxx的0. 去掉 在[ v3_req ]下新增最后一行内容 subjectAltName = @alt_names 新增 alt_names,注意括号前后的空格，DNS.x 的数量可以自己加 上图写错了，DNS.1改为*.a.com和DNS.2=www.a.com 重新走一遍所有证书的操作-第二次NG CA上👇 cd /etc/pki/CA mkdir certs mkdir crl mkdir newcerts mkdir private mkdir ssl (umask 077;openssl genrsa -out private/cakey.pem 4096) openssl req -new -x509 -key /etc/pki/CA/private/cakey.pem -out /etc/pki/CA/cacert.pem -days 3650 touch /etc/pki/CA/index.txt # 存放已经颁发的证书信息 echo 0F > /etc/pki/CA/serial # 存放下一个颁发证书的序列号，0F改成01从第一个号开始分 server上👇 mkdir /etc/httpd/conf.d/ssl cd /etc/httpd/conf.d/ssl (umask 066;openssl genrsa -out httpd.key 2048) #1024可能有问题msyql那会的经验告诉我要4096保持一致 openssl req -new -key httpd.key -out httpd.csr scp /etc/httpd/conf.d/ssl/httpd.csr CAServer:/etc/pki/CA # 把csr申请文件传到CA上，在CA上根据csr文件来颁发证书，也就是对其加密。 CA上👇 openssl ca -in /etc/pki/CA/httpd.csr -out /etc/pki/CA/certs/httpd.crt -days 100 scp /etc/pki/CA/certs/httpd.crt root@httpdServer:/etc/httpd/conf.d/ssl # 把证书复制到server上 scp /etc/pki/CA/cacert.pem root@httpdServer:/etc/httpd/conf.d/ssl # 把ca自己的证书也复制倒server上，此举相当于windows预加载了受信任的根证书文件。 这里调了默认的[]里的值也是在配置文件里 后略了，但是没有 使用者可选名称 ！！ 查询原因 终于有了 知道了自签名和颁发的时候才会使Subject Alternative Name有效 openssl req -new -x509 -nodes -out cert.pem -keyout key.pem -config /etc/pki/tls/openssl.cnf -days 365 -extensions v3_req 这是自签名，我可能需要的是ca颁发的时候，或者server生成csr的时候做出来 使用者可选名称--也就是subject Alternative Name，实际测试时ca颁发或者自签名的时候才会起作用 CSR文件里无需做任何配置，下图👇是错误的，通过CA那边修改配置文件立马生效可知 证明上图时错误的 所以要让server服务器的ssl证书里有subject Alternative name出来，就要在ca颁发server证书的时候①修改openssl的配置文件②颁发的时候带上v3_req版本参数 然后要让浏览器不在说不安全就要①加载ca根证书到\"受信任的根证书颁发机构\"②网站ssl证书里要有Subject Alternative Name。 重做证书-最后一次-ok了 CA上👇 cd /etc/pki/CA mkdir certs mkdir crl mkdir newcerts mkdir private mkdir ssl (umask 077;openssl genrsa -out private/cakey.pem 4096) openssl req -new -x509 -key /etc/pki/CA/private/cakey.pem -out /etc/pki/CA/cacert.pem -days 3650 touch /etc/pki/CA/index.txt # 存放已经颁发的证书信息 echo 0F > /etc/pki/CA/serial # 存放下一个颁发证书的序列号，0F改成01从第一个号开始分 server上👇 mkdir /etc/httpd/conf.d/ssl cd /etc/httpd/conf.d/ssl (umask 066;openssl genrsa -out httpd.key 2048) #1024可能有问题msyql那会的经验告诉我要4096保持一致 openssl req -new -key httpd.key -out httpd.csr scp /etc/httpd/conf.d/ssl/httpd.csr CAServer:/etc/pki/CA # 把csr申请文件传到CA上，在CA上根据csr文件来颁发证书，也就是对其加密。 CA上👇 openssl ca -in /etc/pki/CA/httpd.csr -out /etc/pki/CA/certs/httpd.crt -days 100 -extensions v3_req scp /etc/pki/CA/certs/httpd.crt root@httpdServer:/etc/httpd/conf.d/ssl # 把证书复制到server上 scp /etc/pki/CA/cacert.pem root@httpdServer:/etc/httpd/conf.d/ssl # 把ca自己的证书也复制倒server上，此举相当于windows预加载了受信任的根证书文件。 一下是所有完整过程： 在CA上👇 在server上👇 在CA上👇 在server上👇加载ca证书、server证书和server的key 把ca证书拿到PC，加上.crt后缀，导入 受信任的根证书颁发机构 无痕模式 一定要关闭所有无痕窗口再重新打开，不然确实有缓存的，然后结果就是搞定啦 这个在浏览器里显示为 \"证书主题背景的备用名称\" 导出后补上.crt打开可见为\"使用者的可选名称\" subject 在证书里 显示为 颁发给、使用者、主题，所以只是翻译的问题，subject是本来的名字 上图👆这就是 网站浏览器不再 提示 不安全的原因，一定要①加载根证书②server证书也就是网站证书里要有使用者可选名称--subject Alternative name，这个参数怎么来说的，就是CA颁发的时候加上-extensions v3_req，颁发者(CA颁发或者自签名)的openssl配置文件里也要改的。 搞定搞定~~~ 所以要让server服务器的ssl证书里有subject Alternative name出来，就要在ca颁发server证书的时候①修改openssl的配置文件②颁发的时候带上v3_req版本参数 然后要让浏览器不再说不安全就要①OS层面：加载ca根证书到\"受信任的根证书颁发机构\"--这一步只是让ssl证书导出后打开显示为 “该证书没有问题”；并不能让浏览器认为安全，浏览器认为安全的判断依据是，判断\"网址\" 和 \"使用者可选名称也即是subject alternative name\"里的东西 一致 ②浏览器认为安全的判断依据：网站ssl证书里要有Subject Alternative Name，且该参数里的内容包含网站地址 \"多个域名不用再购买多个证书了\"这话有点吊啊，回头看看公司的ssl证书是怎么买的。(￣▽￣)\" 以前浏览器看这个 上图证书导出来 主体背景 就是 \"使用者\" 翻译问题 现在看这个 上图证书导出，证书主体背景的备用名称 就是\"使用者可选名称\" 删除根证书要到mmc里删除了 这就删除了 删除 \"受信任的根证书\"后，再次打开看看 一样不安全，所以①导入ca证书；②subject Alternative Name里有网站地址。 浅排一下打开www.a.com慢的问题 真TMD高，回头研究下为什么是每个掉用户，load这么高， 直接降低就是修改配置文件，把几个初始化多线程关掉 重启服务后，逐渐就降下来了，估计是参数设置不合理，没有匹配 VM虚拟机的资源。 然后PC 浏览器打开就秒开了，呵呵呵，之前都是很慢 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-11-02 11:05:12 "},"29-HTTP协议和APACHE/8-http的安全加固和重定向.html":{"url":"29-HTTP协议和APACHE/8-http的安全加固和重定向.html","title":"第8节 http的安全加固和重定向","keywords":"","body":"第8节. http的安全加固和重定向 书接上文的一些其他注意点 测试基于https访问相应的主机 浏览器验证https，呵呵 openssl 验证https主机 openssl s_client [-connect host:port] [-cert filename] [-CApath directory] [-CAfilefilename] 其中-cert filename应该是client的证书，这个不用写，一般server也不会验证client证书。 上图是拼接出来的哦，无缝衔接，一字不拉，牛逼不~ 如果不带ca根证书 -CApath . -CAfile cacert.pem 就会error的哦 没有上图的绿色ok了，顺带一提绿色是MobaXterm自带的着色。 以上就是原来绿色ok处的对应截图，现在都是error和 Verify return code 19报错了，原来是Verify return code code 0 ok。 curl验证https curl 带上根证书进行访问https网页 理解下目前实验页面显示状况 为什么https://www.a.com和http://www.a.com内容一样 ①首先按https://www.a.com走的是/etc/httpd/conf.d/ssl.conf里的虚拟主机 而此处没有定影DocumentRoot的路径，,所以去看之前我们定义的/etc/httpd/conf.d/test.conf，要定义DocumentRoot，自然/etc/httpd/conf/httpd.conf下的DocumentRoot要注释掉的 其实我感觉规范的做法就是虚拟主机也配置一遍自己的，不管是否利用默认的，都配一边方便维护。 然后②看下http://www.a.com走的是/etc/httpd/conf.d/test.conf里的虚拟主机 浏览器里输入的是http://www.a.com，所以先看80，再看head里的host是www.a.com所以走的是/data/www/asite下的xx.txt，如果没有xx.txt就是index.html了 所以结合①和②，https和http都是一个页面啦 有人说：https不能说配置多个\"基于主机头的-虚拟主机\"。我按他的思路理解是因为https加密范围是包含了head字段的，虚拟主机处理的时候再ssl卸载之前了，这也是我猜的，尴尬的点在于server具备卸载ssl证书的能力，也就是可以看到主机头，为什么不能针对多个https站点用基于head里的host来实现路由呢。除非 废话不多说，上实验 为了便于对比，将原来的https://www.a.com的页面改成index.html不再使用m.txt 这不是好好的嘛 www.b.com复制的www.a.com虚拟主机的配置，证书要改，否则 subject alternative name里的没有www.b.com网站地址，不能认为安全的👇 只不过www.b.com没有颁发证书而已。搞一个 ①生成csr文件 ②ca颁发一下 发现没有Subject Alternative Name，所以要去/etc/pki/tls/openssl.conf下去配置一下 然后就有了 回到server上配置好www.b.com的证书文件的加载，同样和www.a.com的一样，在虚拟主机里配置，在/etc/httpd/conf.d/ssl.conf里配置 只需要改一行👆 PC上补一个hosts记录 然后就好了啊 所以通过实验不是发现了https的多站点，可以基于head主机头host字段进行配置多个虚拟主机啊。 我就觉的server自己有能力卸载ssl证书-解密，而且卸载的证书和servername都在一起配置的👆，为啥不能基于主机头进行https的多虚拟主机配置呢，对吧。实验证明就是可以的。 下面实现http跳转https 首先知道一个chrome的默认行为， chrome浏览器会自动给你补上https的，比如 使用联想浏览器输入a.com 使用chrome输入a.com，只有chrome会干这事，其他浏览器不会说 输入xx.xx.com自动用https:// 使用火狐，结果发现火狐的证书好像识别可能不是OS的 这样就加载进去了，火狐果然不是用的OS的受信任的证书颁发机构。 然后火狐浏览器就不再报不安全了 然后火狐的行为 输入https://www.a.com或https://www.a.com/都一样。 然后正儿八经开始做server的http重定向到https 区别上面说的Client的chrome的默认https行为，防止误判 两种重定向：301和302👆，通过语句里的[status]区别配置 Location：http://www.jd.com就是301重定向过去的网址。 活久见http跳http，浏览器错误显示了吧 jd就是两次跳转，一次301 从http://www.360buy.com/跳到http://www.jd.com，一次302从http://www.jd.com跳到https://www.jd.com; 也就是第一次是 不同网站的http跳转-301；第二次是相同站点的http跳https。 好像后台自动给你转，就是一次请求就行了，好像也是有此类技术的。 实验 访问www.a.com跳转到www.b.com 将上面的访问都跳转到https://www.b.com 再把https://www.a.com也重定向了 这样就实现了http://www.a.com跳http://www.b.com;https://www.a.com跳https://www/b.com 这样就实现了http://www.a.com跳https://www.b.com curl -L 的说明，curl默认行为就是只发一次请求，-L就会follow redirects，就是会跟随重定向们，多次也没问题 如果你再在上图上地址栏里敲一下回车，由于是chrome就会导致你访问的其实不再是http://www.b.com而TMD的是https://www.b.com了然后就会走别的虚拟主机了，重定向的配置就不生效了，或者别的地方的重新向了，我的配置如下 好烦呐，翻来覆去的，(￣▽￣)\"，反正这里记住，处理思路就是类似网络转发：PHB，per-hop-behavior，这里也是一样一跳一跳的路由转发查询就行了。 淘宝用的301永久重定向，其他大多数用的是302临时重定向。 然后就是搜索引擎比如百度，就不会抓取301重定向前的地址页面了，302的跳转前页面还会抓的。因为301永久重定向被被认为是废弃的地址了不用了，也就不会去这个页面抓取内容了。 不做虚拟主机进行ssl跳转 恢复实验环境①移除/etc/httpd/conf.d/test.conf②恢复/etc/httpd/conf.d/ssl.conf里的配置，证书相关保留③恢复/etc/httpd/conf/httpd.conf里的配置 修改如下👇直接在主配置文件里补上重定向的配置就行redirect temp / https://www.a.com 最多跳转50次 产生这样的跳转的原因不太清楚，解决方法是换一种配置方式 RewriteEngine on RewriteRule ^(/.*)$ https://%{HTTP_HOSTS}$1 [redirect=302] 重启服务后生效 HSTS： ①HSTS:HTTP Strict Transport Security 解决如下问题： 除非第一次就给你劫持了，否则还是比较安全的，靠的是本地缓存，如果缓存被清空或者到期或缓存时间设置较短，还是存在安全风险的具体逻辑如下： HSTS -- HTTP Strict Transport Security 使用该技术的案例👇。其他网址看了下，用的不多。 老化时间是1小时，也就是重定向缓存1小时 ②HTST preload list 是Chrome浏览器中的HSTS预载入列表，在该列表中的网站，使用Chrome浏 览器访问时，会自动转换成HTTPS。Firefox、Safari、Edge浏览器也会采用这个列表 这里和chrome浏览器自动给你补Https的行为还不是一回事。 ①chrome你输入www.baidu.com会自动给你补https://的 注意这里不存在重定向的，要输入http://www.baidu.com才会有302出现 当然curl 也不会触发302，有点奇怪， ②chrome里的hsts列表，这是preload预加载的，你输入http://www.bing.com内部就给你转成https://www.bing.com 使用无痕单开模式输入http://bing.com，不要加www哦，因为上图的found清单里并没有www.bing.com只有bing.com 然后通过F12查看是不是直接就是https出去了 ③就是各种重定向了，301、302、307之类的 但是加上www，由于不在chrome浏览器的hsts清单里所以还是走的服务的重定向不过这里是307 当我在无痕里输入http://www.bing.com的时候，通过F12看到的是307，内部重定向。 把字符集改一下 没改过来！ 好像是开启重定向就会这样，下图👇是不用虚拟主机方式的写法，会造成循环重定向，这里仅仅测试重定向对字符集的影响。 重定向都关了就好了 这些cil进一步研究可以查看官方手册https://httpd.apache.org/docs/2.4/mod/mod_rewrite.html#rewriterule 正向代理和反向代理 图片不多说了，补充要给一般正向代理往往会加一个缓存功能，就是出口代理缓存服务器，比如城域网出口想必是有缓存的。比如内部的Nexus私网原站(pip源、yum源、npm源、docker源)，然后client都将源指向nexus代理服务器，所有的基于各种源的软件安装都会从nexus代理走，然后凡是从nexus下载过的软件都会在nexus本地缓存起来，这样，下一次其他人通过该代理下载就会不用再去互联网请请求了。 同样理论上也是可以在代理服务器上做acl，针对某个用户拒绝代理服务也是可以的。 反向代理服务器，通常就是一个服务器 服务不好 N多个用户了，才需要多个服务器分担。所谓服务不好主要指用户量大了，或者用户地理位置分散-服务器需要有就近服务需求。 类似myslq读写分离的调度器 正向代理，加速、缓存 反向代理，均衡、调度 正反都是欺骗用户，欺骗不太好，用户也知道有这些东西，或者叫都是代理了server服务来着。 正向代理软件，squid老牌正向代理软件，web cache咯http://www.squid-cache.org/有需要再研究吧 反向代理如那件，nginx较多，apache有但是用的很少，还有LVS、还有F5、HAproxy。 实验-apache的反向代理 一般会将背后真正的提供服务的服务器叫做real server👇 再设置一下反向代理服务器 apache的反向代理-常规 ProxyPass \"/\" \"http://192.168.126.130/\" # client访问 我\"/\" 转成 身后 realServer 130 ProxyPassReverse \"/\" \"http://192.168.126.130/\" # 身后realServer回包我，将130转成我自己\"/\" 👆就是中间代理，两头欺骗，不好意思我又用了欺骗一词。因为我找不到更简单词用来替代了。承接？也不明显。用的好就是透明代理，恶意的就是欺骗了吧。 记得重启131的httpd服务 然后就可以测试了，测试之前打开realserver和proxy的log client上不知道真正的服务器s👇：访问的是proxySer proxyser上知道真正的c和s👇：看到的是真正的client IP realSer上不知道真正的c👇：看到的是proxy访问过来的 apache的反向代理-特定URL ProxyPass \"/images\" \"http://www.example.com/\" ProxyPassReverse \"/images\" http://www.example.com/ 找个image测试 修改proxySer的配置，只针对特定url进行转发过去 测试，一般不转发ok 测试，特殊url转发ok 测试，特殊url转发ok apache的反向代理-虚拟主机处配置 这个就有点像nginx了哦，呵呵，基于主机头的负载均衡，后端用端口区分，也可以用nodes的ip区分，貌似可行。 ServerName www.magedu.com ProxyPass / http://localhost:8080/ ProxyPassReverse / http://localhost:8080/ 浅测一下 配置proxySer 修改windows这个client上的hosts 解析到proxySer上 测试负载均衡 还不错啊，貌似用apache一样做反向代理，不过nginx用的比较多，apache用的少，所以就是那家饭店吃饭人多去哪家就是这个朴实无华的道理。 Sendfile机制-属于零复制技术里的一种 先复习 一直看到 然后上图👆结合下图理解一遍👇 4次用户态和内核态的交互如图👇 图中的④未标注，图中的socket buffer到httpd，是内核态到用户态的切换，但是应该不是③的write()返回。 简单理解就是确实存在4次左右的用户态和内核态的交互。这样就发现数据的传递存在不必要的处理过程--数据本来就在内核态里非要从用户态绕一圈没必要，于是sendfile就来了。 简单来讲就是👇下图的绿色箭头，不过socketbuffer好理解，协议栈难不成算到接口的队列缓存里的？ apache默认就启用了该👆sendfiler机制。 该技术不仅仅属于apache，nginx里也有。 sendfiler技术又名零复制，其意思就是没有将数据从内核空间复制到用户空间。 具体零复制，还涉及一些别的技术。 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-10-16 17:58:36 "},"29-HTTP协议和APACHE/9-http协议详解和相关工具.html":{"url":"29-HTTP协议和APACHE/9-http协议详解和相关工具.html","title":"第9节 http协议详解和相关工具","keywords":"","body":"第9节. http协议详解和相关工具 HTTP协议 HTTP请求报文 \"实体主体\"，比如POST上传的数据内容，比如上传文章。正好我用confluence的api上传文章看看 难道所谓的\"实体主体\"就是上图的JavaScript Object Notation，不过这部分内容确实是我上传conf的文章。 上图既有请求报文，也有响应报文，>就是请求， HTTP响应报文 HTTP报文语法 GET POST用的较多，HEAD就是只看头的请求，通过curl -Iv可见👇 关于HTTP的响应码的说明查看方法 https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/200?utm_source=mozilla&utm_medium=devtools-netmonitor&utm_campaign=default 304缓存，F12里有Disable cache开关。我一般都是勾选的，防止缓存带来的误判。 有人缓存就清2个礼拜的，但实际缓存可以存在长达1年之久👇 Cookie cookie是键值对，里面存放了用户信息 ①用户访问服务器的时候，服务器生成cookie值，是key,value键值对，比如user=bob,goods=tesla ②server通过set-cookie这个首部字段信息，发给用户 ③用户的浏览器就收到了， 然后存着，下次访问就会自动在请求报文中携带cookie,user=bob,goods=tesla ④网站服务器一看，这个人又来了，这就实现了HTTP无状态的用户信息连贯性。 胖cookie：早期什么信息都网cookie里放，造成cookie东西太多，带宽占用大。 cookie的有效期：应该也是set-cookie服务让用户浏览器缓存的时间。 会话级的cookie：就是类似mysql的会话级的变量一样，只针对当前会话生效；这里的会话级的cookie就是浏览器一关，cookie就没了。 好像有的登入ID就是用的session级别的cookie。 通过userid来简化cookie携带的内容，id对应的内容放到server端的DB里，这样信息在网络中的传递就少了很多。 说到信息的传递和验证，这块玩的花的玩的6的我接触到的还是cisco的ASA课程里其实不仅仅是ASA就是security方向里用的比较多，印象中有一个ISN、还有DOS防护的一些技巧，当然抗D肯定不是这么玩咯。 再一个session id，这个比如jd都没有登入，但是两次页面刷新，购物车里的东西还在，说明不是基于用户ID来保持购物车里的信息的，这里应该就是基于sessionID来的。 session ID 10000在DB里存在购物车里的商品信息。 sessionID也是放到set-cookie发给用户浏览器的，其实说白了就是因为http长连接也长不了多久，http会话不会保持，http本身设计就是短链接，所以需要有一个东西来做多个tcp连接的承上启下context的作用。不管session ID也好，userid也罢，都是打标 用标，然后标的信息完整信息放到server的DB里作为节省带宽的玩法。 cookie也不会随浏览器关闭而关闭 cookie也可以进一步查看的 不过再详细好像现在版本直接看不到了，之前点进去可以看到类似浏览器F12里的cookie值得。 https://blog.csdn.net/u011781521/article/details/87791125 找到一个chrome浏览器得缓存 cookie找到了，这是chrome浏览器cookie的存放路径 发现是SQLite格式 传到linux里看算了，windows 和linux 一样要安装sqlite https://zhuanlan.zhihu.com/p/99643229 https://juejin.cn/post/7111861277751771173 yum -y install sqlite select * from cookies;结果一堆乱码，操 一堆乱码，唉 算了，不看了，可能是字符集要修改一下👆 1、2、3、4就是一个session1存入到浏览器上了，这里涉及负载均衡和身后的服务器nodes。session1是对应在特定的node节点的。 如果5请求过来，假设负载均衡没有做session保持，那么就有可能将请求路由到其他的node，而新的node上没有之前的信息，比如登入信息，购物车里的商品，这样原来的页面就没了。 解决误区-不做会话保持，为了保持会话，基于某个源IP-1就路由到特定node上，理论上OK的，因为该源IP都是和一个特定node进行通信的，所以会话一致都在--就是用cookies里存放session ID标记就行了；但是如果IP是PAT身后一堆PC呢。这样针对这一堆IP就全部负载分担到某一台node了吧，可能造成一台node负担重。 解决方法-基于sessionID,nodes1通过set-cookies打上sessionid1000给A，A就存入缓存。然后负载均衡就基于该session1000进行转发。 这种方式也存在某一个node承担太多的情况，也不能实现均衡。 解决方法-session复制,随便调度到哪个node都有会话同步，消耗内存大-因为整体上来看，session是每台机器都要保持。 最佳方案-session服务器，主流软件redis。用户访问网站了产生session了，session信息不放在web服务器上，统一放到redis服务上。因为session大家共用的，所以也无需上图复制。 redis特定：基于内存的，速度快；但是不适用于数据持久化，重启就没了，持久化还得靠数据库比如mysql。 比如用户登入密码，放到mysql里。 cookie是开发，java、PHP开发人员大概去具体实施的，动态页面才需要cookie吧，因为静态页面通常页面数据不大，在http的超时时间内拿掉就行了，不过太大最好也要cookie了吧。 动态页面需要更多的交互也就是会话。 JAVA里的sessionID：JSESSIONID PHP里的sessionID：PHPSESSID 浏览器如果禁用了cookies，就无法记录sessionID，就无法保持会话了，一些应用就失效了。 php配置cookie👇 vim /var/www/html/setcookie.php 安装php yum -y install php systemctl restart httpd # 安装完php后要重启httpd 差不多👆上图的时间确实就是从unix元年1970-1-1 00:00:00开始的，通过man date可见 下图是第二天上午敲得命令， 时间相差4个小时，差不多 在这纠结时间不如找到head头里有date字段的看看，验证下图 诺，真要掌握了so easy的时间OK的。 针对上图titlesb，修改一下配置文件 这下超时时间1小时就对了👇 注意上图Expires/Max-Age，一个是session也就是会话级的cookie，一个是1小时超时。 然后重新打开浏览器，但是不要再访问这个192.168.126.130页面 可见就也给cookie了不过这个cookie是啥，现在看不到了，以前浏览器版本点击去就有的，不过可以换浏览器看，或者这样看 cookies文件正在被使用，C:\\Users\\oneye\\AppData\\Local\\Google\\Chrome\\User Data\\Default\\Network 在这个路径下的Cookies文件咯，说被使用，其实就是chrome浏览在使用中，关闭浏览器就好了。 然后就看到浏览器里(仅显示1个Cookie-看不到内容)里面的内容了 7列13342160425029725 是expres_utc，通过date可得出，得出个鬼啊，你算算多大，呵呵 搞不懂，value TEXT竟然连sb字符都不显示的嘛，加上现在浏览器设置里都看不到cookie的具体值，只能在F12里看，是不是从安全出发做了限制了。 links和curl简单用法 有些网站不让看源码，其实下都下来了怎么会看不到呢 网站的文章不错，但是不让你复制粘贴可以这样 wget简单使用 wget 是-O 大的，可不带 ；curl 是-o 小的下载必带 如果页面是一个bash脚本，就可以这样写 优化输出 curl -s xxx |bash -s其实也是有std的，所以可以|管道符到bash 去运行。 还可以用wget的std打印和管道符的用法👇 不过还需要进一步优化-q静默一下 就干净了👆。 所以上面就是一个很好的，将脚本share出去的方法，比如shell/python就可以用这种方式，不过得有web服务咯。这种适合简单场景无需传递参数的情况。 很多这个安装脚本都是这样玩的，比如 玄学上网一键安装脚本(科学的尽头是玄学嘛，你懂的)。 不过我更多脚本share出去一般推荐这样，才可以传递参数👇，然后使用curl去和该api交互 curl -X POST -H \"Content-Type: application/json\" -H \"Data_Type:msg\" -d \"{\\\"name\\\": \\\"Alice\\\", \\\"ip\\\": \\\"130.1.1.11\\\"}\" -s http://192.168.11.77:5000/api | python -c \"import sys; print(sys.stdin.read().encode('utf-8').decode('unicode_escape'))\" 当然eip_rib_add是一个python脚本函数。再一个上图脚本后台运行就行了，nohup clixxx > /dev/null & 敲完后exit退出保证后台运行，或者screen -S xxx开启后台运行clixxx然后直接关闭该窗口就行了--具体用法参见本blog的screen章节。 wget也支持限速 --limit-rate= curl也支持很多协议不仅仅是HTTP https://curl.se/docs/tutorial.html user-agent伪装 修改user-agent这个翻译叫用户代理，其实就是使用的什么方式访问server的，包括浏览器，本质上就是个注释👇 这就比较多了👆，一般都是浏览器访问，user-agent里携带的都是浏览器的表示，不过Mozilla需要了解下 网景 Netscape 值得了解 伪装从哪个网站跳转过来的 这里就涉及字段解释，这个没记错就是在配置文件里有 上文又讲，这里略 然后basic好像加不加一样啊， 帮助信息里也讲了this option is usually pointless。 curl --basic其实是修改认证方式的👇 除了systemctl还有一个启动关闭服务的工具 http对访问日志的处理 日志越来越大，达到一定大小就切分，然后按序命名，然后再生成一个新的access.log文件。 而且默认就是有切分的 具体用法 https://www.apachehttpd.com/programs/rotatelogs.html # 破网站，换成下面的👇 https://httpd.apache.org/docs/2.4/programs/rotatelogs.html 配置到这里👇去： 修改报错记录 修改，\"|/usr/sbin/rotatelogs\" 最前面的|是将原来的log通过管道符传递过来，需要注释掉原来的CustomLog行 这配置是ok的啦，不过你别想看到效果， 不信你看下 如何才能看到呢，往下看咯，curl一下有新的日志生成才会有触发 然后要注意httpd里的默认时间是UTC的 需要修改offset 480就是480分钟，也就是GMT+8啦，然后5就是5秒中一次 生成日志--但是你真要是等5秒钟结果是没有新的文件的，必须是满足5s后且+有新的access日志产生。 http压力测试 弄一下Jmeter https://jmeter.apache.org/download_jmeter.cgi https://www.jianshu.com/p/6bc152ca6126 问题记录 1、JAVA安装后就可以打开jmeter.bat了 https://www.java.com/zh-CN/download/manual.jsp Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-10-20 09:25:36 "},"29-HTTP协议和APACHE/10-httpd源码编译安装.html":{"url":"29-HTTP协议和APACHE/10-httpd源码编译安装.html","title":"第10节 httpd源码编译安装","keywords":"","body":"第10节. httpd源码编译安装 确实有：https://httpd.apache.org/test/flood/ 但是搜不到👇 APR是统一的调用OS的接口，便于开发。而apache也就是httpd软件就是基于APR开发的。 随着开发项目的越来越多，就需要APR这种接口、工具、或者引擎之类的专项小组，这样规模起来了，就需要统一接口开发小组来节省整体的开发成本。 其实软件是否基于什么软件通常都可以查的👇 讲这个就是要明白，编译安装的时候，要注意apache(httpd)的版本，和APR的版本时候适配。 一般yum安装的版本都相对较旧一点 官方有新的且稳定的版本，也不是就要安装最新的，要安装稳定的。判断依据有①该版本发布时间通常晚于最新1年？②和最新的隔1-2个版本。 理论上要先编译安装较新的apr和apr-util软件，再编译安装httpd的较新版本。 也可以把三个软件的源代码拷在一起，一起编译就行了。 方法一：逐个编译，这样就要注意依赖关系 比如👆apr-util依赖于apr，所以--with要知名apr的安装路径。 --with-apr和--with-apr-util就是依赖包的指定，这些依赖都是已经安装好的。 方法二：一起编译 --with-included-apr就表示httpd里的源码包里已经有了par的源码包了。 下面实验快开始，用rockyliux9.2弄得，思路还是和上面一样 1、找源码包 https://httpd.apache.org/ 2、找APR包 https://apr.apache.org/ 好像没有看到各个apache版本和apr的一个对应表，但是有推荐版本，所以猜测用这些就行了。也许人家软件向下兼容的。 3、下载 4、解压 安装bzip2 yum -y install bzip2 tar解压，通过history查看和awk过滤的比较优的方法如下： awk的思路就是：第二列是tar并且不包含字符*，然后去掉第一列序列号啦，再去掉行首行尾的空格。over~👇 [root@server httpd_new]# history |awk '$2==\"tar\" && $0!~\"*\" {$1=\"\";print $0}' |awk '$1=$1' |sort |uniq tar xvf apr-1.7.4.tar.bz2 tar xvf apr-util-1.6.3.tar.bz2 > /dev/null tar xvf httpd-2.4.58.tar.bz2 取history里的需要cli的方法①： 方法②： 合并一下cli 必要时可以去掉行尾 优化下 将两个awk合并一下 得到最屌的cli 再来一个更吊的cli 妈的我在干嘛...... 以上就得到了之运行的几个tar命令，(￣▽￣)\" 5、合并 把apr和apr-util的东西复制到httpd源码指定目录下。 cp -a apr-1.7.4 httpd-2.4.58/srclib/apr cp -a apr-util-1.6.3 httpd-2.4.58/srclib/apr-util 6、安装一些常规依赖包 yum -y install gcc pcre-devel openssl-devel expat-devel; yum -y groupinstall \"Development Tools\" 7、编译安装 cd httpd-2.4.58 ./configure \\ --prefix=/app/httpd24 \\ --enable-so \\ --enable-ssl \\ --enable-cgi \\ --enable-rewrite \\ --with-zlib \\ --with-pcre \\ --with-included-apr \\ --enable-modules=most \\ --enable-mpms-shared=all \\ --with-mpm=prefork make && make install 上图是找到cpu核数，然后并发编译的 编译的过程也会自动记录下来 8、进入编译指定安装路径下查看一下安装的情况，并添加PATH变量或做软连接 cd /app/httpd24 echo 'PATH=/app/httpd24/bin:$PATH' > /etc/profile.d/httpd.sh . /etc/profile.d/httpd.sh 或者用ln -s /app/httpd24/bin/apachectl /usr/local/sbin/ 但是要注意如果当前已经安装了httpd其他版本，还需要去掉其bin文件调用优先。 但是整个bin文件夹 链过去是没有用的，必须是二进制文件在$PATH下不能子目录。 awk的继续优化之去除前几列和空格的方法 ①软链接是文件还好👇 ②软链接是文件夹就一定要小心了 9、启动服务 apachectl start 但是查看不行， 通过修改systemctl的启动配置修正 👇这是yum安装的httpd的systemctl的配置，参考修改 修改之👇 systemctl的配置修改后需要reload加载一下👉：systemctl daemon-reload，再启动服务 死活起不来，这里不太好排查，但是ps aux可以看到 找到个这个，用的是daemon用户，而不是apache这个用户，不过也没关系，①有该daemon用户②httpd可以使用该用户执行 当服务启动的时候 status显示超时 继续排查通过错误日志可见， 可以看到 caught SIGWINCH，shutting down gracefully的情况。 改回apachectl start发现能起来，就是ss -tlnup 等3s就能看到80端口打开了，说明使用这种方式启动服务没问题。 然后去ps auxf看看 尝试将systemctl配置文件里的启动cli改成上图的试试 还是不行，算了换种方式吧，systemctl 有问题实在不行就换成脚本的方式👇 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-10-23 15:15:47 "},"30-实现LAMP架构/30-实现LAMP架构.html":{"url":"30-实现LAMP架构/30-实现LAMP架构.html","title":"第三十章 实现LAMP架构","keywords":"","body":"第三十章 实现LAMP架构 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"30-实现LAMP架构/1-实现LAMP应用phpmyadmin.html":{"url":"30-实现LAMP架构/1-实现LAMP应用phpmyadmin.html","title":"第1节 实现LAMP应用phpmyadmin","keywords":"","body":"第1节. 实现LAMP应用phpmyadmin Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"30-实现LAMP架构/2-LAMP应用部署.html":{"url":"30-实现LAMP架构/2-LAMP应用部署.html","title":"第2节 LAMP应用部署","keywords":"","body":"第2节. LAMP应用部署 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"30-实现LAMP架构/3-实现FCGI的LAMP架构.html":{"url":"30-实现LAMP架构/3-实现FCGI的LAMP架构.html","title":"第3节 实现FCGI的LAMP架构","keywords":"","body":"第3节. 实现FCGI的LAMP架构 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"30-实现LAMP架构/4-编译安装LAMP环境部署应用01.html":{"url":"30-实现LAMP架构/4-编译安装LAMP环境部署应用01.html","title":"第4节 编译安装LAMP环境部署应用01","keywords":"","body":"第4节. 编译安装LAMP环境部署应用01 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"30-实现LAMP架构/5-编译安装LAMP环境部署应用02.html":{"url":"30-实现LAMP架构/5-编译安装LAMP环境部署应用02.html","title":"第5节 编译安装LAMP环境部署应用02","keywords":"","body":"第5节. 编译安装LAMP环境部署应用02 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"31-日志管理rsyslog/31-日志管理rsyslog.html":{"url":"31-日志管理rsyslog/31-日志管理rsyslog.html","title":"第三十一章 日志管理rsyslog","keywords":"","body":"第三十一章 日志管理rsyslog Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"31-日志管理rsyslog/1-日志管理实现远程日志.html":{"url":"31-日志管理rsyslog/1-日志管理实现远程日志.html","title":"第1节 日志管理实现远程日志","keywords":"","body":"第1节. 日志管理实现远程日志 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"31-日志管理rsyslog/2-通过loganalyzer展示数据库中的日志.html":{"url":"31-日志管理rsyslog/2-通过loganalyzer展示数据库中的日志.html","title":"第2节 通过loganalyzer展示数据库中的日志","keywords":"","body":"第2节. 通过loganalyzer展示数据库中的日志 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"32-网络文件共享服务/32-网络文件共享服务.html":{"url":"32-网络文件共享服务/32-网络文件共享服务.html","title":"第三十二章 网络文件共享服务","keywords":"","body":"第三十二章 网络文件共享服务 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"32-网络文件共享服务/1-文件共享服务FTP01.html":{"url":"32-网络文件共享服务/1-文件共享服务FTP01.html","title":"第1节 文件共享服务FTP01","keywords":"","body":"第1节. 文件共享服务FTP01 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"32-网络文件共享服务/2-文件共享服务FTP02.html":{"url":"32-网络文件共享服务/2-文件共享服务FTP02.html","title":"第2节 文件共享服务FTP02","keywords":"","body":"第2节. 文件共享服务FTP02 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"32-网络文件共享服务/3-FTP常见配置和基于DB文件的虚拟用户.html":{"url":"32-网络文件共享服务/3-FTP常见配置和基于DB文件的虚拟用户.html","title":"第3节 FTP常见配置和基于DB文件的虚拟用户","keywords":"","body":"第3节. FTP常见配置和基于DB文件的虚拟用户 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"32-网络文件共享服务/4-基于mysql的FTP的虚拟用户和NFS服务介绍.html":{"url":"32-网络文件共享服务/4-基于mysql的FTP的虚拟用户和NFS服务介绍.html","title":"第4节 基于mysql的FTP的虚拟用户和NFS服务介绍","keywords":"","body":"第4节. 基于mysql的FTP的虚拟用户和NFS服务介绍 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"32-网络文件共享服务/5-基于NFS共享服务器.html":{"url":"32-网络文件共享服务/5-基于NFS共享服务器.html","title":"第5节 基于NFS共享服务器","keywords":"","body":"第5节. 基于NFS共享服务器 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"32-网络文件共享服务/6-NFS网络共享和自动挂载.html":{"url":"32-网络文件共享服务/6-NFS网络共享和自动挂载.html","title":"第6节 NFS网络共享和自动挂载","keywords":"","body":"第6节. NFS网络共享和自动挂载 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"32-网络文件共享服务/7-SAMBA共享服务实现01.html":{"url":"32-网络文件共享服务/7-SAMBA共享服务实现01.html","title":"第7节 SAMBA共享服务实现01","keywords":"","body":"第7节. SAMBA共享服务实现01 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"32-网络文件共享服务/8-SAMBA共享服务实现02.html":{"url":"32-网络文件共享服务/8-SAMBA共享服务实现02.html","title":"第8节 SAMBA共享服务实现02","keywords":"","body":"第8节. SAMBA共享服务实现02 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"32-网络文件共享服务/9-利用infotify和rsync服务实现实时同步.html":{"url":"32-网络文件共享服务/9-利用infotify和rsync服务实现实时同步.html","title":"第9节 利用infotify和rsync服务实现实时同步","keywords":"","body":"第9节. 利用infotify和rsync服务实现实时同步 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"33-linux防火墙/33-linux防火墙.html":{"url":"33-linux防火墙/33-linux防火墙.html","title":"第三十三章 linux防火墙","keywords":"","body":"第三十三章 linux防火墙 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"33-linux防火墙/1-linux防火墙基础.html":{"url":"33-linux防火墙/1-linux防火墙基础.html","title":"第1节 linux防火墙基础","keywords":"","body":"第1节. linux防火墙基础 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"33-linux防火墙/2-iptables防火墙实战.html":{"url":"33-linux防火墙/2-iptables防火墙实战.html","title":"第2节 iptables防火墙实战","keywords":"","body":"第2节. iptables防火墙实战 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"33-linux防火墙/3-iptables防火墙扩展模块实战.html":{"url":"33-linux防火墙/3-iptables防火墙扩展模块实战.html","title":"第3节 iptables防火墙扩展模块实战","keywords":"","body":"第3节. iptables防火墙扩展模块实战 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"33-linux防火墙/4-iptables防火墙扩展模块实战和策略优化.html":{"url":"33-linux防火墙/4-iptables防火墙扩展模块实战和策略优化.html","title":"第4节 iptables防火墙扩展模块实战和策略优化","keywords":"","body":"第4节. iptables防火墙扩展模块实战和策略优化 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"33-linux防火墙/5-网络防火墙和SNAT原理.html":{"url":"33-linux防火墙/5-网络防火墙和SNAT原理.html","title":"第5节 网络防火墙和SNAT原理","keywords":"","body":"第5节. 网络防火墙和SNAT原理 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"33-linux防火墙/6-网络防火墙DNAT实战和端口重定向.html":{"url":"33-linux防火墙/6-网络防火墙DNAT实战和端口重定向.html","title":"第6节 网络防火墙DNAT实战和端口重定向","keywords":"","body":"第6节. 网络防火墙DNAT实战和端口重定向 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"33-linux防火墙/7-firewalld新式防火墙实现.html":{"url":"33-linux防火墙/7-firewalld新式防火墙实现.html","title":"第7节 firewalld新式防火墙实现","keywords":"","body":"第7节. firewalld新式防火墙实现 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"33-linux防火墙/8-firewalld实现防火墙功能.html":{"url":"33-linux防火墙/8-firewalld实现防火墙功能.html","title":"第8节 firewalld实现防火墙功能","keywords":"","body":"第8节. firewalld实现防火墙功能 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"34-LinuxVirtualServer/34-LinuxVirtualServer.html":{"url":"34-LinuxVirtualServer/34-LinuxVirtualServer.html","title":"第三十四章 LinuxVirtualServer","keywords":"","body":"第三十四章 LinuxVirtualServer Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"34-LinuxVirtualServer/1-LVS工作原理和NAT模型.html":{"url":"34-LinuxVirtualServer/1-LVS工作原理和NAT模型.html","title":"第1节 LVS工作原理和NAT模型","keywords":"","body":"第1节. LVS工作原理和NAT模型 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"34-LinuxVirtualServer/2-LVS工作原理DR等三种模型.html":{"url":"34-LinuxVirtualServer/2-LVS工作原理DR等三种模型.html","title":"第2节 LVS工作原理DR等三种模型","keywords":"","body":"第2节. LVS工作原理DR等三种模型 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"34-LinuxVirtualServer/3-LVS和NAT模型实现.html":{"url":"34-LinuxVirtualServer/3-LVS和NAT模型实现.html","title":"第3节 LVS和NAT模型实现","keywords":"","body":"第3节. LVS和NAT模型实现 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"34-LinuxVirtualServer/4-LVS的DR模型实现.html":{"url":"34-LinuxVirtualServer/4-LVS的DR模型实现.html","title":"第4节 LVS的DR模型实现","keywords":"","body":"第4节. LVS的DR模型实现 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"34-LinuxVirtualServer/5-LVS跨网段DR模型和FWM多服务绑定.html":{"url":"34-LinuxVirtualServer/5-LVS跨网段DR模型和FWM多服务绑定.html","title":"第5节 LVS跨网段DR模型和FWM多服务绑定","keywords":"","body":"第5节. LVS跨网段DR模型和FWM多服务绑定 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"34-LinuxVirtualServer/6-LVS实现健康性检查功能.html":{"url":"34-LinuxVirtualServer/6-LVS实现健康性检查功能.html","title":"第6节 LVS实现健康性检查功能","keywords":"","body":"第6节. LVS实现健康性检查功能 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"34-LinuxVirtualServer/7-keepalived实现高可用性原理介绍.html":{"url":"34-LinuxVirtualServer/7-keepalived实现高可用性原理介绍.html","title":"第7节 keepalived实现高可用性原理介绍","keywords":"","body":"第7节. keepalived实现高可用性原理介绍 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"35-高可用集群keepalived/35-高可用集群keepalived.html":{"url":"35-高可用集群keepalived/35-高可用集群keepalived.html","title":"第三十五章 高可用集群keepalived","keywords":"","body":"第三十五章 高可用集群keepalived Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"35-高可用集群keepalived/1-keepalived实现浮动的VIP.html":{"url":"35-高可用集群keepalived/1-keepalived实现浮动的VIP.html","title":"第1节 keepalived实现浮动的VIP","keywords":"","body":"第1节. keepalived实现浮动的VIP Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"35-高可用集群keepalived/2-keepalive实现LVS的高可用性.html":{"url":"35-高可用集群keepalived/2-keepalive实现LVS的高可用性.html","title":"第2节 keepalive实现LVS的高可用性","keywords":"","body":"第2节. keepalive实现LVS的高可用性 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"36-高性能WEB服务nginx01/36-高性能WEB服务nginx01.html":{"url":"36-高性能WEB服务nginx01/36-高性能WEB服务nginx01.html","title":"第三十六章 高性能WEB服务nginx01","keywords":"","body":"第三十六章 高性能WEB服务nginx01 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"36-高性能WEB服务nginx01/1-IO五种模型和select与epoll工作原理.html":{"url":"36-高性能WEB服务nginx01/1-IO五种模型和select与epoll工作原理.html","title":"第1节 IO五种模型和select与epoll工作原理","keywords":"","body":"第1节. IO五种模型和select与epoll工作原理 apache用的模型，nginx都没用 不管多少核，如果负载超过5就算高了--一般是这么认为？ 再次了解下PIO和DMA，也就是CPU不再参与大量I/O的处理。 PIP模型-数据复制是走CPU的，也就是CPU参与I/O DMA模型：就是CPU只发送指令控制命令--比如disk复制数据到MEM里，执行者是DMA专用硬件(正在干活的设备)。真正的数据是不走CPU走的。 所以现在基本上，CPU都是不参与I/O。 图中圈圈就是DMA来完成copy的。硬件之间的一个数据传递。 3.copy从内核到用户空间就不是DMA来实现的，而是CPU完成的，从整个角度来讲CPU其实是参与I/O了咯。不对，都在整个大的内存空间里，DMA不参与，然后CPU参与的其实也不算I/O吧应该是。 ①I/O是DMA完成，CPU就是下发一个控制指令 ②内核和用户空间的数据交互，是CPU完成的 ③I/O，是外界设备，比如网卡、磁盘，这些和内存里的内核空间交互 ④内存里有内核空间和用户空间 ⑤内核里还有socket Buffer和 内核Buffer ⑥网卡将数据送给内核buffer ⑦socket buffer将数据送给网卡 以上是一些关键点，然后再结合看下👇图 看图说话： 1、数据发起：client 网络请求发给网卡 2、数据流转：网卡将数据复制到内存里的内核缓冲区-DMA技术 3、数据流转：内核缓冲区将数据复制到用户空间-CPU转发，用户空间将数据交给应用程序 4、数据处理：应用程序开始处理数据，根据HTTP的请求，比如GET，去所需磁盘上拿数据则👇 5、数据处理：应用程序不能直接和硬盘打交道，通过system call调用内核去访问磁盘上的数据 6、数据处理：数据从磁盘复制到内核缓冲区-DMA技术，再复制到用户空间交还给应用程序-CPU转发。 7、数据处理：应用程序构建HTTP响应报文，head+DATA之类， 8、数据流转：构建完毕后数据复制到内存里的socket buffer中。 9、数据流转：socket buffer再将数据复制到网卡中 10、数据流转：网卡再将数据发给用户。 什么，我上面有些不应叫数据处理，应该叫流传，好的，你赢了。 11、数据流转：sendFile技术减少了一部分的交换过程，好像有的吹牛逼叫 \"零复制\" 技术，其实还有一个内核缓冲区->复制到->socket buffer里的一个复制过程。 12、可能nginx还有其他 \"零复制\"技术，不仅仅是sendFile技术。 I/O表现为：磁盘I/O和网络I/O，都表现为文件的读取，磁盘I/O就是表现为磁盘上的文件好理解；而网络I/O其实就是socket文件的读取。 I/O: 网络IO：本质是socket文件读取 磁盘IO： 每次IO，都要经由两个阶段： 第一步，DMA完成转发：将数据从文件先加载至内核内存空间（缓冲区），等待数据准备完 成，时间较长，因为要读磁盘，要寻址的。 第二步，CPU完成转发的都在内存中交互的：将数据从内核缓冲区复制到用户空间的进程的内存中，时间较短 I/O模型 要了解I/O模型-据说很复杂的-内核来实现的，就要先了解两个概念①同步/异步②阻塞/非阻塞 同步/异步： 1、这个在mysql里说的是另一回事，是主从复制的同步/半同步/异步。 2、在数据传输的时候，说的是类似军队过桥，步伐整齐划一-危险；和乱步走-安全。落实到数据传输就是 数据传输的同步和异步是两种不同的方式。同步传输是指发送端和接收端的时钟同步，数据按照一定速率和时序进行传输，保证数据的顺序和完整性。异步传输则是指没有时钟同步，数据按照不规则的速率和时序传输，需要使用特殊的控制字符来标识数据的开头和结尾。 ​ 然后L2帧结构就有前导码，这个就是数据传输里的异步模式 3、在I/O里的同步异步，上图可能讲的不太到位。同步：调用者等待被调用者的返回结果，才会继续执行原本程序的后面内容；异步：调用者不等待被调用者的返回结果就去执行原本程序的后面内容，等被调用者什么时候通知调用者，那个时候再处理这个返回结果。一般来讲要和阻塞和非阻塞联系起来讲的，不过...继续往下学吧。 ​ 上图PPT应该是对的，同步和异步就指的是消息通信机制，不要和阻塞和非阻塞联系起来，要联系，但是分开来理解，也要联系起来理解。 ​ 同步：就是调用者--一般就是程序本身啦，要等到被调用者--一般就是函数，的数据结果。是直接坐等DATA数据结果。是你等到包裹投递到手上 。 同步+非阻塞 就是 等-不断去问，不还是啥也干不了吗，动不动就去问，能干别的事？还不是等价于同步+阻塞了嘛。 ​ 也可以理解成：是你在接空中的泡泡落到手上。①手一直摆着接的姿势，此乃阻塞②手会放下，一会抬头看下有泡泡来了就抬手接，所以抬头频率满了会借不到，抬头频率快了也不好，其他事就干不了了，此乃非阻塞。 ​ 异步：调用者不是等被调用者的返回数据结果，而是被调用者主动告知调用者结果来了。是被调用者喊过去拿到DATA数据结果。是你等到了门卫喊你取快递。 同样分为异步+阻塞 ：有人来喊你取快递你还在那边干等着 和 异步+非阻塞：有人喊你取快递，你去忙别的。 ​ 所以有没有喊你这个动作就是同步/异步的区分。正是因为同步/异步的情况才需要阻塞和非阻塞的存在。 ​ 调用者-应用程序；被调用者-内核。阻塞和非阻塞其实就是调用者还是被调用者谁多干活的问题，谁更忙。你希望谁更忙？在nginx服务中，nginx应用程序和内核，谁更忙好一些，nginx提供服务，使用非阻塞将活交给内核处理，自己本身可以面向更多的用户提供服务，支持更多的人高并发访问。 4、其实还有mysql的logbuffer的机制innodb_flush_log_at_trx_commit，也可以理解成同步机制，同步动作存在于内存(logbuffer/osCache/)和磁盘(logFile)。 5、其实还有ext3日志的写法也是同步概念，同步动作存在于log文件和磁盘文件。 但是4、5不要真的划进去，否则概念界限不清混为一谈反而不美。 阻塞I/O模型 思考一个问题：apache为什么解决不了C10K的问题？而nginx可以，这些就涉及底层的工作原理。 recvForm所属的位置：就是一种SYSTEMCALL，通过调用内核来对接Ip+port套接字，来接收数据的，也是应用程序面向身后内核缓冲区进而取数据的接口。 同步非阻塞I/O模型 非阻塞I/O模型其实就是，同步+非阻塞的方式，简单讲就是，调用者不断去问被调用者 如上图👆 I/O多路复用模型 应用程序调用select函数(这是系统调用)，很多访问请求过来，应用程并发调用多个select函数，通过这个函数进而访问内核。 应用程序接收很多访问请求进来，上图app1\\app2\\app3也许理解为一个app的多个并发请求为好？ 应用程序要处理请求，要回包就要构建响应报文，要构建，就要获取响应数据，要获取响应数据就要到磁盘上取，而app不能直接访问磁盘这些硬件，需要通过系统调用systemcall去访问磁盘 这里通过select这个系统调用函数去访问内核，通过内核去访问磁盘，取到数据，当数据取到后就返回\"可读条件\"信号给到recvfrom函数，该函数是面向ip+port用户socket的，它就会将数据从内核空间里复制到用户空间完成响应报文构建进而回给 内核里的socket buffer，再有buffer交给网卡。 返回可读条件 说明有提醒消息有人喊你取快递的，就是异步了。但是该模型受限于select IO多路复用（IO Multiplexing) ：是一种机制，程序注册一组socket文件描述符 给操作系统，表示“我要监视这些fd是否有IO事件发生，有了就告诉程序处理” IO多路复用是要和NIO(Not Blocking IO)一起使用的。NIO和IO多路复用是相对独立的。NIO仅仅 是指IO API总是能立刻返回，不会被Blocking；而IO多路复用仅仅是操作系统提 供的一种便利的通知机制(就是异步了)。操作系统并不会强制这俩必须得一起用，可以只用IO 多路复用 + BIO，这时还是当前线程被卡住。IO多路复用和NIO是要配合一起使 用才有实际意义 # 理解这段话，抓住IO多路复用就是有通知就是异步，BIO和NIO就是程序调用函数后阻塞在那。 IO多路复用是指内核一旦发现进程指定的一个或者多个IO条件准备读取，就通知该进程。 # 这不就是异步咯，只不过就是优化升级的异步通知。 多个连接共用一个等待机制，本模型(#这里应该加一个IO多路复用+NIO)会阻塞进程，但是进程是阻塞在select或者poll这两个系统调用上，而不是阻塞在真正的IO操作上。 用户首先将需要进行IO操作添加到select中，同时等待select系统调用返回。当数据到达时，IO被激活，select函数返回。用户线程正式发起read请求，读取数据 并继续执行 阻塞发生点：select调用、poll调用、数据从内核复制到用户空间的过程 信号驱动I/O模型 异步I/O模型 这个就是全程不阻塞了。 总结：五种I/O模型 wait for data👇① 和 copy data 👇② I/O模型的具体实现 说apache并发1W差不多了，为什么达不到C10K，而nginx可以2-3W都没问题，可以就可以在select、poll、epool三种方式上。 遍历就是 数组(linux里数组是列表/字典的统一称呼，列表其实就是下表是1 2 3...的字典） 的一个遍历。 IO效率，拿select举例，就是select遍历操作的时间复杂度O(n)--随着资源越多性能越差，是线性规律。 epoll不是遍历方式，而是回调。IO效率不变都是O(1)。 select存在最大连接数：X86是1024 和 X64是2048 ，这是内核里的自带的FD_SETSIZE就是一个进程最多打开的文件数目，如何在内核文件里找到这个FD_SETSIZE这个文件 wget https://cdn.kernel.org/pub/linux/kernel/v6.x/linux-6.5.8.tar.xz tar xvf linux-6.5.8.tar.xz > /dev/null cd linux-6.5.8 find linux-x.x.x/ -type f |xargs grep \"FD_SETSIZE\" epoll最优秀，nginx用的就epoll 水平触发LT、边缘触发ET 如果一个文件描述符fd变成就绪态了--比如上面有数据了-比如socket收到一个网络请求这就是fd文件里有数据了。此时就会告知进程哪些fd刚刚变成了就绪态，ET边缘触发就是通知一次；LT水平触发就是通知多次。 LT和ET都是IO多路复用的两种模式，LT模式下，当一个文件描述符就绪时会一直通知进程，直到该文件描述符被处理；ET模式下，当一个文件描述符就绪时只会通知一次，需要进程自己保证及时处理。LT模式下可能会导致进程不断地被唤醒，而ET模式则可以减少系统调用次数，提高效率。 零拷贝 mmap技术，是epoll的技术，一般也可以将epoll理解成select和poll的增强版。 mmap也算是一种 零拷贝 技术，之前学过一个sendfile技术。 原始数据复制操作 图中copy过程是DMA完成的👇也不是，是copy下半截-从kernel到hardware才是DMA的活，上半截从用户空间到kernel是CPU的活。当然下半截CPU也是发送了控制指令的，干活还是DMA来做的。 有个问题，之前学到就是网卡将数据复制道Kernel缓存里；socket缓存将数据复制到网卡里。不知道是不是这样的。。。所以上图的箭头都是单向的。还需要补上磁盘文件活网络适配器到kernel缓存的箭头咯。 会导致，数据包在用户态和内核态 频繁复制， SENDFILE也是一种零复制技术 apache和nginx都支持该技术👇 但是有些场景下sendfile是不推荐的，是不合理的，比如上图的磁盘文件不是本地磁盘，而是NFS挂载过来的，此时就不要用sendfile技术。 NFS挂载过来本质上还是走的网络，按这个说法，不就是一样可以用sendfile嘛，还是说要走过用户空间过一遍NFS协议才能解开数据包？可能是的，也许是这个原因就不能用sendfile了。 MMAP：Memory Mapping也是零复制技术 映射过来，省去了内核空间和用户空间的数据复制，但是我觉得只是不走文件复制，物理层面还是要走用户空间和内核空间之间的连接的吧，只不过这个连接在都在整个内存里，具体的表现形式是什么？ 上图的CPU-COPY是从内核缓存复制到socket缓存，这里将的复制可能正如GPT所说不是文件系统层面的复制，所以要节省很多开销。 DMA辅助的SENDFILE 因为是内存和硬件网卡的交互，所以是DMA来sendfile了。 然后这种技术是需要硬件支持的，不具备通用性可能。 mmap和sendfile是软件级别的，更加具备通用性。 总结，nginx采用的是epoll，apache使用的是select，所以性能nginx更好，不过要去官网求证一下 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-10-26 13:37:06 "},"36-高性能WEB服务nginx01/2-nginx编译安装和功能介绍.html":{"url":"36-高性能WEB服务nginx01/2-nginx编译安装和功能介绍.html","title":"第2节 nginx编译安装和功能介绍","keywords":"","body":"第2节. nginx编译安装和功能介绍 nginx介绍 http://nginx.org UDP的反代貌似可以用来做内网的DNS负载。 1、场景：用户从两个出口出去，奇数、偶数，分配到不同的出口。但存在奇数和偶数出口对调的情形。 2、DNS：DNS1和DNS2自然也是奇数偶数配置，就等价于两个线路的用户，自然也是和用户一致。 3、1 和 2 就保证了奇数用户有一个DNS1奇数的IP；偶数用户就有一个偶数的DNS2。 4、此时真正需要干的活就只有(上面的都不需要做啥，默认就有了顶多配置飞塔的ECMP基于源IP出去，和两个DNS服务器)；就只有将奇数用户的DNS请求转发到DNS1，将偶数DNS的请求转发到DNS2 5、此类需求之前通过BIND可以实现，但是BIND的负载LB实在太LOW了--因为不支持reg正则表达式，所以无法支持辣么多的IP的奇偶区分，纯手工嘛！我出家吧~哈哈，所以这个需求是否在nginx这里能够得到圆满的解决呢，拭目以待... nginx的server字段里竟然不是nginx，volt-adc又是啥？nginx.org看看 http://tengine.taobao.org/ http://openresty.org/ 都是自家用自家的啊，哈哈 据说追求极致性能的网站可能用这个openresy软件，官网的性能测试可以达到2W。 事件驱动event-driven、异步IO(aio)、mmap和sendfile apache那会也学习过事件驱动模型，就是多进程里开多线程，线程里有监管和工作线程。 上一篇讲nginx用的是epoll--具有信号驱动I/O模型的一些特点，然后这里又提到aio(异步IO)，问问GPT：👇 模块化设计，较好的扩展性 一般就是编译的时候做加减，编译好以后，不对啊，apache好像是可以灵活安装的。当然具体安装可不是简单地在配置文件里补一行就行了的，卸载模块倒是可以注释掉。 模块如果已经安装，那么加载/卸载就可以👆去到配置文件里打开/注释。 模块如果没有安装，就需要安装的 支持热部署：不停机更新配置文件、升级版本、更换日志文件 nginx软件升级的时候，用户连接挂着老版本，等用户所有连接访问自然结束自行断开后，就会去连新版本进行业务访问了，所有用户都切到新版本后，老版本的进程就销毁了。 ​ 是不是可以换个说法👇 nginx软件升级的时候，存在新旧两个版本同时对外服务、以及很多当前的\"连接\"和请求。连接挂着旧版本的不受影响，新请求则使用新版本去服务。等所有\"旧版本连接\"也就是用户访问结束后，新的连接就转到新版本上去了。等所有旧版本的连接都断开了，就销毁旧版本的进程了。 # 这就是平滑升级了，也可以算到业务层面的一个平滑切换。 # 平滑机1 如果又HA切换的内容就打上 平滑机标签 那会不会存在 用户A的一个浏览器里多个页面访问着新旧两个版本的nginx呢，或者一个页面先后访问了两个版本的nginx呢，其实这个可以测试的后面学到了通过实际测试可以看到，也要通过curl -I xxx去看一下。 不过实际工作中好像是这种，LB后面多个的机器，然后将一台机器下线(其上用户就断开重连并调度到其他机器上去)；然后对其升级，升级后再加入调度，观察用户； 然后就如法炮制一台台升级，仅升级一部分比如说一半的机器，继续观察业务，稳定后全部升级。 # 平滑机2 低内存消耗： 10000个keep-alive连接模式下的非活动连接，仅需2.5M内存。 非活动连接：就是连上来了，但是没有数据传输。这个类似AP可以带多少个用户一样，256个其实是非活动用户。 LVS调度算法里有一种计算最短连接，非活动连接/活动连接 比例达到256。也就是一个活动连接对资源的消耗相当于256个非活动连接。这个点我后面整理LVS的时候注意下我是从apache跳过LVS直接看nginx的。 所以nginx可以用epoll来维持上万个连接--非活动连接？，有数据请求过来了--有数据传递了？-从活动连接变成非活动连接？，epoll才会激活服务。 # 其实就是apache里学的mpm event模型类似吧。 nginx架构 一个主进程+若干个工作进程 一个worker进程，利用epoll监控上万的连接 worker可以对接支持：web服务器，应用程序服务(比如PHP FPM 独立服务监听9000端口)，还支持memcached（提供会话信息，类似redis）,但是没有提到对接redis，将来对接redis如果不能直接对接，也可以通过应用程序来间接对接。比如PHP这个应用程序里面装redis插件模块。session和应用程序相关，让应用程序对接就行了。 作为nginx来讲不需要太多关注应用程序来做的事，apache可能会多做一点类似应用程序要做的事。 nginx通过fastCGI来对接应用程序，而应用程序再去对接session的问题。 proxyCache，就是说nginx支持反向代理的同时也支持缓存。不需要跑到后端服务器上拿数据，直接交给用户就行了。 master管理workers的，load conf，激活woker，no-top update不间断升级。 master复制监听端口，监管worker进程，worker进程负责处理用户请求。woker进程是以普通用户的身份来启动的。master进程应该是以root身份启动的。这一点和apache一样 好像有个一个说法：只有root超级用户才能创建1024以内的监听端口，好像我之前验证过这个说法在rocky-linux里不存在了。 不支持DSO就要编译 worker一般随CPU内核数，几个cpu就配置几个worker。 nginx模块从1.9.11开始支持DSO，分为 安装自带的模型模块、标准模块-人工加载的、和三方模块 标准模块也分为 HTTP、邮件、stream模块 stream是TCP的反代，一般来讲HAproxy和LVS在这方面用的多一些，nginx后来才支持，应该也还行的。 可能nginx用的最多就是http的反代、fastCGI的反代较多一些。 说是重点掌握前三个，其实tcp/udp对我来讲才是重点，或者叫情怀，反正比iptables DNAT用起来更舒服，也更加适合给应用运维用或者和他们沟通。还据：说什么LVS做TCP/UDP代理性能更好，HAPROXY做TCP/UDP代理功能更强。好吧~ fastCGI桥接PHP等众多语言的APP、uWSGI是python做的网站(比如django做的网站、flask做的网站)、 https://zhuanlan.zhihu.com/p/354037327 👈简单了解下 WSGI 的官方定义是，the Python Web Server Gateway Interface 源码包； 预编译包-就是yum类的安装 上图的baseurl可以尝试打开看看的，$releasever 就是自己的centos版本，我的是rocky-linux就用centos就行了，然后$basearch就是x86_64架构，也可以缩到前面看整体的 版本也是对的 关掉最新的nginx.repo源，再info看下 可见nginx是在epel源里的，然后是版本也还行。 也可以编译安装，这个用的也很多 简单了解下👇 编译安装实例：👇，与上面的略有区别什么log估计用的就是默认的路径，而模块多了一些。 useradd -r -s /sbin/nologin nginx ./configure --prefix=/apps/nginx \\ --user=nginx \\ --group=nginx \\ --with-http_ssl_module \\ --with-http_v2_module \\ --with-http_realip_module \\ --with-http_stub_status_module \\ --with-http_gzip_static_module \\ --with-pcre \\ --with-stream \\ --with-stream_ssl_module \\ --with-stream_realip_module make && make install chown nginx.nginx -R /apps/nginx/ 我这边就用官方的yum源安装1.24.0的了，老规矩yum 后rpm看看 nginx不像apache一样，rpm -ql一看一堆模块，nginx的模块都是直接打包到nginx主程序里了。 虽然也有modules文件夹，但是其实是空的 那么问题来了，DSO这种从1.9.11开始支持的模块都在哪里编辑，从而支持安装卸载的呢？可能就是这里，只不过这里目前是空的而已。 systemctl start nginx后(要保证80没有被占用)，修改一下主页面的内容，无需重启，无需reload， 据说高手不用systemctl启动，哦，牛逼，高手一般怎么弄啊，高手用主程序二进制启动👇恩，真牛逼，受不了。 而且nginx这个启动后默认就是后台启动的。 nginx源码编译的时候到底加了哪些选项或者模块 你yum也是yum的人家源码编译好的啊，所该段标题描述没毛病。 nginx和httpd检测配置文件的语法 所以好习惯就是，①先检查(nginx -t检查，人眼检查)②再重启服务，你要知道原来服务启动的着，你重启如果起不来影响就大了，原来只是重启一下也就是1秒不到的时间，现在就不止咯。 nginx -T应该是整合所有的conf文件并检查配置，不仅仅是主配置文件里的内容了 差了8行，哈哈，减去2行测试，就是6行，没找到~ 找到了，就是nginx -T的两个作用①除了测试所有配置文件以外和-t小t一样的作用②还可以合并所有配置文件，并且在模块开头会注释写明调用的哪个模块，一共6行咯。 源码编译安装 也用稳定版 curl -O https://nginx.org/download/nginx-1.24.0.tar.gz tar -xvf nginx-1.24.0.tar.gz yum install gcc pcre-devel openssl-devel zlib-devel useradd -r -s /sbin/nologin nginx # 这里有个说法：就是最好统一id，便于管理，比如用户通过nginx上传资源到后端NFS服务器，如果ID不统一，可能权限出问题？不懂！估计具体问题遇到再看了，emmm。。。 cd nginx-1.24.0 ./configure --prefix=/apps/nginx \\ --user=nginx \\ --group=nginx \\ --with-http_ssl_module \\ --with-http_v2_module \\ --with-http_realip_module \\ --with-http_stub_status_module \\ --with-http_gzip_static_module \\ --with-pcre \\ --with-stream \\ --with-stream_ssl_module \\ --with-stream_realip_module echo $? # 看下是不是0也就是true，表示configure OK make && make install # make -j xcpu个数x && make install echo $? chown nginx.nginx -R /apps/nginx/ # 这条不用加，默认编译安装后自动修改所有者的，除非全是root。 ll /apps/nginx/ # 看看 tree /apps/nginx/ ln -s /apps/sbin/nginx /usr/sbin/nginx #就一个二进制文件，所以直接软连接就行了 vim /etc/rc.d/rc.local /usr/sbin/nginx chmod +x /etc/rc.d/rc.local 就一个二进制文件，没必要加PATH变量了，如果是一堆bin文件可以添加PATH，如果是一个就ln -s xx就行了 开机启动👇简单处理，如果要用service可以复制一个yum安装的service文件改改。 修改主页面 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-10-30 15:50:41 "},"36-高性能WEB服务nginx01/3-nginx全局配置和性能优化.html":{"url":"36-高性能WEB服务nginx01/3-nginx全局配置和性能优化.html","title":"第3节 nginx全局配置和性能优化","keywords":"","body":"第3节. nginx全局配置和性能优化 nginx的配置文件 nginx的配置 上面一段是全局配置，包括，nginx软件以谁的身份来运行，worker进程是几个， 下面的http打头的段，是泛指http，包括http，已经fastCGI-这个其实不是http但是是web服务也和http相关，所以也放在这里；但是后面做tcp的反代后单独块了不在http块里了。 然后语句里面还有嵌套，就是类似字典里还有字典。不同的指令只能出现在不同的语句块中。 比如上图👆的sendfile on，能够出现在什么语句块里，就需要通过官网来了解 然后配置文件，好习惯其实就是规范配置，是一个网站一个配置文件独立存放的，不是堆在一个主配置文件里的。 yum 安装的 nginx的主配置文件还是有点东西的👇 编译安装的主配置文件好像少了的意思👇 cd /apps/nginx/conf mkdir conf.d 稍后配置文件都放到这个conf.d里 总结PPT ​ 看上图👆default默认user就是叫nobody的这个用户，结果编译安装的时候ps auxf看到的是nginx用户，原因就是编译的时候指定了用户了 看看yum安装的 看看PID的路径 yum 安装的 我在想，编译安装的是不是都写到conf里了，应该不是，否则conf不可能那么短的 然后就是conf应该优先于nginx -V看到的配置选项咯，实验过了，是的。 include包含的文件 load_module 模块加载文件 下面看看和性能相关的配置 worker进程数一般推荐和cpu核数一样，不过这也是默认的行为 auto意味着自动根据CPU核数来配置 实验的时候：新增CPU后，保证worker_processes为auto后，nginx -s reload如果nginx的worker进程数没有上来，就需要nginx -s stop 和 nginx，重启生效了。 CPU有L1 L2 L3三级缓存 lscpu可见，L3缓存时所有CPU共享的，L1和L2是针对一个CPU来讲的。 L1有指令缓存和数据缓存 看下跑在哪个CPU上，也就是nginx应用程序和CPU的绑定关系 先看下前面的内容，反正学习的过程中如果存疑，①搜前文②GPT③谷歌 前文关于L1 L2 L3 的说明和如何查看和绑定进程到CPU，当然nginx应该有自己的方式 继续看nginx的worker进程和cpu的关系，然后进一步做cpu绑定。为什么要绑，也不是一定要绑，就是绑了以后L1 L2这两个缓存本来就是CPU专用的，CPU一飘，L1L2的缓存内容就用不了了，所以从找个角度考虑，是需要绑的。 ps axo pid,cmd,psr 目前四个worker运行的CPU情况如下👇 使用ab并发请求，观察是否存在cpu飘的情况：注意ab测试的url要带上http以及最后的/斜杠。 果然cpu开始飘了 下面就绑一下worker进程到各个cpu吧 worker_cpu_affinity 00000001 00000010 00000100 00001000 # 假设有8个cpu，4个worker就这么些 worker_cpu_affinity 0101 1010 # 就是worker2个进程，worker1绑在cpu0和cpu3上；worker2进程绑在cpu1和cpu3上。 有几个cpu，就些几个bit，比如00000000代表第0个CPU，00000001代表第1个CPU。从0计数 我是4核就这么写👇，注意结尾的分号要写的。 这样就worker1绑在cpu0，worker2绑在cpu1，worker3绑在cpu2，worker4绑在cpu3了👇，再次使用ab压力测试，发现此时CPU不飘了就。L1 L2 利用率就上来了，否则CPU一瓢1 2两级缓存就没了。 不过只是warn告警，服务不会停掉，只是绑CPU可能有点问题。 绑定OK后，CPU0就绑在worker1上，CPU1绑在了worker2上，但是不是说CPU0就只能为nginx服务，还可以被别的应用程序使用的。 worker进程的优先级nice ps axo pid,cmd,nice worker的优先级 官网写错了 就算写1000最大也就19(也就是最低优先级是19) worker进程打开fd数要和ulimit一致 看下系统内核本身的fd并发限制--是单进程打开文件的限制 虽然nginx就开了4个worker线程， 但是一个worker就能应对大量并发号称无上限，因为使用的是epoll模型，所ab高并发测试的时候响应灰常快。 永久调整ulimit的值 系统里调整 PAM文件和security文件看看 nginx里调整 在nginx里直接修改配置文件就行 1、所有worker进程总的并发数 2、每个worker进程的并发数 use mothod 不用指定，默认就是epoll应该也是最好的方式了。也不一定如果是nginx跑在linux上默认就是epoll，如果跑在windows上默认就是select。官方就是说默认使用最有效的方式，应该是这么理解的了。 上图👆得到的并发上限是多大，假设它的硬件资源是OK的，1024是一个worker线程的并发数，auto就看lscpu里几个，如果是4核，那么1024*4=4096的并发数。 一般nginx作为web服务器3W基本到顶了，比apache强也不是说没有上限的。apache一般提到的C10K也就是1W咯。 accept_mutex 默认on不会惊群 虽说accept_mutex on是一种优化，不过EPOLL也不需要这种优化。。。感觉最好还是改成on。 mutl_accept默认是off的，如果on，并发就更强了，不知道是否推荐打开。 然后图中写明了事件驱动相关的配置，说明配置的语句块是在event里的，具体官网可查确实是events里配置 然后multi_accept针对kqueue是无用的，kqueue是和epoll和select对等的机制 所以MAC用户如果本地测试可能就要小心了。存在连接处理机制的不同。 调试和定位 nginx命令一敲默认就是后台运行，是通过daemon来配置的off就是前台运行了 master_process on; 就是以master和多个worker进程的方式来运行，off就是只有一个单进程了也就是master。 error_log file，里面除了error日志，还可以带上debug(但是要nginx -V |& grep with-debug 有东西才行，说明编译的时候开启了debug，配置文件里无法打开debug只能编译里启用。)，就好比msyql的慢查询日志里面还可以带上是否用索引的日志。 上图是实测结论，下图是找到的官方依据 就是相对路，相对于--prefix=/apps/nginx/的，所以结论是对的。 还有关于access_log，关注一下关键词combined，这个在httpd里也是出现过的，代表着log的格式， 同样按此思路去找一找nginx的combined的格式定义在哪里的。 默认的log_format就是combined，然后combined的格式如下👇 不管什么日志，access_log也好，error_log也罢，都是要分开来，跟server语句块走的，就是虚拟主机的log各自分开来。 nginix到现在接触到的优化点: worker_process(线程数跟CPU走) worker_cpu_affinity(cpu亲缘性绑定) woker_connecctions(单worker的并发数) 还有log放到server块里。 还有👇 accept_mutex on; # 就是防止惊群效应。 multi_accept on; # 每个worker线程可以同时接收所有新的网络连接 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-12-19 11:01:01 "},"36-高性能WEB服务nginx01/4-nginx实现web服务器01.html":{"url":"36-高性能WEB服务nginx01/4-nginx实现web服务器01.html","title":"第4节 nginx实现web服务器01","keywords":"","body":"第4节. nginx实现web服务器01 nginx的http的语句块配置 主要是ngx_http_core_module这个模块 MIME参考文档： https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Basics_of_HTTP/MIME_Types 不写include，就写type同样放到http语句块下 default_type是有默认值的 但是通常yum和编译都会给你改成 这个，这个就是除了明确的类型以为，浏览器不能识别了就，此时统统提示下载。 测试下default_type application/octet-stream的效果 如果是无痕模式的浏览器，会直接弹 另存为 的对话框，也是下载的动作。 通过curl 看看头部 curl 不加-I 貌似还是直接以文本打开了就 注释掉使其使用默认的text/plain格式 看下php文件的识别 默认就是不支持的 写一个php文件来实验 由于不支持.php所以打开该URL默认就是下载该文件的，对比之前apache的效果，我有两个apache①个yum安装②一个编译安装，其实不管是yum还是编译都不支持php文件的浏览器直接打开，只不过yum安装的apache，后来又yum安装了php，于是 这就找到了cli的出处啦，正式因为yum install php才有了httpd配置文件里的哪个php.conf且放在了conf.d下，才有了httpd浏览器打开了php文件。所以，以此类推现在nginx也要这么搞一下。 但是我现在的nginx是编译安装的，所以我需要尝试蒋这个php.conf复制到编译的路径下 没用php里的ngnix关键字的文件里都没有text/html .php之类的字眼，简单网速搜了下nginx对php的支持不想apache一样简单。具体操作参见以下教程👇 https://blog.51cto.com/928004321/1744675 https://www.php.cn/faq/476519.html tcp_nodelay on; 可优化报文确认频次，提高传输效率 据说是当 数据报文比较大的时候拆包传输了就，此时就一下发好几个包，然后再确认一次就比较合理了。 其实数据报文小的时候不涉及拆包，同样也能提高效率，只是数据量小，资源消耗小，系统也好硬件也罢能对付得了，数据量大的时候资源消耗大了，此时就会从各个方面优化，才需要tcp_nodely on多包确认一次。 tcp_nopush on; 可优化报文合并提高，提高传输效率 默认是off不显示的 也可以利用\"include conf.d/*.conf\"去单开一个文件，我理解就是include是在这个语句块也就是这个缩进层级下的，所以新建的xxx.conf里的内容也只反映到这个语句块层级下的。 只是个显示而已。 server_tokens on|off|build|string; string是商业版的nginx才支持的。 build参数就不是简单修改了的， 所以build是编译的时候，通过--build=xx.xxx.v1001，然后配置文件里写server_tokens build;才会有效果的。 或者修改源码文件里的关键字段；server_tokens on或者off都能改，改的地方不同👇 server_tokens on;修改👇 改成： server_tokens off;修改👇 改成： 当然改完还需要重新编译了 那么就重新变一下看看 编译之前看下二进制主程序的哈希值 担心软连接的哈希，确认下，不是哦，就是源文件的哈希 开始编译，ctrl+r调出历史命令回车就行👇 那个此时之前的nginx服务还在，不会停，因为你用的之前的nginx二进制启动的服务，你重新编译其实也就是对这个二进制进行变化吧，所以之前已经启动了的服务不受影响，服务程序继续对外提供服务。 此时想用nginx -s reload看到效果是不可能的，因为我们修改的/apps/nginx/sbin/nginx二进制程序里的东西，不是配置文件，所以需要重启服务后才能看到效果 然后修改server_token为on，reload配置文件就可以看到效果了👇 server在很多模块里都有 下面梳理core模块里的server server就是虚拟主机 listen PORT|address[:port]|unix:/PATH/TO/SOCKET_FILE listen可以写port、ip+port、unix套接字的路径。但是写unix socket就只能本机访问了。 default_server：默认虚拟主机，就是没有命中的统统用这个虚拟主机来响应，这里在apache里是不用设置，拍最前面的virtualHost就是默认的。 配置server实验 默认的不用动，利用include xx/xx/conf.d/*.conf写到独立的配置文件里去 默认的页面路径yum安装的话在/usr/share/nginx/html/下，新建两个到/data下 新建配置文件，listen不写默认就是80 做一下dns解析，dns的意义①，否则域名无法翻译成IP，无法在网络中寻址路由可达，②同时请求的域名也会写道http头里的host字段里，作为nginx处理转到具体虚拟server的依据--server_name。 如果访问的站点不命中server字段，那么就是走的default_server了。而默认主配置文件里好像也没有明确配置default_server，所以按他说法就是第一个，而主配置文件里没有server，就去conf.d/下找第一个文件里的server👇 人为修改为site2为default_server 修改一下配置文件的名称，把default.conf拍到第一个去 然后设置site.conf里的site2为默认server 主机头也就是server_name可以多个用空格分隔 listen ip :port 和server_name就等价于apache里的虚拟主机ip:port和servername。匹配逻辑可预见的一样 还是先看ip和port，如果ip和port一样再看servername。 匹配不中的，自然就默认走default_server，即使没有配置default_server，其实也是存在的，就是第一个server。 匹配顺序：精确>通配符(左>右)>正则>default_server root页面路径 location 没有定义location的时候，所有的访问url都是server下的root路径下的目录。 用了location可以单独将某个url指向别的不再root下的路径。 而看起来location的值也不一定必须是一个目录，试试文件：结论👆上面test是文件夹所以curl的时候test/不带/就报错，带上/就表示test/index.html；👇下面test是文件，所以curl的时候test带上/就报错，不带就是文件处理了，呵呵烦死了。 就有点搞啊 test是出于url的中间位置的，应是location的匹配规则中的一种。 上图301挺神奇的，好像目录不带/就会报301， 既然是301那么加上-L就行了 为什么会这样，官方也给出了解释 location的路径拼接👇 这个等于，其实就是除去fqdn对应的root，www.site1.com去掉就行了，如果等于location里的path，那么www.site1.com就对应到/opt/testdir/ 这个location里定义的root根了。 就是nginx作为应用程序处理请求URL的时候不区分大小写，但是如果nginx跑在windows上就真的是不区分大小写了，但是如果跑在nginx上由于nginx的文件系统文件名是区分大小写的，所以还是会区分的最终。 location用的非常多，比如现在做一个动静分离 比如各种图片就属于静态资源 上图就是意思一下，实际动态文件php|jsp|asp不是简单的放在这里的，而是后端的反向代理发给后边能处理jsp的比如是PHP也就是fastCGI的服务器地址 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2023-11-03 10:06:08 "},"36-高性能WEB服务nginx01/5-nginx实现web服务器02.html":{"url":"36-高性能WEB服务nginx01/5-nginx实现web服务器02.html","title":"第5节 nginx实现web服务器02","keywords":"","body":"第5节. nginx实现web服务器02 比如统一把静态资源放到/static/下，或者将后缀写全了进行转发。 alias和root，替换和拼接 root是拼接，而alias是看①如果访问的url里的有alias的path比如上图的about，那么就把整个url替换成alias的path。于是www.site1.com/about/index.html就访问了/opt/testdir/index.html了。 加不加/就是为了xx/xxx/zz/和xx/xxx/zz效果一样因为浏览器会自动重定向类似curl -L的效果 上图注意location里是/about/，用户请求的www.site1.com/about里是不包含/about/的所以不会走location的转发，而是走的非location的也就是/data/site1/的转发路径，具体见error.log 而官方的解释很清楚了已经 就是/user/和/user你不想合成一个URL，是可以指到不同的站点URL上去的。而一般情况都是使用/user不带/这样，用户访问/user和/user/其实都是一个站点，因为/user用户访问呢会自动301到/user/上去的。 上面讨论了location里路径的结尾带不带/的区别，下面讨论alias/root的转发路径的结尾带不带/的区别 总结下 修正理解 上图总结的处理问题不大，但是需要补充 用户行为： 1、curl www.site1.com/about这是访问about文件 2、curl www.site1.com/about/这是访问about/index.html文件 通常都会location里写成/about而不是/about/来应对，这样用户不管最后带不带/实际效果都是一样的，因为不带/也会匹配location然后301到/about/。 location匹配 1、写成/about和/about/是有区别的，首先用户访问的url里必须完整包含，比如location写的是/about/但是用户行为里是/about，就不会命中了； 2、结合用户行为，如果是/about/那么就是访问的/about/index.html此时 \"alias\" 就会将/about/的url整个替换成alias的路径，并在最后补上index.html；此时如果alias那里没有写成文件夹而是写成/xxx，那么整个url就有问题了，就变成了xxxindex.html中间会少了/。 不过root不会出现这个问题，因为root是拼接的，会拼接成xxx/about/index.html alias/root转发处理 1、alias是整个替换只要用户行为里包含了location里的比如/about那么整个url都会替换掉alias的东西，当然如果用户行为最后带/会自动补上index.html的。 2、root是拼接，问题不大，总之实测一下，留意就好，实际测试oK就行，不要纠结了。 index 上图👆有一处地方要改，就是location /about/改成lcoation /about，这样curl -L www.site1.com/about 就能利用301重定向了。 error_page code 找不到404 Not Found哪来的，因为配置文件里404是注释的， 我好像找到了，👇应该就是ngx_http_special_response.c文件 具体调用和最终应用到页码不知道什么弄得，不过这里由明确得html的语法，知道是源码里的404已经做好了就行了。 好像只是简单做一个error页面不用写location啊 location在处理error_page时的注意点 1、root没毛病 root的最后/写不写都行，因为时location 和 root 拼接的，location里带了/了 2、alias有点细节要注意 注意由于重定向的存在也就是location转发的存在，这些重定向的动作是不会日志中看到的，日志中只是最终的一个结果。 这里盲猜location = /404.html 被alias转成了/opt/testdir/，然后没有给你自动补一个index.html 总之也实现了alias和root的404location转发。 场景：浏览器劫持 输入www.site1.com/xfsdfaf后跳转的地址被修改了 为了防止这种浏览器的不良行为，应该如何应对，现在来讲，可能也就是你自己的配置问题，没有对应的文件存在👇比如这种：就会让别人有机可乘。当然chrome不会，可以将404报错改成200这种正确响应码。 当然chrome不会 try_files file ...uri; try_files file ... =code; 这就是类似什么呢，类似这个 网工看了就懂咯 配置下try_files 测试效果就是访问 http://www.site1.com/images/ajpg http://www.site1.com/images/b.jpg http://www.site1.com/images/default.jpg 都OK 但是访问 http://www.site1.com/images/xxx.yy 整个uri不存在，就对应到try_files 的$uri整个变量的文件不存在，于是就转到default.jpg上去。 思考👇 总结就是：内部重定向的/images/default.jpg，也会再次命中location的alias，于是 http://www.site1.com/images/default.jpg被alias成http://www.site1.com/data/images/default.jpg了？？？只能这么理解了啊。 如果/images/ keepalive_timeout 这个65怎么体现在测试中： 通过telnet 80 并发送一次get可以感受到时间的长短，操作主要事项①get一次得到页面内容后②不要再做任何操作。此时可以观测到配置的时间。 注意这两个参数是不同的 keepalive_time是一个链接可以存活多久 keepalive_timeout是一个client请求的链接，空闲时间可以存活多久。 可见启用了keepalive_timeout但是没有说多少秒。 写道head里的是10秒，实际是65秒。 持久链接断开的情况 1、keepalive_timeout时间到了。 2、请求的资源个数超了，比如一次长连接允许请求文件为3个。测试👇 禁止那种浏览器使用长连接 keepalive_disable none | browser ...; 手机上各种浏览器 向客户端发送超时时长 send_timeout time; 向客户端发送响应报文的超时时长，此处是指两次写操作之间的间隔时长，而非整个响应时间过程的传输时长。 服务器响应发送时间间隔，也就是两次写操作的间隔，这里写，我的理解是 server要构建response的，自然是写内容的要。 上传文件的限制？ client_max_body_size size; 请求报文中实体的最大值,默认1M，超过了就报错413 client_body_buffer_size size;上传的文件是有buffer的，超过buffer大小默认16K，就会暂存到磁盘上的下面client_body_temp_path指令所定义的位置。 client_body_temp_path path [level1 [level2 [level3]]]; 设定存储客户端请求报文的body部分的临时存储路径及子目录结构和数量 目录名为16进制的数字；用hash之后的值从后往前截取第1、2、3级作为文件名 比如： client_body_temp_path /var/tmp/client_body 1 2 2 # 三级目录1 2 2，分别用1个字符，2个字符，2个字符。 1 1级目录占1位16进制，即2^4=16个目录 0-f 2 2级目录占2位16进制，即2^8=256个目录 00-ff 2 3级目录占2位16进制，即2^8=256个目录 00-ff 👇计算下这样三级命名文件夹的好处--就是用上传的文件的哈希值作为分层目录，这样能够支持1048576个子文件，每个子文件里如果放1个文件也就是100w个文件了。好处就是如果整个100w放在一个文件夹里ls都能卡死，分层放置，查找自然就快了。L1目录顶多16个，L2目录256个，L3目录256个也是。 上传服务器配置生产案例： location /upload { client_max_body_size 100m； client_body_buffer_size 2048k; client_body_temp_path /apps/nginx/temp 1 2 2; … } Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2024-01-17 14:53:32 "},"37-高性能WEB服务nginx02/37-高性能WEB服务nginx02.html":{"url":"37-高性能WEB服务nginx02/37-高性能WEB服务nginx02.html","title":"第三十七章 高性能WEB服务nginx02","keywords":"","body":"第三十七章 高性能WEB服务nginx02 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"37-高性能WEB服务nginx02/1-nginx常见配置.html":{"url":"37-高性能WEB服务nginx02/1-nginx常见配置.html","title":"第1节 nginx常见配置","keywords":"","body":"第1节. nginx常见配置 对客户端进行限制 下载限速 准备下载的资源 下载速度 限速成功👇 限制method limit_except method ... { ... }，仅用于location 限制客户端使用除了指定的请求方法之外的其它方法 method:GET, HEAD, POST, PUT, DELETE，MKCOL, COPY, MOVE, OPTIONS, PROPFIND, PROPPATCH, LOCK, UNLOCK, PATCH limit_except GET { allow 192.168.1.0/24; deny all; } 除了GET和HEAD 之外其它方法仅允许192.168.1.0/24网段主机使用 这里的Not Allowed应该不是没有放行，而是网站不支持的意思，证明如下👇 配置 翻译：限制所有，除了GET和OPTIONS以及GET放了就带了HEAD，IP方面全部包含。 这才是没有放行的报错👇 而这个不是没有放行，而是网站不支持的现象👇 文件操作优化的配置 aio on | off | threads[=pool]; ​ 是否启用异步io，默认off directio size | off; ​ 当文件大于等于给定大小时，同步(直接)写磁盘，而非写缓存，默认off location /video/ { sendfile on; aio on; directio 8m; } open_file_cache off; open_file_cache max=N [inactive=time]; ​ nginx可以使用缓存来加快文件访问速度，可以缓存以下三种信息： ​ ①文件元数据：文件描述符、文件大小和最近一次的修改时间 ​ ②打开的目录结构 ​ ③没有找到的或者没有权限访问的文件的相关信息 ​ max=N：可缓存的缓存项上限，达到上限后会使用LRU算法来管理 ​ inactive=time：缓存项的非活动时长，在此处指定的时长内未命中的或命中次数少于open_file_cahce_min_users指令所指定的次数的缓存项即为非活动项，将被删除。 这里面就体现了缓存的一个使用逻辑：①缓存的空间多少能存多少数据量数据量是条数来定义的吗？②存多久，不用就删，不用的标准是什么，用的少就删，用的少的标准是什么。这里就有一个指定时间。所以上面的逻辑就是答案了。 open_file_cache_min_uses number; ​ open_file_cache指令的inactive参数指定的时长内，至少被命中此处指定的次数方可被归类为活动项。默认为1，1就是等价于LRU算法了--只要命中一次就将优先级提为最高。可以改大点。 open_file_cache_errors on | off，是否缓存查找时发生错误的文件一类的信息，默认off ​ 用户经常访问错误的页面，可以开启这个选项 open_file_cache_valid time，缓存项有效性的检查频率，默认值60s ​ 检查到了非活动项，就会删除了。 ngx_http_access_module 类似acl 该模块，可实现基于ip的访问控制功能 allow address | CIDR | unix: | all; deny address | CIDR | unix: | all; ​ 上下文所属：http，server，location，limit_execpt ​ 自上而下检查，一旦匹配，将生效，条件严格的置前。 示例： location /about { # 这玩意会301重定向为/about/然后走root拼接，就是 root /data/nginx/html/pc; # 拼接为/data/nginx/html/pc/about/index.html index index.html; deny 192.168.1.1; allow 192.168.1.0/24; allow 10.1.1.0/16; allow 2001:0db8::/32; deny all; } 调整一下顺序 ngx_http_auth_basic_module 该模块基于用户访问控制，使用basic机制进行用户认证 auth_basic string | off auth_basic_user_file file; ​ location /admin/ { ​ auth_basic \"Admin Area\"; # 提示语句，弹出对话框里的信息 ​ auth_basic_user_file /etc/nginx/.ngxpasswd; # 你看，和httpd一样，密码都是用.xxx隐藏文件来做一般 } 用户口令文件： 1、明文文本：格式name:passswd:comment 2、加密文本：由htpasswd命令实现 ​ httpd-tools所提供 好像和httpd也就是apache一样？肯定一样了，都是一个工具httpd-tools提供的 按这走一遍咯👆 或者这样更简单 注意-c 只有首次才能加哦 以后就这么配置👇 配置以下使用该用户密码 去掉index test.html才会使认证生效👇 不对，不对，不去掉也可以的，这里实验效果生效可能慢了 要注意这个basic认证的密码，是明文的，抓包可见 抓这个口的报文 这就是为什么要采用https的原因 apache那会讲过status统计页面，nginx同样也有 这有什么用呢，就是将来可以curl xx/xxx/status，就能快捷地获得各个指标，联动报警了。 location /nginx_status { stub_status; allow 127.0.0.1; allow 172.16.0.0/16; # 自己修改成所需要地白名单 deny all; } ab打一下 注意：第二行参数地值也就是2、3两行 是累计地值 最后一行是当前的值。 第三方插件-echo echo就是变量 显示出来比较方便可能。 这是没有echo功能的，需要安装插件 https://github.com/openresty/echo-nginx-module 然后下载nginx源码 https://nginx.org/en/download.html 然后编译的时候，把echo插件加进去 ok👇 图中error只是摸粑粑的着色 然后make -j 4 && make install报错👇 处理方法 完整的编译选项如下👇 ./configure \\ --with-cc-opt='-fPIE -fPIC' \\ --with-ld-opt='-pie' \\ --prefix=/apps/nginx \\ --user=nginx --group=nginx \\ --with-http_ssl_module \\ --with-http_v2_module \\ --with-http_realip_module \\ --with-http_stub_status_module \\ --with-http_gzip_static_module \\ --with-http_perl_module \\ --with-pcre \\ --with-stream \\ --with-stream_ssl_module \\ --with-stream_realip_module \\ --add-module=/usr/local/src/echo-nginx-module make -j 4 && make install 创建测试配置文件 看上图不行哦👆，nginx -t看到的是nginx.conf test OK，其实没有检测test.conf的，因为主配置文件里没有指定includ xxx 加一下 这就是效果了，然后浏览器是由于mime.types应该没有识别所以就统一下载 下载下来打开就是 优化下指一下default_type为text/html;👇 ok，如果注释掉echo，就是index.html内容了 简化配置👇 如果用echo，其实不必要指root的什么文件也无需存在的。 同样echo插件可以打印变量 解释上图👇 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2024-01-22 10:18:33 "},"37-高性能WEB服务nginx02/2-nginx第三方模块echo和自定义json.html":{"url":"37-高性能WEB服务nginx02/2-nginx第三方模块echo和自定义json.html","title":"第2节 nginx第三方模块echo和自定义json","keywords":"","body":"第2节. nginx第三方模块echo和自定义json nginx变量 同样可以利用echo显示出来吧 好像br才能在浏览器中换行 linux cli里还是有点问题 要加引号的 然后br只是针对浏览器的，linux curl无需br的 然后还要关注这里一直看到的 ?id=1&core=100其实就是$args的变量的结果，用在sql语句去后端查DB的。 如果你不清楚nginx的站点的目录，但是你又知道配置文件的路径，可以这么做 cookies的显示需要curl里带上才行的 正常访问网站，server会构建cookie发给你，下次你浏览器就会自动携带这个cookie了-这是浏览器自带的行为。 cookie的用途，将来可以根据cookie来进行调度，session会话，前端有个调度器，如果轮询就不知道轮到那台node去了，之前的信息就丢了，所以可以根据cookie或者说这里的user，如果是ming这个用户，就往同一台node上转发。这就不会造成会话丢失。 但是，cookie是7层内容，LVS不支持。 整体上判断nginx的性能要地域lvs，这是再说四层转发的功能和lvs的四层转发。 自定义变量 变量之间赋值：不过要联系到python里的列表赋值和字典赋值这种 指针类的 要小心。 如果是http，就可以重定向到https。但好像也不用echo一下 判断一下 ，多此一举。 访问日志的格式 和httpd也就是apache一样。 log_format 指令只能在http模块下定义；但是调用log_format指定的格式变量就不一定了 也是①先定义格式②定义完个时候，再引用这个格式。 apache也是一样的格式 还有用户认证的记录，这是之前讲过的 日志如下👇 log_format 指令只能在http模块下定义；但是调用log_format指定的格式变量比如下图的main就不一定了 每个服务器，也就是server都应该有自己的访问日志，区分开的，所以自然是server模块下可以使用access_log来调用log_format格式，进一步产生自己的独立的日志。 自定一下log的格式和产生的地方 http_referer是从哪个url跳转过来的。 上面新的日志格式就改完了，下面就去虚拟主机那里调用就行了。 access_log off;就是不记录这个server块，虚拟主机的日志。 重启服务日志文件就有了，不过是空的，访问一下，日志文件里就有内容了👇 要注意 - 有的是 格式排版，有的是没有数值。 要注意，上图的14就是index.html的文件大小 大小会有出入，文件越大可能出入就出来了。 /favicon.ico是当你访问站点的时候，会自动的找你的图标，这是自动的浏览器行为，结果没有就是404找不到了。 然后可能更提倡用json格式，因为有key value，不像上面的一行一个全是内容，一些值就不清楚具体是什么意思了。 但是用json格式保存，就意味着你查看不是 行记录了，人工查看就不是很舒服咯，对吧。 重启服务后，访问，看下日志 格式化下 关于日志或者大文件的清理方法 1、> 2、cat /dev/null > # 一些shell不支持 上面个的>重定向的方法，就用/dev/null垃圾箱的方式来做 3、别用echo，echo是有一个字节的，是一个换行符 浏览器的行为，会找图标 扣一个图标下来用用 找到站点的根目录，将图标放进去 浏览器的行为 curl就不会，因为curl是cli不是图形界面，不存在图标啊 解决方法就是补一个图标文件 或者访问这个favicon.ico文件的时候就不记录日志，这有点掩耳盗铃哦，也许不是，哈哈 图标默认就是在站点的根，这里上图是指定了具体位置了。 缓存 这图👆是说的文件的缓存 而下图👇是日志的缓存，也是LRU算法，也是max、inactive、min、valid这些参数。 open_log_file_cache on; # 启用缓存 max=N 记录多少条缓存 inactive=time 多长时间内 该缓存 没有被访问，就认为过期了；而且在inactivetime时间内 还要访问min_uses=N个次数才认为是活动的缓存。反之这段时间内该缓存没有达到min_uses次则缓存删除了应该就。 valid=time 多长时间检查一下缓存情况，就是检查一些信息是否过期了。 nginx做下载页面，类似yum源之类的 1、将sr0光盘挂到站点目录下，直接是不能访问的 这里的一个排查思路，就是umount后，写一个index.html文件，再用浏览器打开看看如果可以就说明路径啊，配置啊都没问题，问题是文件夹里没有index.html文件。其实不必测试了，知道这么个思路就好了。 好了，现在将使用ngx_http_autoindex_module模块 涉及选项 autoindex on|off 开关咯 autoindex_exact_size on|off 一般就是off显示粗略的不对的文件大小，主要是没啥大用，on还要实时计算不好，对资源消耗方面。 autoindex_localtime on|off 使用on就是用本机时间，然后本机时间就用ntp同步了。 autoindex_format html|xml|json|jsonp 显示格式 这不就是可以用来当yum源咯👆 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2024-01-25 14:17:59 "},"37-高性能WEB服务nginx02/3-nginx的压缩和https加密实现.html":{"url":"37-高性能WEB服务nginx02/3-nginx的压缩和https加密实现.html","title":"第3节 nginx的压缩和https加密实现","keywords":"","body":"第3节. nginx的压缩和https加密实现 压缩 apache也支持压缩 这是👆httpd的压缩篇章 nginx -t查看编译的配置选项 配置参数如下： gzip on|off 开关 gzip_comp_level level 压缩比修改 1到9，9 最高压缩比，9也是最耗CPU的 虽然是1-9，但是压缩的效果也不会差太多 gzip_disable regex ... 匹配客户端浏览器类型就不执行压缩，比如gzip_disable \"MSIE[1-6]\\.\"; gzip_min_length length 压缩的起点，什么样的大小才开始压缩，比如＞100k的才开始压缩，100Bytes就别压了，压了也没啥效果。 gzip_http_version 1.0|1.1 是支持的http版本 gzip_buffers number szie 压缩的时候启用多大的缓冲区 gzip_types mime-type ... 针对什么类型的文件进行压缩，默认包含text/html的格式支持，不要写，写了反而报错。 gzip_vary on|off 如果启用压缩了，是否在响应报文首部插入\"Vary：Accept-Encoding\" 解释：👇就是说server要插入这个标记，代理那边就会存储两个版本的web页，一个压缩一个不压缩，以此来响应支持和不支持压缩的client浏览器。当然c-ser直连的话就看client那边浏览器是否支持压缩了支持-server就发送经过gzip压缩的页面版本。 gzip_proxied off|expied|no-cache|no-store|private|no_last_modified|no_etag|auth|any ...; nginx做反代的时候，后端服务器将响应报文发给nginx，nginx再回给用户的时候，是否启用压缩，就靠这个参数来做的。 off 就是nginx返给client的时候不压缩 expied|no-cache|no-store|private|no_last_modified|no_etag|auth|any ... 后端服务器响应报文中带有Cache-Control字段，然后这个字段里的值 写的是这些的时候，就启用压缩。 配置下 同样，可以了解下gzip的适配模块 gzip 的总开关 默认就是off的。其他的就是on后的一些选项 观察这个大文件，看下压缩的效果 curl可以看到Content-Lenth大小就是文件的大小👇👆 既是curl带上压缩功能，也没有，因为server那边没有开启 然后server开启压缩功能 然后curl看压缩要启用压缩功能的，不启用是没效果的 curl带上压缩选项，应该是成功了，只是不再显示Content-Length了。 所以说压缩比差不多就行了👇 SSL证书，加密 之前httpd也弄过，自签名证书还挺有意思的，实现了client的安全访问的关键点。 然后购买证书这块的情况 阿里云上有全套的购买申请流程，可以学习下，但是买不一定，需要看哪里性价比高。 apache做ssl，server上是配置3个文件：ca证书、服务器证书、服务器私钥 nginx做ssl，服务器证书、服务器私钥 实现ssl是用的ngx_http_ssl_module模块 ①ssl on|off， ssl开关，不推荐，建议使用listen指令，和httpd一样 listen 443 ssl httpd就是listen 443 https ，不是一个意思嘛。 ②ssl_certificate_file 和 ssl_certificate_key file 服务器证书文件和私钥文件；从供应商购买后会得到两个文件，一个服务器证书文件，一个私钥key ③ssl_protocols 支持的ssl加密协议，默认就行了 ④ssl_session_cache 加速服务器响应速度的吧应该是， ⑤ssl_session_timeout 客户端链接可以复用ssl session cache中缓存的有效时长，默认5m 下面开始实验 还是使用自签名证书咯 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2024-01-26 18:31:00 "},"37-高性能WEB服务nginx02/4-nginx的rewrite模块实现.html":{"url":"37-高性能WEB服务nginx02/4-nginx的rewrite模块实现.html","title":"第4节 nginx的rewrite模块实现","keywords":"","body":"第4节. nginx的rewrite模块实现 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"37-高性能WEB服务nginx02/5-nginx反向代理实现.html":{"url":"37-高性能WEB服务nginx02/5-nginx反向代理实现.html","title":"第5节 nginx反向代理实现","keywords":"","body":"第5节. nginx反向代理实现 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"38-高性能WEB服务nginx03/38-高性能WEB服务nginx03.html":{"url":"38-高性能WEB服务nginx03/38-高性能WEB服务nginx03.html","title":"第三十八章 高性能WEB服务nginx03","keywords":"","body":"第三十八章 高性能WEB服务nginx03 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"38-高性能WEB服务nginx03/1-nginx反向代理缓存和IP透传等功能.html":{"url":"38-高性能WEB服务nginx03/1-nginx反向代理缓存和IP透传等功能.html","title":"第1节 nginx反向代理缓存和IP透传等功能","keywords":"","body":"第1节. nginx反向代理缓存和IP透传等功能 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"38-高性能WEB服务nginx03/2-nginx实现fastcgi反向代理.html":{"url":"38-高性能WEB服务nginx03/2-nginx实现fastcgi反向代理.html","title":"第2节 nginx实现fastcgi反向代理","keywords":"","body":"第2节. nginx实现fastcgi反向代理 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"38-高性能WEB服务nginx03/3-nginx反向代理实现负载均衡及调度方法.html":{"url":"38-高性能WEB服务nginx03/3-nginx反向代理实现负载均衡及调度方法.html","title":"第3节 nginx反向代理实现负载均衡及调度方法","keywords":"","body":"第3节. nginx反向代理实现负载均衡及调度方法 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"38-高性能WEB服务nginx03/4-nginx四层代理功能和tengine编译安装.html":{"url":"38-高性能WEB服务nginx03/4-nginx四层代理功能和tengine编译安装.html","title":"第4节 nginx四层代理功能和tengine编译安装","keywords":"","body":"第4节. nginx四层代理功能和tengine编译安装 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "},"38-高性能WEB服务nginx03/5-keepalived实现反向代理的高可用.html":{"url":"38-高性能WEB服务nginx03/5-keepalived实现反向代理的高可用.html","title":"第5节 keepalived实现反向代理的高可用","keywords":"","body":"第5节. keepalived实现反向代理的高可用 Copyright 🌹 © oneyearice@126.com 2022 all right reserved，powered by Gitbook文档更新时间： 2022-10-25 10:35:00 "}}