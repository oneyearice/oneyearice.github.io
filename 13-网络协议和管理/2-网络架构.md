# 第2节. 网络架构

网工，略







# 工作案例-如何监管开发内网的url访问



这是一个过程记录，没有整理，备忘用的





传统防火墙里的url功能，开源如何实现呢



关键词squid，架构搭建opnsence



**系统学习**https://www.cnblogs.com/weq0805/p/15242170.html#_lab2_0_0



学习记录



squid作为opnsense的一个插件，所以要全面连接这个插件，还是要进行**系统学习**

1、squid作为正代使用的，反代就是nginx、haproxy、f5、lvs直流；而正代做代理的用户clients

2、squid虽说是正向代理，但是也有反代，它的反代就是指的本地加速缓存，访问过的网页站点就有缓存，下次用户直接读取，无需去互联网索取。这就是squid反代的体现。

3、肯定是透明模式落地拉，不用用传统的client也就是pc上设置代理的方式的，不过手机端也许可以灵活测试把这个传统模式用起来。恩灵活还是传统模式，不然手机还得网关上配置PBR。或者防火墙配置PBR之类的。







按照上面的网站走

1、systemctl服务自己弄





2、透明代理的dns自己处理

dns同样配置squid的内网IP，192.168.127.144

但是请求失败，查找原因，找到了👇



这里将dns请求转发的哦VM的虚拟网关

![image-20241009092823661](2-网络架构.assets/image-20241009092823661.png)



通过抓包可见，dns请求出去的ip是内网IP127段的，126.2回包进不了来的，VM的host网络。

![image-20241009092858030](2-网络架构.assets/image-20241009092858030.png)



只需要iptables 做SNAT就行了

![image-20241009093201608](2-网络架构.assets/image-20241009093201608.png)

这不就OK了嘛，所以不要加班搞，不要加班搞，贪狼入命的人，不管干什么都要注意节制：打游戏、看小说、玩、研究技术、学习，唉学习不会，看来学习养人啊，哈哈哈。学习也会的，昨天要是继续不下班研究状态就不好，又伤身。所以贪狼入命一定要小心。

![image-20241009093230191](2-网络架构.assets/image-20241009093230191.png)





再把dns得iptables改成本地3128端口去，尝试模拟传统模式也就是client windows配置代理--sock5肯定是了，因为传统模式也是把dns代理出去得---10.2那边抓包看到了。

关于传统模式和透明模式的dns处理

1、传统模式，代理里的写法其实就是sock5，包含udp的，所以dns也是走的3128squid，suqid机器再给你去10.2本地dns请求的

2、透明模式，iptables 转的，所以出去将udp 53转到本地10.2的dns，同时出向也要做SNAT，否则外界没有内网host网络的IP路由的。这里的外界是VMWork Station的虚拟网关

3、网络结构：windows-192.168.127.143-----host网络-----192.168.127.144-squid代理-192.168.126.134-----NAT网络-----192.168.126.2虚拟网关也是虚拟dns-------192.168.10.2DNS

4、哈哈网络结构上的比较晚，没事，基本都是常规结构。



继续报错

![image-20241009094357823](2-网络架构.assets/image-20241009094357823.png)

可能是MSS没设置，不是

可能是squid的 http_port 192.168.229.60:3128 transparent  配置有配置

![image-20241009102656077](2-网络架构.assets/image-20241009102656077.png)



搞不定，透明模式还是有问题，回去开启opnsence看人家的squid是怎么玩的的，那里我是折腾好了的



然后看到AV防病毒

https://docs.opnsense.org/manual/how-tos/proxyicapantivirus.html

AV也需要透明代理，这里是老的opnsence集成web proxy时候的说明，正好可以拿来对照squid web proxy插件时代的配置项👇

https://docs.opnsense.org/manual/how-tos/cachingproxy.html









这一篇也要看

https://cloud-atlas.readthedocs.io/zh-cn/latest/web/proxy/squid/introduce_squid.html











## 插播：dns的坑，也许不算坑

但是会干扰你的排查故障，这也是致命的，你会人为是dns相应慢，其实不慢。



### 1、现象

windows cmd  nslookup 2s延迟

windows cmd dig 无延迟



linux nslookup或dig 都无延迟



上截图

windows nslookup 每次都慢

<img src="2-网络架构.assets/image-20241009170624622.png" alt="image-20241009170624622" style="zoom:50%;" />

windows dig 每次都快

![image-20241009170758697](2-网络架构.assets/image-20241009170758697.png)



linux 不管是nslookup还是dig都ok

![image-20241009170849026](2-网络架构.assets/image-20241009170849026.png)



![image-20241009170901704](2-网络架构.assets/image-20241009170901704.png)



### 排查，去dns server抓包可见

![image-20241009170936105](2-网络架构.assets/image-20241009170936105.png)

windows的nslookup 每次会多出一步PTR反解

而windows的dig，linux的nslookup、dig都没有这个PTR

![image-20241009171028128](2-网络架构.assets/image-20241009171028128.png)





为什么同一台PC nslooklup  10.100.8.2 有PTR，nslookup  192.168.10.2没有PTR，

**因为下图的Unkown就是原因。去给10.100.8.2配置hostname就行了**   PS: dig不管什么OS都不会，然后linux的nslookup也不会

<img src="2-网络架构.assets/image-20241009171814148.png" alt="image-20241009171814148" style="zoom:50%;" />





补上dnsmasq的/etc/hosts的A记录同时也是PTR记录就行了

<img src="2-网络架构.assets/image-20241009172245024.png" alt="image-20241009172245024" style="zoom:50%;" />





搞定，不卡了

<img src="2-网络架构.assets/image-20241009172438493.png" alt="image-20241009172438493" style="zoom:50%;" />









**>> 继续squid读文**

https://cloud-atlas.readthedocs.io/zh-cn/latest/web/proxy/squid/squid_socks_peer.html#sockssquid

这里调一下，写错了👇

![image-20241010134828542](2-网络架构.assets/image-20241010134828542.png)



然后读文

https://cloud-atlas.readthedocs.io/zh-cn/latest/web/proxy/squid/squid_gfwlist.html

里面提到的gfwlist是国外IP地址，而且txt里也是处理过的，看不到具体ip地址

还不如用国内IP LIST，对吧除此之外的就走节点出去

https://gitee.com/haiyangyu/CN_ISP_RIB/tree/master







继续处理squid的透明模式

发现按照

https://www.cnblogs.com/weq0805/p/15242170.html

配置 透明模式  3128监听端口就没了

问了GPT才知道要看cache的log

![image-20241010144721976](2-网络架构.assets/image-20241010144721976.png)



<img src="2-网络架构.assets/image-20241010144746371.png" alt="image-20241010144746371" style="zoom:50%;" />





然后这个报错 forward-proxy ports 好像在上面的文里也有

![image-20241010144901052](2-网络架构.assets/image-20241010144901052.png)





这里有个点就是

1、opsense里是没有 两个端口的，就是上图的8080和3128，就是不透明和透明的两个端口 两行配置

![image-20241010145705688](2-网络架构.assets/image-20241010145705688.png)



2、然后自己的搭建的squid应该是要些两行，而且端口不能一样

还是通过cache.log可见，重启服务，配置一样的端口

![image-20241010150444517](2-网络架构.assets/image-20241010150444517.png)



![image-20241010150459900](2-网络架构.assets/image-20241010150459900.png)



<img src="2-网络架构.assets/image-20241010150519856.png" alt="image-20241010150519856" style="zoom:50%;" />

所以上图的3128不能一样，这里不知道opnsense怎么做到不写第一行的3128的



**此时http://的就可以访问了**，不会出现squid的invliad页面了👇这是当时的报错：

![image-20241010151037991](2-网络架构.assets/image-20241010151037991.png)

<img src="2-网络架构.assets/image-20241010150917897.png" alt="image-20241010150917897" style="zoom:50%;" />

这样配置，第二行不生效的，不过3128能够起来，然后就是上上图的报错





然后继续折腾https的问题👇，那就有的折腾了，不过opnsense已经ok，思路就是自签名，然后同样端口要错开和http的3128，人家用额3129

![image-20241010151855572](2-网络架构.assets/image-20241010151855572.png)







### 删掉squid，重新编译带上ssl

![image-20241010152912299](2-网络架构.assets/image-20241010152912299.png)

```bash
./configure --prefix=/usr/local/squid --sysconfdir=/etc --enable-arp-acl --enable-linux-netfilter --enable-linux-tproxy --enable-async-io=100 --enable-err-language="Simplify_Chinese" --enable-underscore --enable-poll --enable-gnuregex --enable-ssl
```







**插播，妈的不知咋回事gitbook太慢了，难道是有收费版的原因？**

![image-20241010154123220](2-网络架构.assets/image-20241010154123220.png)

就👆这个共享冲突上面会卡特喵几个小时，，，之前还没这么久，共享冲突每次都出现啊，怎么可能是这个问题。







![image-20241010155849518](2-网络架构.assets/image-20241010155849518.png)

ssl就有了👆



然后还是按他的走一遍，当然systemd自己弄。

https://www.cnblogs.com/weq0805/p/15242170.html

服务起来后，按他的走ssl

https://cloud-atlas.readthedocs.io/zh-cn/latest/web/proxy/squid/squid_transparent_proxy.html

不过话说回来，这么多次ssl的证书，nginx的httpd的mysql的haproxy的，不管是openssl的还是makefile的，还是opnsense自己的图形界面的，还是openvpn的，都有在用，但是好像cli都略有不同，基本一致。好讨厌啊

要不，这就总结下吧

### ssl自签名的各种cli汇总

1、ssh那会不是基于key，而是基于双向非对称加密的。

```bash
1、建立CA：genrsa生成ca私钥--cakey；利用cakey自签名证书--自己给自己颁发证书
(umask 077;openssl genrsa -out private/cakey.pem 4096)
openssl req -new -x509 -key /etc/pki/CA/private/cakey.pem -out /etc/pki/CA/cacert.pem -days 3650 <<EOF
CN
beijing
beijing
ming
devops
ca.ming.com
admin@ming.com
EOF
a.
touch /etc/pki/CA/index.txt    #  存放已经颁发的证书信息
echo 0F > /etc/pki/CA/serial   #  存放下一个颁发证书的序列号，0F改成01从第一个号开始分



2、搞一个证书申请文件

mkdir /etc/httpd/conf.d/ssl
cd /etc/httpd/conf.d/ssl
(umask 066;openssl genrsa -out httpd.key 1024)  #1024可能有问题msyql那会的经验告诉我要4096保持一致
openssl req -new -key httpd.key -out httpd.csr <<EOF
CN
beijing
beijing
ming
devops
ca.ming.com
admin@ming.com


EOF

scp /etc/httpd/conf.d/ssl/httpd.csr CAServer:/etc/pki/CA       # 把csr申请文件传到CA上，在CA上根据csr文件来颁发证书，也就是对其加密。


3、针对申请文件进行颁发证书-也就是签名-也就是用CA的私钥进行加密

openssl ca -in /etc/pki/CA/httpd.csr -out /etc/pki/CA/certs/httpd.crt -days 100

scp /etc/pki/CA/certs/httpd.crt root@httpdServer:/etc/httpd/conf.d/ssl    # 把证书复制到server上
scp /etc/pki/CA/cacert.pem root@httpdServer:/etc/httpd/conf.d/ssl      # 把ca自己的证书也复制倒server上，此举相当于windows预加载了受信任的根证书文件。

```



2、apache那会

```
CA上👇
cd /etc/pki/CA
mkdir certs
mkdir crl
mkdir newcerts
mkdir private
mkdir ssl

(umask 077;openssl genrsa -out private/cakey.pem 4096)
openssl req -new -x509 -key /etc/pki/CA/private/cakey.pem -out /etc/pki/CA/cacert.pem -days 3650



touch /etc/pki/CA/index.txt    #  存放已经颁发的证书信息
echo 0F > /etc/pki/CA/serial   #  存放下一个颁发证书的序列号，0F改成01从第一个号开始分


server上👇
mkdir /etc/httpd/conf.d/ssl
cd /etc/httpd/conf.d/ssl
(umask 066;openssl genrsa -out httpd.key 2048)  #1024可能有问题msyql那会的经验告诉我要4096保持一致

openssl req -new -key httpd.key -out httpd.csr 
scp /etc/httpd/conf.d/ssl/httpd.csr CAServer:/etc/pki/CA       # 把csr申请文件传到CA上，在CA上根据csr文件来颁发证书，也就是对其加密。


CA上👇
openssl ca -in /etc/pki/CA/httpd.csr -out /etc/pki/CA/certs/httpd.crt -days 100 -extensions v3_req

scp /etc/pki/CA/certs/httpd.crt root@httpdServer:/etc/httpd/conf.d/ssl    # 把证书复制到server上
scp /etc/pki/CA/cacert.pem root@httpdServer:/etc/httpd/conf.d/ssl      # 把ca自己的证书也复制倒server上，此举相当于windows预加载了受信任的根证书文件。

```



3、nginx那会makefile文件弄的

不过nginx那里就看到两个文件，不像httpd那会3个文件，本质一样的，因为nginx那会既做CA也做server所以就2个就行了。



这里继续弄squid的ssl吧

![image-20241011093957713](2-网络架构.assets/image-20241011093957713.png)

这个没问题

不过我没有下面这个命令，

<img src="2-网络架构.assets/image-20241011094034589.png" alt="image-20241011094034589" style="zoom:50%;" />

不用多想，重新编译squid吧，你看看opnsense人家的squid就有这个命令

![image-20241011094156211](2-网络架构.assets/image-20241011094156211.png)



重新编译，按人家网关提示，对，我就是看看这个，看看官网，再看看opnsense插件的。

https://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit

![image-20241011094207130](2-网络架构.assets/image-20241011094207130.png)



我的编译如下，多带了一个--enable-ssl也是参考的opnsense和上面一个连接里的。

![image-20241011094813055](2-网络架构.assets/image-20241011094813055.png)



然后squid是私钥和自签名在一个文件里的，所以从httpd的3个文件 到 nginx的两个文件 再到 squid的一个文件，再到openvpn的client也是一个文件。

![image-20241011101402594](2-网络架构.assets/image-20241011101402594.png)

不过openvpn  server还是3个文件+ dh.pem 一共4个文件分开来的，client之所以一就是写在一起了而已。

![image-20241011101304103](2-网络架构.assets/image-20241011101304103.png)



按这个来：

https://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit

先修改openssl配置文件

![image-20241011102008556](2-网络架构.assets/image-20241011102008556.png)

![image-20241011102131995](2-网络架构.assets/image-20241011102131995.png)



![image-20241011102241490](2-网络架构.assets/image-20241011102241490.png)



这里不是csr的申请，所以v3的cli变了一下

```bash
openssl req -new -newkey rsa:2048 -sha256 -days 365 -nodes -x509 -extensions v3_ca -keyout myCA.pem  -out myCA.pem

```

不过csr颁发server证书的时候才有alt_name也就是**subject Alternative name**

ca里是没有的。。。







然后再

![image-20241011101717032](2-网络架构.assets/image-20241011101717032.png)



继续吧，这次重新编译后就有这个文件了👇

![image-20241011102727429](2-网络架构.assets/image-20241011102727429.png)



但是官网它写错了

<img src="2-网络架构.assets/image-20241011102918757.png" alt="image-20241011102918757" style="zoom:50%;" />

改成https和3129和默认的3128区分开来，**也要加上intercept的**，

然后注意重新编译后的log 文件权限给到

![image-20241011104008019](2-网络架构.assets/image-20241011104008019.png)



然后重启就能看到cache.log了，通过它就能发现哪里出问题了

![image-20241011104046315](2-网络架构.assets/image-20241011104046315.png)



<img src="2-网络架构.assets/image-20241011104158463.png" alt="image-20241011104158463" style="zoom:50%;" />





![image-20241011104429137](2-网络架构.assets/image-20241011104429137.png)

再试

不行，还是手动敲一下吧



![image-20241011104805864](2-网络架构.assets/image-20241011104805864.png)



然后由于squid服务一直锲而不舍的尝试，所以不需要重启，就起来了，就看到3128 3129端口了

![image-20241011104910276](2-网络架构.assets/image-20241011104910276.png)



这不就可以了嘛

![image-20241011105829563](2-网络架构.assets/image-20241011105829563.png)



继续把证书搞一下，不然还是不行

![image-20241011110028416](2-网络架构.assets/image-20241011110028416.png)



证书就导出xx.der然后导入到windows里就行了

![image-20241011110317700](2-网络架构.assets/image-20241011110317700.png)



![image-20241011110503943](2-网络架构.assets/image-20241011110503943.png)





搞定！

![image-20241011110750136](2-网络架构.assets/image-20241011110750136.png)





![image-20241011133356854](2-网络架构.assets/image-20241011133356854.png)

观察cache.log还有报错，就处理

![image-20241011133418679](2-网络架构.assets/image-20241011133418679.png)

报错解决







自此，opnsense的squid插件，独立出来 落地实现👆



意味着：我只要在网络核心旁挂一台squid，然后将网关指过去，然后用户PC加载自签名SSL，就可以监控所有上网内容，①这套方案落在开发内网高密环境 ②性能需要测试的。



以下配置cli历史记录，看不到vim里的

```bash

cd /squid
mkdir /squid
cd /squid/


wget https://www.squid-cache.org/Versions/v6/squid-6.10.tar.xz

yum -y install gcc gcc-c++ make

tar -xvf squid-6.10.tar.xz

cd squid-6.10


./configure --prefix=/usr/local/squid --sysconfdir=/etc --enable-arp-acl --enable-linux-netfilter --enable-linux-tproxy --enable-async-io=100 --enable-err-language="Simplify_Chinese" --enable-underscore --enable-poll --enable-gnuregex

👆这里缺失ssl的功能


lscpu
make -j 4 && make install


ln -s /usr/local/squid/sbin/squid /usr/local/sbin   👈PATH变量

squid -h
which squid

ll
ll `which squid`
ll /usr/local/squid/sbin/squid
id squid
useradd -h
useradd -M -s /sbin/nologin squid   👈  服务的启动用户
id squid
chown -R squid.squid /usr/local/squid/var/  👈 日志生成的权限
ll /usr/local/squid/var/
ll /usr/local/squid/var/ -R
vim /etc/squid.conf
squid -k parse   👈 没啥用的检查配置语法，其实还得靠cache.log看报错
vim /etc/squid.conf
squid -k parse
vim /etc/squid.conf
squid -k parse
squid -z
squid
ps auxf |grep -v grep |grep squid
ss -tlnup |grep squid
netstat -anpt |grep squid
netstat -anpt
ss -tlnup
squid -k parse

ll /usr/local/squid/var/run/squid*
ll /usr/local/squid/var/run/squid.pid
cat /usr/local/squid/var/run/squid.pid
ps auxf |grep -v grep |grep squid

cat /etc/squid.conf
ll /usr/local/squid/sbin/squid
squid -h

👇编写systemd的过程

ss -tlnup
/etc/init.d/squid
/etc/init.d/squid restart
/etc/init.d/squid status
cat /etc/init.d/squid
ll /usr/local/squid/var/run/squid.pid
/etc/init.d/squid stop
ss -tlnup |grep squid
/etc/init.d/squid kill
/etc/init.d/squid stop
ss -tlnup |grep squid
squid -k kill
touch /usr/local/squid/var/run/squid.pid
/etc/init.d/squid stop
ll /usr/local/squid/var/run/squid.pid
ss -tlnup |grep squid
/etc/init.d/squid stop
ss -tlnup |grep squid
ll /usr/local/squid/var/run/squid.pid
touch /usr/local/squid/var/run/squid.pid
squid -k kill
pgrep suqid
pgrep squid
kill 86542
pgrep squid
kill -9 86542
pgrep squid
service squid start
service squid status
service squid stop
service squid status
service squid start
service squid status
pgrep squid
kill -9 `pgrep squid`
pgrep squid
squid -k
squid -h
rpm -c nginx
rpm -qc nginx
rpm -ql nginx
cd /usr/lib/systemd/system/
ll
ls
rm -rf /etc/init.d/
vim squid.serviec
vim squid.service
vim nginx.service
vim squid.service
netstat -natp | grep squid
systemctl daemon-reload
systemctl start squid
systemctl status squid
systemctl enable squid
systemctl status squid
systemctl stop squid
ps auxf |grep -v grep |grep squid
ss -tlnup |grep squid
systemctl status squid
systemctl reload squid
systemctl retart squid
systemctl restart squid
systemctl status squid
systemctl reload squid
ss -tlnup |grep squid
ps auxf |grep -v grep |grep squid
cat squid.service
netstat -natp | grep squid
cat /usr/local/squid/var/run/squid.pid
cat nginx.service
cat /usr/local/squid/var/run/squid.pid
cat squid.service
squid -h
cat /usr/local/squid/var/run/squid.pid
squi
cat /usr/local/squid/var/run/squid.pid
squid -k shutdown
cat /usr/local/squid/var/run/squid.pid
systemctl status squid
systemctl restart squid
systemctl status squid
systemctl start squid
systemctl status squid
systemctl stop squid
systemctl status squid
systemctl start squid
systemctl status squid
netstat -natp | grep squid
echo $?
systemctl stop squid
cat nginx.service
cat squid.service
systemctl stop squid
netstat -natp | grep squid
echo $?
netstat -natp | grep squid || exit 0
cd /run/
echo $?

cd /usr/lib/systemd/system
ll
cat nginx.service
cat squid.service
nginx -h
cat nginx.service
cat squid.service
systemctl start squid
ll /usr/local/squid/var/run/squid.pid
ss -tlnup
vim squid.service
ll /usr/local/squid/var/run/squid.pid
squid -k shutdown
ll /usr/local/squid/var/run/squid.pid
vim squid.service
systemctl status squid
systemctl start squid
systemctl daemon-reload
systemctl start squid
systemctl status squid
systemctl stop squid
systemctl start squid
squid -k parse
cd /usr/local/squid/var/cache/squid
ll
vim /etc/squid.conf
systemctl restart squid
systemctl status squid
iptables -vnL
systemctl status docker
iptables -vnL
docker ps
ip a
nmcli conn
route -n
ss -tlnup
tail -f /usr/local/squid/var/logs/access.log
ps auxf |grep -v grep |grep squid
ss -tlnup |grep 3128
ss -tlnup |grep squid
ss -tlnup |grep 3218
ss -tlnup |grep squid
ps auxf |grep -v grep |grep squid
ss -tlnup |grep 95991
ss -tlnup |grep 95
ss -tlnup
ps auxf |grep -v grep |grep squid
tail -f /usr/local/squid/var/logs/access.log
ss -tlnup |grep 3128
ps auxf |grep -v grep |grep squid
ss -tlnup |grep 3128
ss -tlnup
ss -tlnup |grep 3128
tail -f /usr/local/squid/var/logs/access.log
ss -tlnup
tail -f /var/log/nginx/access.log
systemctl status squid
cat /usr/lib/systemd/system/squid.service
cat /etc/squid.conf
cat /etc/squid.conf |grep log
tail -f /usr/local/squid/var/logs/access.log
cat /usr/local/squid/var/logs/access.log
cat /usr/local/squid/var/logs/access.log |grep name
cat /usr/local/squid/var/logs/access.log |grep query
cat /usr/local/squid/var/logs/access.log |grep www.baidu.com
tail -f /usr/local/squid/var/logs/access.log
iptables -vnL
iptables -A -s 192.168.127.0/24 -j DROP
iptables -A INPUT -s 192.168.127.0/24 -j DROP
iptables -vnL
ss -tlnup
tail -f /usr/local/squid/var/logs/access.log
tail -f /usr/local/squid/var/logs/cache.log
tail -f /usr/local/squid/var/logs/access.log
history |grep config
vim squid.service
tail -f /usr/local/squid/var/logs/access.log
top
ps axuf
ps axuf |grep make
ps axuf |grep make -j 4
ps axuf |grep 'make -j 4'
df -h
ll /usr/local/squid/var/run/squid.pid
watch ll /usr/local/squid/var/run/squid.pid
ll /usr/local/squid/var/run/squid.pid
vim /etc/sysctl.conf
echo 'net.ipv4.ip_forward = 1' >> /etc/sysctl.conf   👈配置路由转发，传统模式不需要。透明模式才需要
cat /etc/sysctl.conf
sysctl -p
ip a
iptables -vnL
iptables -t nat -I PREROUTING -i ens33 -s 192.168.0.0/16 -p tcp --dport 80 -j REDIRECT --to 3128
iptables -vnL
iptables -vnL -T NAT
iptables -vnL -t NAT
iptables -vnL -t nat
iptables -t nat -I PREROUTING -i ens33 -s 192.168.0.0/16 -p tcp --dport 443 -j REDIRECT --to 3128
iptables -vnL -t nat
iptables -vnL
iptables -vnL -t nat
iptables -vnL
iptables -F
iptables -t nat
iptables -vnL -t nat
iptables -vnL
iptables -vnL -t nat
iptables -P FORWARD ACCE
iptables -P FORWARD ACCEPT
iptables -vnL -t nat
iptables -vnL
iptables -vnL -t nat
ip a
systemctl restart iptables
systemctl restart docker
iptables -vnL
iptables -vnL -t nat
iptables -t nat -I PREROUTING -s 192.168.0.0/16 -p tcp --dport 443 -j REDIRECT --to 3128  这里其实要改成3129才对，一开始不知道。
iptables -t nat -I PREROUTING -s 192.168.0.0/16 -p tcp --dport 80 -j REDIRECT --to 3128
iptables -vnL -t nat
iptables -vnL
iptables -vnL -t nat
iptables -vnL
iptables -F
iptables -vnL
iptables -vnL -t nat
iptables -vnL
iptables -vnL -t nat
ip a
route -n
iptables -vnL
iptables -t nat -vnL
ss -tlnup
sysctl -p
iptables -F
iptables -F -t nat
iptables -vnL
iptables -vnL -t nat
iptables -t nat -I PREROUTING -s 192.168.0.0/16 -p tcp --dport 80 -j REDIRECT --to 3128
iptables -t nat -I PREROUTING -s 192.168.0.0/16 -p tcp --dport 443 -j REDIRECT --to 3128
iptables -t nat -vnL
vim /etc/squid.conf
systemctl restart squid
systemctl status squid
ss -tlnup
squid -k parse
ps auxf |grep -v grep |grep squid
vim /etc/squid.conf
systemctl restart squid
iptables -vnL -t nat
iptables -t nat -I PREROUTING -s 192.168.0.0/16 -p udp --dport 53 -j REDIRECT --to 192.168.126.2:53
iptables -t nat -I PREROUTING -s 192.168.0.0/16 -p udp --dport 53 -j REDIRECT --to 192.168.126.2 --port 53
iptables -t nat -I PREROUTING -s 192.168.0.0/16 -p udp --dport 53 -j REDIRECT --to 192.168.126.2:533
iptables -t nat -I PREROUTING -s 192.168.0.0/16 -p udp --dport 53 -j REDIRECT --to 192.168.126.2:53
iptables -t nat -I PREROUTING -s 192.168.0.0/16 -p udp --dport 53 -j REDIRECT --to
iptables -t nat -I PREROUTING -s 192.168.0.0/16 -p udp --dport 53 -j DNAT --to-destination 192.168.126.2:53   👈dns配置对的，就是需要加一个出向的SNAT。下面有。
iptables -vnL -t nat
ip a
iptables -vnL -t nat
cat /etc/resolv.conf
dig
dig www.baidu.com @192.168.126.2
iptables -vnL -t nat
dig www.baidu.com @192.168.127.144
iptables -vnL
ip a
iptables -vnL -t nat
tcpdump -nni
tcpdump -nn
tcpdump -nn host 192.168.10.2
tcpdump -nn host 192.168.127.144
tcpdump -nn udp host 192.168.127.144
tcpdump -nn udp and host 192.168.127.144
iptables -vnL
iptables -vnL -t nat
ss -tlnp
ss -tlnup
ip a
tcpdump -nni eth1 udp 53
tcpdump -nni eth1 udp port 53
tcpdump -nnvvvvvi eth1 udp port 3128
tcpdump -nnvvvvvi eth1 port 3128
iptables -vnL
iptables -vnL -t nat
tcpdump -nnvvvvvi eth1 port 3128
iptables -F
history |grep iptables
iptables -vnL -t nat
systemctl restart iptables
iptables -
iptables -h
iptables -Z
iptables -vnL -t nat
iptables -Z -t nat
iptables -vnL -t nat
ifconfig
tcpdump -nnvvvvvi eth0 port 3128
tcpdump -nnvvvvvi eth0
tcpdump -nnvvvvvi eth0 host 192.168.126.2
iptables -vnL
route -n
iptables -vnL -t nat
iptables -vnL
iptables -A POSTROUTING -j MASQUERADE
iptables -t nat -A POSTROUTING -j MASQUERADE
iptables -vnL -t nat
-A FORWARD -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -j TCPMSS --set-mss 1356
iptable -A FORWARD -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -j TCPMSS --set-mss 1356
iptables -A FORWARD -p tcp -m tcp --tcp-flags FIN,SYN,RST,ACK SYN -j TCPMSS --set-mss 1356   # 最后不需要
iptables -vnL
iptables -vnL -t nat
iptables -vnL -t nat -z
iptables -t nat -z
iptables -t nat -Z
iptables -vnL -t nat -Z
iptables -vnL -t nat
ss -tlnup
vim /etc/squid.conf
systemctl restart squid
ss -tlnup
vim /etc/squid.conf
systemctl restart squid
systemctl status squid
ss -tlnup
vim /etc/squid.conf
getenforce
systemctl status firewalld
systemctl status iptables
sudo lsof -i :3128
vim /etc/squid.conf
systemctl restart squid
vim /etc/squid.conf
systemctl restart squid
ss -tlnup
systemctl status squid
vim /etc/squid.conf
systemctl restart squid
ss -tlnup
iptables -vnL
iptables -vnL -t nat
vim /etc/squid.conf
systemctl restart squid
ss -tlnup
systemctl status squid
ss -tlnup
vim /etc/squid.conf
docker ps
docker stop gitlab
ss -tlnup
vim /etc/squid.conf
systemctl restart squid
ss -tlnup
vim /etc/squid.conf
top
systemctl restart squid
ss -tlnup
vim /etc/squid.conf
systemctl restart squid
ss -tlnup
vim /etc/squid.conf
systemctl restart squid
ss -tlnup
cat /etc/squid.conf
squid -k parse
vim /etc/squid.conf
iptables -vnL
vim /etc/squid.conf
systemctl restart squid
ss -tlnup
vim /etc/squid.conf
ip a
vim /etc/squid.conf
sockstat -l
yum search sockstat
ss -tlnup
vim /etc/squid.conf
systemctl restart squid
ss -tlnup
history |grep configure
vim /etc/squid.conf
systemctl restart squid
ss -tlnup
iptables -vnL
iptables -vnL -t nat
iptables -t nat -I PREROUTING -s 192.168.0.0/16 -p udp --dport 53 -j DNAT --to-destination 192.168.126.2:53
iptables -vnL -t nat
iptables -t nat -I PREROUTING -s 192.168.0.0/16 -p udp --dport 53 -j DNAT -port 3128
iptables -t nat -I PREROUTING -s 192.168.0.0/16 -p udp --dport 53 -j DNAT -to-port 3128
history |grep iptables |grep 3128
iptables -t nat -I PREROUTING -s 192.168.0.0/16 -p udp --dport 53 -j REDIREECT --to 3128
iptables -t nat -I PREROUTING -s 192.168.0.0/16 -p udp --dport 53 -j REDIRECT --to 3128
iptables -vnL -t nat
iptables -h
iptables -vnL -t nat
iptables -I -t nat
iptables -vnL
iptables -vnLI
iptables -vnLa
iptables -vnLA
iptables -h
iptables -vnL
iptables -vnL -t nat
iptables -vnL -t nat --line-numbers
iptables -t nat -D 2
iptables -D PREROUTING 2 -t nat
iptables -D PREROUTING 3,4 -t nat
iptables -D PREROUTING 3-4 -t nat
iptables -D PREROUTING 3 -t nat
iptables -D PREROUTING 34-t nat
iptables -D PREROUTING 4 -t nat
iptables -vnL -t nat
iptables -vnL -t nat --line-numbers
iptables -t nat -I 3 PREROUTING -s 192.168.0.0/16 -p udp --dport 80 -j REDIREECT --to 3128
iptables -t nat -I PREROUTING 3 -s 192.168.0.0/16 -p udp --dport 80 -j REDIREECT --to 3128
history |grep iptables |grep 3128
iptables -t nat -I 3 PREROUTING -s 192.168.0.0/16 -p tcp --dport 80 -j REDIREECT --to 3128
iptables -t nat -I PREROUTING 3 -s 192.168.0.0/16 -p tcp --dport 80 -j REDIREECT --to 3128
iptables -t nat -I PREROUTING -s 192.168.0.0/16 -p tcp --dport 80 -j REDIREECT --to 3128
iptables -t nat -I PREROUTING 3 -s 192.168.0.0/16 -p tcp --dport 80 -j REDIRECT --to 3128
iptables -vnL -t nat
iptables -vnL -t nat --line-numbers
iptables -t nat -D PREROUTING 2
iptables -vnL -t nat
history |grep iptables |grep 126.2
iptables -t nat -I PREROUTING -s 192.168.0.0/16 -p udp --dport 53 -j DNAT --to-destination 192.168.126.2:53
iptables -vnL -t nat
vim /etc/squid.conf
systemctl restart squid
yum search squid
cat /usr/lib/systemd/system/squid.service
dig
dig www.bing.com @10.100.8.2
nslookup
nslookup www.bing.com 10.100.8.2
while true;do nslookup www.bing.com 10.100.8.2;done
nslookup www.bing.com 10.100.8.2
dig www.bing.com @10.100.8.2
ip a
docker s
docker ps
docker ps -a
systemctl status squid
ss -tlnpu
cd /etc/squid/certs/
ll
cat openssl
ll
rm -rf openssl
ll
openssl req -new -newkey rsa:4096 -sha256 -days 3650 -nodes -x509 -keyout myCA.pem -out myCA.pem
ll
cat myCA.pem
ll
openssl x509 -in myCA.pem -text -noout
openssl x509 -in myCA.pem -outform DER -out myCA.der
ll
sz myCA.*
**0100000063f694
▒**0100000063f694
▒
cd /etc/squid/certs/
ll
sz
sz myCA.*
**0800000000022d
▒**0800000000022d
▒
ll
squid -v   👈类型nginx -v
/usr/lib64/squid/security_file_certgen -c -s /var/lib/ssl_db -M 4MB
find / -name security_file_certgen
rm -rf /usr/local/squid/
cd /squid/
ll
cd squid-6.10
ll
cd ..
l
ll
rm -rf squid-6.10
ll
tar xvf squid-6.10.tar.xz
ll
cd squid-6.10
ll
./configure --prefix=/usr/local/squid --sysconfdir=/etc --enable-arp-acl --enable-linux-netfilter --enable-linux-tproxy --enable-async-io=100 --enable-err-language="Simplify_Chinese" --enable-underscore --enable-poll --enable-gnuregex --with-openssl --enable-ssl-crtd --enalbe-ssl
ll
./configure --prefix=/usr/local/squid --sysconfdir=/etc --enable-arp-acl --enable-linux-netfilter --enable-linux-tproxy --enable-async-io=100 --enable-err-language="Simplify_Chinese" --enable-underscore --enable-poll --enable-gnuregex --with-openssl --enable-ssl-crtd --enable-ssl  👈编译的选项，重点后面三个需要开启。
make -j 4 && make install
vim /etc/squid.conf
cd cd /etc/squid
cd /etc/squid
ll
rm -rf certs/
ll
mkdir ssl_cert
ll
chown squid:squid ssl_cert
ll
cd ..
ll -d
ll -d squid
cd squid
ll
cd ssl_cert/
ll
cd ..
ll
chmod 700 ssl_cert   # 配置文件需要有权限读取
ll
cd ssl_cert/
ll
openssl req -new -newkey rsa:2048 -sha256 -days 365 -nodes -x509 -extensions v3_ca -keyout myCA.pem -out myCA.pem
ll
rpm -ql openssl
rpm -qc openssl
rpm -ql openssl
rpm -ql openssl |grep cnf
rpm -ql openssl |grep conf
rpm -ql openssl |grep cnf
rpm -qf /etc/pki/tls/openssl.cnf
vim /etc/pki/tls/openssl.cnf   # 没必要，这里是csr申请server证书的时候配置alter_name的。用来浏览器显示安全的，不过squid这里不需要。
ll
rm -rf myCA.pem
openssl req -new -newkey rsa:2048 -sha256 -days 365 -nodes -x509 -extensions v3_ca -keyout myCA.pem -out myCA.pem  # 私钥和证书在一个文件的产生方式。
ll
openssl x509 -in myCA.pem -text -noout  # 明文查看证书的方式
find / -name security_file_certgen
vim /etc/pki/tls/openssl.cnf
vim /etc/squid.conf
squid -k parse
squid -v
ll /usr/local/squid/
tree /usr/local/squid/
systemctl restart squid
systemctl status squid
ss -tlnup
ll
systemctl status squid
ll /usr/local/squid/sbin/squid
ll /usr/local/ -d
ll /usr/local/squid/ -d
history |grep chown
ll /usr/local/squid/var/
chown -R squid.squid /usr/local/squid/var/
systemctl restart squid
ss -tlnu
ll /var/lib/ -d
chmod +w /var/lib/
ll /var/lib/ -d
chmod o+w /var/lib/
ll /var/lib/ -d
systemctl restart squid
ss -tlnu
security_file_certgen
find / -name security_file_certgen
vim /etc/squid.conf
/usr/local/squid/libexec/security_file_certgen -c -s /var/lib/ssl_db -M 4MB  👈初始化db不然squid配置ssl起不来，不过人家会不断尝试初始化，手动敲了这条就行了。
ss -tlnu
iptables -vnL
iptables -vnL -t nat
systemctl stop docker
iptables -vnL -t nat
iptables -F
iptables -vnL -t nat
history |grep iptables
iptables -t nat -A POSTROUTING -j MASQUERADE   👈出向SNAT
iptables -t nat -I PREROUTING -s 192.168.0.0/16 -p tcp --dport 80 -j REDIRECT --to 312
iptables -D PREROUTING
iptables -vnL -t nat
iptables -vnL -t nat --line-numbers
history |grep iptables |grep -D
history |grep iptables |grep '-D'
history |grep iptables |grep '\-D'
iptables -t nat -D PREROUTING 1
iptables -t nat -I PREROUTING -s 192.168.0.0/16 -p tcp --dport 80 -j REDIRECT --to 3128
iptables -t nat -I PREROUTING -s 192.168.0.0/16 -p tcp --dport 443 -j REDIRECT --to 3129
iptables -vnL -t nat
iptables -vnL -t nat --line-numbers
iptables -t nat -D PREROUTING 1
iptables -vnL -t nat --line-numbers
iptables -t nat -I PREROUTING -s 192.168.0.0/16 -p tcp --dport 80 -j REDIRECT --to 3128  👈 http打到3128
iptables -vnL
iptables -t nat -I PREROUTING -s 192.168.0.0/16 -p tcp --dport 443 -j REDIRECT --to 3129  👈https的打到3129
iptables -vnL -t nat
ll
sz myCA.pem
**0800000000022d
▒**0800000000022d
▒
ll
openssl x509 -in myCA.pem -outform DER -out myCA.der  👈windows认.der后缀
ll
sz myCA.der
**0800000000022d
▒**0800000000022d
▒
ll
history
history |awk '{for(i=5;i<=NF;i++){printf("%s ",$i)};printf("\n")}'
history |awk '{for(i=5;i<=NF;i++){printf("%s ",$i)};printf("\n")}' |grep -Ev 'll'
history |awk '{for(i=5;i<=NF;i++){printf("%s ",$i)};printf("\n")}' |grep -Ev 'll|history'
history |awk '{for(i=5;i<=NF;i++){printf("%s ",$i)};printf("\n")}'
[root@mysql-2 ssl_cert]#

```



**这是所有都ok后的cnf👇**

```bash
[root@mysql-2 ssl_cert]# cat /etc/squid.conf
#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 0.0.0.1-0.255.255.255  # RFC 1122 "this" network (LAN)
acl localnet src 10.0.0.0/8             # RFC 1918 local private network (LAN)
acl localnet src 100.64.0.0/10          # RFC 6598 shared address space (CGN)
acl localnet src 169.254.0.0/16         # RFC 3927 link-local (directly plugged) machines
acl localnet src 172.16.0.0/12          # RFC 1918 local private network (LAN)
acl localnet src 192.168.0.0/16         # RFC 1918 local private network (LAN)
acl localnet src fc00::/7               # RFC 4193 local private network range
acl localnet src fe80::/10              # RFC 4291 link-local (directly plugged) machines

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http

#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# This default configuration only allows localhost requests because a more
# permissive Squid installation could introduce new attack vectors into the
# network by proxying external TCP connections to unprotected services.
http_access allow localhost

# The two deny rules below are unnecessary in this default configuration
# because they are followed by a "deny all" rule. However, they may become
# critically important when you start allowing external requests below them.

# Protect web applications running on the same server as Squid. They often
# assume that only local users can access them at "localhost" ports.
http_access deny to_localhost

# Protect cloud servers that provide local users with sensitive info about
# their server via certain well-known link-local (a.k.a. APIPA) addresses.
http_access deny to_linklocal

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# For example, to allow access from your local networks, you may uncomment the
# following rule (and/or add rules that match your definition of "local"):
# http_access allow localnet

# And finally deny all other access to this proxy
http_access allow all
http_access deny all

# Squid normally listens to port 3128
http_port 8080
http_port 3128 intercept
https_port 3129 intercept ssl-bump cert=/etc/squid/ssl_cert/myCA.pem generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
sslcrtd_program /usr/local/squid/libexec/security_file_certgen -s /var/lib/ssl_db -M 4MB
acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump bump all


# Uncomment and adjust the following to add a disk cache directory.
#cache_dir ufs /usr/local/squid/var/cache/squid 100 16 256
cache_effective_user squid
cache_effective_group squid
# Leave coredumps in the first cache dir
coredump_dir /usr/local/squid/var/cache/squid

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
[root@mysql-2 ssl_cert]#

```



这是服务

```bash
[root@mysql-2 squid]# cat /usr/lib/systemd/system/squid.service
[Unit]
Description=Squid Web Proxy
After=network.target

[Service]
Type=forking
PIDFile=/usr/local/squid/var/run/squid.pid
ExecStart=/usr/local/squid/sbin/squid
ExecStop=/usr/local/squid/sbin/squid -k shutdown
#ExecReload=kill -HUP $(cat /usr/local/squid/var/run/squid.pid)
ExecReload=/bin/sh -c 'kill -HUP $(cat /usr/local/squid/var/run/squid.pid)'

#ExecReload=/usr/local/squid/sbin/squid -k reconfigure
#ExecStartPre=/bin/sh -c 'netstat -natp | grep squid &> /dev/null || exit 0'
#ExecStartPost=/bin/sh -c 'echo "squid is starting..."'
ExecStopPost=/bin/sh -c 'rm -f /usr/local/squid/var/run/squid.pid'

[Install]
WantedBy=multi-user.target

[root@mysql-2 squid]#

```

注意上图的kill 要比reconfiure有用，速度快，而且要用/bin/sh -c去运行，否则报错找不到pid文件。

<img src="2-网络架构.assets/image-20241012145949455.png" alt="image-20241012145949455" style="zoom:33%;" />











还有一个补充，缓存的操作👇，当然不要用squid去启动哦，只是看squid -z那一行

![image-20241011141108254](2-网络架构.assets/image-20241011141108254.png)

我的操作

![image-20241011141148553](2-网络架构.assets/image-20241011141148553.png)

上图初始化也报错了，那就stop 掉squid继续

![image-20241011141926727](2-网络架构.assets/image-20241011141926727.png)



此时cache缓存就初始化了

![image-20241011141941757](2-网络架构.assets/image-20241011141941757.png)

启动squid是OK的，同时看日志可见缓存的信息

![image-20241011142151721](2-网络架构.assets/image-20241011142151721.png)

其实思路是对的，因为你ssl卸载降低了用户的速度，你又缓存将这个速度又补回去了。







下午研究下过滤配置吧



### URL-acl

1、首先我要独立的过滤文件

有的还是参考https://www.cnblogs.com/weq0805/p/15242170.html

![image-20241011142609478](2-网络架构.assets/image-20241011142609478.png)



<img src="2-网络架构.assets/image-20241011143747208.png" alt="image-20241011143747208" style="zoom: 33%;" />



看着不错，试试

然后考虑文件的频繁修改和生效，需要修改reload底层cli，用kill -HUP而不用 -k reconfigure-太慢了

![image-20241012150101691](2-网络架构.assets/image-20241012150101691.png)





### 注意url过滤域名和ip的两个url都要写

否则就是域名的https://xxx.yy.zz/123  干掉了，但是xxx.yy.zz对应的ip http://a.b.c.d/123没干掉。

白名单和黑名单 要针对一个url要写域名的url和ip的url两行的



chrome的无痕模式是不是有什么特殊性，

firefox 和 firefox 无痕 都可以打开http://xxx.yy.zz/annoucement

chrome 可以，chrome无痕不行 

https://blog.csdn.net/u010059669/article/details/135158912

这就是原因👆

![](2-网络架构.assets/image-20241012175845837.png)

也就是无痕的问题👇关键这个httpupgrade是chrome的优化，但是在无痕下需要点击 继续访问，而这个点击的动作 结合 squid过滤就无法 继续点击了，直接就干掉了。所有 要关闭这个httpgrade试试。

![image-20241012175919621](2-网络架构.assets/image-20241012175919621.png)

第二个是https的，回退成第一个307了

![image-20241012180005728](2-网络架构.assets/image-20241012180005728.png)



之前是没有这一步的，现在chrome的无痕加了个这个👆。 307是HTTPS回退http的代码，不是是http升到https👇

![image-20241012180353463](2-网络架构.assets/image-20241012180353463.png)



尝试关闭这个无痕模式的httpupgrades，无痕用不了插件的。

https://blog.csdn.net/u010059669/article/details/135158912



上面的问题，什么问题：就是squid做了ip和域名的  url过滤后 firefox 有痕 和 无痕 都可以打开，而chrome 有痕可以，无痕NG的问题解决了，就是有痕的模式下没有192.168.200.18:443这么一个connect，而无痕存在，chrome的无痕需要加一个IP:443的放行



这是chrome无痕下访问http://xxn.it/announcement的情况，注意下图明显看到是https的，要注意是自己跳过去的，和我无关，也无需关注这件事情。

![image-20241014102302005](2-网络架构.assets/image-20241014102302005.png)



通过观察access.log发现有一条

![image-20241014102419994](2-网络架构.assets/image-20241014102419994.png)



于是在过滤url的文件里补一个IP和443就可以弹出这个点击继续的页面了

![image-20241014102530022](2-网络架构.assets/image-20241014102530022.png)

此时继续就OK了，自此完成无痕下的url放行优化。



然后还梳理一个这个问题

就是页面点击首页可以进去，首页其实是squid白名单里没有放行的，也就是deny的嘛，原因是访问url的时候加载了部分的首页资源。所以可以打开些



squid只放行了

![image-20241014104244296](2-网络架构.assets/image-20241014104244296.png)



通过先打开http://lxxn.it/announcement

再点击页面的首页就进去了

虽然squid禁止了log有，

![image-20241014104227199](2-网络架构.assets/image-20241014104227199.png)



但是其实之前访问子页面的时候就加载了好多👇，所以可以站内点击进去，但是

![image-20241014104358236](2-网络架构.assets/image-20241014104358236.png)

但是重新发起就不行了👇

①打开squid放行的url ok的

![image-20241014105006658](2-网络架构.assets/image-20241014105006658.png)





②然后点击页面上的首页就进入了squid没有放开的页面

![image-20241014105107793](2-网络架构.assets/image-20241014105107793.png)



③再次直接访问这个页面可见是不行的

![image-20241014105158038](2-网络架构.assets/image-20241014105158038.png)



总之这块差强人意吧，我说差强人意，不代表 别人可以这么说，特别是不懂细节的人，额b（￣▽￣）d　好像也没人跟我这么说。。。







# 工作案例-如何监管开发内网的HTTPS的payload也就是内容过滤





https://www.cnblogs.com/studio313/archive/2011/09/22/2184969.html



https://www.theopensourcerer.com/2014/04/how-to-install-a-squid-dansguardian-content-filter-on-ubuntu-server/![image-20241014140817595](2-网络架构.assets/image-20241014140817595.png)

我也加上了这一段，除了200 MB要有空格以外还需要删除log_fqdn off这一句过失的命令，其他都没有影响squid的启动。但愿能够起到优化的作用。

测试了下logfile_roate 10 有效果👇

![image-20241014141543395](2-网络架构.assets/image-20241014141543395.png)





dansguardian太老了，应该是收费了吧，所以换成c-icap继续研究

https://c-icap.sourceforge.net/

![image-20241014152711820](2-网络架构.assets/image-20241014152711820.png)

挺好，天生一家👆squid和icap，opnsense那里好像叫o-c-icap好像，回头折腾opnsense的时候再说，要弄的！

看看github上维护很蛮新的

https://github.com/c-icap/c-icap-server

yum后的service文件里的启动用户和组要注释掉，否则起不来。。。。而且nginx和squid都是fork的形式启动的也不一样。先root吧



![image-20241014162612113](2-网络架构.assets/image-20241014162612113.png)





https://blog.csdn.net/liangzhao_jay/article/details/12575839

https://cloud.tencent.com/developer/ask/sof/116943622

https://www.egirna.com/blog/news-2/how-to-configure-squid-proxy-with-icap-10

👇这个是重点

https://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/C-ICAP



opnsense是 squid+c-icap+clamav+redis的，好复杂

不过clamav既然能扫病毒，应该就能扫ftp、pdf、之类的正常文件啊。

https://www.cnblogs.com/gaoyuechen/p/9019098.html这是clamav软件单独的

试下👆安装试验下

![image-20241015171128319](2-网络架构.assets/image-20241015171128319.png)

说这个是默认病毒库

![image-20241015171429314](2-网络架构.assets/image-20241015171429314.png)



![image-20241015172638635](2-网络架构.assets/image-20241015172638635.png)



升级病毒库的cli在clamav-devel包里，

![image-20241015172709166](2-网络架构.assets/image-20241015172709166.png)

有了👇

![image-20241015172725677](2-网络架构.assets/image-20241015172725677.png)

https://wiki.ubuntu.org.cn/ClamAV

但是病毒库升上去也就是下载下来，有可能导致oom的

我这里不加内存了，删掉一个库测试

![image-20241015174919895](2-网络架构.assets/image-20241015174919895.png)

既然能扫出来文件，网络流量里的日志也许也有这种文件名称吧。





https://blog.csdn.net/lionzl/article/details/7749334

这个不错👆

squid 、 c-icap、clamav之间配合，肯定要编译的时候带上一些模块的

![image-20241015175552749](2-网络架构.assets/image-20241015175552749.png)

不过可惜，他没有带上ssl，所以他没法对ssl 也就是https杀毒

这是👇opnsense的编译选项

![image-20241015182702677](2-网络架构.assets/image-20241015182702677.png)



然后yum 安装squid 一样选项多多

![image-20241015182832418](2-网络架构.assets/image-20241015182832418.png)

就是版本低了些



https://wiki.ubuntu.org.cn/ClamAV

clamav要有conf，看来是clamav-daemon了，可惜我们找到这个包

![image-20241015175844783](2-网络架构.assets/image-20241015175844783.png)



竟然有squidclamav这个，看名字就是集成好的咯，算了，我还是分开来学吧

![image-20241015180004958](2-网络架构.assets/image-20241015180004958.png)



![image-20241015180327512](2-网络架构.assets/image-20241015180327512.png)

👆说明安装2个包其实附带安装了很多的。



https://blog.csdn.net/ygm_linux/article/details/60882597

这个也不错👆





https://www.clamav.net/

这个是官网👆，看着酷倒是挺酷，就是有点像病毒。。。



https://docs.clamav.net/appendix/CvdPrivateMirror.html?highlight=squid#use-an-http-proxy

![image-20241015182312286](2-网络架构.assets/image-20241015182312286.png)



![image-20241015182422386](2-网络架构.assets/image-20241015182422386.png)





<img src="2-网络架构.assets/image-20241015183502984.png" alt="image-20241015183502984" style="zoom: 33%;" />





瞥了这么多攻略，找一天时间开干



## 实验

走一遍https://blog.csdn.net/lionzl/article/details/7749334

yum 安装squid就行

由于我这有一个之前编译的版本，所以ln -s下就好了

![image-20241016100045502](2-网络架构.assets/image-20241016100045502.png)

还得弄证书，唉~，不用，直接把之前编译的配置文件复制过来就行了。

```
Icap client for squid配置：
icap_enable on
icap_preview_enable on
icap_preview_size 128
icap_send_client_ip on
icap_service service_avi_req reqmod_precache 0 icap://localhost:1344/srv_clamav
icap_service service_avi respmod_precache 1 icap://localhost:1344/srv_clamav
icap_class class_antivirus service_avi
icap_access class_antivirus allow all
icap_class class_antivirus_req service_avi_req
icap_access class_antivirus_req allow all
```

继续https://blog.csdn.net/lionzl/article/details/7749334



<img src="2-网络架构.assets/image-20241016114616504.png" alt="image-20241016114616504" style="zoom:33%;" />



yum的clam的配置文件如下，不是箭头指的那个，而是freshclam.conf才是，上图行内容在该文件里都有

<img src="2-网络架构.assets/image-20241016114722272.png" alt="image-20241016114722272" style="zoom:44%;" />



既然有配置文件，说明有服务啊，看来我还少安装一个服务

![image-20241016115520738](2-网络架构.assets/image-20241016115520738.png)

神了~ install会给你自动对应过去，search没有。

privodes有的，靠谱

![image-20241016115913908](2-网络架构.assets/image-20241016115913908.png)

结论：search的名称要对，provides 一定程度上可以给你转换你在clamav后面补一个-server，人家自动识别了。



看这个https://www.cnblogs.com/hkgan/p/17346628.html





了解下log和病毒库

![image-20241016141255339](2-网络架构.assets/image-20241016141255339.png)



![image-20241016141345108](2-网络架构.assets/image-20241016141345108.png)



systemctl status clamav-freshclam里也有，不过看不全咯，因为一些动作pre post都是启动后或stop后的动作记录是由屏显宽度的👇daily的就上滚掉了。

![image-20241016141504399](2-网络架构.assets/image-20241016141504399.png)



然后弄c-icap

起不来，发现是clamd没起来



<img src="2-网络架构.assets/image-20241016152746441.png" alt="image-20241016152746441" style="zoom: 40%;" />

没起来就看下https://www.cnblogs.com/hkgan/p/17346628.html

![image-20241016152911441](2-网络架构.assets/image-20241016152911441.png)

再看看

![image-20241016154017457](2-网络架构.assets/image-20241016154017457.png)



<img src="2-网络架构.assets/image-20241016154044368.png" alt="image-20241016154044368" style="zoom:50%;" />





找到原因了👇，sock没给，

![image-20241016155311263](2-网络架构.assets/image-20241016155311263.png)

然后恢复service文件吧，上图👆是排错复制了一份service文件去掉了里面的变量。

用传参的方式来启动clamd服务

![image-20241016155419226](2-网络架构.assets/image-20241016155419226.png)

有进步，但是

![image-20241016155548223](2-网络架构.assets/image-20241016155548223.png)

kaill掉之前的进程，restart就行了，可能之前有手动的残留？应该是的，复现了就是手动用service里的cli启动后，ctrl c退出，再用service启动，就这样了，正常现象。干净的进程 systemctl start就行了



ok了

![image-20241016160131493](2-网络架构.assets/image-20241016160131493.png)



然后启动c-icap服务发现

![image-20241016160654045](2-网络架构.assets/image-20241016160654045.png)

还是要注释掉 Service antivirus_module srv_clamav.so  才能起来

可能是模块缺失

<img src="2-网络架构.assets/image-20241016160742818.png" alt="image-20241016160742818" style="zoom:43%;" />





<img src="2-网络架构.assets/image-20241016160810744.png" alt="image-20241016160810744" style="zoom:50%;" />





![image-20241016161042890](2-网络架构.assets/image-20241016161042890.png)





![image-20241016161138360](2-网络架构.assets/image-20241016161138360.png)

试试



![image-20241016161522412](2-网络架构.assets/image-20241016161522412.png)



看来不是xxx.so文件，还需要编译的👆

看看yum的，之前我是yum的

![image-20241016161748128](2-网络架构.assets/image-20241016161748128.png)

装一下c-icap-modules模块

果然有了很多

![image-20241016161827348](2-网络架构.assets/image-20241016161827348.png)

删掉tmp吧，哈哈不要自己编译了

如果自己安装呢，试试

![image-20241016162744095](2-网络架构.assets/image-20241016162744095.png)



<img src="2-网络架构.assets/image-20241016162804635.png" alt="image-20241016162804635" style="zoom:40%;" />



<img src="2-网络架构.assets/image-20241016162945055.png" alt="image-20241016162945055" style="zoom:40%;" />







![image-20241016163346084](2-网络架构.assets/image-20241016163346084.png)



总之再次创建m4文件夹，然后注释到 版本的初始化方式(大概)，打开0.3.2自定义版本就行了

![image-20241016163423911](2-网络架构.assets/image-20241016163423911.png)



<img src="2-网络架构.assets/image-20241016163635852.png" alt="image-20241016163635852" style="zoom:40%;" />





![image-20241016163522691](2-网络架构.assets/image-20241016163522691.png)

configure文件就有了，可以编译安装了



 我还是指定一个prefix吧

![image-20241016163927710](2-网络架构.assets/image-20241016163927710.png)



看看yum的就知道编译安装大概要哪些包了

![image-20241016164051137](2-网络架构.assets/image-20241016164051137.png)



继续手动编译

![image-20241016164118650](2-网络架构.assets/image-20241016164118650.png)

估计这里就是关键了，肯能是这个 选项一指定，就模块安进去了，大概吧

通过./configure -h可见 prefix不是瞎指定的，而是要知道c-icap安装prefix里去的

![image-20241016164308171](2-网络架构.assets/image-20241016164308171.png)



移走两个yum安装的模块，待会看编译安装是否补进来

![image-20241016164406137](2-网络架构.assets/image-20241016164406137.png)



没找打config的选项，但是找到了c-icap的选项，试试

![image-20241016164619633](2-网络架构.assets/image-20241016164619633.png)



![image-20241016165236902](2-网络架构.assets/image-20241016165236902.png)

然后make && make install报错

![image-20241016165515410](2-网络架构.assets/image-20241016165515410.png)

然后make 继续报错

![image-20241016165543571](2-网络架构.assets/image-20241016165543571.png)

放弃，就用yum吧。。。



然后改一下配置文件里的模块，找不到的就用看着像的替换试试，结果，不行

突然发现c-icap yum安装的 没有启动 --with-clamav。。。。。我日，yum坑我

![image-20241016170755920](2-网络架构.assets/image-20241016170755920.png)

先继续用yum的c-icap试试看

怎么试，就是找srv_clamav.so这个模块

算了 编译吧，不是编译c-icap-modules，而是使用--with-clamav 编译c-icap



### 重新编译安装c-icap

https://c-icap.sourceforge.net/download.html

<img src="2-网络架构.assets/image-20241016171800185.png" alt="image-20241016171800185" style="zoom: 50%;" />



![image-20241016172717497](2-网络架构.assets/image-20241016172717497.png)







![image-20241016172945712](2-网络架构.assets/image-20241016172945712.png)



![image-20241016172916717](2-网络架构.assets/image-20241016172916717.png)



得再下一个c-icap-modules-0.5.7

![image-20241016173427649](2-网络架构.assets/image-20241016173427649.png)

开搞

```bash
./configure --enable-static --prefix=/usr/local/c-icap/

make -j 4 && make install
```

![image-20241016173548763](2-网络架构.assets/image-20241016173548763.png)



![image-20241016173627189](2-网络架构.assets/image-20241016173627189.png)



没报错

![image-20241016173644650](2-网络架构.assets/image-20241016173644650.png)

文件有了

![image-20241016173715887](2-网络架构.assets/image-20241016173715887.png)

看看模块文件，因为是--enable-static的，所以有很多xx.so，但是没有clamav的，肯定啊，人家官网都说了要第二个包

![image-20241016174118841](2-网络架构.assets/image-20241016174118841.png)





大不了参考yum安装得服务自己写一个

然后继续安装第二个modules包

![image-20241016174313194](2-网络架构.assets/image-20241016174313194.png)



![image-20241016174533444](2-网络架构.assets/image-20241016174533444.png)



```bash
./configure --with-c-icap=/usr/local/c-icap/ --with-clamav=/usr/sbin/clamd
```

![image-20241016174517241](2-网络架构.assets/image-20241016174517241.png)

好像失败了

![image-20241016174623556](2-网络架构.assets/image-20241016174623556.png)

那么就clamav也编译安装一下啊？

![image-20241016175142589](2-网络架构.assets/image-20241016175142589.png)



![image-20241016175424613](2-网络架构.assets/image-20241016175424613.png)



https://blog.csdn.net/lionzl/article/details/7749334

```bash
./configure --prefix=/usr/local/clamav --with-dbdir=/usr/clamav
```

不行了，要安这个来👇

https://docs.clamav.net/manual/Installing/Installing-from-source-Unix.html

安装依赖

```bash
python3 -m pip install  cmake pytest
改用 

    dnf install -y \
      gcc gcc-c++ make python3 python3-pip valgrind \
      bzip2-devel check-devel json-c-devel libcurl-devel libxml2-devel \
      ncurses-devel openssl-devel pcre2-devel sendmail-devel zlib-devel
  
  
yum install cmake
dnf install -y cargo rust

```

![image-20241016180526955](2-网络架构.assets/image-20241016180526955.png)



改用yum安装



![image-20241016180936510](2-网络架构.assets/image-20241016180936510.png)





![image-20241016183236727](2-网络架构.assets/image-20241016183236727.png)



```bash
yum -y install bindgen
```



还剩一个了

![image-20241016183402820](2-网络架构.assets/image-20241016183402820.png)



```bash
yum -y install bindgen
```

![image-20241016183437998](2-网络架构.assets/image-20241016183437998.png)



都装好了，还是不行

![image-20241016193922448](2-网络架构.assets/image-20241016193922448.png)



![image-20241017091419941](2-网络架构.assets/image-20241017091419941.png)



![image-20241017091510777](2-网络架构.assets/image-20241017091510777.png)



![image-20241017091537698](2-网络架构.assets/image-20241017091537698.png)



![image-20241017091621066](2-网络架构.assets/image-20241017091621066.png)



json-c搞不定，继续

<img src="2-网络架构.assets/image-20241017092951635.png" alt="image-20241017092951635" style="zoom:50%;" />





现在就有了

![image-20241017093019735](2-网络架构.assets/image-20241017093019735.png)



继续

![image-20241017093049629](2-网络架构.assets/image-20241017093049629.png)



![image-20241017093104467](2-网络架构.assets/image-20241017093104467.png)





![image-20241017094209487](2-网络架构.assets/image-20241017094209487.png)



https://blog.csdn.net/cnm_King/article/details/136546478

![image-20241017094244210](2-网络架构.assets/image-20241017094244210.png)



yum update吧

不行再试试这个

https://rockylinux.pkgs.org/9/rockylinux-crb-x86_64/sendmail-milter-devel-8.16.1-11.el9.x86_64.rpm.html



update 磁盘爆了，挂了。。重新弄







===

<img src="2-网络架构.assets/image-20241018114539905.png" alt="image-20241018114539905" style="zoom:50%;" />





<img src="2-网络架构.assets/image-20241018114805505.png" alt="image-20241018114805505" style="zoom:40%;" />







<img src="2-网络架构.assets/image-20241018115833068.png" alt="image-20241018115833068" style="zoom:43%;" />







<img src="2-网络架构.assets/image-20241018120034841.png" alt="image-20241018120034841" style="zoom:33%;" />



算了，教程都太老了，还用用官方的squidclamav这个组件吧，这下就4个软件配合。。。

































# 如何理解salt 盐

不废话，show u the picture

![image-20241010173347460](2-网络架构.assets/image-20241010173347460.png)

怎么样，openssl和mkpasswd两个cli工具都可以知道哈希算法和salt的情况下，针对源数据cisco12345，生成一样的哈希值。

mkpasswd 的-S是salte，-s是stdin，也就是密码也就是源数据被加密的数据

openssl 没有-s来做stdin，但是可以利用xargs直接一行搞定。大不了明文嘛~~哈哈，就是展示用的。





