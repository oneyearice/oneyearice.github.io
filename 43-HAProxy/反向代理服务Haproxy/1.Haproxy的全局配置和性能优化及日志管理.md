# 1.Haproxy的全局配置和性能优化及日志管理.md



# 1、全局配置



![image-20240806133750292](1.Haproxy的全局配置和性能优化及日志管理.assets/image-20240806133750292.png)



而这个配置文件的指定也是自己写的service文件

![image-20240806133849716](1.Haproxy的全局配置和性能优化及日志管理.assets/image-20240806133849716.png)



然后配置文件里整体分为两大块：全局和代理

![image-20240806134056088](1.Haproxy的全局配置和性能优化及日志管理.assets/image-20240806134056088.png)





![image-20240806132932111](1.Haproxy的全局配置和性能优化及日志管理.assets/image-20240806132932111.png)



**chroot**有点类似os.chdir吧，就是修改工作目录的，不过change root就是修改工作目录的根了，ls /实际就是chroot后面的目录了，主要是安全。

![image-20240806134626369](1.Haproxy的全局配置和性能优化及日志管理.assets/image-20240806134626369.png)





**deamon** 后台运行，如果将来制作为容器，就要拿掉这行，前台运行。



**stats socket /var/lib/haproxy/haproxy.sock mode 600 level admin process 1 **

1、首先mysql也好，docker也罢，都是通过socket和服务进程通信的，socket可以是tcp/ip套接字，也可以是套接字文件。

2、文件就是600权限

3、level admin，是运行通过这个socket文件对其服务进行admin级别的管理

4、process 1就是，只存在和主进程的通信或者主进程下的第一个子进程通信？



**uid gid**
这个应该是创建haproxy这个用户的时候指定的id了，不过我没有指定id，而是指定用户也行的。

，貌似是用来执行worker进程--我理解就是和nginx一样的进程咯：

<img src="1.Haproxy的全局配置和性能优化及日志管理.assets/image-20240806145036243.png" alt="image-20240806145036243" style="zoom:50%;" />

不指定就是root运行了



## 看看多线程和CPU绑定

**nbthread vs nbproc**

nbproc就是和nginx一样多个子进程了

nbthread就是进程下的多线程了。



2.5之前的haproxy用nbproc开启多个wokers进程，这个worker和nginx一个意思

之后的版本就用nbthread来做多个worker，不过没有看到多个worker，因为多个worker也是跑在一个子进程下(33740 pid)的，所以ps aux只会看到一个root 跑起来的haproxy主进程和一个haproxy用户跑起来的一个子进程

![image-20240806145706758](1.Haproxy的全局配置和性能优化及日志管理.assets/image-20240806145706758.png)

而多个线程可以通过pstree -p去观察到，一般就是N个cpu，就开启N-1个线程来着

![image-20240806162757683](1.Haproxy的全局配置和性能优化及日志管理.assets/image-20240806162757683.png)



3个线程的配置nbthread 3，就是开启2个线程，同样是一个子进程下开启的

![image-20240806162859999](1.Haproxy的全局配置和性能优化及日志管理.assets/image-20240806162859999.png)



即使CPU实际就2个，同样可以开到8个线程，反正就是绑在一个子进程下的

![image-20240806163028672](1.Haproxy的全局配置和性能优化及日志管理.assets/image-20240806163028672.png)







这是nginx的worker进程，不过id应该是发生变化了，导致找不到用户了，这个不用管，此图就是看下nginx也是多个worker来着。 不是找不到用户，是docker运行的

![image-20240806143731099](1.Haproxy的全局配置和性能优化及日志管理.assets/image-20240806143731099.png)

不是找不到用户，是docker运行的就这样





haproxy好像是花括号，也就是说haproxy是 线程在跑的，和主线程享用同样的内存空间。

而nginx是子进程再跑的，不是和父进程一个内存空间。

![image-20240806145921639](1.Haproxy的全局配置和性能优化及日志管理.assets/image-20240806145921639.png)

这还有一个区别

![image-20240806154730715](1.Haproxy的全局配置和性能优化及日志管理.assets/image-20240806154730715.png)



而haproxy因为是用的多线程，所以看到了3个线程开在了一个74172下，而74173和74174和74175看不到，应该是开在74172这个子进程里的内存空间了。是共用的内存空间，所以进程ID不会再次显示出来了。

![image-20240806154828571](1.Haproxy的全局配置和性能优化及日志管理.assets/image-20240806154828571.png)



haproxy就是一个总入口，硬盘要求不高不存在存数据的关键要求除非你开log？，正常就是CPU内存要给多谢，转发数据代理这块。

然后由于是多线程的，不知道CPU的使用率会不会出现盯着一个CPU干的情况。。。

所以就有了线程绑定cpu的配置



**cpu-map auto**
原来2.5之前的版本是进程，就用cpu-map 1 0 (# 1 woker 进程 和cpu0进行绑定，多个就写多行 ) 这种方式来绑定进程和cpu；

现在2.5之后的版本只能是线程，所以的用cpu-map auto: 1/1-8 0-7 (# 1-8的worker 线程和0-7的cpu分别绑定 ) 来绑线程和cpu了

![image-20240806163037383](1.Haproxy的全局配置和性能优化及日志管理.assets/image-20240806163037383.png)

上图是2核，开了8个线程，然后都是在一个子进程下的。尝试绑到cpu上去



![image-20240806163832006](1.Haproxy的全局配置和性能优化及日志管理.assets/image-20240806163832006.png)



通过systemctl status haproxy可见，看不全？键盘左右键可以看咯👇

![recording](1.Haproxy的全局配置和性能优化及日志管理.assets/recording.gif)



找了半天没找到找个日志文件，但是除了上图的方法看全，还可以这么导出来看全

![image-20240806165541503](1.Haproxy的全局配置和性能优化及日志管理.assets/image-20240806165541503.png)

👆这是journalctl -u haproxy看的，和systemctl status haproxy一样看不全，

但是可以导出来

journalctl -u haproxy |tail -10  > xxxxx

![image-20240806165646447](1.Haproxy的全局配置和性能优化及日志管理.assets/image-20240806165646447.png)

人家说要么帮帮好，要么不绑，那么问题来了，不绑的话你会自动分担到多个cpu核上吗?



观察CPU绑定的情况

```shell
ps axo pid,cmd,psr 和 ps axo pid,cmd,psr -L 
     
     -L     Show threads, possibly with LWP and NLWP columns.
```

-L 用来显示线程信息的

![image-20240806171726507](1.Haproxy的全局配置和性能优化及日志管理.assets/image-20240806171726507.png)

还可以带上user

突然发现子进程没有用haproxy跑啊

![image-20240806172616017](1.Haproxy的全局配置和性能优化及日志管理.assets/image-20240806172616017.png)

看看配置文件

![image-20240806172654342](1.Haproxy的全局配置和性能优化及日志管理.assets/image-20240806172654342.png)

果然👆

改改

![image-20240806172853764](1.Haproxy的全局配置和性能优化及日志管理.assets/image-20240806172853764.png)

重启服务后就好了👇

![image-20240806172841210](1.Haproxy的全局配置和性能优化及日志管理.assets/image-20240806172841210.png)



即使不手动绑定CPU，也是会自动分担的

![image-20240806173127835](1.Haproxy的全局配置和性能优化及日志管理.assets/image-20240806173127835.png)

就是效率肯定没有绑过去稳定吧，因为要利用L1和L2 缓存还是要绑的，否则CPU一旦飘走就无法利用之前那个CPU的1级和2级的缓存了。



### 奇葩👇我只能称之为未知渲染

![image-20240806173428146](1.Haproxy的全局配置和性能优化及日志管理.assets/image-20240806173428146.png)

没用的，grep不出来，lscpu |tee >> xxx ，标题内容也会丢掉的。

lscpu |awk '{print $0}'

一样看不到标题，分析....肯定有其他程序参与进来了，lscpu的输出一定是经过了其他处理工序了，



做个压力测试观察下

```bash
while true;do ps axo user,pid,cmd,psr -L |grep haproxy |grep -v color;echo ;sleep 1;done

for i in {1..10};do ps axo user,pid,cmd,psr -L |grep haproxy |grep -v color ;echo ;sleep 1;done

```

![image-20240806175803583](1.Haproxy的全局配置和性能优化及日志管理.assets/image-20240806175803583.png)



![image-20240806180705600](1.Haproxy的全局配置和性能优化及日志管理.assets/image-20240806180705600.png)



ab 压力测试 如果不绑cpu就会飘的

![image-20240806181142273](1.Haproxy的全局配置和性能优化及日志管理.assets/image-20240806181142273.png)

L1 L2缓存利用不上了基本上，绑一下就不会飘了



有个疑问，pstree -p看到线程好像少一个，不对，就是2个，ps axo -L看到的一个主进程，然后一个pid子进程下的三个线程？对不上啊。

![image-20240806181724283](1.Haproxy的全局配置和性能优化及日志管理.assets/image-20240806181724283.png)

权威点的查看进程ID下的线程👇可见就是3个,pstree -p看的竟然不全啊--不是不全就是少一个，估计算到进程头上去了。

![image-20240806183247507](1.Haproxy的全局配置和性能优化及日志管理.assets/image-20240806183247507.png)





